# operate_model.py
import inspect
import torch
from tqdm import tqdm
from scipy.stats import spearmanr
import matplotlib.pyplot as plt
from IPython.display import clear_output
import numpy as np

def get_model_inputs(model, print_sig=True):
    sig = inspect.signature(model.forward)
    if print_sig:
        print(f"Model forward signature: {sig}")
    return sig

    
def make_input_to_device(model, batch, device, label_key="label", need_label=True):
    """
    æ ¹æ“š model.forward çš„åƒæ•¸åˆ—è¡¨ï¼Œè‡ªå‹•å¾ batch ä¸­æå–è¼¸å…¥ï¼Œ
    ä¸¦æ¬ç§»åˆ°æŒ‡å®š deviceã€‚å¦‚æœåƒæ•¸ label_key æœ‰è¨­å®šï¼Œå‰‡ä¹Ÿæœƒå˜—è©¦æå–è©² key çš„è³‡æ–™ã€‚
    
    è‹¥åœ¨ batch ä¸­æ‰¾ä¸åˆ° label_key çš„è³‡æ–™ï¼Œå‰‡æ‹‹å‡º KeyErrorï¼Œ
    æç¤ºã€Œä½ çš„ dataset è£¡é¢æ²’æœ‰ labelï¼Œæˆ–æ˜¯ä½ è¦è‡ªå·±æ›´æ”¹æˆä½ é æ¸¬çš„æ±è¥¿ã€ã€‚
    """
    # å–å¾— model.forward çš„åƒæ•¸ç°½åï¼ˆä¸åŒ…å« selfï¼‰
    sig = get_model_inputs(model, print_sig=False)
    # å„²å­˜è¦å‚³çµ¦ forward çš„åƒæ•¸
    inputs = {}
    for name, _ in sig.parameters.items():
        if name == 'self':
            continue

        if name in batch:
            inputs[name] = batch[name].to(device)
        else:
            raise KeyError(f"Model éœ€è¦ {sig}. Batch ä¸­æ‰¾ä¸åˆ°å°æ‡‰ '{name}' çš„è³‡æ–™ï¼Œè«‹ç¢ºèª dataloader çš„è¼¸å‡ºéµèˆ‡ model.forward åƒæ•¸åç¨±ä¸€è‡´ã€‚")
    
    # å° label_key ä½œç‰¹åˆ¥è™•ç†ï¼šè‹¥ label_key å·²å®šç¾©ä½†ä¸åœ¨ inputs ä¸­
    if need_label:
        if label_key in batch:
            label = batch[label_key].to(device)
        else:
            raise KeyError(f"ä½ çš„ dataset è£¡é¢æ²’æœ‰ '{label_key}' è³‡æ–™ï¼Œæˆ–æ˜¯ä½ è¦è‡ªå·±æ›´æ”¹æˆä½ é æ¸¬çš„æ±è¥¿ã€‚")
    else:
        label = None
    return inputs, label

def train_one_epoch(model, dataloader, optimizer, loss_fn, device, **kwargs):
    model.train()
    total_loss = 0
    all_preds, all_targets = [], []
    pbar = tqdm(dataloader, desc="Training", leave=False)
    
    for batch in pbar:
        inputs, label = make_input_to_device(model, batch, device)
        optimizer.zero_grad()
        out = model(**inputs)
        loss = loss_fn(out, label)
        loss.backward()
        optimizer.step()
        
        batch_size = label.size(0)
        total_loss += loss.item() * batch_size
        
        # å„²å­˜æ¯å€‹ batch çš„é æ¸¬èˆ‡çœŸå¯¦å€¼ï¼Œç”¨æ–¼æœ€å¾Œè¨ˆç®— Spearman ç›¸é—œ
        all_preds.append(out.cpu())
        all_targets.append(label.cpu())
        
        avg_loss = total_loss / ((pbar.n + 1) * dataloader.batch_size)
        pbar.set_postfix(loss=loss.item(), avg=avg_loss)
    
    # åˆä½µæ‰€æœ‰ batch çš„é æ¸¬èˆ‡æ¨™ç±¤
    all_preds = torch.cat(all_preds).detach().numpy()
    all_targets = torch.cat(all_targets).detach().numpy()
    
    # è¨ˆç®—æ¯å€‹ cell type çš„ Spearman ç›¸é—œï¼Œä¸¦æ±‚å¹³å‡
    scores = [spearmanr(all_preds[:, i], all_targets[:, i])[0] for i in range(all_preds.shape[1])]
    spearman_avg = np.nanmean(scores)
    
    avg_epoch_loss = total_loss / len(dataloader.dataset)
    return avg_epoch_loss, spearman_avg

from scipy.stats import spearmanr
import numpy as np
from tqdm import tqdm
import torch

def evaluate(model, dataloader, loss_fn, device, **kwargs):
    model.eval()
    total_loss = 0
    preds, targets = [], []
    total_mse = torch.zeros(35).to(device)  # ğŸ‘‰ å‡è¨­ 35 å€‹ cell types
    n_samples = 0

    pbar = tqdm(dataloader, desc="Evaluating", leave=False)
    
    with torch.no_grad():
        for batch in pbar:
            inputs, label = make_input_to_device(model, batch, device)
            out = model(**inputs)
            loss = loss_fn(out, label)
            batch_size = label.size(0)
            total_loss += loss.item() * batch_size
            preds.append(out.cpu())
            targets.append(label.cpu())

            # ğŸ‘‰ åŠ ç¸½æ¯å€‹ cell type çš„ MSE
            loss_per_cell = ((out - label) ** 2).sum(dim=0)  # (35,)
            total_mse += loss_per_cell
            n_samples += batch_size

            pbar.set_postfix(loss=loss.item())

    preds = torch.cat(preds).numpy()
    targets = torch.cat(targets).numpy()

    # ğŸ‘‰ Per-cell-type average MSE
    mse_per_cell = (total_mse / n_samples).cpu().numpy()

    # ğŸ‘‰ Spearman per cell
    spearman_per_cell = [spearmanr(preds[:, i], targets[:, i])[0] for i in range(preds.shape[1])]
    spearman_avg = np.nanmean(spearman_per_cell)
    
    return total_loss / n_samples, spearman_avg, mse_per_cell, spearman_per_cell


def predict(model, dataloader, device, **kwargs):
    model.eval()
    all_preds = []
    
    with torch.no_grad():
        for batch in dataloader:
            # åŒæ¨£åˆ©ç”¨ get_model_inputs æå–è¼¸å…¥
            inputs, _ = make_input_to_device(model, batch, device, need_label=False)
            out = model(**inputs)
            all_preds.append(out.cpu())

    
    return torch.cat(all_preds).numpy()

class EarlyStopping:
    def __init__(self, patience=10, verbose=True):
        self.patience = patience
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.verbose = verbose

    def __call__(self, val_loss):
        if self.best_score is None or val_loss < self.best_score:
            self.best_score = val_loss
            self.counter = 0
        else:
            self.counter += 1
            if self.verbose:
                print(f"EarlyStopping counter: {self.counter}/{self.patience}")
            if self.counter >= self.patience:
                self.early_stop = True



def plot_losses(train_losses, val_losses, ax=None, title="Training vs Validation Loss"):
    """
    ç¹ªè£½ train/validation loss æ›²ç·š
    :param train_losses: list æˆ– arrayï¼Œè¨“ç·´ loss æ•¸å€¼
    :param val_losses: list æˆ– arrayï¼Œé©—è­‰ loss æ•¸å€¼
    :param ax: (optional) å‚³å…¥ matplotlib Axes ç‰©ä»¶ï¼Œå¦‚æœæ²’æœ‰æä¾›ï¼Œå‰‡è‡ªè¡Œå‰µå»ºä¸€å€‹åœ–è¡¨
    :param title: (string) åœ–è¡¨æ¨™é¡Œ
    """
    # å¦‚æœæ²’æœ‰ axï¼Œå‰‡æ–°å»ºç«‹ä¸€å€‹ figure èˆ‡ axï¼Œä¸¦ç”¨ clear_output ä»¥é¿å…é‡ç–Š
    if ax is None:
        clear_output(wait=True)
        fig, ax = plt.subplots(figsize=(8, 4))
    
    ax.plot(train_losses, label="Train Loss", marker='o')
    ax.plot(val_losses, label="Val Loss", marker='o')
    ax.set_xlabel("Epoch")
    ax.set_ylabel("Loss")
    ax.legend()
    ax.grid(True)
    ax.set_title(title)
# æ”¶é›†è³‡æ–™
def plot_per_cell_metrics(mse_vals, spearman_vals, cell_names=None, top_k=5, ax_mse=None, ax_spearman=None):
    """
    ç¹ªè£½æ¯å€‹ cell type çš„ MSE å’Œ Spearman æŸ±ç‹€åœ–ã€‚
    å¯æŒ‡å®šå…©å€‹ axesï¼Œç”¨æ–¼è‡ªè¨‚æ’ç‰ˆï¼ˆå’Œ plot_losses å°é½Šï¼‰ã€‚

    Params:
        mse_vals: array-like, æ¯å€‹ cell type çš„ MSE
        spearman_vals: array-like, æ¯å€‹ cell type çš„ Spearman
        cell_names: list of str, cell type åç¨±ï¼ˆé è¨­ç‚º C1 ~ C35ï¼‰
        top_k: int, è¦æ¨™è¨˜çš„æœ€ä½³/æœ€å·®é …ç›®æ•¸é‡
        ax_mse: matplotlib Axesï¼Œç”¨ä¾†ç•« MSE åœ–
        ax_spearman: matplotlib Axesï¼Œç”¨ä¾†ç•« Spearman åœ–
    """
    if cell_names is None:
        cell_names = [f"C{i+1}" for i in range(len(mse_vals))]

    sorted_idx_mse = np.argsort(mse_vals)
    sorted_idx_spearman = np.argsort(spearman_vals)

    if ax_mse is None or ax_spearman is None:
        fig, (ax_mse, ax_spearman) = plt.subplots(1, 2, figsize=(14, 4))

    # Left: MSE per gene
    ax_mse.clear()
    ax_mse.bar(cell_names, mse_vals, color='skyblue')
    ax_mse.set_title("Per-cell MSE")
    ax_mse.tick_params(axis='x', rotation=45)
    for i in sorted_idx_mse[:top_k]:
        ax_mse.text(i, mse_vals[i] + 0.01, "â†“", ha='center', color='red')
    for i in sorted_idx_mse[-top_k:]:
        ax_mse.text(i, mse_vals[i] + 0.01, "â†‘", ha='center', color='green')

    # Right: Spearman per gene
    ax_spearman.clear()
    ax_spearman.bar(cell_names, spearman_vals, color='orange')
    ax_spearman.set_title("Per-cell Spearman")
    ax_spearman.tick_params(axis='x', rotation=45)
    for i in sorted_idx_spearman[:top_k]:
        ax_spearman.text(i, spearman_vals[i] + 0.01, "â†“", ha='center', color='red')
    for i in sorted_idx_spearman[-top_k:]:
        ax_spearman.text(i, spearman_vals[i] + 0.01, "â†‘", ha='center', color='green')

    if ax_mse is None or ax_spearman is None:
        plt.tight_layout()
        plt.show()



__all__ = [
    "get_model_inputs",
    "train_one_epoch",
    "evaluate",
    "predict",
    "EarlyStopping",
    "plot_losses"
]
