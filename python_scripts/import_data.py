import torch
from torch.utils.data import Dataset
from .operate_model import get_model_inputs
from torchvision import transforms
from PIL import Image
import torch
import numpy as np

def preprocess_data(data, image_keys, transform):
    """
    å°æŒ‡å®šçš„ dataï¼ˆå­—å…¸ï¼‰ä¸­ image_keys çš„æ¬„ä½ä½¿ç”¨ transform åšé è™•ç†ï¼Œ
    è‹¥æ¬„ä½ä¸­çš„æ¯ç­†è³‡æ–™ç‚ºå–®ä¸€åœ–ç‰‡ï¼Œå‰‡é€ç­†è½‰æ›ï¼›
    è‹¥æ¯ç­†è³‡æ–™æœ¬èº«æ˜¯ listï¼ˆä¾‹å¦‚ subtiles æˆ– neighbor_tilesï¼‰ï¼Œå‰‡å°å…¶ä¸­æ¯å€‹åœ–ç‰‡åšè½‰æ›ã€‚

    åƒæ•¸:
      data: åŸå§‹è³‡æ–™å­—å…¸ï¼Œæ ¼å¼ç‚º {key: list([...])}ï¼Œ
            å…¶ä¸­ key å¯èƒ½åŒ…å«åœ–ç‰‡ï¼ˆä¾‹å¦‚ 'center_tile', 'subtiles', ...ï¼‰ã€‚
      image_keys: list æˆ– setï¼ŒæŒ‡å®šå“ªäº›æ¬„ä½æ˜¯åœ–ç‰‡è³‡æ–™ï¼Œéœ€è¦é è™•ç†ã€‚
      transform: torchvision è½‰æ›å‡½æ•¸ï¼Œä¾‹å¦‚ transforms.Compose([...])
      
    å›å‚³:
      processed_data: ä¸€å€‹æ–°çš„è³‡æ–™å­—å…¸ï¼Œå…¶ä¸­ image_keys ä¸­çš„æ¬„ä½å·²ç¶“ç¶“éè½‰æ›ï¼Œ
                      å…¶ä»–æ¬„ä½ä¿æŒä¸è®Šã€‚
    """
    processed_data = {}
    for key, value in data.items():
        if key in image_keys:
            # æª¢æŸ¥è©²æ¬„ä½çš„ç¬¬ä¸€ç­†è³‡æ–™æ˜¯å¦ç‚º list
            if isinstance(value[0], list):
                # å°æ¯ä¸€ç­†è³‡æ–™ä¸­çš„æ¯å¼µåœ–ç‰‡åšè™•ç†
                processed_data[key] = [
                    [transform(img) for img in sublist] for sublist in value
                ]
            else:
                # å–®ä¸€åœ–ç‰‡é€ç­†è™•ç†
                processed_data[key] = [transform(img) for img in value]
        else:
            # éåœ–ç‰‡æ¬„ä½ä¿æŒåŸæ¨£
            processed_data[key] = value
    return processed_data

# ===========================
# ç¯„ä¾‹ä½¿ç”¨
# ===========================
if __name__ == "__main__":
    # å®šç¾©è½‰æ›æµç¨‹ï¼Œåªé‡å°åœ–ç‰‡ä½¿ç”¨
    my_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)
    ])

    # å‡è¨­åŸå§‹åœ–ç‰‡ä½¿ç”¨ PIL.Image
    dummy_img = Image.new("RGB", (64, 64))  # å»ºç«‹ä¸€å€‹ 64x64 çš„ç©ºç™½ RGB åœ–ç‰‡

    num_samples = 100
    original_data = {
        'center_tile': [dummy_img for _ in range(num_samples)],
        'subtiles': [[dummy_img for _ in range(9)] for _ in range(num_samples)],
        'neighbor_tiles': [[dummy_img for _ in range(8)] for _ in range(num_samples)],
        'coords': [[0.5, 0.5] for _ in range(num_samples)],
        'label': [torch.randn(35, dtype=torch.float32) for _ in range(num_samples)]
    }

    image_keys = ['center_tile', 'subtiles', 'neighbor_tiles']

    # å°æŒ‡å®šçš„åœ–ç‰‡æ¬„ä½åšé è™•ç†
    processed_data = preprocess_data(original_data, image_keys, my_transform)

    # æ¥ä¸‹ä¾†ä½ å¯ä»¥æŠŠ processed_data å‚³å…¥ ValidatedDatasetï¼Œtransform é¸ identity
    # ä¾‹å¦‚ï¼š
    # dataset = ValidatedDataset(
    #    data_dict=processed_data,
    #    model=DummyModel(),      # ä½ çš„æ¨¡å‹
    #    image_keys=image_keys,
    #    transform=lambda x: x,   # identity transformï¼Œå› ç‚ºåœ–ç‰‡å·²é è™•ç†
    #    print_sig=True
    # )



import torch
from torch.utils.data import Dataset
import inspect
import numpy as np

def convert_item(item, is_image=False):
    """
    å°‡ä»»æ„ list / numpy.ndarray / Python scalar è½‰æˆ torch.Tensorã€‚
    å¦‚æœ is_image=Trueï¼Œä¸¦ä¸” item æ˜¯ ndarrayï¼Œå°±åœ¨ numpy ç«¯åš HÃ—WÃ—3 â†’ 3Ã—HÃ—W çš„è½‰ç½®ï¼Œ
    ç„¶å¾Œç›´æ¥è½‰æˆ Tensorï¼›å…¶é¤˜æƒ…æ³éƒ½èµ°åˆ°éæ­¸æŠŠç´” Python çµæ§‹è®Šæˆ Tensorã€‚
    """
    # 1) å¦‚æœæ˜¯å½±åƒçš„ numpy arrayï¼Œç›´æ¥åœ¨ numpy ç«¯åš channel-last â†’ channel-first
    if is_image and isinstance(item, np.ndarray):
        arr = item.astype(np.float32)
        if arr.ndim == 3 and arr.shape[2] == 3:
            # [H, W, 3] â†’ [3, H, W]
            arr = arr.transpose(2, 0, 1)
        elif arr.ndim == 4 and arr.shape[-1] == 3:
            # [B, H, W, 3] â†’ [B, 3, H, W]
            arr = arr.transpose(0, 3, 1, 2)
        return torch.from_numpy(arr)

    # 2) æ‰€æœ‰å…¶ä»– numpy arrayï¼Œå…ˆé™æˆç´” Python list
    if isinstance(item, np.ndarray):
        try:
            item = item.tolist()
        except Exception:
            # è‹¥ tolist() å¤±æ•—ï¼Œå…ˆå¼·åˆ¶æˆ float32 å†é™ list
            item = np.asarray(item, dtype=np.float32).tolist()

    # 3) å¦‚æœæ˜¯ listï¼Œéæ­¸ convert ç„¶å¾Œ stack
    if isinstance(item, list):
        converted = [convert_item(elem, is_image=is_image) for elem in item]
        try:
            return torch.stack(converted)
        except Exception:
            raise ValueError(f"è½‰æ›åˆ—è¡¨ä¸­çš„å…ƒç´ å¤±æ•—ï¼Œåˆ—è¡¨å…§å®¹: {item}")

    # 4) å¦‚æœå·²ç¶“æ˜¯ Tensorï¼Œç›´æ¥è¿”å›
    if isinstance(item, torch.Tensor):
        return item

    # 5) å‰©ä¸‹çš„éƒ½æ˜¯ Python æ¨™é‡ï¼ˆint/float/...ï¼‰ï¼Œç›´æ¥ç”¨ torch.tensor()
    try:
        return torch.tensor(item)
    except Exception:
        raise ValueError(f"ç„¡æ³•è½‰æ›è³‡æ–™ç‚º tensorï¼Œè¼¸å…¥è³‡æ–™: {item}")


class importDataset(Dataset):
    def __init__(self, data_dict, model, image_keys=None, transform=None, print_sig=False):
        self.data = data_dict
        self.image_keys = set(image_keys) if image_keys is not None else set()
        self.transform = transform if transform is not None else lambda x: x
        self.forward_keys = list(get_model_inputs(model, print_sig=print_sig).parameters.keys())

        expected_length = None
        for key, value in self.data.items():
            if expected_length is None:
                expected_length = len(value)
            if len(value) != expected_length:
                raise ValueError(f"è³‡æ–™æ¬„ä½ '{key}' çš„é•·åº¦ ({len(value)}) èˆ‡é æœŸ ({expected_length}) ä¸ä¸€è‡´ã€‚")

        for key in self.forward_keys:
            if key not in self.data:
                raise ValueError(f"data_dict ç¼ºå°‘æ¨¡å‹ forward æ‰€éœ€æ¬„ä½: '{key}'ã€‚ç›®å‰å¯ç”¨çš„æ¬„ä½: {list(self.data.keys())}")
        if "label" not in self.data:
            raise ValueError(f"data_dict å¿…é ˆåŒ…å« 'label' æ¬„ä½ã€‚å¯ç”¨çš„æ¬„ä½: {list(self.data.keys())}")
        if "source_idx" not in self.data:
            raise ValueError("data_dict å¿…é ˆåŒ…å« 'source_idx' æ¬„ä½ï¼Œç”¨æ–¼ trace åŸå§‹é †åºå°æ‡‰ã€‚")
        if "position" not in self.data:
            raise ValueError("data_dict å¿…é ˆåŒ…å« 'position' æ¬„ä½ï¼Œç”¨æ–¼ trace åŸå§‹é †åºå°æ‡‰ã€‚")
    def __len__(self):
        return len(next(iter(self.data.values())))

    def __getitem__(self, idx):
        sample = {}
        for key in self.forward_keys:
            value = self.data[key][idx]
            value = self.transform(value)
            value = convert_item(value, is_image=(key in self.image_keys))
            if isinstance(value, torch.Tensor):
                value = value.float()
            sample[key] = value

        label = self.transform(self.data["label"][idx])
        label = convert_item(label, is_image=False)
        if isinstance(label, torch.Tensor):
            label = label.float()
        sample["label"] = label

        # åŠ å…¥ source_idx
        source_idx = self.data["source_idx"][idx]
        sample["source_idx"] = torch.tensor(source_idx, dtype=torch.long)
        # åŠ å…¥ position ï¼ˆå‡è®¾ data_dict ä¸­ 'position' æ˜¯ (x, y) æˆ– [x, y]ï¼‰
        pos = self.data["position"][idx]
        sample["position"] = torch.tensor(pos, dtype=torch.float)
        return sample
    def check_item(self, idx=0, num_lines=5):
        expected_keys = self.forward_keys + ['label', 'source_idx', 'position']
        sample = self[idx]
        print(f"ğŸ” Checking dataset sample: {idx}")
        for key in expected_keys:
            if key not in sample:
                print(f"âŒ è³‡æ–™ä¸­ç¼ºå°‘ key: {key}")
                continue
            tensor = sample[key]
            if isinstance(tensor, torch.Tensor):
                try:
                    shape = tensor.shape
                except Exception:
                    shape = "N/A"
                dtype = tensor.dtype if hasattr(tensor, "dtype") else "N/A"
                output_str = f"ğŸ“ {key} shape: {shape} | dtype: {dtype}"
                if tensor.numel() > 0:
                    try:
                        tensor_float = tensor.float()
                        mn = tensor_float.min().item()
                        mx = tensor_float.max().item()
                        mean = tensor_float.mean().item()
                        std = tensor_float.std().item()
                        output_str += f" | min: {mn:.3f}, max: {mx:.3f}, mean: {mean:.3f}, std: {std:.3f}"
                    except Exception:
                        output_str += " | ç„¡æ³•è¨ˆç®—çµ±è¨ˆæ•¸æ“š"
                print(output_str)
                if key not in self.image_keys:
                    if tensor.ndim == 0:
                        print(f"--- {key} è³‡æ–™ç‚ºç´”é‡:", tensor)
                    elif tensor.ndim == 1:
                        print(f"--- {key} head (å‰ {num_lines} å€‹å…ƒç´ ):")
                        print(tensor[:num_lines])
                    else:
                        print(f"--- {key} head (å‰ {num_lines} åˆ—):")
                        print(tensor[:num_lines])
            else:
                # å¦‚æœ position å­˜çš„æ˜¯ list/tuple/etcï¼Œä¹Ÿä¼šèµ°è¿™é‡Œ
                print(f"ğŸ“ {key} (é tensor è³‡æ–™):", tensor)
        print("âœ… All checks passed!")



import os
import torch
import random

def load_all_tile_data(folder_path,
                       model,
                       fraction: float = 1.0,
                       shuffle : bool = False):
    """
    å›å‚³ dictï¼Œå…¶ä¸­åŒ…å«ï¼š
        - Model forward() éœ€è¦çš„æ¬„ä½
        - 'label'
        - 'slide_idx'    â† for GroupKFold
        - 'source_idx'   â† å¾ .pt æª”æ¡ˆå…§éƒ¨è®€å–
    """
    sig            = get_model_inputs(model, print_sig=False)
    fwd_keys       = list(sig.parameters.keys())
    required_keys  = set(fwd_keys + ['label', 'slide_idx', 'position'])   # include slide_idx
    keep_meta_keys = required_keys.union({'source_idx'})

    pt_files = sorted(f for f in os.listdir(folder_path) if f.endswith('.pt'))
    N        = len(pt_files)
    keep_n   = max(1, int(N * fraction))
    pt_files = random.sample(pt_files, keep_n) if shuffle else pt_files[-keep_n:]

    data_dict = {k: [] for k in keep_meta_keys}

    for fname in pt_files:
        fpath = os.path.join(folder_path, fname)
        d = torch.load(fpath, map_location='cpu')

        # âœ… å„ªå…ˆå¾æª”æ¡ˆå…§éƒ¨è®€å– source_idx
        if 'source_idx' in d:
            data_dict['source_idx'].append(d['source_idx'])
        else:
            data_dict['source_idx'].append(fname)  # optional fallback

        # â‹ è£œå…¥å…¶ä»–æ¬„ä½
        for k in required_keys:
            data_dict[k].append(d.get(k, None))

    return data_dict




def load_node_feature_data(pt_path: str, model, num_cells: int = 35) -> dict:
    """
    æ ¹æ“š model.forward çš„åƒæ•¸ï¼Œè‡ªå‹•è¼‰å…¥ .pt æª”æ¡ˆä¸­æ‰€éœ€æ¬„ä½ï¼Œ
    ä¸¦è‡ªå‹•è£œ 'label'ï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰ç‚º 0 tensorã€‚
    æ”¯æ´è‡ªå‹•è®€å– 'position' å’Œ 'source_idx' æ¬„ä½ï¼ˆè‹¥ forward æœ‰ç”¨åˆ°ï¼‰ã€‚

    è¿”å›ï¼š
      dict: key å°æ‡‰ forward çš„åƒæ•¸å + label, position, source_idxï¼ˆå¦‚éœ€ï¼‰
    """
    import torch
    import inspect

    raw = torch.load(pt_path, map_location="cpu")

    # æ¨¡å‹éœ€è¦å“ªäº›åƒæ•¸ï¼Ÿ
    sig = inspect.signature(model.forward)
    param_names = [p for p in sig.parameters if p != "self"]
    param_names.append('source_idx')
    param_names.append('position')

    out = {}
    for name in param_names:
        # a) ç›´æ¥åŒå
        if name in raw:
            out[name] = raw[name]
            continue
        # b) name + 's'ï¼ˆpluralï¼‰
        if name + "s" in raw:
            out[name] = raw[name + "s"]
            continue
        # c) æ¨¡ç³ŠåŒ¹é…
        cands = [k for k in raw if name in k or k in name]
        if len(cands) == 1:
            out[name] = raw[cands[0]]
            continue
        raise KeyError(f"âŒ ç„¡æ³•æ‰¾åˆ° '{name}'ï¼Œraw keys: {list(raw.keys())}")

    # æ¨æ–· batch å¤§å°
    dataset_size = None
    for v in out.values():
        if hasattr(v, "__len__"):
            dataset_size = len(v)
            print(f"âš ï¸ å¾ '{type(v)}' æ¨æ–·æ¨£æœ¬æ•¸é‡: {dataset_size}")
            break
    if dataset_size is None:
        raise RuntimeError("âŒ ç„¡æ³•æ¨æ–·æ¨£æœ¬æ•¸é‡ã€‚")

    # é è¨­è£œä¸Š label
    out["label"] = raw.get("label", torch.zeros((dataset_size, num_cells), dtype=torch.float32))

    # âœ… é¡å¤–è£œä¸Š position å’Œ source_idxï¼ˆå¦‚æœ‰ï¼‰
    for meta_key in ["position", "source_idx"]:
        if meta_key in raw:
            out[meta_key] = raw[meta_key]

    return out

# ==============================================
# ç¯„ä¾‹ä½¿ç”¨
# ==============================================
if __name__ == "__main__":
    # å®šç¾©ä¸€å€‹æ¨¡å‹ï¼Œå‡è¨­ forward æ‰€éœ€åƒæ•¸ç‚º center_tile, subtiles, neighbor_tiles, coords
    class DummyModel:
        def forward(self, center_tile, subtiles, neighbor_tiles, coords):
            pass

    model = DummyModel()

    # æ¨¡æ“¬ 100 ç­†è³‡æ–™ï¼Œæ¯ç­†è³‡æ–™çš„åœ–ç‰‡åŸå§‹æ ¼å¼ç‚º channel-first (3, H, W)
    num_samples = 100
    dummy_center = [torch.randn(3, 64, 64) for _ in range(num_samples)]
    dummy_subtiles = [[torch.randn(3, 32, 32) for _ in range(9)] for _ in range(num_samples)]
    dummy_neighbor = [[torch.randn(3, 64, 64) for _ in range(8)] for _ in range(num_samples)]
    dummy_coords = [[0.5, 0.5] for _ in range(num_samples)]
    dummy_label = [torch.randn(35, dtype=torch.float32) for _ in range(num_samples)]  # å‡è¨­ label é•·åº¦ç‚º 35

    # å»ºç«‹è³‡æ–™å­—å…¸ï¼Œkey å‘½åå¿…é ˆèˆ‡ DummyModel.forward ç›¸ç¬¦ï¼Œå†åŠ ä¸Š label
    data = {
        'center_tile': dummy_center,
        'subtiles': dummy_subtiles,
        'neighbor_tiles': dummy_neighbor,
        'coords': dummy_coords,
        'label': dummy_label
    }

    # æŒ‡å®šå“ªäº›æ¬„ä½ç‚ºåœ–ç‰‡è³‡æ–™
    image_keys = ['center_tile', 'subtiles', 'neighbor_tiles']

    # å»ºç«‹ ValidatedDataset
    dataset = ValidatedDataset(
        data_dict=data,
        model=model,
        image_keys=image_keys,
        transform=lambda x: x,  # identity transform
        print_sig=True
    )

    # å–å¾—ç¬¬ä¸€ç­†è³‡æ–™
    sample = dataset[0]
    # å°å‡ºçµ„åˆè³‡æ–™çš„é †åºï¼Œå…¶é †åºç‚º (center_tile, subtiles, neighbor_tiles, coords, label)
    print("å–å¾—çš„ sample è³‡æ–™é †åºï¼š")
    print("center_tile shape:", sample[0].shape)
    print("subtiles shape:", sample[1].shape)
    print("neighbor_tiles shape:", sample[2].shape)
    print("coords:", sample[3])
    print("label shape:", sample[4].shape)

    # æª¢æŸ¥ç¬¬ä¸€ç­†è³‡æ–™
    dataset.check_item(idx=0)
    
    
    
