import torch
from torch.utils.data import Dataset
from .operate_model import get_model_inputs
from torchvision import transforms
from PIL import Image
import torch
import numpy as np

def preprocess_data(data, image_keys, transform):
    """
    å°æŒ‡å®šçš„ dataï¼ˆå­—å…¸ï¼‰ä¸­ image_keys çš„æ¬„ä½ä½¿ç”¨ transform åšé è™•ç†ï¼Œ
    è‹¥æ¬„ä½ä¸­çš„æ¯ç­†è³‡æ–™ç‚ºå–®ä¸€åœ–ç‰‡ï¼Œå‰‡é€ç­†è½‰æ›ï¼›
    è‹¥æ¯ç­†è³‡æ–™æœ¬èº«æ˜¯ listï¼ˆä¾‹å¦‚ subtiles æˆ– neighbor_tilesï¼‰ï¼Œå‰‡å°å…¶ä¸­æ¯å€‹åœ–ç‰‡åšè½‰æ›ã€‚

    åƒæ•¸:
      data: åŸå§‹è³‡æ–™å­—å…¸ï¼Œæ ¼å¼ç‚º {key: list([...])}ï¼Œ
            å…¶ä¸­ key å¯èƒ½åŒ…å«åœ–ç‰‡ï¼ˆä¾‹å¦‚ 'center_tile', 'subtiles', ...ï¼‰ã€‚
      image_keys: list æˆ– setï¼ŒæŒ‡å®šå“ªäº›æ¬„ä½æ˜¯åœ–ç‰‡è³‡æ–™ï¼Œéœ€è¦é è™•ç†ã€‚
      transform: torchvision è½‰æ›å‡½æ•¸ï¼Œä¾‹å¦‚ transforms.Compose([...])
      
    å›å‚³:
      processed_data: ä¸€å€‹æ–°çš„è³‡æ–™å­—å…¸ï¼Œå…¶ä¸­ image_keys ä¸­çš„æ¬„ä½å·²ç¶“ç¶“éè½‰æ›ï¼Œ
                      å…¶ä»–æ¬„ä½ä¿æŒä¸è®Šã€‚
    """
    processed_data = {}
    for key, value in data.items():
        if key in image_keys:
            # æª¢æŸ¥è©²æ¬„ä½çš„ç¬¬ä¸€ç­†è³‡æ–™æ˜¯å¦ç‚º list
            if isinstance(value[0], list):
                # å°æ¯ä¸€ç­†è³‡æ–™ä¸­çš„æ¯å¼µåœ–ç‰‡åšè™•ç†
                processed_data[key] = [
                    [transform(img) for img in sublist] for sublist in value
                ]
            else:
                # å–®ä¸€åœ–ç‰‡é€ç­†è™•ç†
                processed_data[key] = [transform(img) for img in value]
        else:
            # éåœ–ç‰‡æ¬„ä½ä¿æŒåŸæ¨£
            processed_data[key] = value
    return processed_data

# ===========================
# ç¯„ä¾‹ä½¿ç”¨
# ===========================
if __name__ == "__main__":
    # å®šç¾©è½‰æ›æµç¨‹ï¼Œåªé‡å°åœ–ç‰‡ä½¿ç”¨
    my_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)
    ])

    # å‡è¨­åŸå§‹åœ–ç‰‡ä½¿ç”¨ PIL.Image
    dummy_img = Image.new("RGB", (64, 64))  # å»ºç«‹ä¸€å€‹ 64x64 çš„ç©ºç™½ RGB åœ–ç‰‡

    num_samples = 100
    original_data = {
        'center_tile': [dummy_img for _ in range(num_samples)],
        'subtiles': [[dummy_img for _ in range(9)] for _ in range(num_samples)],
        'neighbor_tiles': [[dummy_img for _ in range(8)] for _ in range(num_samples)],
        'coords': [[0.5, 0.5] for _ in range(num_samples)],
        'label': [torch.randn(35, dtype=torch.float32) for _ in range(num_samples)]
    }

    image_keys = ['center_tile', 'subtiles', 'neighbor_tiles']

    # å°æŒ‡å®šçš„åœ–ç‰‡æ¬„ä½åšé è™•ç†
    processed_data = preprocess_data(original_data, image_keys, my_transform)

    # æ¥ä¸‹ä¾†ä½ å¯ä»¥æŠŠ processed_data å‚³å…¥ ValidatedDatasetï¼Œtransform é¸ identity
    # ä¾‹å¦‚ï¼š
    # dataset = ValidatedDataset(
    #    data_dict=processed_data,
    #    model=DummyModel(),      # ä½ çš„æ¨¡å‹
    #    image_keys=image_keys,
    #    transform=lambda x: x,   # identity transformï¼Œå› ç‚ºåœ–ç‰‡å·²é è™•ç†
    #    print_sig=True
    # )



import torch
from torch.utils.data import Dataset
import inspect
import numpy as np

def convert_item(item, is_image=False):
    """
    å°‡ä»»æ„ list / numpy.ndarray / Python scalar è½‰æˆ torch.Tensorã€‚
    å¦‚æœ is_image=Trueï¼Œä¸¦ä¸” item æ˜¯ ndarrayï¼Œå°±åœ¨ numpy ç«¯åš HÃ—WÃ—3 â†’ 3Ã—HÃ—W çš„è½‰ç½®ï¼Œ
    ç„¶å¾Œç›´æ¥è½‰æˆ Tensorï¼›å…¶é¤˜æƒ…æ³éƒ½èµ°åˆ°éæ­¸æŠŠç´” Python çµæ§‹è®Šæˆ Tensorã€‚
    """
    # 1) å¦‚æœæ˜¯å½±åƒçš„ numpy arrayï¼Œç›´æ¥åœ¨ numpy ç«¯åš channel-last â†’ channel-first
    if is_image and isinstance(item, np.ndarray):
        arr = item.astype(np.float32)
        if arr.ndim == 3 and arr.shape[2] == 3:
            # [H, W, 3] â†’ [3, H, W]
            arr = arr.transpose(2, 0, 1)
        elif arr.ndim == 4 and arr.shape[-1] == 3:
            # [B, H, W, 3] â†’ [B, 3, H, W]
            arr = arr.transpose(0, 3, 1, 2)
        return torch.from_numpy(arr)

    # 2) æ‰€æœ‰å…¶ä»– numpy arrayï¼Œå…ˆé™æˆç´” Python list
    if isinstance(item, np.ndarray):
        try:
            item = item.tolist()
        except Exception:
            # è‹¥ tolist() å¤±æ•—ï¼Œå…ˆå¼·åˆ¶æˆ float32 å†é™ list
            item = np.asarray(item, dtype=np.float32).tolist()

    # 3) å¦‚æœæ˜¯ listï¼Œéæ­¸ convert ç„¶å¾Œ stack
    if isinstance(item, list):
        converted = [convert_item(elem, is_image=is_image) for elem in item]
        try:
            return torch.stack(converted)
        except Exception:
            raise ValueError(f"è½‰æ›åˆ—è¡¨ä¸­çš„å…ƒç´ å¤±æ•—ï¼Œåˆ—è¡¨å…§å®¹: {item}")

    # 4) å¦‚æœå·²ç¶“æ˜¯ Tensorï¼Œç›´æ¥è¿”å›
    if isinstance(item, torch.Tensor):
        return item

    # 5) å‰©ä¸‹çš„éƒ½æ˜¯ Python æ¨™é‡ï¼ˆint/float/...ï¼‰ï¼Œç›´æ¥ç”¨ torch.tensor()
    try:
        return torch.tensor(item)
    except Exception:
        raise ValueError(f"ç„¡æ³•è½‰æ›è³‡æ–™ç‚º tensorï¼Œè¼¸å…¥è³‡æ–™: {item}")


class importDataset(Dataset):
    def __init__(self, data_dict, model, image_keys=None, transform=None, print_sig=False):
        """
        åƒæ•¸:
          data_dict: dictï¼Œæ¯å€‹ key å°æ‡‰ä¸€å€‹ listï¼Œå…¶ä¸­ list[i] è¡¨ç¤ºç¬¬ i ç­†è³‡æ–™çš„è©²æ¬„ä½å…§å®¹ã€‚
                     è³‡æ–™æ¬„ä½å¿…é ˆåŒ…å«æ¨¡å‹ forward æ‰€éœ€çš„åƒæ•¸åç¨±ï¼Œå¦å¤–é‚„å¿…é ˆæœ‰ "label" æ¬„ä½ã€‚
          model: æ¨¡å‹ç‰©ä»¶ï¼Œå°‡æ ¹æ“š model.forward çš„åƒæ•¸é †åºæ±ºå®šè¼¸å…¥çµ„åˆé †åºã€‚
          image_keys: list æˆ– setï¼Œæ¨™è¨˜å“ªäº›æ¬„ä½éœ€è¦è¦–ç‚ºåœ–ç‰‡è³‡æ–™ï¼Œè™•ç†æ™‚æœƒè½‰æ›ç‚º channel-last æ ¼å¼ã€‚
          transform: æ¯ç­†è³‡æ–™çš„è½‰æ›å‡½æ•¸ï¼Œè‹¥æœªæŒ‡å®šå‰‡ç‚º identity functionã€‚
          print_sig: æ˜¯å¦å°å‡ºæ¨¡å‹ forward å‡½å¼çš„ç°½åã€‚
        """
        self.data = data_dict
        self.image_keys = set(image_keys) if image_keys is not None else set()
        self.transform = transform if transform is not None else lambda x: x

        self.forward_keys = list(get_model_inputs(model, print_sig=print_sig).parameters.keys())

        # è³‡æ–™é•·åº¦æª¢æŸ¥ï¼šæ‰€æœ‰æ¬„ä½çš„ list é•·åº¦å¿…é ˆä¸€è‡´
        expected_length = None
        for key, value in self.data.items():
            if expected_length is None:
                expected_length = len(value)
            if len(value) != expected_length:
                raise ValueError(f"è³‡æ–™æ¬„ä½ '{key}' çš„é•·åº¦ ({len(value)}) èˆ‡é æœŸ ({expected_length}) ä¸ä¸€è‡´ã€‚")
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½ï¼šå¿…é ˆåŒ…å«æ¨¡å‹ forward æ‰€éœ€æ¬„ä½èˆ‡ 'label'
        for key in self.forward_keys:
            if key not in self.data:
                raise ValueError(f"data_dict ç¼ºå°‘æ¨¡å‹ forward æ‰€éœ€æ¬„ä½: '{key}'ã€‚ç›®å‰å¯ç”¨çš„æ¬„ä½: {list(self.data.keys())}")
        if "label" not in self.data:
            raise ValueError(f"data_dict å¿…é ˆåŒ…å« 'label' æ¬„ä½ã€‚å¯ç”¨çš„æ¬„ä½: {list(self.data.keys())}")

    def __len__(self):
        return len(next(iter(self.data.values())))

    def __getitem__(self, idx):
        sample = {}
        # ä¾ç…§æ¨¡å‹ forward çš„é †åºä¾æ¬¡å–å‡ºè³‡æ–™ä¸¦è™•ç†ï¼ˆä¿æŒ key åç¨±ä¸è®Šï¼‰
        for key in self.forward_keys:
            try:
                value = self.data[key][idx]
            except IndexError as e:
                raise IndexError(f"ç´¢å¼• {idx} è¶…å‡ºæ¬„ä½ '{key}' çš„è³‡æ–™ç¯„åœï¼Œå…±æœ‰ {len(self.data[key])} ç­†è³‡æ–™ã€‚") from e
            try:
                value = self.transform(value)
            except Exception as e:
                raise ValueError(f"è½‰æ›æ¬„ä½ '{key}' çš„è³‡æ–™æ™‚å‡ºéŒ¯ï¼Œè³‡æ–™: {value}") from e
            try:
                if key in self.image_keys:
                    value = convert_item(value, is_image=True)
                else:
                    value = convert_item(value, is_image=False)
            except Exception as e:
                raise ValueError(f"è½‰æ›æ¬„ä½ '{key}' çš„è³‡æ–™ç‚º tensor æ™‚å‡ºéŒ¯ï¼Œè³‡æ–™å…§å®¹: {value}") from e
            # è½‰æ›æˆ float32
            if isinstance(value, torch.Tensor):
                value = value.float()
            sample[key] = value
        
        # è™•ç† label
        try:
            label = self.data["label"][idx]
        except IndexError as e:
            raise IndexError(f"ç´¢å¼• {idx} è¶…å‡º 'label' æ¬„ä½çš„è³‡æ–™ç¯„åœï¼Œå…±æœ‰ {len(self.data['label'])} ç­†è³‡æ–™ã€‚") from e
        try:
            label = self.transform(label)
        except Exception as e:
            raise ValueError(f"è½‰æ› 'label' è³‡æ–™æ™‚å‡ºéŒ¯ï¼Œè³‡æ–™å…§å®¹: {label}") from e
        try:
            label = convert_item(label, is_image=False)
        except Exception as e:
            raise ValueError(f"è½‰æ› 'label' ç‚º tensor æ™‚å‡ºéŒ¯ï¼Œè³‡æ–™å…§å®¹: {label}") from e
        if isinstance(label, torch.Tensor):
            label = label.float()
        sample["label"] = label

        return sample

    def check_item(self, idx=0, num_lines=5):
        """
        æª¢æŸ¥ç¬¬ idx ç­†è³‡æ–™ä¸­æ¯å€‹æ¬„ä½çš„è©³ç´°è³‡è¨Šã€‚
        å°æ¯å€‹æ¬„ä½ï¼ˆä¾æ“š forward_keys åŠ ä¸Š 'label'ï¼‰å°å‡ºï¼š
          - shape èˆ‡ dtypeï¼Œ
          - å¦‚æœæ˜¯ tensorï¼Œå°å‡º min, max, mean, stdï¼ˆè¨ˆç®—æ™‚å¼·åˆ¶è½‰ç‚º float32ï¼‰ï¼Œ
          - å°æ–¼éåœ–ç‰‡è³‡æ–™ï¼Œå°å‡ºè©² tensor å‰ num_lines åˆ—/å…ƒç´ çš„å…§å®¹ã€‚
        """
        expected_keys = self.forward_keys + ['label']
        sample = self[idx]
        print(f"ğŸ” Checking dataset sample: {idx}")
        for key in expected_keys:
            if key not in sample:
                print(f"âŒ è³‡æ–™ä¸­ç¼ºå°‘ key: {key}")
                continue
            tensor = sample[key]
            if isinstance(tensor, torch.Tensor):
                try:
                    shape = tensor.shape
                except Exception:
                    shape = "N/A"
                dtype = tensor.dtype if hasattr(tensor, "dtype") else "N/A"
                output_str = f"ğŸ“ {key} shape: {shape} | dtype: {dtype}"
                if tensor.numel() > 0:
                    try:
                        # å°‡ tensor è½‰æˆ float32 è¨ˆç®—çµ±è¨ˆæ•¸æ“š
                        tensor_float = tensor.float()
                        mn = tensor_float.min().item()
                        mx = tensor_float.max().item()
                        mean = tensor_float.mean().item()
                        std = tensor_float.std().item()
                        output_str += f" | min: {mn:.3f}, max: {mx:.3f}, mean: {mean:.3f}, std: {std:.3f}"
                    except Exception:
                        output_str += " | ç„¡æ³•è¨ˆç®—çµ±è¨ˆæ•¸æ“š"
                print(output_str)
                # è‹¥éåœ–ç‰‡è³‡æ–™ï¼Œå°å‡ºå‰ num_lines åˆ—/å…ƒç´ 
                if key not in self.image_keys:
                    if tensor.ndim == 0:
                        print(f"--- {key} è³‡æ–™ç‚ºç´”é‡:", tensor)
                    elif tensor.ndim == 1:
                        print(f"--- {key} head (å‰ {num_lines} å€‹å…ƒç´ ):")
                        print(tensor[:num_lines])
                    else:
                        print(f"--- {key} head (å‰ {num_lines} åˆ—):")
                        print(tensor[:num_lines])
            else:
                print(f"ğŸ“ {key} (é tensor è³‡æ–™):", tensor)
        print("âœ… All checks passed!")


import os
import torch
import random

def load_all_tile_data(folder_path,
                       model,
                       fraction: float = 1.0,
                       shuffle : bool   = False):
    """
    å›å‚³ dictï¼Œå…¶ä¸­åŒ…å«
        - Model forward() éœ€è¦çš„æ¬„ä½
        - 'label'
        - 'slide_idx'    â† è®“ GroupKFold ç”¨
        - 'source_idx'   â† optionalï¼Œè¿½è¹¤æª”å
    """
    sig            = get_model_inputs(model, print_sig=False)
    fwd_keys       = list(sig.parameters.keys())
    required_keys  = set(fwd_keys + ['label', 'slide_idx'])   # â˜… æ–°å¢ slide_idx
    keep_meta_keys = required_keys.union({'source_idx'})

    pt_files = sorted(f for f in os.listdir(folder_path) if f.endswith('.pt'))
    N        = len(pt_files)
    keep_n   = max(1, int(N * fraction))
    pt_files = random.sample(pt_files, keep_n) if shuffle else pt_files[-keep_n:]

    data_dict = {k: [] for k in keep_meta_keys}
    for fname in pt_files:
        d = torch.load(os.path.join(folder_path, fname), map_location='cpu')

        # âŠ æª”åè¿½è¹¤
        data_dict['source_idx'].append(fname)

        # â‹ åªæŒ‘éœ€è¦çš„æ¬„ä½ï¼Œè‹¥ç¼ºå‰‡å¡« None
        for k in required_keys:
            data_dict[k].append(d.get(k, None))

    return data_dict


# ==============================================
# ç¯„ä¾‹ä½¿ç”¨
# ==============================================
if __name__ == "__main__":
    # å®šç¾©ä¸€å€‹æ¨¡å‹ï¼Œå‡è¨­ forward æ‰€éœ€åƒæ•¸ç‚º center_tile, subtiles, neighbor_tiles, coords
    class DummyModel:
        def forward(self, center_tile, subtiles, neighbor_tiles, coords):
            pass

    model = DummyModel()

    # æ¨¡æ“¬ 100 ç­†è³‡æ–™ï¼Œæ¯ç­†è³‡æ–™çš„åœ–ç‰‡åŸå§‹æ ¼å¼ç‚º channel-first (3, H, W)
    num_samples = 100
    dummy_center = [torch.randn(3, 64, 64) for _ in range(num_samples)]
    dummy_subtiles = [[torch.randn(3, 32, 32) for _ in range(9)] for _ in range(num_samples)]
    dummy_neighbor = [[torch.randn(3, 64, 64) for _ in range(8)] for _ in range(num_samples)]
    dummy_coords = [[0.5, 0.5] for _ in range(num_samples)]
    dummy_label = [torch.randn(35, dtype=torch.float32) for _ in range(num_samples)]  # å‡è¨­ label é•·åº¦ç‚º 35

    # å»ºç«‹è³‡æ–™å­—å…¸ï¼Œkey å‘½åå¿…é ˆèˆ‡ DummyModel.forward ç›¸ç¬¦ï¼Œå†åŠ ä¸Š label
    data = {
        'center_tile': dummy_center,
        'subtiles': dummy_subtiles,
        'neighbor_tiles': dummy_neighbor,
        'coords': dummy_coords,
        'label': dummy_label
    }

    # æŒ‡å®šå“ªäº›æ¬„ä½ç‚ºåœ–ç‰‡è³‡æ–™
    image_keys = ['center_tile', 'subtiles', 'neighbor_tiles']

    # å»ºç«‹ ValidatedDataset
    dataset = ValidatedDataset(
        data_dict=data,
        model=model,
        image_keys=image_keys,
        transform=lambda x: x,  # identity transform
        print_sig=True
    )

    # å–å¾—ç¬¬ä¸€ç­†è³‡æ–™
    sample = dataset[0]
    # å°å‡ºçµ„åˆè³‡æ–™çš„é †åºï¼Œå…¶é †åºç‚º (center_tile, subtiles, neighbor_tiles, coords, label)
    print("å–å¾—çš„ sample è³‡æ–™é †åºï¼š")
    print("center_tile shape:", sample[0].shape)
    print("subtiles shape:", sample[1].shape)
    print("neighbor_tiles shape:", sample[2].shape)
    print("coords:", sample[3])
    print("label shape:", sample[4].shape)

    # æª¢æŸ¥ç¬¬ä¸€ç­†è³‡æ–™
    dataset.check_item(idx=0)
    
    
    
