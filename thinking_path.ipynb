{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Search Studies\n",
    "\n",
    "- [Benchmarking the translational potential of spatial gene expression prediction from histology](https://www.nature.com/articles/s41467-025-56618-y)  \n",
    "- [DeepSpot: Leveraging Spatial Context for Enhanced Spatial Transcriptomics Prediction from H&E Images](https://www.medrxiv.org/content/10.1101/2025.02.09.25321567v1)  \n",
    "\n",
    "> These papers survey state-of-the-art techniques for predicting spatial gene expression from H&E histology images.\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "- https://www.kaggle.com/code/tarundirector/histology-eda-spotnet-visual-spatial-dl  \n",
    "- https://www.kaggle.com/code/dalloliogm/eda-exploring-cell-type-abundance  \n",
    "- https://www.kaggle.com/code/prajwaldongreonly-eda-you-need-to-understand-this-data  \n",
    "\n",
    "> Use these notebooks to visualize spot distributions, cell-type abundances, and other spatial features.\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Data Preprocessing\n",
    "\n",
    "## 3.1 Image Data  \n",
    "1. **Stain normalization**  (One of the most important step) \n",
    "   - Essential for reducing color variability across slides.  \n",
    "   - Sample patches from all images to compute stable normalization parameters.  \n",
    "2. **Background masking**  \n",
    "   - Grayscale: `gray = rgb2gray(image)`  \n",
    "   - Threshold: `mask = gray <= mean_threshold`  \n",
    "   - Closing: `closing(mask, disk(2))`  \n",
    "   - Fill holes: `remove_small_holes(..., area_threshold=5000)`  \n",
    "   - **Output:** clean binary tissue mask  \n",
    "\n",
    "## 3.2 Spot Data  \n",
    "1. **Expression ranking**  (One of the most important step) \n",
    "   - Replace raw counts with rank values. (I also check UMAP with them to see which combination or replacement would be better to let the ML to predict. In the end replace with rank us the most promising one.)\n",
    "2. **Spot realignment**  \n",
    "   - Minor effect if background spots are already filtered out.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Model Preparation\n",
    "\n",
    "## 4.1 Encoder\n",
    "\n",
    "### DeepTileEncoder  \n",
    "- **Input size:** `[B, 3, 78, 78]`  \n",
    "- **Purpose:** Processes the entire 78×78 tile (from spot coordinates).  \n",
    "- **Residual blocks:** Stacked `ResidualBlock`s (two 3×3 Conv + BN + SiLU; 1×1 Conv shortcut if needed)  \n",
    "- **Multi-scale pooling:**  \n",
    "  - Global: `AdaptiveAvgPool2d(1×1)` → `[B,256]`  \n",
    "  - Mid-scale: `AdaptiveAvgPool2d(3×3)` → `[B,256×3×3]`  \n",
    "- **MLP (3 layers):**  \n",
    "\n",
    "\n",
    "### SubtileEncoder  \n",
    "- **Input size:** `[B, 9, 3, 26, 26]`  \n",
    "- **Purpose:** Captures local details from 9 subtiles.  \n",
    "- **Residual blocks:** Applied after reshaping to `[B×9, 3, 26, 26]`  \n",
    "- **Multi-scale pooling (per patch):**  \n",
    "  - Global 1×1 → `[B×9,128]`  \n",
    "  - Mid 2×2 → `[B×9,128×2×2]`  \n",
    "  - Large 3×3 → `[B×9,128×3×3]`  \n",
    "- **Aggregation:**  \n",
    "  1. Reshape to `[B, 9, total_dim]`  \n",
    "  2. Average over 9 → `[B, total_dim]`  \n",
    "- **MLP (2 layers):**  \n",
    "\n",
    "\n",
    "### CenterSubtileEncoder  \n",
    "- **Input size:** `[B, 3, 26, 26]`  \n",
    "- **Purpose:** Focuses on the single central patch.  \n",
    "- **Structure:** Same as SubtileEncoder but only for the center.  \n",
    "- **Multi-scale pooling:** 1×1, 2×2, 3×3 → concatenate → Flatten  \n",
    "- **MLP (2 layers):** \n",
    "\n",
    "---\n",
    "\n",
    "## 4.2 Decoder\n",
    "\n",
    "1. **Concatenate:** `[tile_dim] + [subtile_dim] + [subtile_dim]` → `[B, tile_dim+2×subtile_dim]`  \n",
    "2. **Four-layer MLP:**  \n",
    "3. **Output:** Multi-task prediction vector of length `output_dim`, which is 35.\n",
    "\n",
    "**Loss function:** Mean Squared Error (MSE)\n",
    "\n",
    "---\n",
    "\n",
    "# 5. Training Strategy\n",
    "\n",
    "## 5.1 Leave-One-Out (LOO) Cross-Validation  \n",
    "- Six folds → six models.\n",
    "\n",
    "## 5.2 Model Stacking  \n",
    "1. Use each of the six models to predict on all samples → produce a dataframe of shape `(spots_n, 35 × 6)`.  \n",
    "2. Train a small MLP on this dataframe → final output `(spots_n, 35)`.  \n",
    "   - Learns to weight each fold’s prediction adaptively.\n",
    "\n",
    "---\n",
    "\n",
    "# Optimization Notes\n",
    "\n",
    "1. **Model structure:** Residual + multi-scale design proved most stable.  \n",
    "2. **Input size:** 78×78 tile + 9×26×26 subtiles + center 26×26 gave best results.  \n",
    "3. **Patch size choice:** Mean spot spacing ≈ 26 px, so 3×26 covers full receptive field. That's why I use 26*3 as the global vision for input and 26 as the local vesion.\n",
    "\n",
    "# Future Improvements\n",
    "\n",
    "- Diversify stacked models to increase ensemble variance.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatialhackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
