{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d6db04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b70981c-db23-4ea7-bd9c-dca6279d7e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <FB2FD416-6C4D-3621-B677-61F07C02A3C5> /opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/spatialhackathon/lib/python3.9/lib-dynload/../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/spatialhackathon/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13fdff3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_30582/2116005886.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_image_data = torch.load(\"../SML_train_dataset.pt\")\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_30582/2116005886.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  graph_data = torch.load(\"../train_graph_dataset.pt\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# ËºâÂÖ•Ë≥áÊñô\n",
    "train_image_data = torch.load(\"../SML_train_dataset.pt\")\n",
    "graph_data = torch.load(\"../train_graph_dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5db02b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class importDataset(Dataset):\n",
    "    def __init__(self, S_tiles, M_tiles, L_tiles, labels, meta_info, normal_coords, node_feats, adj_lists,edge_feats):\n",
    "        \"\"\"\n",
    "        Custom Dataset to load image tiles, labels, and edge indices for training.\n",
    "        \n",
    "        Args:\n",
    "            S_tiles (list): Small scale image tiles (spot-level features).\n",
    "            M_tiles (list): Medium scale image tiles (spot-level features).\n",
    "            L_tiles (list): Large scale image tiles (spot-level features).\n",
    "            labels (list): Ground truth labels (spot-level cell type compositions).\n",
    "            meta_info (list): Metadata containing slide_id, x, y coordinates for each spot.\n",
    "            normal_coords (list): Normalized coordinates for each spot.\n",
    "            slide_edge_indices (dict): Dictionary containing the slide-level edge indices for each slide.\n",
    "        \"\"\"\n",
    "        self.S_tiles = S_tiles\n",
    "        self.M_tiles = M_tiles\n",
    "        self.L_tiles = L_tiles\n",
    "        self.labels = labels\n",
    "        self.meta_info = meta_info\n",
    "        self.normal_coords = normal_coords\n",
    "        self.node_feats = node_feats\n",
    "        self.adj_lists = adj_lists\n",
    "        self.edge_feats = edge_feats\n",
    "        # Optional: Apply any additional processing to the data here\n",
    "        # e.g., scaling, normalization, etc.\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of samples (spots) in the dataset\n",
    "        return len(self.S_tiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the spot-level data for the sample at index `idx`\n",
    "        S_tile = self.S_tiles[idx]\n",
    "        M_tile = self.M_tiles[idx]\n",
    "        L_tile = self.L_tiles[idx]\n",
    "        label = self.labels[idx]\n",
    "        meta = self.meta_info[idx]  # This is a tuple (slide_id, x, y)\n",
    "        normal_coord = self.normal_coords[idx]\n",
    "        adj_list = self.adj_lists[idx]\n",
    "        \n",
    "        # Convert the tiles to the correct format (channels-first)\n",
    "        S_tile = torch.tensor(S_tile, dtype=torch.float).permute(2, 0, 1)  # Convert from (H, W, 3) to (3, H, W)\n",
    "        M_tile = torch.tensor(M_tile, dtype=torch.float).permute(2, 0, 1)\n",
    "        L_tile = torch.tensor(L_tile, dtype=torch.float).permute(2, 0, 1)\n",
    "        \n",
    "        # Convert label and normal_coord to tensors\n",
    "        label = torch.tensor(label, dtype=torch.float)\n",
    "        normal_coord = torch.tensor(normal_coord, dtype=torch.float)\n",
    "        # ‚ûï Graph features\n",
    "        max_neighbors = 7  # or whatever k you use\n",
    "        adj_list = self.adj_lists[idx] if self.adj_lists is not None else []\n",
    "\n",
    "        # ËΩâÊàêÂõ∫ÂÆöÈï∑Â∫¶ÁöÑ Tensor\n",
    "        adj_array = np.zeros((max_neighbors, 2))\n",
    "        for i, (j, w) in enumerate(adj_list[:max_neighbors]):\n",
    "            adj_array[i] = [j, w]\n",
    "         # üõ†Ô∏è edge_feat ËΩâÂûãËôïÁêÜ\n",
    "        edge_feat_i = self.edge_feats[idx]\n",
    "        if isinstance(edge_feat_i, np.ndarray) and edge_feat_i.dtype == object:\n",
    "            edge_feat_i = np.array(edge_feat_i.tolist())\n",
    "        elif isinstance(edge_feat_i, list):\n",
    "            edge_feat_i = np.array(edge_feat_i)\n",
    "\n",
    "\n",
    "        graph_feats = {\n",
    "            'node_feat': torch.tensor(self.node_feats[idx], dtype=torch.float) if self.node_feats is not None else None,\n",
    "            'adj_list': torch.tensor(adj_array, dtype=torch.float),\n",
    "            'edge_feat': torch.tensor(edge_feat_i, dtype=torch.float) if edge_feat_i is not None else None,\n",
    "        }\n",
    "        # Return the data in a PyTorch-friendly format as a dictionary\n",
    "        return {\n",
    "            'S_tile': S_tile,\n",
    "            'M_tile': M_tile,\n",
    "            'L_tile': L_tile,\n",
    "            'label': label,\n",
    "            'meta': meta,\n",
    "            'normal_coord': normal_coord,\n",
    "            **graph_feats  # ‚ûï Âêà‰ΩµÈÄ≤ batch dictionary\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "401ef8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Step 2: Âª∫Á´ã Dataset ======\n",
    "image_train_dataset = importDataset(\n",
    "    S_tiles=train_image_data['S_tiles'],\n",
    "    M_tiles=train_image_data['M_tiles'],\n",
    "    L_tiles=train_image_data['L_tiles'],\n",
    "    labels=train_image_data['labels'],\n",
    "    meta_info=train_image_data['meta_info'],\n",
    "    normal_coords=train_image_data['normal_coords'],\n",
    "    node_feats=graph_data['node_feats'],\n",
    "    adj_lists=graph_data['adj_lists'],\n",
    "    edge_feats=graph_data['edge_feats']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e8a237d-3fff-47d5-831c-0b915cbecb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking dataset sample: 0\n",
      "üìè Center tile shape: torch.Size([3, 32, 32]) | dtype: torch.float32 | min: 0.451, max: 1.000\n",
      "üìè Subtiles shape: torch.Size([3, 64, 64]) | dtype: torch.float32\n",
      "üìè Neighbor tiles shape: torch.Size([3, 128, 128]) | dtype: torch.float32\n",
      "üß¨ Label shape: torch.Size([35]) | dtype: torch.float32\n",
      "üìå Coordinates (meta): x = 1554, y = 1297\n",
      "üìä Node feature shape: torch.Size([14]) | dtype: torch.float32\n",
      "üîó Edge feature shape: torch.Size([7, 5]) | dtype: torch.float32\n",
      "üîó Sample edge_feat[0]: tensor([26.0000, 26.0000,  0.0000,  0.0000,  0.0385])\n",
      "üìé Adjacency list shape: torch.Size([7, 2]) | dtype: torch.float32\n",
      "üìé Sample: tensor([[6.2800e+02, 3.8462e-02],\n",
      "        [2.3700e+02, 3.8462e-02],\n",
      "        [1.3880e+03, 3.7851e-02]])\n",
      "‚úÖ All checks passed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_30582/3814644018.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'node_feat': torch.tensor(self.node_feats[idx], dtype=torch.float) if self.node_feats is not None else None,\n"
     ]
    }
   ],
   "source": [
    "def check_dataset_item(dataset, idx=0):\n",
    "    item = dataset[idx]\n",
    "\n",
    "    print(\"üîç Checking dataset sample:\", idx)\n",
    "\n",
    "    # --- Center Tile ---\n",
    "    tile = item['S_tile']\n",
    "    print(f\"üìè Center tile shape: {tile.shape} | dtype: {tile.dtype} | min: {tile.min():.3f}, max: {tile.max():.3f}\")\n",
    "\n",
    "    # --- Subtiles ---\n",
    "    subtiles = item['M_tile']\n",
    "    print(f\"üìè Subtiles shape: {subtiles.shape} | dtype: {subtiles.dtype}\")\n",
    "\n",
    "    # --- Neighbors ---\n",
    "    neighbors = item['L_tile']\n",
    "    print(f\"üìè Neighbor tiles shape: {neighbors.shape} | dtype: {neighbors.dtype}\")\n",
    "\n",
    "    # --- Label ---\n",
    "    label = item['label']\n",
    "    print(f\"üß¨ Label shape: {label.shape} | dtype: {label.dtype}\")\n",
    "    assert label.shape[0] == 35 and label.dtype == torch.float32, \"‚ùå Label ÊáâÁÇ∫ float32 ‰∏îÈï∑Â∫¶ÁÇ∫ 35\"\n",
    "\n",
    "    # --- Coordinates (meta) ---\n",
    "    coordinates = item['meta']\n",
    "    print(f\"üìå Coordinates (meta): x = {coordinates[1]}, y = {coordinates[2]}\")\n",
    "\n",
    "    # --- Node Features ---\n",
    "    if 'node_feat' in item and item['node_feat'] is not None:\n",
    "        node_feat = item['node_feat']\n",
    "        print(f\"üìä Node feature shape: {node_feat.shape} | dtype: {node_feat.dtype}\")\n",
    "\n",
    "\n",
    "    # --- Edge Features ---\n",
    "    if 'edge_feat' in item and item['edge_feat'] is not None:\n",
    "        edge_feat = item['edge_feat']\n",
    "        print(f\"üîó Edge feature shape: {edge_feat.shape} | dtype: {edge_feat.dtype}\")\n",
    "        print(f\"üîó Sample edge_feat[0]: {edge_feat[0]}\")\n",
    "        assert edge_feat.ndim == 2 and edge_feat.shape[1] == 5, \"‚ùå Edge feature ÊáâÁÇ∫ (k, 5)\"\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Edge features Êú™Êèê‰æõ\")\n",
    "\n",
    "    # --- Adjacency List ---\n",
    "    if 'adj_list' in item and item['adj_list'] is not None:\n",
    "        adj_list = item['adj_list']\n",
    "        print(f\"üìé Adjacency list shape: {adj_list.shape} | dtype: {adj_list.dtype}\")\n",
    "        print(f\"üìé Sample: {adj_list[:3]}\")\n",
    "        assert adj_list.ndim == 2 and adj_list.shape[1] == 2, \"‚ùå Adjacency list ÊáâÁÇ∫ (k, 2)\"\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Adjacency list Êú™Êèê‰æõ\")\n",
    "\n",
    "    print(\"‚úÖ All checks passed!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "check_dataset_item(image_train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c83a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Train set size: 6679 samples\n",
      "‚úÖ Validation set size: 1670 samples\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Á¢∫ÂÆöÊï∏ÊìöÈõÜÁöÑÁ∏ΩÂ§ßÂ∞èÔºàÂÖ©ËÄÖÂøÖÈ†àÁõ∏ÂêåÔºâ\n",
    "dataset_size = len(image_train_dataset)  # ÂêåÊôÇ image_train_dataset Âíå graph_train_dataset Èï∑Â∫¶ÊáâÁõ∏Âêå\n",
    "\n",
    "# Ë®≠ÂÆöË®ìÁ∑¥ÊØî‰æãÔºåÈÄôË£°‰ª• 80% ÁÇ∫Ë®ìÁ∑¥ÈõÜÔºå20% ÁÇ∫È©óË≠âÈõÜ\n",
    "train_ratio = 0.8\n",
    "split_index = int(np.floor(train_ratio * dataset_size))\n",
    "\n",
    "# ÁîüÊàêÈö®Ê©üÁ¥¢Âºï\n",
    "indices = torch.randperm(dataset_size).tolist()\n",
    "\n",
    "# Â∞áÁ¥¢ÂºïÊãÜÂàÜÁÇ∫Ë®ìÁ∑¥ÂíåÈ©óË≠âÈÉ®ÂàÜ\n",
    "train_indices = indices[:split_index]\n",
    "val_indices = indices[split_index:]\n",
    "\n",
    "# ‰ΩøÁî® Subset Ê†πÊìöÁõ∏ÂêåÁöÑÁ¥¢ÂºïÂª∫Á´ãÂ≠êÈõÜ\n",
    "image_train_subset = Subset(image_train_dataset, train_indices)\n",
    "image_val_subset = Subset(image_train_dataset, val_indices)\n",
    "\n",
    "# ÁèæÂú®Ôºå‰Ω†ÊúâÂÖ©Â∞ç DataLoaderÔºå‰∏îÂÆÉÂÄëÁöÑÁ¥¢ÂºïÊòØ‰∏Ä‰∏ÄÂ∞çÊáâÁöÑ\n",
    "print(f\"‚úÖ Train set size: {len(image_train_subset)} samples\")\n",
    "print(f\"‚úÖ Validation set size: {len(image_val_subset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46d21906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sample keys: dict_keys(['S_tile', 'M_tile', 'L_tile', 'label', 'meta', 'normal_coord', 'node_feat', 'adj_list', 'edge_feat'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_30582/3814644018.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'node_feat': torch.tensor(self.node_feats[idx], dtype=torch.float) if self.node_feats is not None else None,\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "# from torch.utils.data import DataLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data, Batch\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(image_train_subset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(image_val_subset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "# Ê∏¨Ë©¶‰∏Ä‰∏ã DataLoader ÂèñÂá∫ÁöÑÊï∏Êìö\n",
    "for batch in train_loader:\n",
    "\n",
    "    print(\"Image sample keys:\", batch.keys() if hasattr(batch, 'keys') else \"Not a dict\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ccdc3b",
   "metadata": {},
   "source": [
    "Poteintial issues:\n",
    "# 1. my val_set tiles image may be included in the sub_tiles of train_set\n",
    "\n",
    "Note: Since neighbor tiles are reused across samples, some mild information overlap may exist between train and val sets. However, final test set is completely held out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45327c2e",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f90c9b",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GraphSAGE, global_mean_pool\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "\n",
    "\n",
    "# --- CustomGAT ÂÆöÁæ© ---\n",
    "class CustomGAT(nn.Module):\n",
    "    def __init__(self, in_features, n_heads=8, head_dim=32):\n",
    "        \"\"\"\n",
    "        in_features: ÊØèÂÄãÁØÄÈªûÂàùÂßãÁâπÂæµÁ∂≠Â∫¶ÔºàÈÄôË£°ÊáâÁÇ∫ 14Ôºâ\n",
    "        n_heads: Ê≥®ÊÑèÂäõÈ†≠Êï∏Ôºà‰æãÂ¶Ç 8Ôºâ\n",
    "        head_dim: ÊØèÂÄãÊ≥®ÊÑèÂäõÈ†≠Ëº∏Âá∫Á∂≠Â∫¶Ôºà‰æãÂ¶Ç 32Ôºâ\n",
    "        \"\"\"\n",
    "        super(CustomGAT, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = head_dim\n",
    "        # Â∞çÊØèÂÄãÊ≥®ÊÑèÂäõÈ†≠ÈÉΩÊúâ‰∏ÄÂÄãÁ∑öÊÄßËÆäÊèõÁü©Èô£ÔºåËº∏Âá∫ shape: [B, head_dim]\n",
    "        self.W = nn.Parameter(torch.randn(n_heads, in_features, head_dim))\n",
    "        # Ê≥®ÊÑèÂäõË®àÁÆóÂèÉÊï∏ÔºåÂàÜÂà•Â∞ç query Âíå key ‰ΩúÁî®\n",
    "        self.a1 = nn.Parameter(torch.randn(n_heads, head_dim, 1))\n",
    "        self.a2 = nn.Parameter(torch.randn(n_heads, head_dim, 1))\n",
    "        self.leakyrelu = nn.LeakyReLU(0.01)\n",
    "    \n",
    "    def forward(self, node_features, adj_list, edge_feat):\n",
    "        \"\"\"\n",
    "        node_features: tensor, shape [B, in_features] ÔºõB = batch sizeÔºà‰ª£Ë°® B ÂÄã spotsÔºâ\n",
    "        adj_list: tensor, shape [B, num_neighbors, 2]\n",
    "                  ÂÅáË®≠ÊØèÂÄãÂÖÉÁ¥†ÁöÑÁ¨¨‰∏ÄÂÄãÂÄºÊòØÈÑ∞Â±ÖÁ¥¢ÂºïÔºàÂèØËÉΩÁÇ∫ floatÔºâÔºåÁ¨¨‰∫åÂÄãÂÄºÁÇ∫Ê¨äÈáçÔºàÂèØÂøΩÁï•Ôºâ\n",
    "        edge_feat: tensor, shape [B, num_neighbors, edge_feat_dim]Ôºõ‰æãÂ¶Ç edge_feat_dim = 5\n",
    "        \"\"\"\n",
    "        B = node_features.size(0)\n",
    "        num_neighbors = adj_list.size(1)\n",
    "        head_outputs = []\n",
    "        \n",
    "        for h in range(self.n_heads):\n",
    "            # Á∑öÊÄßËÆäÊèõÔºöÂ∞çÊØèÂÄãÁØÄÈªûÂÅöËÆäÊèõ\n",
    "            # transformed: [B, head_dim]\n",
    "            transformed = torch.matmul(node_features, self.W[h])\n",
    "            # ÂàùÂßãÂåñÊ≥®ÊÑèÂäõÂæóÂàÜÁü©Èô£ eÔºåÂΩ¢ÁãÄ [B, B]Ôºå‰ΩÜÊàëÂÄëÂè™Â∞çÊØèÂÄã node i ËàáÂÖ∂ÈÑ∞Â±Ö j ÈÄ≤Ë°åË®àÁÆó\n",
    "            # ÈÄôË£°ÊàëÂÄëÁî® -inf Â°´ÂÖÖÈùûÈÑ∞Â±Ö‰ΩçÁΩÆ\n",
    "            e = torch.full((B, B), float('-inf'), device=node_features.device)\n",
    "            \n",
    "            # Â∞çÊØèÂÄãÁØÄÈªû i\n",
    "            for i in range(B):\n",
    "                # ÂèñÂá∫Ë©≤ node ÁöÑÈÑ∞Â±ÖË≥áË®äÔºåÂΩ¢ÁãÄ [num_neighbors, 2]\n",
    "                # ÊàëÂÄëÈúÄË¶ÅÁç≤ÂæóÈÑ∞Â±ÖÁ¥¢ÂºïÔºå‰∏¶Á¢∫‰øùÁÇ∫Êï¥Êï∏\n",
    "                neighbors = adj_list[i, :, 0]  # shape: [num_neighbors]\n",
    "                # Â¶ÇÊûú neighbors ÊòØÊµÆÈªûÂûãÔºåÂ∞áÂÖ∂ËΩâÊèõÁÇ∫ int\n",
    "                neighbors = neighbors.long()  # Â¶ÇÊûúÂéüÂßãÂ≠òÁöÑÊòØ floatÔºåÂèØÁõ¥Êé•Áî® .long()\n",
    "                for k in range(num_neighbors):\n",
    "                    j = int(neighbors[k].item())  # j ÁÇ∫ÈÑ∞Â±ÖÁ¥¢Âºï\n",
    "                    # ÂèñÂæóËÆäÊèõÂæåÁöÑÁâπÂæµÔºöquery Ëàá key ÂàÜÂà• [head_dim, 1]\n",
    "                    query = transformed[i].unsqueeze(1)\n",
    "                    key   = transformed[j].unsqueeze(1)\n",
    "                    e_ij = torch.matmul(self.a1[h].T, query) + torch.matmul(self.a2[h].T, key)\n",
    "                    e_ij = self.leakyrelu(e_ij)\n",
    "                    # Â¶ÇÊûúÊèê‰æõ‰∫Ü edge_featÔºåÊ†πÊìöÈÇäÁâπÂæµË™øÊï¥ e_ij\n",
    "                    if edge_feat is not None:\n",
    "                        # ÂèñÂá∫Â∞çÊáâÈÇäÁöÑÁâπÂæµÔºåÂΩ¢ÁãÄ: [edge_feat_dim]\n",
    "                        current_edge_feat = edge_feat[i, k]  # tensor, shape: [edge_feat_dim]\n",
    "                        # ÈÄôË£°Á∞°ÂñÆ‰ΩøÁî®Á¨¨‰∏ÄÂÄãÂÄº‰ΩúÁÇ∫Ë™øÊï¥Âõ†Â≠ê\n",
    "                        e_ij *= 1.0 / (current_edge_feat[0] + 1e-6)\n",
    "                    # Â∞áË®àÁÆóÂ•ΩÁöÑ e_ij Â≠òÂÖ•Â∞çÊáâÁöÑ‰ΩçÁΩÆ [i, j]\n",
    "                    e[i, j] = e_ij.squeeze()\n",
    "            \n",
    "            # Â∞çÊØèÂÄãÁØÄÈªûÁöÑÈÑ∞Â±ÖÊ≥®ÊÑèÂäõÂæóÂàÜÈÄ≤Ë°å softmax\n",
    "            attention = F.softmax(e, dim=1)  # [B, B]\n",
    "            # ËÅöÂêàÈÑ∞Â±ÖÁöÑË®äÊÅØÔºöÂ∞çÊØèÂÄãÁØÄÈªû iÔºåÁî®ÈÑ∞Â±Ö j ÁöÑËÆäÊèõÂæåÁâπÂæµÂä†Ê¨äÊ±ÇÂíå\n",
    "            head_output = torch.zeros(B, self.head_dim, device=node_features.device)\n",
    "            for i in range(B):\n",
    "                weighted_sum = torch.zeros(self.head_dim, device=node_features.device)\n",
    "                for j in range(B):\n",
    "                    if attention[i, j] > 0:\n",
    "                        weighted_sum += attention[i, j] * transformed[j]\n",
    "                head_output[i] = F.relu(weighted_sum)\n",
    "            head_outputs.append(head_output)\n",
    "        \n",
    "        # Â§öÈ†≠ÊãºÊé•ÔºöÊúÄÁµÇËº∏Âá∫ shape [B, n_heads*head_dim]\n",
    "        multi_head_output = torch.cat(head_outputs, dim=1)\n",
    "        return multi_head_output\n",
    "# Define a CNN for each scale (S_tile, M_tile, L_tile)\n",
    "class SmallScaleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallScaleCNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x).view(x.size(0), -1)  # Flatten the output for feature vector\n",
    "\n",
    "class MediumScaleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MediumScaleCNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x).view(x.size(0), -1)  # Flatten the output for feature vector\n",
    "\n",
    "class LargeScaleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LargeScaleCNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x).view(x.size(0), -1)  # Flatten the output for feature vector\n",
    "\n",
    "\n",
    "class GraphSAGEModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GraphSAGEModel, self).__init__()\n",
    "        # GraphSAGE layer\n",
    "        self.graphsage = GraphSAGE(input_dim, hidden_dim, aggr='mean')\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)  # For predicting 35 cell types\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Assuming `data` contains the features and edge_index for the graph\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.graphsage(x, edge_index)  # Apply GraphSAGE to the features\n",
    "        x = global_mean_pool(x, data.batch)  # Global pooling for each graph (slide)\n",
    "        return self.fc(x)  # Predict the cell type composition\n",
    "\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=input_dim, num_heads=1)\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply attention mechanism\n",
    "        attn_output, _ = self.attention(x, x, x)  # Self-attention on the feature vector\n",
    "        return self.fc(attn_output)\n",
    "\n",
    "\n",
    "class CellTypePredictionModel(nn.Module):\n",
    "    def __init__(self, small_cnn, medium_cnn, large_cnn, graphsage_model, attention_head):\n",
    "        super(CellTypePredictionModel, self).__init__()\n",
    "        self.small_cnn = small_cnn  # CNN for small-scale patch\n",
    "        self.medium_cnn = medium_cnn  # CNN for medium-scale patch\n",
    "        self.large_cnn = large_cnn  # CNN for large-scale patch\n",
    "        self.graphsage_model = graphsage_model  # GraphSAGE for graph-based feature learning\n",
    "        self.attention_head = attention_head  # Attention mechanism to focus on important features\n",
    "\n",
    "    def forward(self, S_tile, M_tile, L_tile, edge_index, normal_coords):\n",
    "        # Step 1: CNN feature extraction for each scale (S_tile, M_tile, L_tile)\n",
    "        S_features = self.small_cnn(S_tile)\n",
    "        M_features = self.medium_cnn(M_tile)\n",
    "        L_features = self.large_cnn(L_tile)\n",
    "        \n",
    "        # Combine features from all scales into one feature vector (F_i)\n",
    "        combined_features = torch.cat([S_features, M_features, L_features], dim=1)\n",
    "        \n",
    "        # Step 2: Create PyG Data object for Graph Neural Network\n",
    "        data = Data(x=combined_features, edge_index=edge_index, pos=normal_coords)\n",
    "        \n",
    "        # Step 3: GraphSAGE layer to learn spatial context-aware features\n",
    "        graphsage_output = self.graphsage_model(data)\n",
    "        \n",
    "        # Step 4: Attention mechanism to focus on the relevant features for cell-type prediction\n",
    "        attention_output = self.attention_head(graphsage_output.unsqueeze(0))  # Add batch dimension\n",
    "        return attention_output.squeeze(0)  # Remove batch dimension for final output\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the individual CNNs for each scale\n",
    "small_cnn = SmallScaleCNN()\n",
    "medium_cnn = MediumScaleCNN()\n",
    "large_cnn = LargeScaleCNN()\n",
    "\n",
    "# Instantiate the GraphSAGE model and attention head\n",
    "graphsage_model = GraphSAGEModel(input_dim=16 + 32 + 64, hidden_dim=256, output_dim=256)\n",
    "attention_head = AttentionHead(input_dim=256, output_dim=35)  # Predict 35 cell types\n",
    "\n",
    "# Instantiate the final model\n",
    "model = CellTypePredictionModel(small_cnn, medium_cnn, large_cnn, graphsage_model, attention_head)\n",
    "\n",
    "# Example input: Assuming you have a batch of data\n",
    "S_tile = torch.rand(32, 3, 32, 32)  # Example batch of small-scale image tiles\n",
    "M_tile = torch.rand(32, 3, 64, 64)  # Example batch of medium-scale image tiles\n",
    "L_tile = torch.rand(32, 3, 128, 128)  # Example batch of large-scale image tiles\n",
    "meta_info = [(f\"S_{i}\", torch.rand(2)) for i in range(32)]  # Dummy metadata for batch\n",
    "edge_index = torch.randint(0, 32, (2, 50))  # Dummy graph edge indices for each slide\n",
    "\n",
    "# Forward pass\n",
    "output = model(S_tile, M_tile, L_tile, meta_info, edge_index)\n",
    "print(\"Output shape:\", output.shape)  # Should be (batch_size, 35) for the 35 cell types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d68d1eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#########################\n",
    "# MultiScaleCNN Ê®°Âûã    #\n",
    "#########################\n",
    "class MultiScaleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiScaleCNN, self).__init__()\n",
    "        # S_branch: Input: [3,32,32] ‚Üí Output: [16,8,8]\n",
    "        self.conv_s = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),     # [16, 32, 32]\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),           # [16, 16, 16]\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),     # [16, 16, 16]\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)            # [16, 8, 8]\n",
    "        )\n",
    "        \n",
    "        # M_branch: Input: [3,64,64] ‚Üí Output: [32,8,8]\n",
    "        self.conv_m = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),      # [32, 64, 64]\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),           # [32, 32, 32]\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),     # [32, 32, 32]\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),           # [32, 16, 16]\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),     # [32, 16, 16]\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)            # [32, 8, 8]\n",
    "        )\n",
    "        \n",
    "        # L_branch: Input: [3,128,128] ‚Üí Output: [64,8,8]\n",
    "        self.conv_l = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),      # [64, 128, 128]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),           # [64, 64, 64]\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),     # [64, 64, 64]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),           # [64, 32, 32]\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),     # [64, 32, 32]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),           # [64, 16, 16]\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),     # [64, 16, 16]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)            # [64, 8, 8]\n",
    "        )\n",
    "    \n",
    "    def forward(self, S_tile, M_tile, L_tile):\n",
    "        # S_branch: flatten [B,16,8,8] ‚Üí [B, 16*8*8] = [B, 1024]\n",
    "        f_s = self.conv_s(S_tile).view(S_tile.size(0), -1)\n",
    "        # M_branch: flatten [B,32,8,8] ‚Üí [B, 32*8*8] = [B, 2048]\n",
    "        f_m = self.conv_m(M_tile).view(M_tile.size(0), -1)\n",
    "        # L_branch: flatten [B,64,8,8] ‚Üí [B, 64*8*8] = [B, 4096]\n",
    "        f_l = self.conv_l(L_tile).view(L_tile.size(0), -1)\n",
    "        # ÊãºÊé•ÂæóÂà∞ [B, 1024+2048+4096=7168]\n",
    "        return torch.cat([f_s, f_m, f_l], dim=1)\n",
    "\n",
    "##########################################\n",
    "# FusionMLP Ê®°ÂûãÔºöËûçÂêà CNN ÁâπÂæµËàá engineered node_features\n",
    "# ÈÄôË£°ÊàëÂÄëÁî® NodeMLP ÈáçÊñ∞Ë®≠Ë®àÔºå‰ΩøÂÖ∂Êé•ÂèóËûçÂêàÂæåÁöÑÁâπÂæµ‰∏¶ÊúÄÁµÇËº∏Âá∫35Á∂≠\n",
    "##########################################\n",
    "class FusionMLP(nn.Module):\n",
    "    def __init__(self, in_dim, dropout_rate=0.5):\n",
    "        \"\"\"\n",
    "        in_dim: ËûçÂêàÂæåÁöÑËº∏ÂÖ•Á∂≠Â∫¶Ôºå= cnn_out_dim + engineered_dim\n",
    "        dropout_rate: dropout Ê©üÁéá\n",
    "        \"\"\"\n",
    "        super(FusionMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc_out = nn.Linear(256, 35)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [B, in_dim]\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x  # ÊúÄÁµÇ [B, 35]\n",
    "\n",
    "###############################\n",
    "# HEVisium ËûçÂêàÊ®°Âûã\n",
    "###############################\n",
    "class HEVisium(nn.Module):\n",
    "    def __init__(self, cnn_backbone, fusion_mlp, cnn_out_dim=7168, engineered_dim=14):\n",
    "        \"\"\"\n",
    "        cnn_backbone: MultiScaleCNN Ê®°ÂûãÔºàËº∏Âá∫ cnn_out_dimÔºâ\n",
    "        fusion_mlp: Áî®ÊñºËûçÂêà CNN Ëº∏Âá∫Ëàá engineered node features ÁöÑ MLP Ê®°Âûã\n",
    "        cnn_out_dim: CNN Ê®°ÂûãËº∏Âá∫Á∂≠Â∫¶ÔºåÊ†πÊìö MultiScaleCNN ÊßãÈÄ†ÔºõÊ≠§ËôïÁÇ∫7168\n",
    "        engineered_dim: engineered node features Á∂≠Â∫¶ÔºåÊ≠§ËôïÁÇ∫14\n",
    "        \"\"\"\n",
    "        super(HEVisium, self).__init__()\n",
    "        self.cnn_backbone = cnn_backbone\n",
    "        self.fusion_mlp = fusion_mlp\n",
    "    \n",
    "    def forward(self, S_tile, M_tile, L_tile, node_features):\n",
    "        # CNN ÈÉ®ÂàÜ\n",
    "        cnn_feats = self.cnn_backbone(S_tile, M_tile, L_tile)  # [B, cnn_out_dim]\n",
    "        # ËûçÂêà engineered node features Ëàá CNN Ëº∏Âá∫Ôºöcat ÁöÑÈ†ÜÂ∫èÈúÄÂ∞çÊáâÂêå‰∏Ä spot\n",
    "        combined = torch.cat([cnn_feats, node_features], dim=1)  # [B, cnn_out_dim + engineered_dim]\n",
    "        # ËûçÂêàÂæåÈÄöÈÅé MLP Ëº∏Âá∫ 35 Á∂≠ÁµêÊûú\n",
    "        out = self.fusion_mlp(combined)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d9d3692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------------\n",
    "# Ë®ìÁ∑¥‰∏ÄÂÄã epoch\n",
    "# ------------------------------\n",
    "def train_one_epoch(model, dataloader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for batch in pbar:\n",
    "        # ÂèñÂá∫ÂúñÂÉè patch Ëàá engineered node featuresÔºåÊ≥®ÊÑèÊàëÂÄë‰∏çÂÜç‰ΩøÁî® 'adj_list' Ëàá 'edge_feat'\n",
    "        S_tile = batch['S_tile'].to(device)\n",
    "        M_tile = batch['M_tile'].to(device)\n",
    "        L_tile = batch['L_tile'].to(device)\n",
    "        label = batch['label'].to(device)\n",
    "        node_feat = batch['node_feat'].to(device)  # engineered node features, shape [B, 14]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Êñ∞ÁöÑÊ®°Âûã forward ÂÉÖ‰ΩøÁî® S_tile, M_tile, L_tile, node_feat\n",
    "        out = model(S_tile, M_tile, L_tile, node_feat)\n",
    "        \n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * S_tile.size(0)\n",
    "        avg_loss = total_loss / ((pbar.n + 1) * dataloader.batch_size)\n",
    "        pbar.set_postfix(loss=loss.item(), avg=avg_loss)\n",
    "    \n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "# ------------------------------\n",
    "# È©óË≠âÊ®°Âûã\n",
    "# ------------------------------\n",
    "def evaluate(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    preds, targets = [], []\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=\"Evaluating\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in pbar:\n",
    "            S_tile = batch['S_tile'].to(device)\n",
    "            M_tile = batch['M_tile'].to(device)\n",
    "            L_tile = batch['L_tile'].to(device)\n",
    "            label = batch['label'].to(device)\n",
    "            node_feat = batch['node_feat'].to(device)\n",
    "            \n",
    "            # Êñ∞ÁöÑ forward Ë™øÁî®\n",
    "            out = model(S_tile, M_tile, L_tile, node_feat)\n",
    "            \n",
    "            loss = loss_fn(out, label)\n",
    "            total_loss += loss.item() * S_tile.size(0)\n",
    "            preds.append(out.cpu())\n",
    "            targets.append(label.cpu())\n",
    "            \n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    preds = torch.cat(preds).numpy()\n",
    "    targets = torch.cat(targets).numpy()\n",
    "    \n",
    "    # ‰ΩøÁî® Spearman Áõ∏Èóú‰øÇÊï∏Ë®àÁÆóÊØèÂÄãËº∏Âá∫Á∂≠Â∫¶ÁöÑÁõ∏ÈóúÊÄß\n",
    "    scores = [spearmanr(preds[:, i], targets[:, i])[0] for i in range(preds.shape[1])]\n",
    "    spearman_avg = np.nanmean(scores)\n",
    "    \n",
    "    return total_loss / len(dataloader.dataset), spearman_avg\n",
    "\n",
    "# ------------------------------\n",
    "# È†êÊ∏¨ÂáΩÊï∏\n",
    "# ------------------------------\n",
    "def predict(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_meta = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            S_tile = batch['S_tile'].to(device)\n",
    "            M_tile = batch['M_tile'].to(device)\n",
    "            L_tile = batch['L_tile'].to(device)\n",
    "            node_feat = batch['node_feat'].to(device)\n",
    "            # meta ‰ø°ÊÅØÈÄöÂ∏∏ÂåÖÂê´ spot Êàñ slide Ë≠òÂà•‰ø°ÊÅØ\n",
    "            meta = batch['meta']  \n",
    "            \n",
    "            out = model(S_tile, M_tile, L_tile, node_feat)\n",
    "            all_preds.append(out.cpu())\n",
    "            all_meta.extend(meta)\n",
    "    \n",
    "    return torch.cat(all_preds).numpy(), all_meta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e616b268",
   "metadata": {},
   "source": [
    "# callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f6e2ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=True):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_score is None or val_loss < self.best_score:\n",
    "            self.best_score = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"EarlyStopping counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(train_losses, label=\"Train Loss\", marker='o')\n",
    "    plt.plot(val_losses, label=\"Val Loss\", marker='o')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.title(\"Training vs Validation Loss\")\n",
    "    plt.show()\n",
    "# Êî∂ÈõÜË≥áÊñô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7c9b4556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 56\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     val_loss, val_spearman \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, loss_fn, device)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# ‚úÖ ÂÑ≤Â≠òÊúÄÂ•ΩÁöÑÊ®°Âûã\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[91], line 14\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, dataloader, optimizer, loss_fn, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     12\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# ÂèñÂá∫ÂúñÂÉè patch Ëàá engineered node featuresÔºåÊ≥®ÊÑèÊàëÂÄë‰∏çÂÜç‰ΩøÁî® 'adj_list' Ëàá 'edge_feat'\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     S_tile \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS_tile\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m     M_tile \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM_tile\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[9], line 46\u001b[0m, in \u001b[0;36mimportDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Convert the tiles to the correct format (channels-first)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m S_tile \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(S_tile, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Convert from (H, W, 3) to (3, H, W)\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m M_tile \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM_tile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     47\u001b[0m L_tile \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(L_tile, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Convert label and normal_coord to tensors\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "\n",
    "# üîß Ë®≠ÂÆöË£ùÁΩÆ\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"‚úÖ Using device: {device}\")\n",
    "\n",
    "# üîß ÂàùÂßãÂåñÊ®°Âûã & ÂÑ™ÂåñÂô®\n",
    "# üîß ÂàùÂßãÂåñÊ®°Âûã & ÂÑ™ÂåñÂô®\n",
    "cnn_backbone = MultiScaleCNN()  # ÈÄôÊòØ‰Ω†ÂÆöÁæ©ÁöÑÂ§öÂ∞∫Â∫¶CNN\n",
    "# ÂãïÊÖãË®àÁÆó cnn_out_dimÔºàÂæû‰Ω†ÁöÑ MultiScaleCNN ÂæóÂà∞ÔºåÊ≠§ËôïÂÉÖÁ§∫ÁØÑÁî® dummy Ëº∏ÂÖ•Ôºâ\n",
    "dummy_S = torch.randn(1, 3, 32, 32)\n",
    "dummy_M = torch.randn(1, 3, 64, 64)\n",
    "dummy_L = torch.randn(1, 3, 128, 128)\n",
    "cnn_backbone = MultiScaleCNN()\n",
    "dummy_out = cnn_backbone(dummy_S, dummy_M, dummy_L)\n",
    "cnn_out_dim = dummy_out.shape[1]\n",
    "print(\"Calculated CNN output dimension:\", cnn_out_dim)\n",
    "\n",
    "gat_out_dim = 256  # CustomGAT Ëº∏Âá∫Á∂≠Â∫¶Ôºå8 heads √ó 32 = 256\n",
    "final_out_dim = 35  # È†êÊ∏¨ 35 Á∂≠ÁµêÊûú\n",
    "\n",
    "engineered_dim = 14  # ‰Ω†Â∑•Á®ãÂåñÁöÑÁâπÂæµÁ∂≠Â∫¶\n",
    "\n",
    "fusion_in_dim = cnn_out_dim + engineered_dim\n",
    "fusion_mlp = FusionMLP(in_dim=fusion_in_dim, dropout_rate=0.5)\n",
    "\n",
    "# Âª∫Á´ãÁ∂úÂêàÊ®°Âûã HEVisium\n",
    "model = HEVisium(cnn_backbone=cnn_backbone, fusion_mlp=fusion_mlp,\n",
    "                    cnn_out_dim=cnn_out_dim, engineered_dim=engineered_dim).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.001)\n",
    "loss_fn = torch.nn.MSELoss()  # Êàñ‰æùÈúÄÊ±ÇÊõøÊèõÂÖ∂‰ªñÊêçÂ§±ÂáΩÊï∏\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "early_stopper = EarlyStopping(patience=10)  # ÂÅáË®≠ EarlyStopping È°ûÂ∑≤ÂØ¶Áèæ\n",
    "\n",
    "# Ë®òÈåÑË®ìÁ∑¥Êó•Ë™å\n",
    "log_file = open(\"training_log.csv\", mode=\"w\", newline=\"\")\n",
    "csv_writer = csv.writer(log_file)\n",
    "csv_writer.writerow([\"Epoch\", \"Train Loss\", \"Val Loss\", \"Val Spearman\", \"Learning Rate\"])\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "# üîÅ ÈñãÂßãË®ìÁ∑¥\n",
    "num_epochs = 150\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "    val_loss, val_spearman = evaluate(model, val_loader, loss_fn, device)\n",
    "\n",
    "    # ‚úÖ ÂÑ≤Â≠òÊúÄÂ•ΩÁöÑÊ®°Âûã\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        print(\"‚úÖ Saved best model!\")\n",
    "\n",
    "    # ‚úÖ Ë™øÊï¥Â≠∏ÁøíÁéá\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # ‚úÖ ÂØ´ÂÖ• CSV log\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    csv_writer.writerow([epoch+1, train_loss, val_loss, val_spearman, lr])\n",
    "\n",
    "    # ‚úÖ Âç∞ epoch ÁµêÊûú\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | loss: {train_loss:.4f} | val_loss: {val_loss:.4f} | œÅ: {val_spearman:.4f} | lr: {lr:.2e}\")\n",
    "\n",
    "    # ‚úÖ Êõ¥Êñ∞ loss list ‰∏¶Áï´Âúñ\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    plot_losses(train_losses, val_losses)\n",
    "\n",
    "    # ‚úÖ Early stopping\n",
    "    early_stopper(val_loss)\n",
    "    if early_stopper.early_stop:\n",
    "        print(\"‚õî Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# ‚úÖ ÈóúÈñâ log Ê™îÊ°à\n",
    "log_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1782cd7",
   "metadata": {},
   "source": [
    "# Only S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d77c6515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "##############################\n",
    "# Modified MultiScaleCNN Ê®°Âûã - ÂÉÖÊé•Êî∂ S_tile\n",
    "##############################\n",
    "class MultiScaleCNN_S(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiScaleCNN_S, self).__init__()\n",
    "        # Âè™‰ΩøÁî® S_branch: Input: [3,32,32] ‚Üí Output: [16,8,8]\n",
    "        self.conv_s = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),   # [16,32,32]\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),         # [16,16,16]\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),   # [16,16,16]\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)          # [16,8,8]\n",
    "        )\n",
    "    def forward(self, S_tile):\n",
    "        # Â±ïÂπ≥Ôºö [B,16,8,8] ‚Üí [B, 16*8*8] = [B, 1024]\n",
    "        f_s = self.conv_s(S_tile).view(S_tile.size(0), -1)\n",
    "        return f_s\n",
    "\n",
    "##########################################\n",
    "# FusionMLP Ê®°ÂûãÔºöÂ∞á CNN Ëº∏Âá∫Ëàá engineered node features ËûçÂêàÂæåÁ∂ì MLP Áõ¥Êé•Ëº∏Âá∫35Á∂≠\n",
    "##########################################\n",
    "class FusionMLP(nn.Module):\n",
    "    def __init__(self, in_dim, dropout_rate=0.5):\n",
    "        \"\"\"\n",
    "        in_dim: ËûçÂêàÂæåÁöÑËº∏ÂÖ•Á∂≠Â∫¶Ôºå= cnn_out_dim + engineered_dim\n",
    "        dropout_rate: dropout Ê©üÁéá\n",
    "        \"\"\"\n",
    "        super(FusionMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc_out = nn.Linear(256, 35)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [B, in_dim]\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x  # ÊúÄÁµÇËº∏Âá∫ [B, 35]\n",
    "\n",
    "##########################################\n",
    "# HEVisium ËûçÂêàÊ®°ÂûãÔºöÂ∞á CNN Ëàá engineered ÁâπÂæµËûçÂêàÂæåËº∏Âá∫35Á∂≠ÁµêÊûú\n",
    "##########################################\n",
    "class HEVisium(nn.Module):\n",
    "    def __init__(self, cnn_backbone, fusion_mlp, cnn_out_dim=1024, engineered_dim=14):\n",
    "        \"\"\"\n",
    "        cnn_backbone: MultiScaleCNN_S Ê®°ÂûãÔºåËº∏Âá∫ cnn_out_dim (1024)\n",
    "        fusion_mlp: ËûçÂêà MLP Ê®°ÂûãÔºåËº∏ÂÖ•Á∂≠Â∫¶ = cnn_out_dim + engineered_dim\n",
    "        engineered_dim: engineered node features Á∂≠Â∫¶ÔºåÊ≠§ËôïÁÇ∫ 14\n",
    "        final_out_dim: ÊúÄÁµÇÈ†êÊ∏¨Á∂≠Â∫¶Âõ∫ÂÆöÁÇ∫ 35ÔºàÂú® fusion_mlp ‰∏≠Âõ∫ÂÆöËº∏Âá∫Ôºâ\n",
    "        \"\"\"\n",
    "        super(HEVisium, self).__init__()\n",
    "        self.cnn_backbone = cnn_backbone\n",
    "        self.fusion_mlp = fusion_mlp\n",
    "    \n",
    "    def forward(self, S_tile, node_features):\n",
    "        # CNN ÈÉ®ÂàÜÔºöËº∏Âá∫ [B, cnn_out_dim]\n",
    "        cnn_feats = self.cnn_backbone(S_tile)\n",
    "        # ËûçÂêà engineered node featuresÔºönode_features ÂΩ¢ÁãÄ [B, engineered_dim]\n",
    "        combined = torch.cat([cnn_feats, node_features], dim=1)  # [B, cnn_out_dim + engineered_dim]\n",
    "        out = self.fusion_mlp(combined)  # [B, 35]\n",
    "        return out\n",
    "\n",
    "##########################################\n",
    "# ‰ΩøÁî®Á§∫‰æã\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9348a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------------\n",
    "# Ë®ìÁ∑¥‰∏ÄÂÄã epoch\n",
    "# ------------------------------\n",
    "def train_one_epoch(model, dataloader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for batch in pbar:\n",
    "        # ÂèñÂá∫ÂúñÂÉè patch Ëàá engineered node featuresÔºåÊ≥®ÊÑèÊàëÂÄë‰∏çÂÜç‰ΩøÁî® 'adj_list' Ëàá 'edge_feat'\n",
    "        S_tile = batch['S_tile'].to(device)\n",
    "        label = batch['label'].to(device)\n",
    "        node_feat = batch['node_feat'].to(device)  # engineered node features, shape [B, 14]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Êñ∞ÁöÑÊ®°Âûã forward ÂÉÖ‰ΩøÁî® S_tile, M_tile, L_tile, node_feat\n",
    "        out = model(S_tile, node_feat)\n",
    "        \n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * S_tile.size(0)\n",
    "        avg_loss = total_loss / ((pbar.n + 1) * dataloader.batch_size)\n",
    "        pbar.set_postfix(loss=loss.item(), avg=avg_loss)\n",
    "    \n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "# ------------------------------\n",
    "# È©óË≠âÊ®°Âûã\n",
    "# ------------------------------\n",
    "def evaluate(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    preds, targets = [], []\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=\"Evaluating\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in pbar:\n",
    "            S_tile = batch['S_tile'].to(device)\n",
    "            label = batch['label'].to(device)\n",
    "            node_feat = batch['node_feat'].to(device)\n",
    "            \n",
    "            # Êñ∞ÁöÑ forward Ë™øÁî®\n",
    "            out = model(S_tile, node_feat)\n",
    "            \n",
    "            loss = loss_fn(out, label)\n",
    "            total_loss += loss.item() * S_tile.size(0)\n",
    "            preds.append(out.cpu())\n",
    "            targets.append(label.cpu())\n",
    "            \n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    preds = torch.cat(preds).numpy()\n",
    "    targets = torch.cat(targets).numpy()\n",
    "    \n",
    "    # ‰ΩøÁî® Spearman Áõ∏Èóú‰øÇÊï∏Ë®àÁÆóÊØèÂÄãËº∏Âá∫Á∂≠Â∫¶ÁöÑÁõ∏ÈóúÊÄß\n",
    "    scores = [spearmanr(preds[:, i], targets[:, i])[0] for i in range(preds.shape[1])]\n",
    "    spearman_avg = np.nanmean(scores)\n",
    "    \n",
    "    return total_loss / len(dataloader.dataset), spearman_avg\n",
    "\n",
    "# ------------------------------\n",
    "# È†êÊ∏¨ÂáΩÊï∏\n",
    "# ------------------------------\n",
    "def predict(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_meta = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            S_tile = batch['S_tile'].to(device)\n",
    "            node_feat = batch['node_feat'].to(device)\n",
    "            # meta ‰ø°ÊÅØÈÄöÂ∏∏ÂåÖÂê´ spot Êàñ slide Ë≠òÂà•‰ø°ÊÅØ\n",
    "            meta = batch['meta']  \n",
    "            \n",
    "            out = model(S_tile, node_feat)\n",
    "            all_preds.append(out.cpu())\n",
    "            all_meta.extend(meta)\n",
    "    \n",
    "    return torch.cat(all_preds).numpy(), all_meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "10f959e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/209 [00:00<?, ?it/s]/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_30582/3814644018.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'node_feat': torch.tensor(self.node_feats[idx], dtype=torch.float) if self.node_feats is not None else None,\n",
      "                                                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 45\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     val_loss, val_spearman \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, loss_fn, device)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# ‚úÖ ÂÑ≤Â≠òÊúÄÂ•ΩÁöÑÊ®°Âûã\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[116], line 31\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, dataloader, optimizer, loss_fn, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m S_tile\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     30\u001b[0m     avg_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m ((pbar\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m dataloader\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mpbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_postfix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mavg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mavg_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader\u001b[38;5;241m.\u001b[39mdataset)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/tqdm/std.py:1431\u001b[0m, in \u001b[0;36mtqdm.set_postfix\u001b[0;34m(self, ordered_dict, refresh, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostfix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m postfix[key]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m   1429\u001b[0m                          \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m postfix\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m refresh:\n\u001b[0;32m-> 1431\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/tqdm/std.py:1347\u001b[0m, in \u001b[0;36mtqdm.refresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1346\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m-> 1347\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nolock:\n\u001b[1;32m   1349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/tqdm/std.py:1495\u001b[0m, in \u001b[0;36mtqdm.display\u001b[0;34m(self, msg, pos)\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoveto(pos)\n\u001b[0;32m-> 1495\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__str__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos:\n\u001b[1;32m   1497\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoveto(\u001b[38;5;241m-\u001b[39mpos)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/tqdm/std.py:459\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.print_status\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprint_status\u001b[39m(s):\n\u001b[1;32m    458\u001b[0m     len_s \u001b[38;5;241m=\u001b[39m disp_len(s)\n\u001b[0;32m--> 459\u001b[0m     \u001b[43mfp_write\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlast_len\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlen_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     last_len[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m len_s\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/tqdm/std.py:453\u001b[0m, in \u001b[0;36mtqdm.status_printer.<locals>.fp_write\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfp_write\u001b[39m(s):\n\u001b[1;32m    452\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mstr\u001b[39m(s))\n\u001b[0;32m--> 453\u001b[0m     \u001b[43mfp_flush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/tqdm/utils.py:196\u001b[0m, in \u001b[0;36mDisableOnWriteError.disable_on_exception.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m5\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/ipykernel/iostream.py:609\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(evt\u001b[38;5;241m.\u001b[39mset)\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[0;32m--> 609\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mevt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush_timeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    610\u001b[0m         \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIOStream.flush timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39m__stderr__)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 581\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "\n",
    "# üîß Ë®≠ÂÆöË£ùÁΩÆ\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"‚úÖ Using device: {device}\")\n",
    "\n",
    "# üîß ÂàùÂßãÂåñÊ®°Âûã & ÂÑ™ÂåñÂô®\n",
    "# üîß ÂàùÂßãÂåñÊ®°Âûã & ÂÑ™ÂåñÂô®\n",
    "cnn_out_dim =1024\n",
    "fusion_in_dim = cnn_out_dim + engineered_dim  # 1024 + 14 = 1038\n",
    "    \n",
    "    # ÂâµÂª∫Ê®°ÂûãÊ®°ÁµÑ\n",
    "cnn_model = MultiScaleCNN_S()\n",
    "fusion_mlp = FusionMLP(in_dim=fusion_in_dim, dropout_rate=0.5)\n",
    "    \n",
    "model = HEVisium(cnn_backbone=cnn_model, fusion_mlp=fusion_mlp, \n",
    "                     cnn_out_dim=cnn_out_dim, engineered_dim=engineered_dim).to(device)\n",
    "    \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.001)\n",
    "loss_fn = torch.nn.MSELoss()  # Êàñ‰æùÈúÄÊ±ÇÊõøÊèõÂÖ∂‰ªñÊêçÂ§±ÂáΩÊï∏\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "early_stopper = EarlyStopping(patience=10)  # ÂÅáË®≠ EarlyStopping È°ûÂ∑≤ÂØ¶Áèæ\n",
    "\n",
    "# Ë®òÈåÑË®ìÁ∑¥Êó•Ë™å\n",
    "log_file = open(\"training_log.csv\", mode=\"w\", newline=\"\")\n",
    "csv_writer = csv.writer(log_file)\n",
    "csv_writer.writerow([\"Epoch\", \"Train Loss\", \"Val Loss\", \"Val Spearman\", \"Learning Rate\"])\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "# üîÅ ÈñãÂßãË®ìÁ∑¥\n",
    "num_epochs = 150\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "    val_loss, val_spearman = evaluate(model, val_loader, loss_fn, device)\n",
    "\n",
    "    # ‚úÖ ÂÑ≤Â≠òÊúÄÂ•ΩÁöÑÊ®°Âûã\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        print(\"‚úÖ Saved best model!\")\n",
    "\n",
    "    # ‚úÖ Ë™øÊï¥Â≠∏ÁøíÁéá\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # ‚úÖ ÂØ´ÂÖ• CSV log\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    csv_writer.writerow([epoch+1, train_loss, val_loss, val_spearman, lr])\n",
    "\n",
    "    # ‚úÖ Âç∞ epoch ÁµêÊûú\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | loss: {train_loss:.4f} | val_loss: {val_loss:.4f} | œÅ: {val_spearman:.4f} | lr: {lr:.2e}\")\n",
    "\n",
    "    # ‚úÖ Êõ¥Êñ∞ loss list ‰∏¶Áï´Âúñ\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    plot_losses(train_losses, val_losses)\n",
    "\n",
    "    # ‚úÖ Early stopping\n",
    "    early_stopper(val_loss)\n",
    "    if early_stopper.early_stop:\n",
    "        print(\"‚õî Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# ‚úÖ ÈóúÈñâ log Ê™îÊ°à\n",
    "log_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8f5aa0",
   "metadata": {},
   "source": [
    "# CNN_s + MMLP for node + MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffe33ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ÂÅáË®≠‰Ω†Â∑≤Á∂ìÊúâ‰ª•‰∏ãÂÖ©ÂÄãÊ®°Â°äÔºö\n",
    "# MultiScaleCNN_S: ÂÉÖÂ∞ç S_tile ÈÄ≤Ë°åËôïÁêÜÔºåËº∏Âá∫ [B, cnn_out_dim]Ôºà‰æãÂ¶Ç cnn_out_dim = 1024Ôºâ\n",
    "# EngineeredFeaturesMLP: ËôïÁêÜ engineered node_featuresÔºà‰æãÂ¶Ç shape [B, 14]ÔºâËº∏Âá∫ [B, emb_dim]Ôºà‰æãÂ¶Ç emb_dim = 256Ôºâ\n",
    "\n",
    "class MultiScaleCNN_S(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiScaleCNN_S, self).__init__()\n",
    "        self.conv_s = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),   # [16, 16, 16]\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)    # [16, 8, 8]\n",
    "        )\n",
    "    def forward(self, S_tile):\n",
    "        # Â±ïÂπ≥ [B, 16, 8, 8] ‚Üí [B, 16*8*8] = [B, 1024]\n",
    "        out = self.conv_s(S_tile).view(S_tile.size(0), -1)\n",
    "        return out\n",
    "\n",
    "class EngineeredFeaturesMLP(nn.Module):\n",
    "    def __init__(self, in_dim=14, dropout_rate=0.5):\n",
    "        super(EngineeredFeaturesMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "    def forward(self, x):\n",
    "        # Ëº∏ÂÖ• x: [B, 14]\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        return x  # Ëº∏Âá∫ [B, 256]\n",
    "\n",
    "# ËûçÂêàÂæåÁöÑ MLP Ê®°ÂûãÔºåÊúÄÁµÇËº∏Âá∫ 35 Á∂≠\n",
    "class FusionMLP(nn.Module):\n",
    "    def __init__(self, in_dim, dropout_rate=0.5):\n",
    "        super(FusionMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        self.fc_out = nn.Linear(256, 35)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "# Á∂úÂêàÊ®°ÂûãÔºöÂÖàÁî® CNN ÊèêÂèñÂúñÂÉèÁâπÂæµÔºåÂÜçËûçÂêà engineered ÁâπÂæµÔºåÊúÄÂæåÈÄöÈÅé MLP Ëº∏Âá∫\n",
    "class HEVisium(nn.Module):\n",
    "    def __init__(self, cnn_backbone, eng_mlp, fusion_mlp, cnn_out_dim=1024, eng_dim=14):\n",
    "        \"\"\"\n",
    "        cnn_backbone: MultiScaleCNN_S Ê®°ÂûãÔºåËº∏Âá∫ cnn_out_dimÔºà‰æãÂ¶Ç 1024Ôºâ\n",
    "        eng_mlp: EngineeredFeaturesMLP Ê®°ÂûãÔºåËº∏Âá∫Á∂≠Â∫¶ÁÇ∫ 256\n",
    "        fusion_mlp: ËûçÂêà MLP Ê®°ÂûãÔºåËº∏ÂÖ•Á∂≠Â∫¶ = cnn_out_dim + 256ÔºåÊúÄÁµÇËº∏Âá∫ 35 Á∂≠\n",
    "        \"\"\"\n",
    "        super(HEVisium, self).__init__()\n",
    "        self.cnn_backbone = cnn_backbone\n",
    "        self.eng_mlp = eng_mlp\n",
    "        self.fusion_mlp = fusion_mlp\n",
    "        \n",
    "    def forward(self, S_tile, engineered_feats):\n",
    "        # CNN ÂàÜÊîØÔºöËôïÁêÜ S_tile\n",
    "        cnn_feats = self.cnn_backbone(S_tile)  # [B, cnn_out_dim] (ÈÄôË£°ÊòØ 1024)\n",
    "        # engineered ÁâπÂæµÂàÜÊîØÔºöËôïÁêÜ engineered_featsÔºàÊØîÂ¶ÇÂéüÊú¨ÁöÑ 14 Á∂≠Ôºâ\n",
    "        eng_feats = self.eng_mlp(engineered_feats)  # [B, 256]\n",
    "        # ËûçÂêàÔºöÊãºÊé• cnn_feats Âíå eng_feats\n",
    "        combined = torch.cat([cnn_feats, eng_feats], dim=1)  # [B, 1024+256 = 1280]\n",
    "        out = self.fusion_mlp(combined)  # Ëº∏Âá∫ [B, 35]\n",
    "        return out\n",
    "    \n",
    "    import torch\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------------\n",
    "# Ë®ìÁ∑¥‰∏ÄÂÄã epoch\n",
    "# ------------------------------\n",
    "def train_one_epoch(model, dataloader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for batch in pbar:\n",
    "        # ÂèñÂá∫ÂúñÂÉè patch Ëàá engineered node featuresÔºåÊ≥®ÊÑèÊàëÂÄë‰∏çÂÜç‰ΩøÁî® 'adj_list' Ëàá 'edge_feat'\n",
    "        S_tile = batch['S_tile'].to(device)\n",
    "        label = batch['label'].to(device)\n",
    "        node_feat = batch['node_feat'].to(device)  # engineered node features, shape [B, 14]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Êñ∞ÁöÑÊ®°Âûã forward ÂÉÖ‰ΩøÁî® S_tile, M_tile, L_tile, node_feat\n",
    "        out = model(S_tile, node_feat)\n",
    "        \n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * S_tile.size(0)\n",
    "        avg_loss = total_loss / ((pbar.n + 1) * dataloader.batch_size)\n",
    "        pbar.set_postfix(loss=loss.item(), avg=avg_loss)\n",
    "    \n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "# ------------------------------\n",
    "# È©óË≠âÊ®°Âûã\n",
    "# ------------------------------\n",
    "def evaluate(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    preds, targets = [], []\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=\"Evaluating\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in pbar:\n",
    "            S_tile = batch['S_tile'].to(device)\n",
    "            label = batch['label'].to(device)\n",
    "            node_feat = batch['node_feat'].to(device)\n",
    "            \n",
    "            # Êñ∞ÁöÑ forward Ë™øÁî®\n",
    "            out = model(S_tile, node_feat)\n",
    "            \n",
    "            loss = loss_fn(out, label)\n",
    "            total_loss += loss.item() * S_tile.size(0)\n",
    "            preds.append(out.cpu())\n",
    "            targets.append(label.cpu())\n",
    "            \n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    preds = torch.cat(preds).numpy()\n",
    "    targets = torch.cat(targets).numpy()\n",
    "    \n",
    "    # ‰ΩøÁî® Spearman Áõ∏Èóú‰øÇÊï∏Ë®àÁÆóÊØèÂÄãËº∏Âá∫Á∂≠Â∫¶ÁöÑÁõ∏ÈóúÊÄß\n",
    "    scores = [spearmanr(preds[:, i], targets[:, i])[0] for i in range(preds.shape[1])]\n",
    "    spearman_avg = np.nanmean(scores)\n",
    "    \n",
    "    return total_loss / len(dataloader.dataset), spearman_avg\n",
    "\n",
    "# ------------------------------\n",
    "# È†êÊ∏¨ÂáΩÊï∏\n",
    "# ------------------------------\n",
    "def predict(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_meta = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            S_tile = batch['S_tile'].to(device)\n",
    "            node_feat = batch['node_feat'].to(device)\n",
    "            # meta ‰ø°ÊÅØÈÄöÂ∏∏ÂåÖÂê´ spot Êàñ slide Ë≠òÂà•‰ø°ÊÅØ\n",
    "            meta = batch['meta']  \n",
    "            \n",
    "            out = model(S_tile, node_feat)\n",
    "            all_preds.append(out.cpu())\n",
    "            all_meta.extend(meta)\n",
    "    \n",
    "    return torch.cat(all_preds).numpy(), all_meta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1582c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "\n",
    "# üîß Ë®≠ÂÆöË£ùÁΩÆ\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"‚úÖ Using device: {device}\")\n",
    "\n",
    "# üîß ÂàùÂßãÂåñÊ®°Âûã & ÂÑ™ÂåñÂô®\n",
    "# üîß ÂàùÂßãÂåñÊ®°Âûã & ÂÑ™ÂåñÂô®\n",
    "cnn_out_dim = 1024\n",
    "    # Engineered ÁâπÂæµ MLP Ëº∏Âá∫Âõ∫ÂÆöÁÇ∫ 256\n",
    "eng_out_dim = 256  \n",
    "fusion_in_dim = cnn_out_dim + eng_out_dim  # 1024 + 256 = 1280\n",
    "    \n",
    "    \n",
    "    # ÂâµÂª∫Ê®°ÂûãÊ®°ÁµÑ\n",
    "cnn_model = MultiScaleCNN_S()\n",
    "fusion_mlp = FusionMLP(in_dim=fusion_in_dim, dropout_rate=0.5)\n",
    "\n",
    "eng_mlp = EngineeredFeaturesMLP(in_dim=14, dropout_rate=0.5)\n",
    "\n",
    "model = HEVisium(cnn_backbone=cnn_model, eng_mlp=eng_mlp, fusion_mlp=fusion_mlp,\n",
    "                     cnn_out_dim=cnn_out_dim, eng_dim=14).to(device)\n",
    "    \n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.001)\n",
    "loss_fn = torch.nn.MSELoss()  # Êàñ‰æùÈúÄÊ±ÇÊõøÊèõÂÖ∂‰ªñÊêçÂ§±ÂáΩÊï∏\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "early_stopper = EarlyStopping(patience=10)  # ÂÅáË®≠ EarlyStopping È°ûÂ∑≤ÂØ¶Áèæ\n",
    "\n",
    "# Ë®òÈåÑË®ìÁ∑¥Êó•Ë™å\n",
    "log_file = open(\"training_log.csv\", mode=\"w\", newline=\"\")\n",
    "csv_writer = csv.writer(log_file)\n",
    "csv_writer.writerow([\"Epoch\", \"Train Loss\", \"Val Loss\", \"Val Spearman\", \"Learning Rate\"])\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "# üîÅ ÈñãÂßãË®ìÁ∑¥\n",
    "num_epochs = 150\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "    val_loss, val_spearman = evaluate(model, val_loader, loss_fn, device)\n",
    "\n",
    "    # ‚úÖ ÂÑ≤Â≠òÊúÄÂ•ΩÁöÑÊ®°Âûã\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        print(\"‚úÖ Saved best model!\")\n",
    "\n",
    "    # ‚úÖ Ë™øÊï¥Â≠∏ÁøíÁéá\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # ‚úÖ ÂØ´ÂÖ• CSV log\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    csv_writer.writerow([epoch+1, train_loss, val_loss, val_spearman, lr])\n",
    "\n",
    "    # ‚úÖ Âç∞ epoch ÁµêÊûú\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | loss: {train_loss:.4f} | val_loss: {val_loss:.4f} | œÅ: {val_spearman:.4f} | lr: {lr:.2e}\")\n",
    "\n",
    "    # ‚úÖ Êõ¥Êñ∞ loss list ‰∏¶Áï´Âúñ\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    plot_losses(train_losses, val_losses)\n",
    "\n",
    "    # ‚úÖ Early stopping\n",
    "    early_stopper(val_loss)\n",
    "    if early_stopper.early_stop:\n",
    "        print(\"‚õî Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# ‚úÖ ÈóúÈñâ log Ê™îÊ°à\n",
    "log_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71e3a81",
   "metadata": {},
   "source": [
    "# Only node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "81fe20ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([32, 35])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NodeFeatureMLP(nn.Module):\n",
    "    def __init__(self, input_dim, final_out_dim, dropout_rate=0.5):\n",
    "        \"\"\"\n",
    "        input_dim: Ëº∏ÂÖ•ÁöÑ engineered node features Á∂≠Â∫¶ (‰æãÂ¶Ç 14)\n",
    "        final_out_dim: ÊúÄÁµÇÈ†êÊ∏¨Ëº∏Âá∫ÁöÑÁ∂≠Â∫¶ (‰æãÂ¶Ç 35)\n",
    "        dropout_rate: Dropout Ê©üÁéá\n",
    "        \"\"\"\n",
    "        super(NodeFeatureMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc3 = nn.Linear(256, 512)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc4 = nn.Linear(512, 1024)\n",
    "        self.bn4 = nn.BatchNorm1d(1024)\n",
    "        self.dropout4 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Ëº∏Âá∫Â±§ÔºöÊúÄÁµÇËº∏Âá∫ final_out_dim Á∂≠ÁöÑÁµêÊûú (‰æãÂ¶Ç35)\n",
    "        self.fc_out = nn.Linear(1024, final_out_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [B, input_dim]\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = F.relu(self.bn4(self.fc4(x)))\n",
    "        x = self.dropout4(x)\n",
    "        \n",
    "        out = self.fc_out(x)\n",
    "        return out  # [B, final_out_dim]\n",
    "\n",
    "def build_model(input_dim, final_out_dim, dropout_rate=0.5, learning_rate=0.0001, weight_decay=0.001):\n",
    "    \"\"\"\n",
    "    input_dim: Ëº∏ÂÖ•ÁöÑ engineered node features Á∂≠Â∫¶Ôºà‰æãÂ¶Ç 14Ôºâ\n",
    "    final_out_dim: ÊúÄÁµÇÈ†êÊ∏¨Ëº∏Âá∫ÁöÑÁ∂≠Â∫¶Ôºà‰æãÂ¶Ç 35Ôºâ\n",
    "    dropout_rate: Dropout Ê©üÁéá\n",
    "    learning_rate: ÂÑ™ÂåñÂô®Â≠∏ÁøíÁéá\n",
    "    weight_decay: Adam ÂÑ™ÂåñÂô®‰∏≠ÁöÑ weight_decayÔºåÁî®Êñº L2 Ê≠£ÂâáÂåñ\n",
    "    \"\"\"\n",
    "    model = NodeFeatureMLP(input_dim, final_out_dim, dropout_rate)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    loss_fn = nn.MSELoss()  # ÊàñÂÖ∂‰ªñ‰Ω†ÈúÄË¶ÅÁöÑÊêçÂ§±ÂáΩÊï∏\n",
    "    return model, optimizer, loss_fn\n",
    "\n",
    "# -------------------------------\n",
    "# ‰ΩøÁî®Á§∫‰æãÔºö\n",
    "# ÂÅáË®≠ÊàëÂÄëÁöÑ engineered node features ÁöÑ shape ÁÇ∫ [B, 14],\n",
    "# ‰∏îÊúÄÁµÇÊàëÂÄëË¶ÅÈ†êÊ∏¨ 35 Á∂≠ÁµêÊûú\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    B = 32  # ÊâπÊ¨°Â§ßÂ∞è\n",
    "    input_dim = 14\n",
    "    final_out_dim = 35\n",
    "    \n",
    "    # Ê®°Êì¨Ëº∏ÂÖ•Êï∏Êìö: engineered node features\n",
    "    node_features = torch.randn(B, input_dim)\n",
    "    \n",
    "    model, optimizer, loss_fn = build_model(input_dim, final_out_dim, dropout_rate=0.5, learning_rate=0.0001, weight_decay=0.001)\n",
    "    \n",
    "    # Ê®°Êì¨Ê®°ÂûãÂâçÂêëÂÇ≥Êí≠\n",
    "    output = model(node_features)\n",
    "    print(\"Output shape:\", output.shape)  # È†êÊúü: [32, 35]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1a058f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------------\n",
    "# Ë®ìÁ∑¥‰∏ÄÂÄã epoch\n",
    "# ------------------------------\n",
    "def train_one_epoch(model, dataloader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for batch in pbar:\n",
    "        # ÂèñÂá∫ÂúñÂÉè patch Ëàá engineered node featuresÔºåÊ≥®ÊÑèÊàëÂÄë‰∏çÂÜç‰ΩøÁî® 'adj_list' Ëàá 'edge_feat'\n",
    "        label = batch['label'].to(device)\n",
    "        node_feat = batch['node_feat'].to(device)  # engineered node features, shape [B, 14]\n",
    "        out = model( node_feat)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Êñ∞ÁöÑÊ®°Âûã forward ÂÉÖ‰ΩøÁî® S_tile, M_tile, L_tile, node_feat\n",
    "        \n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * S_tile.size(0)\n",
    "        avg_loss = total_loss / ((pbar.n + 1) * dataloader.batch_size)\n",
    "        pbar.set_postfix(loss=loss.item(), avg=avg_loss)\n",
    "    \n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "# ------------------------------\n",
    "# È©óË≠âÊ®°Âûã\n",
    "# ------------------------------\n",
    "def evaluate(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    preds, targets = [], []\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=\"Evaluating\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in pbar:\n",
    "            label = batch['label'].to(device)\n",
    "            node_feat = batch['node_feat'].to(device)\n",
    "            \n",
    "            # Êñ∞ÁöÑ forward Ë™øÁî®\n",
    "            out = model( node_feat)\n",
    "            \n",
    "            loss = loss_fn(out, label)\n",
    "            total_loss += loss.item() * S_tile.size(0)\n",
    "            preds.append(out.cpu())\n",
    "            targets.append(label.cpu())\n",
    "            \n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    preds = torch.cat(preds).numpy()\n",
    "    targets = torch.cat(targets).numpy()\n",
    "    \n",
    "    # ‰ΩøÁî® Spearman Áõ∏Èóú‰øÇÊï∏Ë®àÁÆóÊØèÂÄãËº∏Âá∫Á∂≠Â∫¶ÁöÑÁõ∏ÈóúÊÄß\n",
    "    scores = [spearmanr(preds[:, i], targets[:, i])[0] for i in range(preds.shape[1])]\n",
    "    spearman_avg = np.nanmean(scores)\n",
    "    \n",
    "    return total_loss / len(dataloader.dataset), spearman_avg\n",
    "\n",
    "# ------------------------------\n",
    "# È†êÊ∏¨ÂáΩÊï∏\n",
    "# ------------------------------\n",
    "def predict(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_meta = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            node_feat = batch['node_feat'].to(device)\n",
    "            # meta ‰ø°ÊÅØÈÄöÂ∏∏ÂåÖÂê´ spot Êàñ slide Ë≠òÂà•‰ø°ÊÅØ\n",
    "            meta = batch['meta']  \n",
    "            out = model( node_feat)\n",
    "            all_preds.append(out.cpu())\n",
    "            all_meta.extend(meta)\n",
    "    \n",
    "    return torch.cat(all_preds).numpy(), all_meta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c31178d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAAGHCAYAAABS74GwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAACbEUlEQVR4nOzdd3xT5f7A8c9Juie0UErZG8tGtrJElgourgNBUBQXXhUn1wGoV0HvFfS6fi4QueK4CKIigiJLtgzZApbdUmYnbdPk/P44Tdq0GSdt0qTt9/16QdNzTk6e5Gnab57zfb6PoqqqihBCCCGEENWUwd8NEEIIIYQQwpck4BVCCCGEENWaBLxCCCGEEKJak4BXCCGEEEJUaxLwCiGEEEKIak0CXiGEEEIIUa1JwCuEEEIIIao1CXiFEEIIIUS1JgGvEEIIIYSo1iTgFUKUi6Iouv6tWrWqQo8zbdo0FEUp131XrVrllTYEmhtvvJHw8HAuXrzo9Jg77riD4OBgTp8+rfu8iqIwbdo02/eevH7jx4+nadOmuh+rpHfffZe5c+eW2X7kyBEURXG4z9esP3dnz56t9McWQnhfkL8bIISomjZs2GD3/UsvvcSvv/7KypUr7bYnJydX6HHuuecehg0bVq77du3alQ0bNlS4DYFmwoQJLF68mM8//5wHH3ywzP6MjAwWLVrEddddR7169cr9OJX1+r377rvUqVOH8ePH222vX78+GzZsoEWLFj59fCFE9ScBrxCiXHr16mX3fd26dTEYDGW2l5abm0tERITux2nYsCENGzYsVxtjYmLctqcqGj58OElJSXzyyScOA94FCxZw6dIlJkyYUKHH8ffrFxoaWi37TwhR+SSlQQjhMwMGDKB9+/asWbOGPn36EBERwd133w3Al19+yZAhQ6hfvz7h4eFcdtllPPPMM+Tk5Nidw1FKQ9OmTbnuuutYtmwZXbt2JTw8nLZt2/LJJ5/YHefokvz48eOJiori0KFDXHPNNURFRdGoUSMef/xx8vPz7e5/4sQJRo0aRXR0NLVq1eKOO+5gy5Ytbi+z79y5E0VR+Pjjj8vs+/HHH1EUhSVLlgBw5swZJk6cSKNGjQgNDaVu3bpcccUV/Pzzz07PbzQaGTduHL///ju7du0qs3/OnDnUr1+f4cOHc+bMGR588EGSk5OJiooiISGBq666irVr1zo9v5WzlIa5c+fSpk0bQkNDueyyy5g3b57D+0+fPp2ePXsSFxdHTEwMXbt25eOPP0ZVVdsxTZs2Zc+ePaxevdqWBmNNjXCW0rBu3ToGDRpEdHQ0ERER9OnThx9++KFMGxVF4ddff+WBBx6gTp06xMfHc9NNN3Hq1Cm3z12vJUuW0Lt3byIiIoiOjmbw4MFlrn7o6ePt27dz3XXXkZCQQGhoKElJSVx77bWcOHHCa20VoiaTEV4hhE+lpqYyZswYnnrqKV555RUMBu1z9sGDB7nmmmt49NFHiYyMZP/+/cycOZPNmzeXSYtwZOfOnTz++OM888wz1KtXj48++ogJEybQsmVL+vXr5/K+JpOJkSNHMmHCBB5//HHWrFnDSy+9RGxsLC+88AIAOTk5DBw4kPPnzzNz5kxatmzJsmXLuPXWW922rVOnTnTp0oU5c+aUGWWdO3cuCQkJXHPNNQCMHTuWbdu28c9//pPWrVtz8eJFtm3bxrlz51w+xt13382MGTP45JNPmDVrlm373r172bx5M8888wxGo5Hz588DMHXqVBITE8nOzmbRokUMGDCAX375hQEDBrh9PqXbf9ddd3H99dfz73//m4yMDKZNm0Z+fr6tb62OHDnCfffdR+PGjQHYuHEjDz/8MCdPnrS9zosWLWLUqFHExsby7rvvAtrIrjOrV69m8ODBdOzYkY8//pjQ0FDeffddRowYwYIFC8r0zz333MO1117L559/zvHjx3nyyScZM2aMrp8xdz7//HPuuOMOhgwZwoIFC8jPz+e1116zvbZXXnkl4L6Pc3JyGDx4MM2aNeOdd96hXr16pKWl8euvv5KVlVXhdgohAFUIIbxg3LhxamRkpN22/v37q4D6yy+/uLyvxWJRTSaTunr1ahVQd+7cads3depUtfSvqiZNmqhhYWHq0aNHbdsuXbqkxsXFqffdd59t26+//qoC6q+//mrXTkD96quv7M55zTXXqG3atLF9/84776iA+uOPP9odd99996mAOmfOHJfP6a233lIB9cCBA7Zt58+fV0NDQ9XHH3/cti0qKkp99NFHXZ7Lmf79+6t16tRRCwoKbNsef/xxFVD//PNPh/cpLCxUTSaTOmjQIPXGG2+02weoU6dOtX1f+vUzm81qUlKS2rVrV9VisdiOO3LkiBocHKw2adLEaVvNZrNqMpnUF198UY2Pj7e7f7t27dT+/fuXuU9KSkqZ17pXr15qQkKCmpWVZfec2rdvrzZs2NB23jlz5qiA+uCDD9qd87XXXlMBNTU11WlbVbX45+7MmTNOn09SUpLaoUMH1Ww227ZnZWWpCQkJap8+fWzb3PXx1q1bVUBdvHixyzYJIcpPUhqEED5Vu3ZtrrrqqjLb//rrL0aPHk1iYiJGo5Hg4GD69+8PwL59+9yet3PnzraRQ4CwsDBat27N0aNH3d5XURRGjBhht61jx4529129ejXR0dFlJszdfvvtbs8PWpWE0NBQu8vx1lHAu+66y7atR48ezJ07l5dffpmNGzdiMpl0nR+0yWtnz561pUcUFhYyf/58+vbtS6tWrWzHvf/++3Tt2pWwsDCCgoIIDg7ml19+0fU6l3TgwAFOnTrF6NGj7dJMmjRpQp8+fcocv3LlSq6++mpiY2NtffzCCy9w7tw50tPTPXps0EZCN23axKhRo4iKirJtNxqNjB07lhMnTnDgwAG7+4wcOdLu+44dOwLo+jlxxfpajB071m5kOyoqiptvvpmNGzeSm5sLuO/jli1bUrt2bZ5++mnef/999u7dW6G2CSHKkoBXCOFT9evXL7MtOzubvn37smnTJl5++WVWrVrFli1b+OabbwC4dOmS2/PGx8eX2RYaGqrrvhEREYSFhZW5b15enu37c+fOOaxwoLfqQVxcHCNHjmTevHmYzWZASwfo0aMH7dq1sx335ZdfMm7cOD766CN69+5NXFwcd955J2lpaW4fw5oKMGfOHACWLl3K6dOn7dIo3njjDR544AF69uzJwoUL2bhxI1u2bGHYsGG6XquSrJfgExMTy+wrvW3z5s0MGTIEgA8//JDffvuNLVu28OyzzwL6+ri0CxcuoKqqw5+ppKQkuzZalf45saZLlOfxS7I+jrO2WCwWLly4ALjv49jYWFavXk3nzp35xz/+Qbt27UhKSmLq1KkefQASQjgnObxCCJ9yVEN35cqVnDp1ilWrVtlGdQGXdWUrW3x8PJs3by6zXU8ganXXXXfx9ddfs2LFCho3bsyWLVt477337I6pU6cOs2fPZvbs2Rw7dowlS5bwzDPPkJ6ezrJly1yePzw8nNtvv50PP/yQ1NRUPvnkE6Kjo/nb3/5mO2b+/PkMGDCgzOOWJzfUGjw6eg1Kb/viiy8IDg7m+++/t/twsXjxYo8f16p27doYDAZSU1PL7LNORKtTp065z+8J62vhrC0Gg4HatWvb2uSujzt06MAXX3yBqqr88ccfzJ07lxdffJHw8HCeeeaZSnlOQlRnMsIrhKh01iC49OSk//u///NHcxzq378/WVlZ/Pjjj3bbv/jiC93nGDJkCA0aNGDOnDnMmTOHsLAwlykRjRs3ZtKkSQwePJht27bpeowJEyZgNpt5/fXXWbp0Kbfddptd2TdFUcq8zn/88UeZSgJ6tGnThvr167NgwQK7SgtHjx5l/fr1dscqikJQUBBGo9G27dKlS3z22Wdlzqt3ZD4yMpKePXvyzTff2B1vsViYP38+DRs2pHXr1h4/r/Jo06YNDRo04PPPP7d7LXJycli4cKGtckNp7vpYURQ6derErFmzqFWrlu6fAyGEazLCK4SodH369KF27drcf//9TJ06leDgYP773/+yc+dOfzfNZty4ccyaNYsxY8bw8ssv07JlS3788Ud++ukngDIVCRwxGo3ceeedvPHGG8TExHDTTTcRGxtr25+RkcHAgQMZPXo0bdu2JTo6mi1btrBs2TJuuukmXe3s1q0bHTt2ZPbs2aiqWqYqxHXXXcdLL73E1KlT6d+/PwcOHODFF1+kWbNmFBYWevCKaM/5pZde4p577uHGG2/k3nvv5eLFi0ybNq1MSsO1117LG2+8wejRo5k4cSLnzp3jX//6l8MKDNbRzS+//JLmzZsTFhZGhw4dHLbh1VdfZfDgwQwcOJAnnniCkJAQ3n33XXbv3s2CBQvKvSqfM9999x3R0dFlto8aNYrXXnuNO+64g+uuu4777ruP/Px8Xn/9dS5evMiMGTMAfX38/fff8+6773LDDTfQvHlzVFXlm2++4eLFiwwePNirz0eImkoCXiFEpYuPj+eHH37g8ccfZ8yYMURGRnL99dfz5Zdf0rVrV383D9BGE1euXMmjjz7KU089haIoDBkyhHfffZdrrrmGWrVq6TrPXXfdxauvvsqZM2fsJquBNtGuZ8+efPbZZxw5cgSTyUTjxo15+umneeqpp3S3dcKECTzyyCMkJyfTs2dPu33PPvssubm5fPzxx7z22mskJyfz/vvvs2jRonItuWwNqGfOnMlNN91E06ZN+cc//sHq1avtznfVVVfxySefMHPmTEaMGEGDBg249957SUhIKBOUT58+ndTUVO69916ysrJo0qQJR44ccfj4/fv3Z+XKlUydOpXx48djsVjo1KkTS5Ys4brrrvP4+bhjrRtdmqqqjB49msjISF599VVuvfVWjEYjvXr14tdff7VN4tPTx61ataJWrVq89tprnDp1ipCQENq0acPcuXMZN26c15+TEDWRopa8FiOEEMKlV155heeee45jx46VewU4IYQQlUtGeIUQwom3334bgLZt22IymVi5ciVvvfUWY8aMkWBXCCGqEAl4hRDCiYiICGbNmsWRI0fIz8+3XYp+7rnn/N00IYQQHpCUBiGEEEIIUa1JWTIhhBBCCFGtScArhBBCCCGqNQl4hRBCCCFEtSaT1hywWCycOnWK6OhorxcxF0IIIYQQFaeqKllZWSQlJbldDEgCXgdOnTpFo0aN/N0MIYQQQgjhxvHjx92WipSA1wHrMpLHjx8nJibG549nMplYvnw5Q4YMITg42OePJ9yTPgk80ieBRfoj8EifBB7pE9/KzMykUaNGDpf/Lk0CXgesaQwxMTGVFvBGREQQExMjb4gAIX0SeKRPAov0R+CRPgk80ieVQ0/6qUxaE0IIIYQQ1ZoEvEIIIYQQolqTgFcIIYQQQlRrksMrhBBCiGpDVVUKCwsxm83+bgomk4mgoCDy8vICoj1VUXBwMEajscLnkYBXCCGEENVCQUEBqamp5Obm+rspgBZ8JyYmcvz4canrX06KotCwYUOioqIqdB4JeIUQQghR5VksFlJSUjAajSQlJRESEuL3INNisZCdnU1UVJTbhRFEWaqqcubMGU6cOEGrVq0qNNIrAa+fmS0qm1LO8/tZhfiU8/RumYDRIJ8ChRBCCE8UFBRgsVho1KgRERER/m4OoAW8BQUFhIWFScBbTnXr1uXIkSOYTCYJeKuqZbtTmf7dXlIz8gAj8w5upX5sGFNHJDOsfX1/N08IIYSociSwrF68NUovPxV+smx3Kg/M31YU7BZLy8jjgfnbWLY71U8tE0IIIYSoXvwa8K5Zs4YRI0aQlJSEoigsXrzY5fGrVq1CUZQy//bv32933MKFC0lOTiY0NJTk5GQWLVrkw2fhObNFZfp3e1Ed7LNum/7dXswWR0cIIYQQQghP+DXgzcnJoVOnTrz99tse3e/AgQOkpqba/rVq1cq2b8OGDdx6662MHTuWnTt3MnbsWG655RY2bdrk7eaX2+aU82VGdktSgdSMPDannK+8RgkhhBAC0AamNhw+x7c7TrLh8LkqOQA1YMAAHn30UX83I2D4NYd3+PDhDB8+3OP7JSQkUKtWLYf7Zs+ezeDBg5kyZQoAU6ZMYfXq1cyePZsFCxZUpLlek57lPNgtz3FCCCGE8A77+TUaX86vcZejOm7cOObOnevxeb/55huCg4PL2SrN+PHjuXjxotsr8FVBlZy01qVLF/Ly8khOTua5555j4MCBtn0bNmzgscceszt+6NChzJ492+n58vPzyc/Pt32fmZkJaAWjTSaTdxsPxEfoe9njI4J88vjCPevrLq9/4JA+CSzSH4GnpveJyWRCVVUsFgsWi6Vc51i2O42HPt9eJuXQOr/mndFdGNY+Uff5VFW1fXXWppMnT9puf/XVV0ydOpV9+/bZtoWHh9vd12Qy6QpkrQOD5X0tQGu3q7ZXBovFgqqqDqs0ePKzXqUC3vr16/PBBx9w+eWXk5+fz2effcagQYNYtWoV/fr1AyAtLY169erZ3a9evXqkpaU5Pe+rr77K9OnTy2xfvny5T0qbWFSoFWLkYgGAo092KrVC4MzejSzd52C3qDQrVqzwdxNEKdIngUX6I/DU1D4JCgoiMTGR7OxsCgoKAC1gyzPpC9bMFpVpS/a4nF8z7bs9dEwIcVs+NCzYYDdym5WV5fTYknFGSEiI3bZjx47RqVMnPvnkEz7++GO2bt3Kv//9b4YPH86TTz7Jxo0buXDhAk2bNmXy5MmMGjXKdq7rrruODh068OqrrwLQsWNHxo0bR0pKCt9++y2xsbE88cQTjB8/3mnbTCYThYWFtoHA0n777TdeeOEFdu/eTe3atbntttt47rnnCArSwstvv/2WmTNnkpKSQnh4OB07duS///0vkZGRrFu3jqlTp7J//36CgoJo27YtH374IY0bN7Z7jIKCAi5dusSaNWsoLCy02+fJAiNVKuBt06YNbdq0sX3fu3dvjh8/zr/+9S9bwAtlLw+oquryksGUKVOYPHmy7fvMzEwaNWrEkCFDiImJ8eIzKBbc9DQPf7FTa1+J7UrR/y/f1Imh7eo5uKeoDCaTiRUrVjB48OAKXxIS3iF9ElikPwJPTe+TvLw8jh8/TlRUFGFhYQDkFhTSZab3PgCkZxVw5Wz3c4J2TxtMREgQqqqSlZVFdHS0rvJaYWFhKIpiiz2sq4u9+OKLvP7663Tp0oXQ0FBUVaVXr148++yzxMTEsHTpUu6//37atWtHz549Ae0DQEhIiO1cBoOBd999lxdffJEXXniBhQsX8vjjjzNkyBDatm3rsD3BwcEEBQU5jIVOnjzJLbfcwrhx4/jss8/Yv38/9913H7GxsUydOpXU1FTuueceZs6cyQ033EBWVhbr1q0jOjqasLAwxowZwz333MMXX3xBQUEBmzdvJiYmpsxj5eXlER4eTr9+/Wz9auUsEHekSgW8jvTq1Yv58+fbvk9MTCwzmpuenl5m1Lek0NBQQkNDy2wPDg722S+N6zo3JCjIWCZPKFHq8AYUX/4MiPKRPgks0h+Bp6b2idlsRlEUDAaDrRavv2ryWttgTQWwtkvP/Rx9ffTRR+1GbwGefPJJ2+2///3v/PTTTyxcuJDevXvbtpd+3GuuuYaHHnoIgGeeeYbZs2ezZs0akpOTHbbHWg3LUdvff/99GjVqxDvvvIOiKCQnJ5OWlsbTTz/N1KlTOX36NIWFhdx88800adIEgE6dOgFw/vx5MjIyGDFihK3wQLt27Zy+JoqiOPy59uTnvMoHvNu3b6d+/eLgsHfv3qxYscIuj3f58uX06dPHH81zaVj7+gxOTuSnXSd5cIE22rvy8QGEh5R/JREhhBBCaMKDjex9caiuYzennGf8nC1uj5t7V3d6NItz+7je1K1bN7vvzWYzM2bM4Msvv+TkyZO2uUiRkZEuz9OxY0fbbUVRSExMJD09vVxt2rdvH71797Ybub7iiivIzs7mxIkTdOrUiUGDBtGhQweGDh3KkCFDGDVqFLVr1yYuLo7x48czdOhQBg8ezNVXX80tt9xiF895m1/LkmVnZ7Njxw527NgBQEpKCjt27ODYsWOAlmpw55132o6fPXs2ixcv5uDBg+zZs4cpU6awcOFCJk2aZDvmkUceYfny5cycOZP9+/czc+ZMfv7554AtzWE0KAxqm4ChKLEh41LNnGwghBBCeJuiKESEBOn617dVXerHhjmcWQNaymH92DD6tqrr9lzeWh3MqnQg++9//5tZs2bx1FNPsXLlSnbs2MHQoUNtucvOlB4RVRSl3BPSHKWLWifpKYqC0WhkxYoV/PjjjyQnJ/Of//yHNm3akJKSAsCcOXPYsGEDffr04csvv6R169Zs3LixXG3Rw68B79atW+nSpQtdunQBYPLkyXTp0oUXXngBgNTUVFvwC1ri8hNPPEHHjh3p27cv69at44cffuCmm26yHdOnTx+++OIL5syZQ8eOHZk7dy5ffvmlLaclEBkMClFFP4Nns/NdHyyEEEIIrzMaFKaO0C7tlw5Xrd9PHZHsdsJaZVi7di3XX389Y8aMoVOnTjRv3pyDBw9WahuSk5NZv369LcgFWL9+PdHR0TRo0ADQAt8rrriC6dOns337dkJCQuwWA+vSpQtTpkxh/fr1tG/fns8//9xn7fVrSsOAAQPsXqjSStede+qpp3jqqafcnnfUqFFlcl0CXXQwZJrgjAS8QgghhF8Ma1+f98Z0Dfj5NS1btmThwoWsX7+e2rVr88Ybb5CWlsZll13m9cfKyMiwXYm3iouL48EHH2T27Nk8/PDDTJo0iQMHDjB16lQmT56MwWBg06ZN/PLLLwwZMoSEhAQ2bdrEmTNnuOyyy0hJSeGDDz5g5MiRJCUlceDAAf7880+7q/reVuVzeKuL6GAVUDiX7fpyhBBCCCF8xzq/ZnPKedKz8kiIDqNHs7iAGNm1ev7550lJSWHo0KFEREQwceJEbrjhBjIyMrz+WKtWrbJdibeyLoaxdOlSnnzySTp16kRcXBwTJkzgueeeAyAmJoY1a9Ywe/ZsMjMzadKkia2k2unTp9m/fz+ffvop586do379+kyaNIn77rvP6+23koA3QEhKgxBCCBEYjAaF3i3iK/1xx48fb1cXt2nTpg6vhMfFxbld/WzVqlV23x85cqTMMaVHbkubO3euy1Xe+vfvz+bNmx3uu+yyy1i2bJnDffXq1bNLbagMfs3hFcWirQFvlgS8QgghhBDeJAFvgNBSGmSEVwghhBDC2yTgDRDWEd5zOZLDK4QQQgjhTRLwBghrwHtGUhqEEEIIIbxKAt4AER1iTWmQEV4hhBBCCG+SgDdAWEd4z+fkY7E4r00shBBCCCE8IwFvgIgqKhBnUeFCrozyCiGEEEJ4iwS8AcJogFrh2jCvpDUIIYQQQniPBLwBJD4qBIBzUppMCCGEEMJrJOANIPGRWsB7RgJeIYQQwn8sZkhZC7v+p321mP3dIrcGDBjAo48+6u9mBCwJeANInaIRXklpEEIIIfxk7xKY3R4+vQ4WTtC+zm6vbfeBESNGcPXVVzvct2HDBhRFYdu2bRV+nLlz51KrVq0Kn6eqkoA3gMRHhQKy2poQQgjhF3uXwFd3QuYp++2Zqdp2HwS9EyZMYOXKlRw9erTMvk8++YTOnTvTtWtXrz9uTSMBbwCpEyk5vEIIIYTXqCoU5Oj7l5cJPz4FOCoNWrRt2dPace7OpeovL3rdddeRkJDA3Llz7bbn5uby5ZdfMmHCBM6dO8ftt99Ow4YNiYiIoEOHDixYsKDcL4sjx44d4/rrrycqKoqYmBhuueUWTp8+bdu/c+dOBg4cSHR0NDExMVx++eVs3boVgKNHjzJixAhq165NZGQk7dq1Y+nSpV5tX0UF+bsBoli8pDQIIYQQ3mPKhVeSvHQyVRv5ndHI/aH/OAUhkbrOGhQUxJ133sncuXN54YUXUBQFgK+//pqCggLuuOMOcnNzufzyy3n66aeJiYnhhx9+YOzYsTRv3pyePXtW5EkBoKoqN9xwA5GRkaxevZrCwkIefPBBbr31VlatWgXAHXfcQZcuXXjvvfcwGo3s2LGD4GCtutRDDz1EQUEBa9asITIykr179xIVFVXhdnmTBLwBxDrCKykNQgghRM1x99138/rrr7Nq1SoGDhwIaOkMN910E7Vr16Z27do88cQTtuMffvhhli1bxtdff+2VgPfnn3/mjz/+ICUlhUaNtID+s88+o127dmzZsoXu3btz7NgxnnzySdq2bQtAq1atbPc/duwYN998Mx06dACgefPmFW6Tt0nAG0CKy5LJCK8QQghRYcER2mirHkfXw39HuT/ujv9Bkz7uH9cDbdu2pU+fPnzyyScMHDiQw4cPs3btWpYvXw6A2WxmxowZfPnll5w8eZL8/Hzy8/OJjNQ3iuzOvn37aNSokS3YBUhOTqZWrVrs27eP7t27M3nyZO655x4+++wzrr76av72t7/RokULAP7+97/zwAMPsHz5cq6++mpuvvlmOnbs6JW2eYvk8AYQa8B7Jjsf1YP8HyGEEEI4oChaaoGefy2ugpgkQHF2MohpoB3n7lyKs3M4N2HCBBYuXEhmZiZz5syhSZMmDBo0CIB///vfzJo1i6eeeoqVK1eyY8cOhg4dSkGBdwbIVFW1pVI42z5t2jT27NnDtddey8qVK0lOTmbRokUA3HPPPfz111+MHTuWXbt20a1bN/7zn/94pW3eIgFvAKkTqVVpKCi0kJVf6OfWCCGEEDWIwQjDZhZ9Uzr4K/p+2AztOB+45ZZbMBqNfP7553z66afcddddtmBz7dq1XH/99YwZM4ZOnTrRvHlzDh486LXHTk5O5tixYxw/fty2be/evWRkZHDZZZfZtrVu3ZrHHnuM5cuXc9NNNzFnzhzbvkaNGnH//ffzzTff8Pjjj/Phhx96rX3eICkNASQ8xEhkiJGcAjPnsguICQv2d5OEEEKImiN5JNwyT6vGULI0WUySFuwmj/TZQ0dFRXHrrbfyj3/8g4yMDMaPH2/b17JlSxYuXMj69eupXbs2b7zxBmlpaXbBqB5ms5kdO3bYbQsJCeHqq6+mY8eO3HHHHcyePds2aa1///5069aNS5cu8eSTTzJq1CiaNWvGiRMn2LJlCzfffDMAjz76KMOHD6d169ZcuHCBlStXetw2X5OAN8DER4WScz6Xs9n5NKvjndwcIYQQQuiUPBLaXqvl9Gafhqh6Ws6uj0Z2S5owYQIff/wxQ4YMoXHjxrbtzz//PCkpKQwdOpSIiAgmTpzIDTfcQEZGhkfnz87OpkuXLnbbmjRpwpEjR1i8eDEPP/ww/fr1w2AwMGzYMFtagtFo5Ny5c9x5552cPn2aOnXqcNNNNzF9+nRAC6QfeughTpw4QUxMDMOGDWPWrFkVfDW8SwLeAFMnKoRj53M5myWVGoQQQgi/MBihWd9Kf9jevXs7nMMTFxfH4sWLXd7XWj7MmfHjx9uNGpfWuHFjvv32W4f7QkJCXNb9DbR8XUckhzfA1JHV1oQQQgghvEoC3gBTJ9oa8EppMiGEEEIIb5CAN8DI4hNCCCGEEN4lAW+AKR7hlYBXCCGEEMIbJOANMNYcXlltTQghhPCcLNxUvXirPyXgDTDxktIghBBCeCw4WKtdn5ub6+eWCG+yriZnNFasLJyUJQswMmlNCCGE8JzRaKRWrVqkp6cDEBER4XC53MpksVgoKCggLy8Pg0HGGD1lsVg4c+YMERERBAVVLGSVgDfAWFMasvMLyTOZCQv2faFrIYQQojpITEwEsAW9/qaqKpcuXSI8PNzvwXdVZTAYaNy4cYVfPwl4A0xMWBAhRgMFZgtns/NpWDvC300SQgghqgRFUahfvz4JCQmYTCZ/NweTycSaNWvo16+fLeVCeCYkJMQro+MS8AYYRVGIjwohNSOPs9kFEvAKIYQQHjIajRXO+fRWOwoLCwkLC5OA188koSQA2VZbk+WFhRBCCCEqTALeAFQnSqvUcC5HAl4hhBBCiIqSgDcAxUdJpQYhhBBCCG+RgDcAWVMazkhKgxBCCCFEhUnAG4CKUxpkhFcIIYQQoqIk4A1AdaNl0poQQgghhLdIwBuA4iOtObwS8AohhBBCVJQEvAGoTrSW0iABrxBCCCFExUnAG4Csk9Yu5JooNFv83BohhBBCiKpNAt4AVDsiBEPRktHnZeKaEEIIIUSF+DXgXbNmDSNGjCApKQlFUVi8eLHu+/72228EBQXRuXNnu+1z585FUZQy//Ly8rzbeB8yGhTiIrW0hjOS1iCEEEIIUSF+DXhzcnLo1KkTb7/9tkf3y8jI4M4772TQoEEO98fExJCammr3LywszBtNrjTWtIZzsviEEEIIIUSFBPnzwYcPH87w4cM9vt99993H6NGjMRqNDkeFFUUhMTHRCy30n/gombgmhBBCCOENfg14y2POnDkcPnyY+fPn8/LLLzs8Jjs7myZNmmA2m+ncuTMvvfQSXbp0cXrO/Px88vOLA8vMzEwATCYTJpPJu0/AAetjlHysuIhgAE5nXKqUNgh7jvpE+Jf0SWCR/gg80ieBR/rEtzx5XatUwHvw4EGeeeYZ1q5dS1CQ46a3bduWuXPn0qFDBzIzM3nzzTe54oor2LlzJ61atXJ4n1dffZXp06eX2b58+XIiIiK8+hxcWbFihe121hkDYGDLrv0kZe6ttDYIeyX7RAQG6ZPAIv0ReKRPAo/0iW/k5ubqPrbKBLxms5nRo0czffp0Wrdu7fS4Xr160atXL9v3V1xxBV27duU///kPb731lsP7TJkyhcmTJ9u+z8zMpFGjRgwZMoSYmBjvPQknTCYTK1asYPDgwQQHayO7x9eksCr1ILEJDbjmmg4+b4Ow56hPhH9JnwQW6Y/AI30SeKRPfMt6RV6PKhPwZmVlsXXrVrZv386kSZMAsFgsqKpKUFAQy5cv56qrripzP4PBQPfu3Tl48KDTc4eGhhIaGlpme3BwcKX+gJZ8vITYcADO5RbKm8SPKvtnQLgnfRJYpD8Cj/RJ4JE+8Q1PXtMqE/DGxMSwa9cuu23vvvsuK1eu5H//+x/NmjVzeD9VVdmxYwcdOlStUdK6RVUazmbJpDUhhBBCiIrwa8CbnZ3NoUOHbN+npKSwY8cO4uLiaNy4MVOmTOHkyZPMmzcPg8FA+/bt7e6fkJBAWFiY3fbp06fTq1cvWrVqRWZmJm+99RY7duzgnXfeqbTn5Q22smQ5EvAKIYQQQlSEXwPerVu3MnDgQNv31jzacePGMXfuXFJTUzl27JhH57x48SITJ04kLS2N2NhYunTpwpo1a+jRo4dX2+5r1rJk57ILsFhUDNal14QQQgghhEf8GvAOGDAAVVWd7p87d67L+0+bNo1p06bZbZs1axazZs3yQuv8yxrwFlpUMi6ZqF208poQQgghhPCMX1daE86FBhmJCdM+j0hagxBCCCFE+UnAG8DqRGt5vGeyZHlhIYQQQojykoA3gNWJLKrUIMsLCyGEEEKUW5UpS1YT1Ym2TlwrCngtZji6HrJPQ1Q9aNIHDEY/tlAIIYQQIvBJwBvArKXJzmYXwN4lsOxpyDxVfEBMEgybCckj/dRCIYQQQojAJykNASy+KKWh3snl8NWd9sEuQGaqtn3vEj+0TgghhBCiapCAN4DViQ7BgIVrT84GHJVvK9q27Bkt3UEIIYQQQpQhAW8AqxMVSg/DfuLMZ10cpULmSS23VwghhBBClCEBbwCrExVKAhf1HZx92qdtEUIIIYSoqiTgDWB1okJIp5a+g6Pq+bQtQgghhBBVlQS8AaxOVCibLW05pcahojg5SoGYBlqJMiGEEEIIUYYEvAEsMjSI0OBgppvudHJEURA8bIbU4xVCCCGEcEIC3gAXHxXCT5Ye/DXwXVBKdVdMEtwyT+rwCiGEEEK4IAtPBLg6UaGcuHCJQ/EDaYEBsEBwOIz+WlZaE0IIIYTQQUZ4A5x1tbXMC2dALdQ2mi5JsCuEEEIIoZMEvAGuTlQIAJcupNnvuHSx8hsjhBBCCFEFScAb4KwjvKbMUnV2L13wQ2uEEEIIIaoeCXgDnHWEV81Ot98hAa8QQgghhC4S8Aa4OtHaCK8h54z9jkvn/dAaIYQQQoiqRwLeABcfqQW8IXln7XfICK8QQgghhC4S8Aa4utFaSkO46Zz9Dgl4hRBCCCF0kYA3wFknrcWYM7QNRi0AloBXCCGEEEIfCXgDXExYMEEGhTpKUcAb31L7mis5vEIIIYQQekjAG+AMBoX4qBDqUBTw1mmtfZURXiGEEEIIXSTgrQLqRIYUj/DWbat9lYBXCCGEEEIXCXirgIaRFsKVAu2butYRXklpEEIIIYTQQwLeKqBJWDYAJkM4xDTUNsoIrxBCCCGELhLwVgENg3MAyA6qDeG1tY0S8AohhBBC6CIBbxVQPygLgIuGWhARp23MywBzof8aJYQQQghRRUjAWwVYJ6ydIxbCahXvyMvwT4OEEEIIIaoQCXirgNrqRQDSLTFgDILQGG2HpDUIIYQQQrglAW8VEGPWAtuTpmhtgy2PVyo1CCGEEEK4IwFvFRBh0gLeEwWRmC2qTFwTQgghhPCABLxVQGjeWQDOqLGczymQgFcIIYQQwgMS8FYBSs4ZAM6qsZzLyS+u1JArKQ1CCCGEEO5IwFsVWANeYjmbJSO8QgghhBCekIA30JnyID8T0EZ4z2bnS8ArhBBCCOEBCXgDXdHorkkJJpOIooC3KKVBqjQIIYQQQrglAW+gy0kHIDeoNqBwNltSGoQQQgghPCEBb6DL1kZ480PjASSlQQghhBDCQxLwBrqiEd7C8DoAnMuWKg1CCCGEEJ6QgDfQZWsBL1EJAKVSGi76p01CCCGEEFWIBLyBrmjSWlC0NeAtkdKQnwHmQn+1TAghhBCiSvBrwLtmzRpGjBhBUlISiqKwePFi3ff97bffCAoKonPnzmX2LVy4kOTkZEJDQ0lOTmbRokXea3RlKwp4Q2LrAXAuuwA1LLZ4f95FPzRKCCGEEKLq8GvAm5OTQ6dOnXj77bc9ul9GRgZ33nkngwYNKrNvw4YN3HrrrYwdO5adO3cyduxYbrnlFjZt2uStZleuopSGiLgkAArMFjILgNCioFcmrgkhhBBCuBTkzwcfPnw4w4cP9/h+9913H6NHj8ZoNJYZFZ49ezaDBw9mypQpAEyZMoXVq1cze/ZsFixY4I1mV64SI7xRIXlkF5j5astxxgbHEJafIQGvEEIIIYQbfg14y2POnDkcPnyY+fPn8/LLL5fZv2HDBh577DG7bUOHDmX27NlOz5mfn09+fr7t+8xMbWUzk8mEyWTyTsNdsD6Go8cKyk5HAVafULlksgDwz6X76BkSREcDbN5zkC6JXXzexprGVZ8I/5A+CSzSH4FH+iTwSJ/4lieva5UKeA8ePMgzzzzD2rVrCQpy3PS0tDTq1atnt61evXqkpaU5Pe+rr77K9OnTy2xfvnw5ERERFWu0B1asWGH3vaIWMrJoNbXJS09hJhZQALioRgHwxZo/WHYqmk7xaqW1syYp3SfC/6RPAov0R+CRPgk80ie+kZubq/vYKhPwms1mRo8ezfTp02ndurXLYxVFsfteVdUy20qaMmUKkydPtn2fmZlJo0aNGDJkCDExMRVruA4mk4kVK1YwePBggoODi3dkpcEOMGPgAjFYg12Ai2gBby0lhx9PR/DUHf0wGpw/R+EZp30i/Eb6JLBIfwQe6ZPAI33iW9Yr8npUmYA3KyuLrVu3sn37diZNmgSAxWJBVVWCgoJYvnw5V111FYmJiWVGc9PT08uM+pYUGhpKaGhome3BwcGV+gNa5vHytfzc82o0llLzC60jvLFKNqkZ+Ww/kUXvFvGV1taaorJ/BoR70ieBRfoj8EifBB7pE9/w5DWtMnV4Y2Ji2LVrFzt27LD9u//++2nTpg07duygZ8+eAPTu3bvMpYPly5fTp08ffzS7YopWWTurxpbZdaFohLc22QCkZ+VVXruEEEIIIaoQv47wZmdnc+jQIdv3KSkp7Nixg7i4OBo3bsyUKVM4efIk8+bNw2Aw0L59e7v7JyQkEBYWZrf9kUceoV+/fsycOZPrr7+eb7/9lp9//pl169ZV2vPymmytQsMZBwFvhmpNadAC3oTosMprlxBCCCFEFeLXEd6tW7fSpUsXunTRqgxMnjyZLl268MILLwCQmprKsWPHPDpnnz59+OKLL5gzZw4dO3Zk7ty5fPnll7YR4CqlaIQ3JziO0tm5F9VIAGqRTf3YMHo0i6vkxgkhhBBCVA1+HeEdMGAAquq8usDcuXNd3n/atGlMmzatzPZRo0YxatSoCrYuABTV4G3bohns0qasWV+tC0QD2gjvhCubyYQ1IYQQQggnqkwOb41UlNLQrEkz3hvTlcTY4rSFjBIjvO+tOsyh9Gy/NFEIIYQQItBVmSoNNVJRSgNRCQxrX5/ByYlsTjlPelYejS0JsATijLmcyyngjo828tV9vWkSH+nfNgshhBBCBBgJeANZ0QgvkQkAGA1KcemxHG20N0rNoW1COPvTLzH6w018fX9v6sWE2QLjhGgtv1dSHoQQQghRU0nAG8hsI7x1y+4LK67c8Nno1twy/xApZ3O44Z3fAEjPKl4quX5sGFNHJDOsfX2fNlcIIYQQIhBJDm+gslgg56x2O9JBwGsMglAt6K0bdIn/3tOTuIgQ0rPy7YJdgLSMPB6Yv41lu1N93WohhBBCiIAjAW+gunQBVLN221HACxBRW/uae556MWFO0xaslR2mf7cXs8V5VQwhhBBCiOpIAt5AZU1nCK8NRidL54UXBbyXLrA55TxnsvMdH4cW9KZm5LE55bx32ymEEEIIEeAkhzdQZRcFvEUT1hwqEfCmo29pYVmCWAghhBA1jYzwBqqiRSeIchXwFq2udum87qWFZQliIYQQQtQ0EvAGKtsIbx3nx5QY4e3RLI76sWFlliC2UkCWIBZCCCFEjSQBb6DKsa/B61CJgNdoUJg6IhnAYdCrAs9fmyz1eIUQQghR45Qr4D1+/DgnTpywfb9582YeffRRPvjgA681rMZzVYPXKqJotDZXm4g2rH39MksQl3TsQq43WyiEEEIIUSWUa9La6NGjmThxImPHjiUtLY3BgwfTrl075s+fT1paGi+88IK321nzZHs2wmtVegnihOgwDp/J5rnFu3n9pwN0b1qby5tIWoMQQgghao5yjfDu3r2bHj16APDVV1/Rvn171q9fz+eff87cuXO92b6ayzbC61nAC8VLEF/fuQG9W8RzR8/GjOiUhNmi8vDn27mQU+CjRgshhBBCBJ5yBbwmk4nQ0FAAfv75Z0aOHAlA27ZtSU2V1by8wjbC6yKloUSVBlcUReGVG9vTrE4kpzLyePJ/O1FVWYBCCCGEEDVDuQLedu3a8f7777N27VpWrFjBsGHDADh16hTx8fFebWCNpKolJq25CnitI7wX3Z4yOiyYt0d3ISTIwM/70vl4XQpmi8qGw+f4dsdJNhw+J6uwCSGEEKJaKlcO78yZM7nxxht5/fXXGTduHJ06dQJgyZIltlQHUQH5mWAuWjVNT0pDfiaYTc5XZCvSLimW569L5vnFu3ll6T7eW3WYcyXSG+rHhjF1RDLD2tev6DMQQgghhAgY5Qp4BwwYwNmzZ8nMzKR27dq27RMnTiQiIsJrjauxrOkMIdEQHO78uPBaxbfzMlzX7C0ypmdjFm07wbZjF+2CXYC0jDwemL+N98Z0laBXCCGEENVGuVIaLl26RH5+vi3YPXr0KLNnz+bAgQMkJLgYkRT66ClJBmAwQlisdjvXdR6vlUWFkxcvOdxnTWiY/t1eSW8QQgghRLVRroD3+uuvZ968eQBcvHiRnj178u9//5sbbriB9957z6sNrJFsq6y5CXjBaaUGZzannOd0Zr7T/SqQmpHH5hR9AbQQQgghRKArV8C7bds2+vbtC8D//vc/6tWrx9GjR5k3bx5vvfWWVxtYI+mZsGZlq9SgL+BNz8rz6nFCCCGEEIGuXAFvbm4u0dHRACxfvpybbroJg8FAr169OHr0qFcbWCNZA15XE9asbCO8+kZkE6Idr8JW3uOEEEIIIQJduQLeli1bsnjxYo4fP85PP/3EkCFDAEhPTycmJsarDayRbCkNngS8+kZ4ezSLo35sGIqLY+rHhtGjmazGJoQQQojqoVwB7wsvvMATTzxB06ZN6dGjB7179wa00d4uXbp4tYE1km2EV0dKQ4RnKQ1Gg8LUEckAToPeif2aYzS4ComFEEIIIaqOcgW8o0aN4tixY2zdupWffvrJtn3QoEHMmjXLa42rscozaU1nlQaAYe3r896YriTG2qctBBu1IPeDNX9xykklByGEEEKIqqZcdXgBEhMTSUxM5MSJEyiKQoMGDWTRCW/J8V1Kg9Ww9vUZnJzI5pTzpGflkRAdRquEKG79YAOHz+Qw9uNN/O/+PtSODPGw8UIIIYQQgaVcI7wWi4UXX3yR2NhYmjRpQuPGjalVqxYvvfQSFovF222seXLOal89mrTmWcALWnpD7xbxXN+5Ab1bxFMnOpR5E3pSPzaMw2dyuGvuFnLyC2UJYiGEEEJUaeUa4X322Wf5+OOPmTFjBldccQWqqvLbb78xbdo08vLy+Oc//+ntdtYcBblQkK3d9qgsmXfq5jaoFc68u3vwt//bwI7jF/nb+xs4n1NAWmZxmTJZglgIIYQQVUm5Rng//fRTPvroIx544AE6duxIp06dePDBB/nwww+ZO3eul5tYw1jTGYLCIDTa/fEVGOF1plW9aD4Z350Qo4G9qZl2wS4UL0G8bHeq1x5TCCGEEMJXyhXwnj9/nrZt25bZ3rZtW86flxW6KiS7xKITio5KCbaA96JXm9GpYS0iQ40O98kSxEIIIYSoSsoV8Hbq1Im33367zPa3336bjh07VrhRNVqOBxUaoLgsWX4mmE1ea8bmlPNcyHV+PlmCWAghhBBVRblyeF977TWuvfZafv75Z3r37o2iKKxfv57jx4+zdOlSb7exZvFklTWAsNji25cu6qvdq0N5liA2W1S7qg89msVJPV8hhBBC+F25At7+/fvz559/8s4777B//35UVeWmm25i4sSJTJs2jb59+3q7nTVHyZQGPQxGLejNy9DyeL0U8OpdWjgyVPsRWrY7lenf7SU1Qya3CSGEELpZzHB0PWSfhqh60KSP9rddeFW56/AmJSWVqcawc+dOPv30Uz755JMKN6zGsqY06B3hBa1SQ16G1yo1QPESxGkZebjK0n3si+0MbJvAdztTyxxnndz23piu5Qp6ZcRYCCFEtbZ3CSx7GjJPFW+LSYJhMyF5pP/aVQ2VO+AVPuLJKmtW4bXhQopXKzVYlyB+YP42FLALZq3f148NIzUjjyU7HVdrUIuOnf7dXgYnJ3oUrMqIsRBCiGpt7xL46k4oPVyUmaptv2WeBL1eVK5Ja8KHcjxMaQCflCYD50sQJ8aG8f6Yrqx7+iomDWzh8hzlmdy2bHcqD8zfZhfsgpRDE0IIUU1YzNrIrsNrqEXblj2jHSe8QkZ4A012OVIarJUacr1fMcHREsQlUwta1dNRKxj9k+DMFpXp3+11+ivA0YixpD4IIYSoUo6ut09jKEOFzJPacc1kXpQ3eBTw3nTTTS73X7x4sSJtEVBihNeTHF7fjPBaWZcgdkTv5La6UaG2264C1M0p58uM7JZUcsS4d4t4SX0QQghR9WSf9u5xwi2PAt7Y2Fi3+++8884KNahGMxdA3kXttkeT1nwb8Lqid3LbtCV7eGJoG8wWlRe/dxygDk5OZMNf53Q9blrGJVvqg7cnywkhhBA+FVXPu8cJtzwKeOfMmeOrdgiAnLPaV8UIYbX03y+8KKXBi1Ua9NIzuS0s2MCf6dlM/Ox3h+dIzcjj/vnbiAoNIju/UNfjPrtoFxacZz+Vd7KcEEII4XNN+mjVGDJTcfyXTNH2N+lT2S2rtmTSWiApucqawYOu8eMIL7if3LZpytXc37+52/Nk5xcSHWokLNj1c1eAXJOFPJPF6TGOJsuZLSobDp/j2x0n2XD4XLVfFrk6PV+zRWVTynl+P6uwKeV8lX4uAc1ihpS1sOt/2leZMCOEbxiMWukxh4oGaYbNkHq8XiST1gKIYltlzcPFI/wc8IL7yW39Wyfw/uq/3J7nvTGXk51fyAPztwFlR4wB3h7dhT9PZ/PmLwfdns86Wa6m5fr66vl6e4KgnvPZPxcj8w5urdZ95zdSD1SIypU8Uis9tnCCltJoFZOkBbvyvvMqCXgDiTWlwZMJa1CiSoP/Al5wPblNb5WGczkFXN+5Ae+N6VomYEssEeTEHT6nK+BdvieNc9kFvPR92coPVTXX112Q6KvcZm8H0XrO56vnIpU9SpF6oEL4R/JI+KkeZBzXvr96OvR5WEZ2fcCvAe+aNWt4/fXX+f3330lNTWXRokXccMMNTo9ft24dTz/9NPv37yc3N5cmTZpw33338dhjj9mOmTt3LnfddVeZ+166dImwMH0VBfyleITXw4A3AEZ43dFbzcF6nLsRY72T5X7YlcYPu9Ic7nNV5sx6+Tw+5Ty9WyY4DIb8ETS5CxLLU9ZN7+N6M/DUc77ByYk+ey41abTfLbf1QBWtHmjba+WPsBDeZjFDVona8tGJ8j7zEb8GvDk5OXTq1Im77rqLm2++2e3xkZGRTJo0iY4dOxIZGcm6deu47777iIyMZOLEibbjYmJiOHDggN19Az3YBUrk8Nbx7H7WgLcgC8wmMAZ7t11e4C5AVdBGcHs0i7NtczVi7G6yHMB9/Zuz5cgFfj/q/IOA6zJnzi+f+yJo8sbIbWx4sEdl3fS2y5uBp7vzATzx9R9cVj/F689FKns4IPVAhfCf7HSwFNp/L3zCrwHv8OHDGT58uO7ju3TpQpcuXWzfN23alG+++Ya1a9faBbyKopCYmOjVtlYGpTw1eAHCYrHVRLh00fMc4EqgJ0CdOiLZo5E662Q5V6kP3+446TLgtdpx/AIXcwt48L/ugyFPgybP81Q1nozcAkz6fDuqqm8yl94UE/C8NnJFzwfaBMYtR/RdsSj5XFy91r4a/a7ypB6oEP6TccL++xwJeH2lSufwbt++nfXr1/Pyyy/bbc/OzqZJkyaYzWY6d+7MSy+9ZBcol5afn09+fr7t+8zMTABMJhMmk8k3jS/B+hhq0Se7wvB4VA8fNygsFiXvIqasdAit5e0mesWgNnX4z22deHnpftIyi1/vxNhQnh3elkFt6nj8eg9qU4cBrfqy9egF0rPySYgOpVuT2hgNCiaTifgIfT/iM5cdwKC4LnM2bckeujSM4fnFu90ETXsY0Coeo0Hhpz2nyz7fmFCeu6YtQ9tp9RV/2nOah7/Y6TSA/s9tnTBbVLdBYqEHlQviI4J0v9apF3N0H2cyxXjtfFe0iOO3w+5L7Z26kIvJZHL7Wm/SGbhvOJROzxJXGqo7JTxe1x+C0r+XrD8/lfE7UugjfRJ43PWJcuGo3fvPknUas/Sfbp78rCuq3iEhH1MUxW0Or1XDhg05c+YMhYWFTJs2jeeff962b+PGjRw6dIgOHTqQmZnJm2++ydKlS9m5cyetWrVyeL5p06Yxffr0Mts///xzIiIiyv2cPDVg37PE5h1nfYsnORPTwaP7DtrzBFEF6axt9Rzno1r7qIXeYVHhcKZCpgligqFFjIqvBtQsKkzfZuRiARSPJZekEqRox1kc7nfOgIUehv0kcJF0arHZ0hZLUaW/By4zk2+GT/60llgreW7tLXd3awsd4lS37TOgv203NDbza5qBDBfnqxUCU7uadb/mBzMU3t7rPqdsUrKZVrHuf53oPd+Dl5n5/LDB5Wtj3d4o0sLxHOsxZV/rvvUsHM5UOHXJfbm/O1uZubxOQPxarByqhSF7JhNmOu/0Vb4UHMeKdm+AIpUshfCmFqd/pP2pBagoKKicju7AxpZP+rtZVUZubi6jR48mIyODmBjXAy5VMuBNSUkhOzubjRs38swzz/D2229z++23OzzWYrHQtWtX+vXrx1tvveXwGEcjvI0aNeLs2bNuX0BvMJlMrFixgpEHJqPknsV0zyqo196jcxjnDMFwahuFf5uP2nqYbxpaRVlHUMFxKsV/butEdn4hzyzao/ucQw2bmRo8jySleATylBrHdNOd/GTpQZABDIqBArPzWsF1okIY27MRs3457MnTcWn+3d24mGty+Hyt7rmiCU8Pa6P7nCcuXGLQrLU4G0DW8q9D+XVyP905vL1nruJCrpMRjxLn+3lfutO+U4H+reuw7uBZzF78LTb/7m41aoQXQNn/PcaFdwFqqY8LRekgN89BbXud3X2sv7cGDx5McHDgzRuoiaRPAo+7PjEsfxbjlv9DTUhGSd+LWq8Dhff86oeWVk2ZmZnUqVNHV8BbJVMamjVrBkCHDh04ffo006ZNcxrwGgwGunfvzsGDzktYhYaGEhoaWmZ7cHBw5f3SUC22ldKCY+uDp49bVJosqCDT8/tWc9d1bkhQkNFlru+Gw/qWNH5mWBu2L/+M94Jnl9mXyHneC57NA6ZH+cnSA3Ae7AKczS7QHey+elN73vrlkNtJf9aKEo6eb0SIkdwCM//dfIIbL29EuyTXS4UDZOWZeODzHbZgt3T+NUXfTx3RjrDQEF3P5WzGJUxOItTifG7tfHr6buG2Ezz+1U63jzuqawNW/3mWs9n5Tit71C/xGtYoHW4EoxG+fwxyz9o2K0X1QINclCSr1N+TQhfpk8DjtE+ytQmjSlJXSN+LknNG+s4DnrxWVTLgLUlVVbvRWUf7d+zYQYcOnqUIVLbQwiwU1QIoEOFhlQaoEqXJ/KmiZc6sAeXdfZpwYdVnoFImJcBQlBoxPeQzOvcbzczlh9y2q05UCGezC9we1zQ+yqNJf46eb9fGtbhn3lbWHjzLvZ9u5dtJV1I3uuwHPSuT2cJDn29nf1oWdaNDeXRQK97+9VCZPFgFiIt0fp7S55z0+Xay8wtpVDsck9lSKp+7bKUL63PZcCid5Ws3MaRvT7ugNEhncNq3dV2uTq7n8DW0urdv85oX7Folj4SCbFj8gPa9IRge+QOMVf7PhBCByzpprUEX2DEfcs6AxeLZaqtCF7/+JsvOzubQoeKgICUlhR07dhAXF0fjxo2ZMmUKJ0+eZN68eQC88847NG7cmLZt2wJaXd5//etfPPzww7ZzTJ8+nV69etGqVSsyMzN566232LFjB++8807lPjkPhRZmaDci4sr3Bya86BKsBLxOVbTM2dQRyYSc3Eg9zjlOKUULehM5R7/QQzhbNLKkN2/twhP/26mrXJvRoLitSuHu+b59e1dufPc3/jqbw/3zf+fze3sSGlQ2n1ZVVV74djdr/jxDeLCRT8Z1p0PDWG7r0bhEEB3KV1uOs2jHKf6+YDtLH+lLXKTrUd6ZP+7n96MXiA4LYv49PWlYO0JXLWOjQaFnszjO7VPpWeoYT2o8924R7/A1DDFq6SefbTzKqG4NiQmroSMsmSeLb1tMkJ9ZvLCNEML7Morec/U7a19VM+RdlPedD/g14N26dSsDBw60fT958mQAxo0bx9y5c0lNTeXYsWO2/RaLhSlTppCSkkJQUBAtWrRgxowZ3HfffbZjLl68yMSJE0lLSyM2NpYuXbqwZs0aevToUXlPrBxCTVplCI9LklnZRnjdz2oXjukpc8au33Sd67LoXOrHxrkNZHu1iK/wyK0nC17ERgTz0bhu3PDOb/x+9ALPLtrN66M6oij2939/9V8s2HwcRYG3bu9Ch4Za+kPpILpjw1rsPJHBX2dzeOLrnXx0ZzcMTtqybHcqH61LAeBff+tEk/hIAN01dJ3xtMazo9ewRd1Ibnx3PSlnc5j85U4+GHu50+dRrZUukZSVJn94hfCVwvziMmS1m0FYLS3YzU6X950P+DXgHTBggMu6oXPnzrX7/uGHH7YbzXVk1qxZzJo1yxvNq1ShhUUBb3lr6EpKg1e4u3xOVD1d5zFEJzJ1REtdgayuQLsEVyPVejSvG8Xbo7syfs5m/vf7CVolRNGxYS1b8HcmK4+Zy/ZrbbwumcHJzp9zZGgQb4/uyg3v/sbK/el8vC6Fe/s1L3PckbM5PPn1HwDc27cZQ9t5r052eWo8O3oN3xvTlVHvb+Dnfad5+9dD/H2Q46ou1VqZgPcU1Ev2T1uEqO6sV1SCwrUANypBC3hz0oG2/mxZtSTJWQHCltIQWc6AN0JSGrzF1eVzmvSBmCTITMVxFqii7W/Sh2EGo+5AtqIjt57q17ouz1+XzPTv9vLqj/sdHnPXFU0Zf0Uzt+dKTorhheuSeW7xbmYu20+3prXp0ri2bX+eycwD/91GVn4h3ZrU5qlh3v9F7umHBkc6NqzFyze056n//cGsn/+kQ4NYBrbVd8XFH8tM+4T18mpQGBTmaSO8QgjfsH7AjG0AiqJd4T37p6y25iMS8AYIr6U05EpKg08ZjDBsJnx1p4OdRQHOsBm2tdA9CWQrOnLrqcQY17mv3Zvov6R2R8/GbDh8jh92pTLp8+18N+lKDpzOIj0rj8XbT7IvNZP4yBDeHt2VYKNvJmN440PDLd0a8ceJi8zfeIxHvtjOogevID0rv0Kr5FUZqgoZx7Xb9TvD8Y2QlerXJglRrVk/YMY00L5ar/DmnHV8vKgQCXgDhG2Et8IpDRe90h7hQvJIuGWeNpu9ILt4e3htGPGmtr+Eyg5k9TBbVF78fq/T/Qrw0g97Gdpe3zK7iqLw6s0d+OPkRY6fv0TvGb+QX2hflm1MryYkxuqbYFZe3nitX7iuHXtPZbLt2EWGzl5jt4Jd6UDW02WmA1peRvHPc8NuWsCbKQGvED6TaR3hbaR9tV7hleWFfULqXgQI701ak5SGSpE8EloM0m4bi4K4tteWCXYD1Wady+xuTtF/xSAmLJg7ejYBKBPsArz1y0GW7Q78ACokyMAt3bQ/QKWXa7YGsst2p2K2qEz/bq/TZaYBpn+3F7MHSz77lfXyakQ8xBWlsgRgSoPZorLh8Dm+3XGSDYfPVZ3XV4jSSqY0QPHff0lp8AkZ4Q0QxZPWKhjwFmRBYQEE6VsEQFTA+b+0r11Gw9ZP4Mg6/7bHA+lZzoPd8hwHWiDy6fojLo+Z/t1eBifrGzX2F7NF5c1fHC9UYw2tHl6wndoRwaRnOa+hXPJDQ6CN8Dtk++PbEKKTtNsBltJQbdJHhIDilIbYhtpXW0rDGf+0p5qTEd4AUTxprRyLTgCExWLLIc276I0mCVdUFc4XrZLWZSwoRriQAheP+7ddOnlSu1YvX4wa+4O75wFgMqsug92SPPnQ4FclL69GF1XRCKCA15o+UrpvSo66C1GlWD9kxsgIb2WQgDcQqGrxCG95UxoMxqKgF0lrqAxZqWDK1QLdxA6Q1EXbfmStf9ulk7V2rbNxVgVt5Mxau1YPX4wa+4Pe9t3ctYGu4zz50OBXJf/4RheNlmafBovZf20qUu3SR4SA4rJk1hHeSJm05ksS8AaCvIsY1KI/KuUtSwbFpcmkUoPvnStaIbB2UzAGQ7N+2vcpVSPgtdauhbKLxjmrXeuOL0aN/UFv+27q0tDrHxr8qmRKQ1QCKAZQLQFxebW6XD0QwiYvQ1vJEBxUaUjXriIKr5KA198sZpSDPwGgBkdowVN5ycS1ymMNeONbal+b9dW+pqypMr+orLVrS1dOSIwNK1d1AV+MGvuD3udhXSXPuq00Fc8/NPhVyYDXYCxeZCXzlP/aVKS6XD0QwsaavxtWC0KjtNvWK7yFeZCf5ZdmVWcyac2f9i6BZU8TVPQHRTHlwuz2Wp3X8sz2l4C38pwryt+Nb6F9bdQLDMFaHuSFFIgru9pYIPLmghflWfEsEHnyPJwteAHQoFYYg5O9t6Kcz2WUKpEUnail7gRApYbqcvWgpGqzWIkoH1s6Q6PibSEREBKllQfMOQNhMf5pWzUlAa+/7F1StHhBqdHAzFRt+y3zPA96w62rrcllPZ+zjfAWBbwhEdCwOxxbr43yVpGAF7xbJ9gbK54FAk+eR+kPDREhRh7/aicnL+bx5ZbjjO7Z2B9PwTMWc/FIrjWfMDoJ2B4QE9e6N61NRIiR3ALH+cQKWt8E+tUDK6k2IWyLvMSWmgsQWac44LX+fRFeIQGvP1jMsOxpHC9NqwIKLHtGq+tatGKXLjLCW3lKpzSAlsd7bL2Wx3v5eL80KxBU9jLJvlKRVfIeG3yJ6d/t5d/LD3Bdp/rEhFUgVakyZKWBagZDUHFpxACq1PDRuhSnwS5UrfSRarVYiSi/0iXJrCIT4MIRqdTgA5LD6w9H17vJi1O1yx1H13t2Xgl4K4e5UPuFBKUC3qqXx+sr1gDw+s4N6N0ivkoEIo6U93mM6dWE5nUjOZdTwDu/HvJxK73AVqEhqfhDtrVSg58D3iU7TzHjx/0A/O1ybaKgIyFBgf/nTKpNCJvSJcmsrB84ZbU1rwv83xDVUfZp7x5nJVUaKsfFo2AphKDw4gL9oKU0BIVpv6jO/um/9gm/CzYaeO7aywCYs+4Ix87l+rlFbtgur5bIJ4yxBrz+y+Hd9Nc5nvhqJwATrmzG63/rxLqnr2LBvb1487bOLLi3J7f10Nr89wU7OJQe2BN9pNqEsCldkszKWqkp2//VUaobCXj9wTr72VvHWckIb+UoOWHNUOItFBQKjXpqt1PWVH67REAZ2CaBvq3qUGC28OqP+3zyGF5bZrdkhQYra0pDpn9GeA+lZ3HvvK0UmC0Mb5/Is9doHyDsR93r8OLI9vRoFkd2fiH3fLqVi7n6FgTxB6k2IWwcveegRC1eCXi9TQJef2jSR7t06KrwUUwD7ThPSMBbOUpPWCvJVo9XAt6aTlEUnrs2GYMCP+5OY9Nf57x6/mW7U7ly5kpu/3Ajj3yxg9s/3MiVM1eWb8UxR6NNlZzSUDJ4/3F3Knd+vJnMvEK6Nq7FrFs7Y3CSThISZOC9O7rSoFY4R87lMunz7RSaLZXSZk8Umi2sO6hvQYGqVG1ClIPFUvyeq0YpDV77AO4jMmnNHwxGrfTYV3eCs8JHw2Z4NmENSlRpuFjxNgrnHE1Ys7IGvEfWar/UDPKZsiZrkxjN7T0a899Nx3jph70seehKp4FbSe5KVnl94lPRaJMlugGbDp8jPSuPpJAwuoNW9aUwX7uC4SOOqhYA1I0K4aNx3QkLdv27MD4qlI/GdePm99az7tBZ/rl0H89dm+yXiZOO+u7EhVwe/XIH249ddHv/OlEhVabahCin3LNgLkAb3Eqy31dFUxqqQuURCXj9JXmkVnps2dP2E9hikrRgt1x1eGtpX6UsmW9ZA944ByO8SV20OoqXLsDp3VC/Y+W2TQScyYNbs2THKXafzGThthP8rVsjl8e7+8PhbuKTgjbxaXByov4AryiH94nl5/gme6PtbAfCggnFpI3y1m5qO9xsUdmUcp7fzyrEp5ynd8uEcgeTzoJ3gDPZBWxOOafrD+Zl9WN445ZO3D9/G3N+O8I3206Scclk218Zf3wd9V1seDCXTGYKCi1EhwUx6vKGzP3tCOC4Tk92fiF7TmXQsWEtn7UzkNWI+sTWnPnoxLKLTVXBEd6qUnlEAl5/Sh4Jba+l8K817Fj7E537DiWoeT/PR3atrCkNBdlQWABBId5rqyhmy+F1MMJrDIbGveHQCm2UVwLeGi8+KpSHB7XklaX7eW3ZfupEhZKZZyr3yK3RoOie+KS3vnLB+WOEALtzSha6VzhtqUVjwxk27txDrwFNbW0sDuqMzDu4tdzBpKvgXWuBZ8H7sPb1ua5jfb7/I9Uu2AXf//F11nfWdrSuF8Wcu3rQoFY4PZvFla3xHBNGVGgQh85kM+ajTXx+by/aN4j1ejsDOaCsCqOEXpHhJJ0BSuTw6kt/8TeffAD3EQl4/c1gRG1yJSf3ZNKpyZXlD3ZBW6LQmiKRd7H4k6LwnoJcbTU1cBzwgpbWcGiFlsfb+6HKa5sIWOP6NOXDNX9xJruAu+ZusW33ZOQW4KH/bsOsMy2u5MQnV0GOOS+bkIIMAE6p9gFyGnE05gzfrdtG937XsGJvmldHcjypWqAneDdbVLYecTyHwZd/fN0F7gBZeYUkxmi5uc5qPF8ymRn3yWZ+P3qBMR9v4vN7etEmMdprAWogB5RVZZTQK5xNWIPigDc/E0x5EBzY+dzefg/7kgS81YnBoKU1XLqglSaTgNf7LqRoX8NqFZeBK81aj/foeq1mr1HeZjXdr/vTOZNdtnqA9Y/5Sze0JyvP5PIPB6A72AVYuS+dK1vWYcuR8y6DnD/27qULkKlGkE2E3TnSVe2qUeil03y6PoV3Vx326kiOt6sWbE45T1pm5f/xdfdHHweP62iFw6jQIObe1Z07P9nM9mMX+dv76wkPMXK2xM9OeQNUTwNKb48Eu/zQVYVGCb3CWUkygLBYMIZoOb456VArsFdqrEqVR+QvcXUTXlsLeKVSg2+UnLCmOPnFm9hR+6WVlwGpO6Hh5ZXXPhFwrH/MHbH+gX9u8W7d53vlxvb8Z+Uh0jLyXI4ofrvzFD/uTqPAQcUCa5Dz/HXJmA/upAtwUi0bAJ4uCngTlAu8+L3r0mrlCSYPpOmrm6u3aoG//vh683Gjw4L59O4ejPjPOo6eyyWn1Apz5Rnx9DSg9PZIsLvzVaVRQq9wNcKrKNpqa5kntIlrAR7w6n1vBkLlEZlCXt3YKjVIwOsTrio0WBmM0ORK7fYRKU9W0+kZ/QOoE6lv+eFmdaKYOiIZKFvYUCn6d1//5rRPinEY7IIWQKjAi9/v5dChAwCkOgh404oC3nrKBWLC9I2PlE6lcFSmKLegkCe+3sm7qw67PJeCFhjprVqg949qyaWeK1pKKb/QzM/79C0SpLd9kSFB5JkcL6VcnhXZPAkorSPBpY+3Btqelr1zd74Xv9vD6z/t13WuQBgl9Apnq6xZRdbRvlaBWrydGsUS6mKVQ0/fw74kI7zVja0Wr45KDRazdtk9+7S2yEWTPhXLIa4JXE1YK6lZPzjwg5bHe+Vjvm+XCFh6/0g/e20yr/10wOnIrQIkxhZfCn5vTNeyE59KjJptaH2W2z/c5PZxO0VnQl7Z/F0oHuFtFJTBe3dczh0fuT/fgbQszBaVFXvTHI7qTejbjAWbjnH4TA4GBa7toE0yA4cFGpk6Iln3ZewezeKoHxvmdvR7yjd/MG1ke1RV5cXv9Y1kOrokfyAti8lf7WC/m5Hqkn2nx+aU85zOzHe639MRT70/g499sZ3M/EKvpRboyUv/pKhihR6BMEroFa5SGqDKVGrIM5l58L/byC90/MG6PO9hX5KAt7rRu/jE3iVOSqLNLFsSTQLjYrYR3uauj7Pm8R7bKBUzariSf6QNWOhh2E8CF0mnFpstbbEUXWhLjA1n6ohkHpi/zVl1brs/HM4mPln3p2c5D5hKurJuPhyHU2qdMo+bjvb75LLIbMKax+sKJt9ddZhF206S6iCXNjUjj5eLUiPqxYTy5m1d6NU8nms7lr3knViOS+hGg+LyNVSB+KgQ0jLzuX/+7w7P4ShlwNEl+ejQIHJNhZgtEB8Zwt+6NeT/Vv8FDh4XPPuj7+3UjAInAUlpaW5+ZhwF2q5yc/Ve3RjRsT7rD5/jfE6B05+tejGhATFK6AmH5fsspuLluosC3tKvYc/IutpvhWzfBrwVydO+VGDm3nlbWXfoLGHBBu7r14Kvth6v8HvYlyTgrW4idKQ07F1StOhFqV8tmana9lvmFQe9ngTGNYGelAaAupdBRB2twPjJ36FJb9+3TQQk66hjp6w1vBA8jySl+OrLKTWOF013sjO6n+6R25IcTXyy0jsaFmvSLscPvaIbi3aG2T2uJTIRTBBZcBbcBJMA13dO4pd9px0GuyWFBhn4btKVJLipWlCeUaFh7eu7fA0HtEngPysP8s6vjtMpSo9kOqtMkZVfCEDHhrF8Mr47daJC6dyollcCd719F1FiQQ5HwZUCzF1/xO3S1gqQEBPKNe0SmbPhqNvHPV3Uv65ycwddVo9f9utL9bg6uR7Xdqzv8GfLKiTIQJ7JTGRo1QhbnJXvm3FVDP1RtYlpEXUcvoYvRl7iTvBpSoMnedqlA+PkpBjunbeVzSnniQgx8sn47vRqHs/fB7UK2JJ3IAFv9WMd4c11ktJgMWsBrKuLVsuegbbXwv4f9AfGNUHuecgtWh7W0aITJRkM0PRK2LtYq8crAW+NZTQovNv1BJ3Wzy6zL5HzvBs8m51dm+seudXL3eV962X2mAItKOnUrj3rhvW2f9wGITBjklbbOz/LbTA5rH19ft53mns+3eqybfmFFg6fybEFvNbXyVsTkty9hle2rOs04IXikcwb313Hn6ezXY5on8nKp3ZEiK7H1UtvasYT/9vJMzkFxIYF89IP9sFVQnQo8VEh7EvV0i2S68ewNzXT6YeV6SPbERseoivgffH7PXy38xS/7C87Apmakcf987cRHRZEVl6hruebEB1G7xbxDn+2EqJDyS0wc/z8JR76fBsf3dmNIGNgTz9yVRHj3cXb6R8KxDRg2d7TDo87mhcBwZB66hi+GBv1pGKHo8A42KhgMqtEhwYx9+7uXN5EG2jz5nvYFyTgrW7cpTQcXW8/WluGquUXrXkNtnyMrsC4pqQ3nNcuVxJdH0Kj3B/frJ8W8Kasgf5P+bRpIoBZzHTZMwNVKTvJzKCAikKXPTNh8Bjbe8kbfzjcXd4HmHpdW5TFxUXwHT5uaIxWEzQzFepG24K6DYfSWb52E0P69rRbaS0nX1+Q4+sJSK5eQ72P/ceJTLfH6Ck35ik9qRlJsWGcyshjyje7HJ4jPSuf9Kx8ggwKL4xIZmyvJvy0p2xedWKpWtDuAm0FOJ9jchjslpSVV0hcRBD5hWqZShMlz1Uyt9nZB4ZdJzO47YMNrDpwhue/3c0rN3ZAcVYlx8/c5S3XV7RBE0tMA6fHnVG1BUdOnjhGgkWttJrReq9umIrqIz40sKUt2K0KAvtjkvCcuyoN2fouMbFqhpvLKUWB8dH1HjWvStM7Yc2qWT/t6/HNYLrkvXZYzJCyFnb9T/tqcfzHRASIog+Zzv5kKT58L1lHZBNj7S+RJ8aGaaM4zYLBnA8oWqqSI9GJ2tes4tn5RoNCz2ZxXF5HpWepEcyqUKZI72MPaquvlrkvgndXfff+mK6sfmogz157mdOfK6vakSHc0bMJiqIwrH191j19FQvu7cWbt3Vmwb29WPf0VbbRPGugDc4rgLx5W2eeGNJa13N46/au/PuWTrb7lj4flM1ttn5guL5zA3q3iMdoUOjcqBb/ub0rBgUWbD7Ou6sOV7i6hq+4y1uuX5TStPSY0elxZ9EC3hjzBTan6JiA7sX2Wa9ujP5wA098vdPlFYZPNxwJmNddDxnhrW7cVWmIqqfvPNGJxYn1rugNoKsDW/6um3QGq/iW2mhwVqoW9DbvX/E2SE511aP3PeKj95LLy+wniyZuRdfXlsV2JLo+nP1T3+8D9KdS+HMCkt423n1lM7cjmeC74N1dikT7pFiXAQloKReejEDrSVv5dsdJXe0/l1PA9Z0beJSX7szg5HpMG9mOF77dw+s/HeCDNX/ZLR/tqk5wZS6n7O7DT5KiLRmcYqrt9JhzqrbEdx0lg33l+DDl6vmmnM3WdY5NKe5Lm1a12sgS8FY3toD3ouP9TfpASCQU5Dg5QdFIzw3vwTwdAZTeALo60DthzUpRoGlf2PWVlsdb0YDXk8mGInDofY/48L3kNMjJcFMeCbSAFyDLVSqU/WN5Um3CH/S2sZebyhSVEbx7IzXD0xFod4G2p6P43sptvrN3U9YePMuKvaftgl1wviCHL5ZTdhZQqqrKkbO5Lu9rTWlo3LQlHHJ8zNmilIY4JZuESM/CNGfP99lrL+N0Zj7/1lnz+IqW8fx26Jzb46pSbWQJeKubCDc5vHu/dR3sAgyboU24iknSgilnv+pjkrQAuqbwNOAFLa1h11daHm9FeDLZsKbkVFcVTfoE7nvJ1YpPVraUBn0jvKBvlNDf9LYxkIN3X6aPuAq0yzOK743cZrNFZdeJDIf7nK0Y58lyyno4Cyjv79+CX/ans+ZP15UVGhQFvNdc2YMZZ4IcvoYXiMasKhgVlR4J+krKWdvm6PmmZuQx6fPttu+DDAqFTlIRrH334ICWugLeqlQbWQLe6sY6wluQXbb+a/p++HaSdrvtdXBqm4NL4zOKRwmHzSwaUXRUKEaFIf+sOcGVqhbn8Lqr0FCStR7vyd8hP1vfZDdH9E42PLq++DFFYDAYS7yXSivxIdMf7yVbwOtkxScozu3N8myFLW+WGvMVPW0M5ODdX+kj/hrF35xynjQXJe+s+afzNhyhV/N4Xvh2j0eLaLhLfXAVUE5dsgeAEKOBQZclsGx3mu2xrBSKR3iDazdi6ojaDl9DCwbOE0NdMjDmnoFY9z9jriajWRkUeOmG9tQOD+Ghz7c5bB8EztUNb5OAt7oJjQXFAKpFG+WNLrpMmp8FX40FU4426vi3T7VL7q4WlEgeqV0mL50zan17nvod2t9Ymc/Of7LStNdOMUDtpvrvV7spxDaCjOOw5nVoeXX5Fu7wcx6oqKDkkXDzx7DwbvvtpT9kVraM49rX2EbOj7GO8GZ6FvBC4JcpAn1tDNTg3Z/pI/74IKD38vn07/a6Pab0IhruUh/0BJShQQZ++HtfWiZEOTxfsxiVWtYrrLENGVYvxuFrGBli5KwaQ10lg617DtCtfke3z0fPIh8WFZrXidJKwBmq9tWN8pCAt7oxGCCsljZpzRrwqip8+5A28SQ6CW7+BIxFXe9uNDB5pHaZvGRgnJMO/7sb1v8H6nWATrf6/Gn5nTWdoVYTz1ZN27ukuHbvb7O1f+WZZBYAeaCigqyBY0g0FBQtRXvPSohJ9F+bdKU0WHN49ac0VEeBGrz7cwS6sj8I6L18nhgTRla+iZx89xVsjl/IJWN3gdvUh9jwELcBZX6hhTNZ+bRMiHJcvi/2AryHVuovTJuY5ug17N60Nn+9UQ9yjvPlqm3kNRnIla3quHxsT/O5q/rVjfKQgLc6Cq9dFPAWVWrY8I6Wu2sI1kZso+p6dj6DsWxgfHovrP0XLHkY6rSCBl290/ZAdd7DkmTg3UlmbvNAgZgGNSunuqo5VlR2rOUgSN0JF1Lg7H7/BryZnkxaS9U+PAdo/dOazF1tZF+qzA8CelM41j19FZtTznP7hxvdnvMfC//AaDQ4TX0AeOzLncSE6QuXSgae1vJ95/YVle87ulvbUer95ug1bNm8OezaSi31IhM/28r8e3rSqWEthwGq2aKy95T7mtFg/6GhKl/dKA8JeKujsFra1/0/wKmdsPx57fthr0Kj7t55jIHPwuk98OeP8MUdMHFVcfpEdeTphDVvTzJzmQdaZPBLNSenuio6VvTHt0kfsBRqAe/pPdB8gH/aU5hfnALjKqXBetXAYtKuVkS6HmkS/lEmuKqCAYk7nqRw6Fmtzlg0eauw0PXEsEsmM5dM+uqduxyFtl5RiXGRM1/EEKXVgO4cV8CHZ8yM+WgTESFGzmYX2I5JjA3jpi4N+Hnfaf487brcWEVybgP16oanZOGJ6mbvEjhd9Clyw9vw0zOABRr3hu73eO9xDAa46QOo00YrV/TVWCjIrb4LItgWndA5Yc2TSWZ6JY+Evo+X3a4UvY1PbNZ/LlG5LGatFjNo78V67bXbp/f4r03W0d2g8OLJro4EhUBEUZDr4cQ1IbzN7WIqHiyi8fbtXXh6WBtdj3tP36YkRIe6WEBGy/l1GVDarqi4D3itHyyHNjHQrE4EuQVmu2AXipYqXnWYP09nExsezM1dG3i0yEdNIyO81YmzS+igjS7t+867k2PCYuD2BfDhQDi+CV5vAaYSNQir04IIno7w+mqS2bmD2tfLRkLy9droW342fHEbbHofWlwFrYd6dk7he6d3a8vzhsZAvXZw4Ujxdn8pmb/rLk0hpj7kntXyeBM7+L5tQrig9zK7nhzUDYfdl94CGNQ2kW5N4io2iUtPzrxVpDbCa8w9S66TpZlth4Ya+fXxAcRFhTA4uV61ybn1Ngl4qwuXl9CL+KJOa3wL6DFRq0BgKlVwu7osiGAuhPMp2m29Aa8vJpnlnIP9S7Xb/Z+yDzx63q8FvIsfhAd+K54gJQLD0Q3a10Y9tfdfvXba9+n7tZ8vox9+FXvyxze6PqTtcnPVQojKo/cyu7vg2JPSbkaDUrFJXLaUBh3vuaKUhtwLaZzOzHd5aE6+mQOns+gdFV+tcm69TQLe6sJfdVotZtjxX+ePWR0WRMg4puUvBoXpyr0CfLPYwK6vtXbU71R2lO3q6XDkNzi9CxbdD2O+0dJORGCwTlhr0lv7WrsZBEdoHxLPH4a6+i6repVHAa/ni08IEShcBceelnarUECpZ5KoVaQ2udx4yfVCFlalJ8tVh5xbb5O/iNWFv+q0+iJXNdDYFpxorj+ItE4yA8pmVAGoni02oKqw/TPtdpexZfcHh8Goj7V8zL9+1fK3RWBQ1eIR3sZFH3AMBkjQ8gv9ltZgC3hdTFizii7f4hNCVAV684KtrAHl9Z0b0LtFvL5gV1X1LfRiVRTwhuafR8H9amtVacUzf5ER3urCX3VaA2FBBIvZ9QIaFWXL3/VghTVwsXAH0LSvZ2keqTu1wMgYCu1vdnxM3TZaJY7vH4VfXtReB9Ml370uQp/zf2m1q42h9uX76rWDk1u1iWvO+tSXPPnjaxvhlYBXVE8+TwW4dB4Ki0Zh9VwpLAp4FdVMm5hCDmSGVJsVz/zFryO8a9asYcSIESQlJaEoCosXL3Z5/Lp167jiiiuIj48nPDyctm3bMmvWrDLHLVy4kOTkZEJDQ0lOTmbRokU+egYBxHoJ3dUcUl/UafX3ggh7l8Ds9vDpdbBwgvZ1dnttu7ecK0cNXqvkkfDobhj3vbbS1jX/0rYf2+jZ5WFr2kjbayHCxS+2y8fDZSO01IePh/j2dRH6WK9uNLgcgkKLt/u7UoOnObwgAa+o1so1cquX9f0WmWD/e8CZoBBbidFnB2gVG6T6QsX4NeDNycmhU6dOvP22vsuvkZGRTJo0iTVr1rBv3z6ee+45nnvuOT744APbMRs2bODWW29l7Nix7Ny5k7Fjx3LLLbewadMmXz2NwODyEnrR955cQtfLbaANGEO08mXeZq1KUXr01DpZrnRwZzGXr2yapxUaSrMu3NFhFPS4Fxr10gLSzR+4vy+AKQ/++Eq73WWM62MVBdpco91WSz0/Z6+L8K1jRekM1vxdK+vENX8EvHaXV3WkNMTIamtCVITiSUkyq6KJa33rqx6lXAjH/JrSMHz4cIYPH677+C5dutClSxfb902bNuWbb75h7dq1TJw4EYDZs2czePBgpkyZAsCUKVNYvXo1s2fPZsGCBQ7Pm5+fT35+8SzIzExtxRKTyYTJZPL4eXnK+hgVfqxWw1FunoNx+T9QsoqDQDUmCfPgf6K2Gg4+eD7K4FcwLrwLUFBKXHSx3lLMBagfX03hLZ9rl90tZpTjG2yX2tVGvT0PxC1mgn7UqlKUDbVVbeuyZyhsMQQMRpT935d9XaKTMA95BbXtdWXOULJPgs4dQgEKY5uieuH1U3o8QNDxjahbPqaw198hJNL18XuXEJR3ETU6icJGV7juQ4uZoF9e0u5XZmfZ16Uq8dr7pJIFHV2v/fw06GH/8xPXmmCAjOOYss7ZlhqtFJcuEGzKAcAUXtf974WwOgQDanY6hXm5YAyusv1RnUmfBB5rX1guHNO+RjfArLN/jBHxGIDCjFQGtevNgFZ92Xr0AulZ+SREh9KtSW2MBqVG97cnz71K5/Bu376d9evX8/LLL9u2bdiwgccee8zuuKFDhzJ79myn53n11VeZPn16me3Lly8nIiLCa+11Z8WKFV44iwFavEJ89gHCTBfJC67Fuag28JcB/lrqhfM7fsz6zSbR4cR/CTedt229FBzHoYThtDizgsiLR+GjqzlcdzBNzq8rc9yuhneQWkv/KnDxWfu4Msv5ZDmlaLLcpq9nE2LOpnvKf8oelHUK48LxbGn2sNPH/uWnH7iuaCRsxbYUCnbpq9nokqoyKLQeUXmn2bfgOVLqDnZ5eK9Db1EP+DOiG/uX/eTyWE9el3PRl5Wn9X7nnfdJ5Qg1XWTYhRRUFH7ae5HCA/bvwcHBcUSYzrNxycecj6q8Sg0xuccYCOQFxfDTil/d30G1MAIjBsys/O5L8kKK02qqUn/UFNIngeforvW0AlLOF7B7qb6/xd0yzTQA9m1ZzV9HSywJDJwDftrni5ZWLbm5ue4PKlIlA96GDRty5swZCgsLmTZtGvfcU7yCWFpaGvXq2eeL1qtXj7Q055fipkyZwuTJk23fZ2Zm0qhRI4YMGUJMjO9HXUwmEytWrGDw4MEEBwd76axlRy196xqwPEdhiZHb4Ea9ucxghNxzWP43juDjG2lzuuzl9DDTBbqnvI355jkOR1sdUfZcgkPuj7vi9Dy4pAWpjhI9VBS6n/uGwtuesxvxtPbJ1V1boOxUUcNiuXrkre4L9OtkqJcOPz1Fh+y1XDb2X85HWzNPErRdm8Xf/ObnaV67mcvz6n1derVvitruGk+b7Ve+eZ/4lrJ3MewG6rVnyIiyE9OMWZ/BoRX0aR6LpVvl9Yfy5zI4ACF1mnHNNfoeV/krETJPMqh7MmqDrlWyP6o76ZPAY+2TZnEhkA5NO11J45763nOGn9bA1s0kN0mg7cCq9fu6slivyOtRJQPetWvXkp2dzcaNG3nmmWdo2bIlt99+u22/UiooUVW1zLaSQkNDCQ0tm0QeHBxcqb80KvvxvC8YWg4suzk2EcYugtdboJRenIKiUUcUglY8C+1G6rvUrjMPSsk66Xp/0Yhn8KktDusTB2ce1Y6La0FwSIiux9Tl8rGwZgbKxSMEH/5JWzXNkd1fAyo0uZLghNbuz6vzdQmKbQBV9GetSr1PTmrLCStNr3Dc5sQOcGgFxrP7MFbmc8rRBgAMtRph0Pu40fW1D2CX0u1+dqpUf9QQ0ieBx5CtXXkz1m6s/71eVB3FeOls5f5+qEI8+TmvknV4mzVrRocOHbj33nt57LHHmDZtmm1fYmJimdHc9PT0MqO+opKd/L3sSmx2PKzXa5ss54yiVYbo/bC+8zkpm6acr0CFBldCIqD7BO32eieTNi0W2DFfu+1uspqVv6p1CMds9Xd7O97vr4lrGce1r3omrFnJ4hNClJtt0pqeVdasIrXqDOToW3xCuFYlA96SVFW1m3DWu3fvMvlLy5cvp08f+QPvV96u12swQt/HnewsCvau+Re0HqrvfE7KpikVKUnmTvd7tQoWJzbDMQdVRI6thwtHICRaf81eby94Icrv0sXiRSWcfcCwLTG8V/uAU1k8KUlmZf2AKaXJhPCIopqL3zeevOeKqjSQne79RtVAfk1pyM7O5tCh4oTDlJQUduzYQVxcHI0bN2bKlCmcPHmSefPmAfDOO+/QuHFj2rZtC2h1ef/1r3/x8MPFo3iPPPII/fr1Y+bMmVx//fV8++23/Pzzz6xbt65yn5yw5+16vaoKfy7XbhtDwFxQvC8mSQvqkkdqpccqssTvhb+0r54uOqFHdD3oeKu2gtqG/0Djnvb7txeN7ra/0W0lBzuuFryo186zBS9E+R3fDKgQ16L4D1dp8S21n9+CbLh4FOJc52h7TYYHS5xayQivEOUSarqIolrAEOT8d4EjkUXH5pz1TcNqGL8GvFu3bmXgwOKcT+vEsXHjxjF37lxSU1M5duyYbb/FYmHKlCmkpKQQFBREixYtmDFjBvfdd5/tmD59+vDFF1/w3HPP8fzzz9OiRQu+/PJLevYsFUyIymW91F7ewLO0A0vh4E9gCIaJayD3rOMVxawjnl/diXWamj3XI54+S2mw6j1JC3j3fa8tcGENrPMyYe+32m1HSwm7kzxSW6TCugIdwDf3aZfOU9Y6zFcWXnasKD2ndP3dkozBWqm+tF1a31RawFuOEV7r4hMulxIXQpQWUVBU3ScmybOra1HaamvkpGuDPF6aNF1T+TXgHTBgAKrqKPjRzJ071+77hx9+2G4015lRo0YxatSoijZPeFMFA087BTnw49Pa7T4PQz035bVcjXiGx0HLQQ7vFlSYg2LNnfLFCC9AQltoNQQOLoeN78G1RSux7Vmk5TzHt4KG+su12bEueGF1bANs+QhWvgx3L5Nfnr5my9918yGuXvvigPeySqiuYi4Ea+m68gS8MsIrhEdsZTg9yd8F2/LCFOZBflbl1uquhqp8Dq+oQqyBZ4yTVWFKrwzmzJrXtUk3sY2h35P6H7vkEr9jFmoTdi6dh9/edHiXqPyikdGoRAiN1vc45dF7kvZ1+3zILfrFaF1KuMsY7wWmfZ+AoDA4vhEO/eydc1YWixnl6DoanN+AcnSd/lXy/MWUB6e2abddjfBCiYlru33bJqusVFAt2tWRSA8ur8rywkKUS7h1hNeTD5igpbIFF6WzycS1CquSZclEFVb6UntUPTi8Eta9AUsegQaXQ63Gzu+fvh/WFy0iMXymVu1Ar9IjnkP/qY04//amFliWetyo/KKRLF+lM1g16weJHSHtD1jxPNRpC8c3AQbodJv3HiemPnS/Bza8DStfgpZXV41R3r1LYNnTBGWeohvA0feK8rRnBm4+8snftbzyqERwUzu50is12NIZGoDBgzEPaw5v3kUwXUL+fAihT3HA68GywlZRdeFCjhbw+upKYw0hI7yi8lkDzw6jtK8D/6Fdts/PgIX3apdcHVFVWPoEWAqh9XBoW8FC3JeNhKZ9tctFy58vszvSFvA2r9jjuKMo0OQK7fb2+bDiOe12UHDRxCcvunIyhERB6k7Y953n97eYtRzgXf/Tvvp6pHXvEu1DSelUlMxUbfveUguZVHb7nCmZv+vuQ0W99trX839p6Tq+Zi2P5ElJMoCwWAgu+oApo7xC6Fac0lCOgDdSKjV4iwS8wv+MwXDzRxAao11uX/Oa4+N2fQ1H1kJQOAyfUfHHVRQtb1gxwN7FcMS+kkdUXiWN8O5dApveL7u9MN9xUFcRkfHQ60Ht9q//9Cwg3LsEZreHT6+DhRO0r7Pbe7d9JVnMWt61w0mORduWPVP8HCq7fa7ozd8FbdZ2ZF1A1a5g+JqtBq+Hl1cVRSo1CFEOxSO8Hn7IhOI83hwJeCtKAl4RGGo3hetmabfXvF52AYpLF+GnZ7Xb/Z7QjveGxPZw+V3a7R+fsQsAKyWlwWVQV2TZM94dqez9kDZad2a/NhKqh6cjrd5wdL2bigAlFivxR/ucsZiLR+bd5e9aVWYerzWloTyjTVKpQQiP2UZ4y5vSAJAtObwVJQGvCBwdRkHnO7QJNQvv1d7g1svT3z6kfcKNb6VVZvCmgc9qAeDpXbDtU22bqpZIafBhwOtJUOct4bXgike026teAbPJ9fGejrRa71PR1AK9i5Cs+Rd893fP2udLabugIAtCYyEhWd99rGkNlZHHW56SZFZSqUEIz5hyCS3M0m6X5z1nq8UrAW9FyawDEViGvwbHNsL5w9rl6MI8+/3tb4agUO8+ZmQ8DPiHFtT98hK0uxHycgi25KEqBhRvjSY74u0V6PTqeb9WBu3CEa0ixOXjnR/rSVDerK9tkpndfTydZKaq+oO/lFXuTmbfPtCC35ITJ0vWbq6oY9Z0hp76z1mZE9dsAW85Lq/aUhr8mMPry74TwtuKfg+qwZEoYbU8v791oQpJaagwCXhFYAmNgsvHwYoXyga7AKtn+ma1sO4T4Pc52mX+VTMwxBQFAxF1tdVxfMXbK9DpFRKpLc287BlY/Rp0vA2CwxwfqzfYvpACly4U1VouNdpqTS24ZZ593zkKXi4eg+8fg79+dfOACoTXhqSucFhHmTXr8/BGQO6KdTS+sc50BrBPafB1gXmvjPD6KeD1dd8J4WWK9Wc1Jql87+vIOtpXSWmoMAl4RWCxmB1P4Cpp2TNaaTNvjuoYg2HYq/DZjbDpfaxnVnJOayPNvvqD6u0V6Dxx+V1aibfMk7D8OWjcq+yI2YWjxUscu7Pk79rr6DS1QLHvO0fBS2iMVsPWUgDGUO01t+UZlzxv0R+OEW9qQa+egHfdbEhZA9vmlW2js4DcU6paPMLrSZ/VaQOKUSv5lXmqfLl+euRnaY8B5XuMGD+mNFjztH3Vd0L44upBpvYBU41tSLk+xkbKCK+3SMArAounl8+9KT/b8XZf/kF1uQJd0a9HvSvQeSo4TFvl7fc5sOVD7R9oAfZVz2uX1zd/oNWTdccQpJWLc3lsUd8d+kUbvXcUvORnal8TkuHW+VrdyctGOhnVm6H1h8Xs5kNDkdO7tH/O2lY6IC+Pc4e1XDtjKCR10X+/4DCo00q7wnB6j+8C3oyikmRhseVbTMVfI7xu88i90HeiZvPR1QPFWgYwOql8J7ClNJwtdxuERiaticDir5xW2x9UR3w88cnZCnQxSb4dtdq7BH6fW3Z75ilY/IC2QIW5QFsYY/CLaAF46TGKom2j5sDQV/Q97ud/g6/H4TI4zcsorsRRtEpe4ZjFbG3yAIVjFsOju4pfF+uHBlt7HLTv2jeg291uGuaFCYLW+rsNu3mea14ZlRoqkr8LxTm8manaaHZl8cfkTlFz+LDKi5JRPMJbLtayZPmZ2tUvUW4S8IrA4q+cVn//QS299PG47+2DOm/TUw7NEAy3fwV3LtGqOrgLyhM76n981eJ6f+nX2mBEbXIlJ+N6oza5suwonrsPDd0nFC/u4U5FPkzZ6u96kL9rZQ140/eW//HdKW8NXivrCG/hpeLR+Mrgrw/CovorTxUaT2QVTVorTxlA0K7GGEO025LWUCGS0iACi79yWgPhD2rppY99yW2AD1hM2tLN1okWjpaFLpnjprfv+j0F3z/ivo2evtbu2ufLD1PW3L9Dy7XvG/Xw/ByVUZrMtspaOQPe4HAIq6XlAVdmHq+/PgiL6s+XaXQWM8rZPwFQLl3Ufk94mnKjKNoob+ZJbeJarcae3V/YyAivCCxuL0/jm5zWmvYHtbwBfulloUv2g96+07sefHlea1ftswbkrqaOxDTw/MNUyRXerHl23z3i+WVQ6wjv2T+1VfZ8oSIVGqyKRnmVyszjtfWdC9YPOEJ4wleDHUW/F6w5vMZfXij/yo+21dakUkNFSMArAo8/clrdBkNK+YKhQOWrAF9P3/nrtXYZkBe5crJnH6ac5f5lpXme+xfTQLt8aSnUgl5fsK2yVoGA19q32ZU4wmswwlA3y4nnZcHR3yqnPaL68MXvQm/nBEstXq+QgFcEpsrOafXXyLK/+DLodNd3/nytnQXk1hy5bXPBdEnfubyd+6covk9rqGgOL5QY4a3k0mSR8UU3Sv3MRNeHOq2hMBc+uwn++Frb7o3V/kT15/bqgYe/C32RE2wd4c2WgLciJIdXBK7KzGmF4mDIVQms6sLX5dDc9Z0/X2tHub61msCHA7VlgZc+Ade/4/48vsj9q9dOG6X0RaUGi6W4LFmFAt6Sq621dvOYXqxraq0H3WUMdLzV/pxmEyy6D/Yuhm/u0XKpj6yTBSqEe7bfhWMd7CzH70Jf/F6QlAavkIBXiJKKgqHCv9awY+1PdO47lKDm/arPyG5J/g7w3U0y8yVHAfmoj7WFR7bPh0Y9oeudrs/hi9y/hGTtqy9GeHPOaBMRFUNxtYXysI7wZqdBhIvjvFnXNC8T9izWbncdB4262+83GLXSeCsaauX0/viq7DlkgQrhTPJI7ee6dF56eX4X+uL3gi2lQQLeipCAV4jSrCWw9mTSyVEJrOrEn0EnVP4ovivNB8BVz8EvL8IPT2hl1pI6Oz8+rJa+83qS++dpSoPeEVSLGfZ9r90Oj6vY0sW2xSdcBLzeXhVtzyKtFFqd1lqNY0cMBq1e9LbPID/DwQFOFqjwxepaomo586cW7CpBMPSf2gc1YyhM+h1Cwj07ly9ygq2rrUlKQ4VIwCtETRdIQae/XfEYHN8Cf/6oXeK8Z6W2+lnpYOjQz/D9Y25OVo4SegmXaV+zT2sliKLqOj9W7whq6eNyz1ZsueySVRoc/c32xapoJdMZXAXrR9c7CXZLPH7Jy8k+Wl1LVDH7iz4MNu8PPSbCmtcg9xyk7oAmHtbU9kVpzcg62lcZ4a0QmbQmhBBWBgPc+J62ytvFYzC7nVZubOEE7esbyfDxMJh/M2Qcg3AnE6nKmwcdGgW1m2m3012M8uqdBe6LFaRsVRpOO15AxNuLuJw5ACc2g2KEjre5PlbvZeLtn8Hmj3y2ulaNUh0mB1oD3suu034HNC0aADiy1vNz2SblOgl2wfPfC1EywusNEvAKIURJ4bWh2z3a7dL1cLPT4PgGQIFeD8Gjf8Atn3m3hJ5tiWEnAa/eWeCFBb5ZQSoyAVBQVDOhhVll93s7h9E6utt6KES7uQys9zLxH1/C0sfx2epaNUXJGtTWD4XlrTXrL5mn4OTvgAJtrtG2Wa94pawp3zmTR0JDB4vPlPf3gjWl4dJ5bYKmKBdJaRBCiJIsZtj0rutjIuvCkJe0URpv50HXa6+NODkLePWOoL7ews3yv+VcQcoYpI04ZZ8mzHSh7H5v5jCaTbDzC+12lzHuj9dzOTksBmIbuamEUYHVtWoKb+dp+8v+H7SvDbsXVyBp1l/7enwzmPIgOMyzc5oL4ewB7ebQmWzff6RiE6Aj4rTJpqpFS7WwtlN4REZ4hRCiJD3LLuek21+Sd7XCm6dsI7xOAjK9I6Mug91ynK+kojxehwGvnlXR9NY1PfSz9lpH1oVWQ9wfr6fG88i34Up3+ddFfLmUeFXmi1qz/mINeNteW7wtviVEJYI5X0un8dTJ3yEvA8JqYek6npNxvVErMgHaYISIovQpSWsoNwl4hRCiJF8tNaqXNeBN36+NFJWmdwS110P6jivPEs62gPdi2X0GHbm2Q1/V98ffms7Q8VYwButrm57V/mraUuLe5u08bX+5dKE4T/eyEcXbFaVEWkM58ngP/ax9bXGV9yp+WNMaZLW1cpOUBiGEKMnfwVDtZhAcAaZcOH8Y6rYp3qeqcHKrmxMUzQK/ehrsXeTd2eJWRZdUHY7wZpyA3+dot0MioSDH/jFRIc/B/UrLToc/l2m39aQzlOQuzcQXM+lrEn9/KPSWgyu0pbzrXgbxLez3NesHu74uyuN91rPzWgPelld7pZmAVrElHa16iygXGeEVQoiSfLnssh4Gg/YHGGDLR8Uz3015sPgB+HmafVtKtw20WeBBIb5bwrkoZaFMwGsuhP9N0EbOkrrAE4ftl5ge8rJ23IoX3F+a/eNLLRhp0K24XJsnXKWZuEx9KFLe16Y6VC1wx98fCr1l33fa15LpDFbWSg0nt5b60OZGzlk4tV273XJQxdpXkm2EVwLe8pKAVwghStKTB1qRZZfd2bsEzuzTbm/+oLgc2vtXwM4FWnmu4a+7v2wP+i7vl4dthPei/fZVr8DxjRAaA6M+0Yr2lww6e94P9Ttp+Y0//cP5+VXVvvauLzh7bRQD3PRh+V4bT6oWVOXAuEkfiHaTp40CF1K0voTAe76mS8UjsZddV3Z/7aYQ21j70HVsg/7zHv4VUKFeB+9OLrMtLywpDeUlKQ1CCFGav5ZddjbzPTsNstFSHW77HFoM1La3vc59dQhfrKbnaNLaoV9g7Rva7RFvQlzzsvczBsF1s+GjQdrl4s6jtTzH0k5u0xb8CAqH9jeVv53ulHxtMk/B8ue0gMLl4hVOeFK1oKoveKEYtP7NcpPHu+Rh2L0Q2o6Adf8OrOf71yotbSimIdTvXHa/NY93x3+1AF1veoItncGLo7tQvAiNpDSUmwS8QgjhSGUvu+xy5nuR0Ggtt9BK7yp53l5NryjgDbcGvFlpsOg+QIVud7sOUht01Vaz2vQ+fD8ZHtwAwaWWb93+mfY1eSSExXqv3Y6UfG3yLsKPT8H6t+Hyu/T3tSery+3/oeqX8/rtTTi6DjBARG2tVJZVTAMY8k+4eBRWvaoFln+tKnsOfz9f61Lbba91vnpf06KAV+8CFBYLHP5Fu+3N/F2QSWteIAGvEEI4U5nLLusph5Z9OjBqwxb98Q0tzKLwr5Ww4T9abmG99jD0Fff3H/isNsp5IQXW/AsGPV+8ryBXGxUE36UzONNljBakXUjR8jvb3aDvfnqrFnx9F6SsxqNlly3myvvQpce+74vzyK95TfuA46x9ba7RUnHMBQ5OVM5lpr3BXAgHlmq3HaUzWFnfZ6e2F5UZc/PhK+0P7X0QEgWNenqnrVZRHuTwBtrPTICQgFcIIQJBVZn5br0cXyRowS3aDWMojJpTdrTWkbAYGD4TvhqrjRZ2+BsktNX27ftOqyFcqwk0udIHT8CFkEjofi+seQ3WvwXJ1zsf/StJb5/s+9bNAaUWvAi01IfUP+CbiVo7u98LPe7Vtjv7AJZ92kmwa+WnBT6Ob9RWLQuvDY1dTD6Nbailbpz/C45ugDbDXJ/Xms7QrL82adSbIutoX92lNATaz0wAkUlrQggRCKrCzHdrnqqj0UxzvpZ3q9dlI6D1cLCY4PtHodCk5Uqu/be2v9PtWsWKytZjIgSFaYsH6K0jq7dPkrrqO27ju/DLS45fa2sqQGUv35t1GhbcDqYcaD5Ay2V3J1A/xFkXm2g9XMsrd8VarUHPMsOHrOkMXs7fBfsqDRaL42OcvT/99TMTYCTgFUKIQODvcmjuuM0xVjxbXUtR4JrXIThSmwX/r5ZaVYOiJVn5fY5//kBH1dWCbdBGn/Vo0kerTOFUUd9dPU3f+Q4shbX/wicrmemtllDyuEO/aMFu5gmIbwV/m+s+UITA/BCnqvb5u+5Yc+aPuAl48zLg+Cbttk8C3qJJa6pZK/tXWnVa/c5HJOAVQohA4O9yaO74YnWtWo2KL7PmXbTfl53uv1GpPg8DChz8SVvxzp3Tu13Uai3Rd02vdPOhBgirBS3cBUzlXMlMb9m00sfNvwlO/a5VCRn9pZYKoIfbD3FoEyAr80Nc2i7IOKZVAHFUIaQ06whv2m7IPe/8uL9Wa8FofCutpJm3BYVoPxvgOI+3uqx+50MS8AohRKDwVd1cb/DF5WmLWQsUHPLjqFR8i+LJTOv/4/pY0yVYeK8W7DS43LYoh03JvnP7oUaBkf/RyrXp4clrrfdyt6u0FVMunN6j/zH1LPAREuUmz9fL9heN7rYcBCER7o+Prgd12wIqHFnn/DhfrK5WmqtavIGaPhJAJOAVQohAkjwSHt1tv0LZo7v8P+HEF5enj653X8vVX6NSfR7Rvv7xZdESxE6smKqlYUTVg9Ffu+87PR9qvP1a67ncvfRJOL5Fy6f2VtoKOH++UfW0EeNzB7WJcM7yUr3Nls7gojpDadZRXmflyVS1RP6uDwNea6UGR6sUmgt1niPAV7/zIanSIIQQgaYyy6HpZb08nZmK44BI0fZ7cnk6kEelGnXXZvAfWw+b3oPBL5Y95tAvsPn/tNvXvwuR8dptd33nrsaz29caQNE/Mqrncnd2GnzsLlgrZ1UFZ8/32Ab47EbYtwRWPA9D/6n/nOVx/i9I36OtVth6qP77NesLWz50PnHtzAEtvzkoDJpe4Z22OmIb4S2V0rBnMfzwuPv7l3cOQDUpcyYjvEIIIdzzRY5xIE5qKumKv2tft86BvEz7fbnnYfGD2u3u90IrD0f2rB9qrMsul3zd9LzWqPDfv8Gm/9NGGC1mlKPraHB+A8rRdfajsFlp+toUpKOkHJTvA4ij59v0SrjhPW3/hrdh4/u+XYLYWp2h6RUQEaf/ftYR3jP7HY+uWtMZmlyhryxfeUUUfaBKWaO9NqY8WPYP+HocmLKhThtsqTGOdL/H80DVk+WyA5wEvEIIIfTxdo5xoFemaDUU6rTW6gJv+7R4u6pql/6z07T9jkZ/K8rVa33zJ9DxNi1v+MenYN71MKs9QfNvoNvR9wiaf4MWlOxepAWOq17V95glFwBxxZsfQDqMKq5esexpeL2l74Ira8DbdoRn94uIg3odtNuO0hoqI3937xLY9ZV2+8BS7bWZ0Qg2vqNtu+IReGC945+ZoDDt66b/c52e4+gxq1GZM0lpEEIIoV/R5enCv9awY+1PdO47lKDm/cp3idM6kvnVnWhBb8nL9wFQmcJg0Co2LHkY1r8DCe3h0jltxv7eb8EQBDd9oG/yU3m4Sn1ofxMktoflzxet3lZK5in433idD1SUjtL9Xm2k1ZtpK3pc8ag2anl4pbYgREneWILYYob9S7UUCvAsncGqWV84vUtrZ/ubi7cX5BbnmPsq4LUGnqX7xJrScsWjMHi6dtvRz0xiB/hkGJzZpy32Mv4HCAp1/ZieLJddRdIbZIRXCCGEZwxG1CZXcjKuN2qTKyv2By+QK1MAdLxVW1I2OxXm36CNPP42S9uXfAMkdfHt4ztLfVAU6PWg+0vzigH6P6PlGDu83F3ig0VQiH9K46kWF+XfKlitw3pJ/qsSy1TPGeb56KS1Hm9KqRHeo79pi67ENoY6rTxvnzt66l/v+tr+tSn9MxNeC277r/ZzfGIL/DBZu0rhSjUsc+bXgHfNmjWMGDGCpKQkFEVh8eLFLo//5ptvGDx4MHXr1iUmJobevXvz008/2R0zd+5cFEUp8y8vL8+Hz0QIIUS5BWplCoA/f9IWFXBk90L/XtY9uh5yz7k+RrVoubJd7tD3wcIfH0B8Va3Dm5fkm/TRPjycPwwZJ4u329IZBulbhtpT3go841toS38rBtg+H7Z85Dpf+txBfe2rQmXO/JrSkJOTQ6dOnbjrrru4+eab3R6/Zs0aBg8ezCuvvEKtWrWYM2cOI0aMYNOmTXTpUvwpOyYmhgMHDtjdNywszOvtF0II4SWBWJnCNrrmgj8v63pa5cJddQgrvcd5i69qPHvzknxYLNTvDKe2aXm8nW7Ttvs6f9ebr03LQXD1dK0ixo9PwaoZkHu2eH9MEgx5GTJOaPv0qEJlzvwa8A4fPpzhw4frPn727Nl237/yyit8++23fPfdd3YBr6IoJCYmequZQgghaiJPRtf8EayXp8qF3g8WlfkBxFc1nr3dd836agFvSlHAez4Fzh3ScrmtKQ/e5u3Xps/D2qS3Yxvsg10oyvu+u/h7QzBYTM7PZQyFxI76HjcAVOlJaxaLhaysLOLi7HOYsrOzadKkCWazmc6dO/PSSy/ZBcSl5efnk5+fb/s+M1MrP2MymTCZXHS2l1gfozIeS+gjfRJ4pE8CS03oDyXjpK4/koUZJ1H98TokdScoOgmyUlEcjGSqRZPMCpO6QyD3k9vnAcQ08Oh5+KLvlEZ9COJN1JTVFJpMGP5cjhGwNOyB2RjusG0Vfp94u48tZoIuHNGej5NDVMWA+ZpZEBqN8ZsJRccWP7b1lmLOxzLvesy3LoDIOh48Ke/x5HWt0gHvv//9b3Jycrjlllts29q2bcvcuXPp0KEDmZmZvPnmm1xxxRXs3LmTVq0cJ5S/+uqrTJ8+vcz25cuXExHho9m3DqxYsaLSHkvoI30SeKRPAkt17o/4rCNcqeO4jbuPcO7oUp+3x5H6dW6me9Z/rBfpbdSi/7fE30Tqsp8c3jeQuHoeCnDC0IDfPXgevug7ozmPazBiyDjOqkWf0v7kAuoD+00NOLjU9Tkq8j7xZh/HZ+3jyizXpckU1cLGA2mci65N/WaT6HDiv4SbiqtnXAqOI6XO1bRMX0po6nZy3xvA+pZPcSk4jvjsA4SZLpIXXItzUW20nGEfys3N1X2soqrupupVDkVRWLRoETfccIOu4xcsWMA999zDt99+y9VXO8+dsVgsdO3alX79+vHWW285PMbRCG+jRo04e/YsMTExHj2P8jCZTKxYsYLBgwcTHBzs88cT7kmfBB7pk8BSI/rDYibo7S7uR9ce2ubX0kzK/u8xLv8HSomJX2pMA8yD/4nqyRK6fubweYTVQsm7CEDhNW+gdrlT37m2zcX44xPORzHL2XfGT6/BcGIz5mGvY/hlGoopB9OEX7XSXw54633irT5W9iwkaPF9bo8rvOH/UNsVza2ymFGOb7Dlc6uNemuv2dmDBC34G0rmCdSwWmAMRimxCpwanYR5yCs+/RnMzMykTp06ZGRkuI3XquQI75dffsmECRP4+uuvXQa7AAaDge7du3PwoPMZh6GhoYSGlq1JFxwcXKm/yCv78YR70ieBR/oksFTv/giG4c7rBCsAw2YQHOrnSdEdboR2I8vURg6qIvVRbYqeR8nJckqTPtrCGWteJ+jHJyA2Cdq4mfvz21vaxCwbL/Zd8/5wYjPGta+DKQfCahOc1BGMrsOpCr9PnLw2HvdxbANdhwXFNgBbe4Oh5cCyB9VPhntWwEeDUTJPlNmtZKUStPAun5YX9OQ1rXJ1eBcsWMD48eP5/PPPufbaa90er6oqO3bsoH79+m6PFUIIIewEep1gK2/WRvYnR3WHBz4LncdoJda+vguOb3F8X1WFX14qDnaveNT7facUva45RUsM512ANztUTnk6V8tR6+Xt1Q2j6mkr/jlUwRrKXubXEd7s7GwOHTpk+z4lJYUdO3YQFxdH48aNmTJlCidPnmTevHmAFuzeeeedvPnmm/Tq1Yu0NG198PDwcGJjYwGYPn06vXr1olWrVmRmZvLWW2+xY8cO3nnnncp/gkIIIaq+yi7TJewpCoyYrb32h1bA57fAXT9Czpni/mjUC36aAls+1O4zaCr0nazdbnudd/pu7xJYPbPsdm+sBldZvL264dH14DIn2M+VTErwa8C7detWBg4sHiafPFn74Rw3bhxz584lNTWVY8eO2fb/3//9H4WFhTz00EM89NBDtu3W4wEuXrzIxIkTSUtLIzY2li5durBmzRp69OhROU9KCCFE9ROIdYJrEmMw3PIpzL1OKw32Xh/7kcXgcDBdAhS49l/Q/Z7ifd7ou+q01K71qsWyp+1Lt8UkacGuJ0G7L2oo+4hfA94BAwbgas6cNYi1WrVqldtzzpo1i1mzZlWwZUIIIYQIKCGR0G0CLNlW9jK66ZL2tef99sGutwR6TWZPeeuqhS9qKPtIlcvhFUIIIUQNZDHDqn+6PmbfEt/ki1ahkUzdAjEn2Ick4BVCCCFE4HM7ykrxKKu3VaGRzEplzQkGyga95cgJ9iEJeIUQQggR+Pw5ylqFRjIrXRWpZFIl6/AKIYQQoobx5yirt6sbVDdVoJKJjPAKIYQQIvD5e5S1ioxk+o03coJ9SEZ4hRBCCBH4AmGUtQqMZArHJOAVQgghRNXgzRqy5SU1maskCXiFEEIIUXXIKKsoBwl4hRBCCFG1yCir8JBMWhNCCCGEENWaBLxCCCGEEKJak4BXCCGEEEJUaxLwCiGEEEKIak0CXiGEEEIIUa1JwCuEEEIIIao1KUvmgKpqq7dkZmZWyuOZTCZyc3PJzMwkODi4Uh5TuCZ9EnikTwKL9EfgkT4JPNInvmWN06xxmysS8DqQlZUFQKNGjfzcEiGEEEII4UpWVhaxsbEuj1FUPWFxDWOxWDh16hTR0dEoiuLzx8vMzKRRo0YcP36cmJgYnz+ecE/6JPBInwQW6Y/AI30SeKRPfEtVVbKyskhKSsJgcJ2lKyO8DhgMBho2bFjpjxsTEyNviAAjfRJ4pE8Ci/RH4JE+CTzSJ77jbmTXSiatCSGEEEKIak0CXiGEEEIIUa1JwBsAQkNDmTp1KqGhof5uiigifRJ4pE8Ci/RH4JE+CTzSJ4FDJq0JIYQQQohqTUZ4hRBCCCFEtSYBrxBCCCGEqNYk4BVCCCGEENWaBLxCCCGEEKJak4A3ALz77rs0a9aMsLAwLr/8ctauXevvJtUYa9asYcSIESQlJaEoCosXL7bbr6oq06ZNIykpifDwcAYMGMCePXv809ga4NVXX6V79+5ER0eTkJDADTfcwIEDB+yOkT6pXO+99x4dO3a0Fc7v3bs3P/74o22/9Id/vfrqqyiKwqOPPmrbJn1SuaZNm4aiKHb/EhMTbfulPwKDBLx+9uWXX/Loo4/y7LPPsn37dvr27cvw4cM5duyYv5tWI+Tk5NCpUyfefvtth/tfe+013njjDd5++222bNlCYmIigwcPJisrq5JbWjOsXr2ahx56iI0bN7JixQoKCwsZMmQIOTk5tmOkTypXw4YNmTFjBlu3bmXr1q1cddVVXH/99bY/2NIf/rNlyxY++OADOnbsaLdd+qTytWvXjtTUVNu/Xbt22fZJfwQIVfhVjx491Pvvv99uW9u2bdVnnnnGTy2quQB10aJFtu8tFouamJiozpgxw7YtLy9PjY2NVd9//30/tLDmSU9PVwF19erVqqpKnwSK2rVrqx999JH0hx9lZWWprVq1UlesWKH2799ffeSRR1RVlfeIP0ydOlXt1KmTw33SH4FDRnj9qKCggN9//50hQ4bYbR8yZAjr16/3U6uEVUpKCmlpaXb9ExoaSv/+/aV/KklGRgYAcXFxgPSJv5nNZr744gtycnLo3bu39IcfPfTQQ1x77bVcffXVdtulT/zj4MGDJCUl0axZM2677Tb++usvQPojkAT5uwE12dmzZzGbzdSrV89ue7169UhLS/NTq4SVtQ8c9c/Ro0f90aQaRVVVJk+ezJVXXkn79u0B6RN/2bVrF7179yYvL4+oqCgWLVpEcnKy7Q+29Efl+uKLL9i2bRtbtmwps0/eI5WvZ8+ezJs3j9atW3P69Glefvll+vTpw549e6Q/AogEvAFAURS771VVLbNN+I/0j39MmjSJP/74g3Xr1pXZJ31Sudq0acOOHTu4ePEiCxcuZNy4caxevdq2X/qj8hw/fpxHHnmE5cuXExYW5vQ46ZPKM3z4cNvtDh060Lt3b1q0aMGnn35Kr169AOmPQCApDX5Up04djEZjmdHc9PT0Mp8GReWzzrKV/ql8Dz/8MEuWLOHXX3+lYcOGtu3SJ/4REhJCy5Yt6datG6+++iqdOnXizTfflP7wg99//5309HQuv/xygoKCCAoKYvXq1bz11lsEBQXZXnfpE/+JjIykQ4cOHDx4UN4jAUQCXj8KCQnh8ssvZ8WKFXbbV6xYQZ8+ffzUKmHVrFkzEhMT7fqnoKCA1atXS//4iKqqTJo0iW+++YaVK1fSrFkzu/3SJ4FBVVXy8/OlP/xg0KBB7Nq1ix07dtj+devWjTvuuIMdO3bQvHlz6RM/y8/PZ9++fdSvX1/eIwFEUhr8bPLkyYwdO5Zu3brRu3dvPvjgA44dO8b999/v76bVCNnZ2Rw6dMj2fUpKCjt27CAuLo7GjRvz6KOP8sorr9CqVStatWrFK6+8QkREBKNHj/Zjq6uvhx56iM8//5xvv/2W6Oho26hIbGws4eHhtnqj0ieV5x//+AfDhw+nUaNGZGVl8cUXX7Bq1SqWLVsm/eEH0dHRtpx2q8jISOLj423bpU8q1xNPPMGIESNo3Lgx6enpvPzyy2RmZjJu3Dh5jwQSv9WHEDbvvPOO2qRJEzUkJETt2rWrrQST8L1ff/1VBcr8GzdunKqqWkmZqVOnqomJiWpoaKjar18/ddeuXf5tdDXmqC8Adc6cObZjpE8q19133237/VS3bl110KBB6vLly237pT/8r2RZMlWVPqlst956q1q/fn01ODhYTUpKUm+66SZ1z549tv3SH4FBUVVV9VOsLYQQQgghhM9JDq8QQgghhKjWJOAVQgghhBDVmgS8QgghhBCiWpOAVwghhBBCVGsS8AohhBBCiGpNAl4hhBBCCFGtScArhBBCCCGqNQl4hRBCCCFEtSYBrxBCCKcURWHx4sX+boYQQlSIBLxCCBGgxo8fj6IoZf4NGzbM300TQogqJcjfDRBCCOHcsGHDmDNnjt220NBQP7VGCCGqJhnhFUKIABYaGkpiYqLdv9q1awNausF7773H8OHDCQ8Pp1mzZnz99dd299+1axdXXXUV4eHhxMfHM3HiRLKzs+2O+eSTT2jXrh2hoaHUr1+fSZMm2e0/e/YsN954IxEREbRq1YolS5b49kkLIYSXScArhBBV2PPPP8/NN9/Mzp07GTNmDLfffjv79u0DIDc3l2HDhlG7dm22bNnC119/zc8//2wX0L733ns89NBDTJw4kV27drFkyRJatmxp9xjTp0/nlltu4Y8//uCaa67hjjvu4Pz585X6PIUQoiIUVVVVfzdCCCFEWePHj2f+/PmEhYXZbX/66ad5/vnnURSF+++/n/fee8+2r1evXnTt2pV3332XDz/8kKeffprjx48TGRkJwNKlSxkxYgSnTp2iXr16NGjQgLvuuouXX37ZYRsUReG5557jpZdeAiAnJ4fo6GiWLl0qucRCiCpDcniFECKADRw40C6gBYiLi7Pd7t27t92+3r17s2PHDgD+v537ZVUkisM4/sxFg8o08U8zqRi0aNJmsgnaRKaKIBa7vgJ9BUZBMFg1GAfEZFPfgIhGEbTohgXh4rJ7d2G9Onw/6cyZmcPvtIfDj7NarZRKpe5hV5Ky2ayu16s2m40Mw9B2u1U+n/9tDclk8j72+XwyTVP7/f5ftwQAT0fgBYAX5vP5HloM/sQwDEnS7Xa7j3/1jcfj+dJ6brf74d/r9fpXNQHAd6KHFwDe2Hw+f3iOx+OSpEQioeVyqdPpdH9v27Y+Pj4UjUZlmqYikYhms9lTawaAZ+OEFwBe2OVy0W63+zTncrnk9/slSaPRSOl0WrlcToPBQIvFQv1+X5JUqVTUbrdlWZY6nY4Oh4MajYaq1aqCwaAkqdPpqFarKRAIqFAo6Hg8yrZtNRqN524UAP4jAi8AvLDJZKJwOPxpLhaLab1eS/p5g8JwOFS9XlcoFNJgMFAikZAkeb1eTadTNZtNZTIZeb1elUoldbvd+1qWZel8PqvX66nVasnv96tcLj9vgwDwBNzSAABvyjAMjcdjFYvF7y4FAF4aPbwAAABwNAIvAAAAHI0eXgB4U3SkAcDXcMILAAAARyPwAgAAwNEIvAAAAHA0Ai8AAAAcjcALAAAARyPwAgAAwNEIvAAAAHA0Ai8AAAAc7QebLEea73YZ0AAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 10/10\n",
      "‚õî Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "\n",
    "# üîß Ë®≠ÂÆöË£ùÁΩÆ\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"‚úÖ Using device: {device}\")\n",
    "\n",
    "\n",
    "input_dim = 14\n",
    "final_out_dim = 35\n",
    "    \n",
    "\n",
    "    \n",
    "model, optimizer, loss_fn = build_model(input_dim, final_out_dim, dropout_rate=0.5, learning_rate=0.0001, weight_decay=0.001)\n",
    "    \n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.001)\n",
    "loss_fn = torch.nn.MSELoss()  # Êàñ‰æùÈúÄÊ±ÇÊõøÊèõÂÖ∂‰ªñÊêçÂ§±ÂáΩÊï∏\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "early_stopper = EarlyStopping(patience=10)  # ÂÅáË®≠ EarlyStopping È°ûÂ∑≤ÂØ¶Áèæ\n",
    "\n",
    "# Ë®òÈåÑË®ìÁ∑¥Êó•Ë™å\n",
    "log_file = open(\"training_log.csv\", mode=\"w\", newline=\"\")\n",
    "csv_writer = csv.writer(log_file)\n",
    "csv_writer.writerow([\"Epoch\", \"Train Loss\", \"Val Loss\", \"Val Spearman\", \"Learning Rate\"])\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "\n",
    "# üîÅ ÈñãÂßãË®ìÁ∑¥\n",
    "num_epochs = 150\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "    val_loss, val_spearman = evaluate(model, val_loader, loss_fn, device)\n",
    "\n",
    "    # ‚úÖ ÂÑ≤Â≠òÊúÄÂ•ΩÁöÑÊ®°Âûã\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        print(\"‚úÖ Saved best model!\")\n",
    "\n",
    "    # ‚úÖ Ë™øÊï¥Â≠∏ÁøíÁéá\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # ‚úÖ ÂØ´ÂÖ• CSV log\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    csv_writer.writerow([epoch+1, train_loss, val_loss, val_spearman, lr])\n",
    "\n",
    "    # ‚úÖ Âç∞ epoch ÁµêÊûú\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | loss: {train_loss:.4f} | val_loss: {val_loss:.4f} | œÅ: {val_spearman:.4f} | lr: {lr:.2e}\")\n",
    "\n",
    "    # ‚úÖ Êõ¥Êñ∞ loss list ‰∏¶Áï´Âúñ\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    plot_losses(train_losses, val_losses)\n",
    "\n",
    "    # ‚úÖ Early stopping\n",
    "    early_stopper(val_loss)\n",
    "    if early_stopper.early_stop:\n",
    "        print(\"‚õî Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# ‚úÖ ÈóúÈñâ log Ê™îÊ°à\n",
    "log_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f55274",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7220265a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_30582/2115051499.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NodeFeatureMLP(\n",
       "  (fc1): Linear(in_features=14, out_features=128, bias=True)\n",
       "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc3): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout3): Dropout(p=0.5, inplace=False)\n",
       "  (fc4): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  (bn4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout4): Dropout(p=0.5, inplace=False)\n",
       "  (fc_out): Linear(in_features=1024, out_features=35, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== ÈúÄË¶ÅÁöÑ Libraries =====\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import csv\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"‚úÖ Using device: {device}\")\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "77d22647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_30582/1390325486.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  test_data = torch.load(\"../SML_test_dataset.pt\")\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_30582/1390325486.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  graph_data = torch.load(\"../test_graph_dataset.pt\")\n"
     ]
    }
   ],
   "source": [
    "# Ê≠£Á¢∫ÊñπÂºè\n",
    "\n",
    "test_data = torch.load(\"../SML_test_dataset.pt\")\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ËºâÂÖ•Ë≥áÊñô\n",
    "graph_data = torch.load(\"../test_graph_dataset.pt\")\n",
    "# ====== Step 2: Âª∫Á´ã Dataset ======\n",
    "test_dataset = importDataset(\n",
    "    S_tiles=test_data['S_tiles'],\n",
    "    M_tiles=test_data['M_tiles'],\n",
    "    L_tiles=test_data['L_tiles'],\n",
    "    labels=test_data['labels'],\n",
    "    meta_info=test_data['meta_info'],\n",
    "    normal_coords=test_data['normal_coords'],\n",
    "    node_feats=graph_data['node_feats'],\n",
    "    adj_lists=graph_data['adj_lists'],\n",
    "    edge_feats=graph_data['edge_feats']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ea4d8725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_30582/3814644018.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'node_feat': torch.tensor(self.node_feats[idx], dtype=torch.float) if self.node_feats is not None else None,\n"
     ]
    }
   ],
   "source": [
    "test_preds, test_meta = predict(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba8ddbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2088, 35)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f26de3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved submission.csv\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# ==== ËÆÄÂèñ test spot index Áî®ÊñºÂ∞çÊáâ ID ====\n",
    "with h5py.File(\"../elucidata_ai_challenge_data.h5\", \"r\") as f:\n",
    "    test_spots = f[\"spots/Test\"]\n",
    "    test_spot_table = pd.DataFrame(np.array(test_spots['S_7']))  # Example: S_7\n",
    "\n",
    "\n",
    "ensemble_df = pd.DataFrame(test_preds, columns=[f\"C{i+1}\" for i in range(test_preds.shape[1])])\n",
    "ensemble_df.insert(0, 'ID', test_spot_table.index)\n",
    "ensemble_df.to_csv(\"submissionÔºøonly_nodes.csv\", index=False)\n",
    "print(\"‚úÖ Saved submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatialhackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
