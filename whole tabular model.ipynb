{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/pretrain_model.py:310: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ae.load_state_dict(torch.load(ae_checkpoint, map_location=\"cpu\"))\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_14152/3220337273.py:319: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('output_folder/rank-spot/realign/whole_worflow/s_m_l/filtered_directly_rank/k-fold_mix/realign_all/Macenko_masked/results/model_epoch022.pt', map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable / total params = 6,639,142 / 6,639,142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionMLP_MultiTask(\n",
       "  (encoder_tile): DeepTileEncoder(\n",
       "    (layer0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU()\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "    )\n",
       "    (global_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (mid_pool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
       "    (fc): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=2560, out_features=512, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "      (5): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (6): LeakyReLU(negative_slope=0.01)\n",
       "      (7): Dropout(p=0.1, inplace=False)\n",
       "      (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (encoder_subtile): SubtileEncoder(\n",
       "    (layer0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU()\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "    )\n",
       "    (global_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (mid_pool): AdaptiveAvgPool2d(output_size=(2, 2))\n",
       "    (large_pool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
       "    (fc): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=1792, out_features=256, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "      (5): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (6): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (encoder_center): CenterSubtileEncoder(\n",
       "    (layer0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU()\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "    )\n",
       "    (global_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (mid_pool): AdaptiveAvgPool2d(output_size=(2, 2))\n",
       "    (large_pool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
       "    (fc): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=1792, out_features=256, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "      (5): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (6): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (gate_fc): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=64, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=64, out_features=3, bias=True)\n",
       "    (3): Softmax(dim=1)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): Dropout(p=0.1, inplace=False)\n",
       "    (9): Linear(in_features=64, out_features=35, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from python_scripts.pretrain_model import PretrainedEncoderRegressor\n",
    "import torch.nn as nn\n",
    "\n",
    "name = 'AE_Center_noaug'\n",
    "\n",
    "checkpoint_path = f\"AE_model/128/{name}/best.pt\"\n",
    "\n",
    "# 1) 实例化（会自动加载并冻结 encoder）\n",
    "model = PretrainedEncoderRegressor(\n",
    "    ae_checkpoint=checkpoint_path,\n",
    "    ae_type=\"center\",\n",
    "    tile_dim=128,\n",
    "    center_dim=128,\n",
    "    neighbor_dim=128,\n",
    "    output_dim=35\n",
    ")\n",
    "\n",
    "# 2) monkey‐patch 一个新的 head\n",
    "model.decoder  = nn.Sequential(\n",
    "    nn.Linear(128+128+128, 256),\n",
    "    nn.LeakyReLU(0.01),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.LeakyReLU(0.01),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.LeakyReLU(0.01),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(64, 35)\n",
    "    \n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(out_channels)\n",
    "        self.act1  = nn.SiLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        self.act2 = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.act1(self.bn1(self.conv1(x)))\n",
    "        out = self.act2(self.bn2(self.conv2(out)))\n",
    "        if self.shortcut is not None:\n",
    "            identity = self.shortcut(x)\n",
    "        return out + identity\n",
    "\n",
    "\n",
    "\n",
    "class DeepTileEncoder(nn.Module):\n",
    "    \"\"\"加深的 Tile 分支：全局信息，多尺度池化 + 三层 MLP\"\"\"\n",
    "    def __init__(self, out_dim, in_channels=3, negative_slope=0.01):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(2)  # 78→39\n",
    "        )\n",
    "        self.layer1 = nn.Sequential(\n",
    "            ResidualBlock(32, 64),\n",
    "            ResidualBlock(64, 64),\n",
    "            nn.MaxPool2d(2)  # 39→19\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            ResidualBlock(64, 128),\n",
    "            ResidualBlock(128, 128),\n",
    "            nn.MaxPool2d(2)  # 19→9\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            ResidualBlock(128, 256),\n",
    "            ResidualBlock(256, 256)\n",
    "        )  # 保持 9×9\n",
    "\n",
    "        # 多尺度池化\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))  # [B,256,1,1]\n",
    "        self.mid_pool    = nn.AdaptiveAvgPool2d((3, 3))  # [B,256,3,3]\n",
    "\n",
    "        total_dim = 256*1*1 + 256*3*3\n",
    "        # 三层 MLP：total_dim → 2*out_dim → out_dim → out_dim\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(total_dim, out_dim*4),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(out_dim*4, out_dim*2),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(out_dim*2, out_dim),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        # x: [B,256,9,9]\n",
    "        g = self.global_pool(x).contiguous().reshape(x.size(0), -1)  # [B,256]\n",
    "        m = self.mid_pool(x).contiguous().reshape(x.size(0), -1)     # [B,256*3*3]\n",
    "\n",
    "        return self.fc(torch.cat([g, m], dim=1))\n",
    "\n",
    "\n",
    "class SubtileEncoder(nn.Module):\n",
    "    \"\"\"多尺度 Subtile 分支：局部信息 + 两层 MLP\"\"\"\n",
    "    def __init__(self, out_dim, in_channels=3, negative_slope=0.01):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(2)  # 26→13\n",
    "        )\n",
    "        self.layer1 = nn.Sequential(\n",
    "            ResidualBlock(32, 64),\n",
    "            ResidualBlock(64, 64),\n",
    "            nn.MaxPool2d(2)  # 13→6\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            ResidualBlock(64, 128),\n",
    "            ResidualBlock(128, 128)\n",
    "        )  # 保持 6×6\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.mid_pool    = nn.AdaptiveAvgPool2d((2,2))\n",
    "        self.large_pool    = nn.AdaptiveAvgPool2d((3,3))\n",
    "\n",
    "        total_dim = 128*1*1 + 128*2*2 + 128*3*3\n",
    "        # 两层 MLP：total_dim → out_dim*2 → out_dim\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(total_dim, out_dim*2),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(out_dim*2, out_dim),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C, H, W = x.shape\n",
    "        x = x.contiguous().reshape(B*N, C, H, W)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        # g,m: [B*N, feat]\n",
    "        g = self.global_pool(x).contiguous().reshape(B, N, -1)\n",
    "        m = self.mid_pool(x).contiguous().reshape(B, N, -1)\n",
    "        l = self.large_pool(x).contiguous().reshape(B, N, -1)\n",
    "\n",
    "        # 合并 N 张 subtiles，再 FC\n",
    "        feat = torch.cat([g, m, l], dim=2).mean(dim=1).contiguous()  # [B, total_dim]\n",
    "        return self.fc(feat)\n",
    "class CenterSubtileEncoder(nn.Module):\n",
    "    \"\"\"專門處理中心 subtile 的 Encoder\"\"\"\n",
    "    def __init__(self, out_dim, in_channels=3, negative_slope= 0.01):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(2)  # 26→13\n",
    "        )\n",
    "        self.layer1 = nn.Sequential(\n",
    "            ResidualBlock(32, 64),\n",
    "            ResidualBlock(64, 64),\n",
    "            nn.MaxPool2d(2)  # 13→6\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            ResidualBlock(64, 128),\n",
    "            ResidualBlock(128, 128)\n",
    "        )  # 6×6\n",
    "\n",
    "        # 多尺度池化\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.mid_pool    = nn.AdaptiveAvgPool2d((2,2))\n",
    "        self.large_pool    = nn.AdaptiveAvgPool2d((3,3))\n",
    "\n",
    "        total_dim = 128*1*1 + 128*2*2 + 128*3*3\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(total_dim, out_dim*2),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(out_dim*2, out_dim),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        g = self.global_pool(x).contiguous().reshape(x.size(0), -1)\n",
    "        m = self.mid_pool(x).contiguous().reshape(x.size(0), -1)\n",
    "        l = self.large_pool(x).contiguous().reshape(x.size(0), -1)\n",
    "\n",
    "        return self.fc(torch.cat([g, m, l], dim=1)).contiguous()\n",
    "\n",
    "\n",
    "\n",
    "class VisionMLP_MultiTask(nn.Module):\n",
    "    \"\"\"整體多任務模型：融合 tile + subtile + center，使用動態權重融合\"\"\"\n",
    "    def __init__(self, tile_dim=128, subtile_dim=64, output_dim=35, negative_slope=0.01):\n",
    "        super().__init__()\n",
    "        self.encoder_tile    = DeepTileEncoder(tile_dim)\n",
    "        self.encoder_subtile = SubtileEncoder(subtile_dim)\n",
    "        self.encoder_center  = CenterSubtileEncoder(subtile_dim)\n",
    "\n",
    "        # 融合層：輸入三個分支的 concat，輸出三個 gate\n",
    "        self.gate_fc = nn.Sequential(\n",
    "            nn.Linear(tile_dim + subtile_dim + subtile_dim, 64),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Linear(64, 3),  # 對 tile, subtile, center 分支輸出 gate\n",
    "            nn.Softmax(dim=1)  # 轉成權重\n",
    "        )\n",
    "\n",
    "        # 輸出 decoder：輸入為 tile_dim (因為融合後只剩一個 vector)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(tile_dim, 256),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, tile, subtiles):\n",
    "        tile = tile.contiguous()\n",
    "        subtiles = subtiles.contiguous()\n",
    "        center = subtiles[:, 4]\n",
    "\n",
    "        f_tile = self.encoder_tile(tile)         # [B, tile_dim]\n",
    "        f_sub  = self.encoder_subtile(subtiles)  # [B, subtile_dim]\n",
    "        f_center = self.encoder_center(center)   # [B, subtile_dim]\n",
    "\n",
    "        # 拼接三個分支做 gating\n",
    "        features_cat = torch.cat([f_tile, f_sub, f_center], dim=1)  # [B, tile+sub+center]\n",
    "        gates = self.gate_fc(features_cat)  # [B, 3]\n",
    "\n",
    "        # 對三個分支做 weighted sum\n",
    "        f_fused = (\n",
    "            gates[:, 0:1] * f_tile + \n",
    "            gates[:, 1:2] * f_sub + \n",
    "            gates[:, 2:3] * f_center\n",
    "        )  # [B, tile_dim]（注意：需保證 f_tile == f_sub == f_center 的維度）\n",
    "\n",
    "        return self.decoder(f_fused)\n",
    "    \n",
    "# class VisionMLP_MultiTask(nn.Module):\n",
    "#     \"\"\"整體多任務模型：融合 tile + subtile + center + position 特徵\"\"\"\n",
    "#     def __init__(self, tile_dim=128, subtile_dim=128, output_dim=35, negative_slope=0.01):\n",
    "#         super().__init__()\n",
    "#         self.encoder_tile    = DeepTileEncoder(tile_dim)\n",
    "#         self.encoder_subtile = SubtileEncoder(subtile_dim)\n",
    "#         self.encoder_center  = CenterSubtileEncoder(subtile_dim)\n",
    "\n",
    "#         self.feature_dim = tile_dim + subtile_dim + subtile_dim # +2 for position(x,y)\n",
    "\n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(self.feature_dim, 256),\n",
    "#             nn.LeakyReLU(negative_slope),\n",
    "#             nn.Dropout(0.1),\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.LeakyReLU(negative_slope),\n",
    "#             nn.Dropout(0.1),\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.LeakyReLU(negative_slope),\n",
    "#             nn.Dropout(0.1),\n",
    "#             nn.Linear(64, output_dim),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, tile, subtiles):\n",
    "#         tile = tile.contiguous()\n",
    "#         subtiles = subtiles.contiguous()\n",
    "#         center = subtiles[:, 4]\n",
    "\n",
    "#         f_tile = self.encoder_tile(tile)         # [B, tile_dim]\n",
    "#         f_sub  = self.encoder_subtile(subtiles)  # [B, subtile_dim]\n",
    "#         f_center = self.encoder_center(center)   # [B, subtile_dim]\n",
    "\n",
    "#         # 拼接特徵向量與座標\n",
    "#         features_cat = torch.cat([f_tile, f_sub, f_center], dim=1)  # [B, tile+sub+center+2]\n",
    "\n",
    "#         return self.decoder(features_cat)\n",
    "\n",
    "\n",
    "# 用法示例\n",
    "model = VisionMLP_MultiTask(tile_dim=128, subtile_dim=128, output_dim=35)\n",
    "\n",
    "\n",
    "# —— 5) 确保只有 decoder 可训练 ——  \n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total     = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Trainable / total params = {trainable:,} / {total:,}\")\n",
    "\n",
    "\n",
    "device   = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('output_folder/rank-spot/realign/whole_worflow/s_m_l/filtered_directly_rank/k-fold_mix/realign_all/Macenko_masked/results/model_epoch022.pt', map_location=\"cpu\"))\n",
    "model.to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same in multiple .pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/import_data.py:251: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d = torch.load(fpath, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded keys: dict_keys(['subtiles', 'label', 'source_idx', 'slide_idx', 'tile', 'position'])\n",
      "Samples: 8348\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import inspect\n",
    "from python_scripts.import_data import load_all_tile_data\n",
    "\n",
    "# 用法範例\n",
    "#folder = \"dataset/spot-rank/version-3/only_tile_sub/original_train\"\n",
    "folder = \"dataset/spot-rank/filtered_directly_rank/masked/realign/Macenko_masked/filtered/train_data/\"\n",
    "\n",
    "grouped_data = load_all_tile_data( \n",
    "        folder_path=folder,\n",
    "        model=model,\n",
    "        fraction=1,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # grouped_data 現在只會有 model.forward() 需要的 key，\n",
    "    # 像 ['tile','subtiles','neighbors','norm_coord','node_feat','adj_list','edge_feat','label','source_idx']\n",
    "print(\"Loaded keys:\", grouped_data.keys())\n",
    "print(\"Samples:\", len(next(iter(grouped_data.values()))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checking dataset sample: 0\n",
      "📏 tile shape: torch.Size([3, 78, 78]) | dtype: torch.float32 | min: 0.157, max: 1.000, mean: 0.680, std: 0.142\n",
      "📏 subtiles shape: torch.Size([9, 3, 26, 26]) | dtype: torch.float32 | min: 0.157, max: 1.000, mean: 0.680, std: 0.142\n",
      "📏 label shape: torch.Size([35]) | dtype: torch.float32 | min: 1.000, max: 35.000, mean: 18.000, std: 10.247\n",
      "--- label head (前 5 個元素):\n",
      "tensor([12., 24., 18.,  6., 30.])\n",
      "📏 source_idx shape: torch.Size([]) | dtype: torch.int64 | min: 0.000, max: 0.000, mean: 0.000, std: nan\n",
      "--- source_idx 資料為純量: tensor(0)\n",
      "📏 position shape: torch.Size([2]) | dtype: torch.float32 | min: 0.171, max: 0.632, mean: 0.401, std: 0.326\n",
      "--- position head (前 5 個元素):\n",
      "tensor([0.6318, 0.1707])\n",
      "✅ All checks passed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_14152/3062057575.py:79: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/miniforge3/conda-bld/libtorch_1744320376245/work/aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
      "  std = tensor_float.std().item()\n"
     ]
    }
   ],
   "source": [
    "from python_scripts.import_data import convert_item, get_model_inputs\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import inspect\n",
    "import numpy as np\n",
    "\n",
    "class importDataset(Dataset):\n",
    "    def __init__(self, data_dict, model, image_keys=None, transform=None, print_sig=False):\n",
    "        self.data = data_dict\n",
    "        self.image_keys = set(image_keys) if image_keys is not None else set()\n",
    "        self.transform = transform if transform is not None else lambda x: x\n",
    "        self.forward_keys = list(get_model_inputs(model, print_sig=print_sig).parameters.keys())\n",
    "\n",
    "        expected_length = None\n",
    "        for key, value in self.data.items():\n",
    "            if expected_length is None:\n",
    "                expected_length = len(value)\n",
    "            if len(value) != expected_length:\n",
    "                raise ValueError(f\"資料欄位 '{key}' 的長度 ({len(value)}) 與預期 ({expected_length}) 不一致。\")\n",
    "\n",
    "        for key in self.forward_keys:\n",
    "            if key not in self.data:\n",
    "                raise ValueError(f\"data_dict 缺少模型 forward 所需欄位: '{key}'。目前可用的欄位: {list(self.data.keys())}\")\n",
    "        if \"label\" not in self.data:\n",
    "            raise ValueError(f\"data_dict 必須包含 'label' 欄位。可用的欄位: {list(self.data.keys())}\")\n",
    "        if \"source_idx\" not in self.data:\n",
    "            raise ValueError(\"data_dict 必須包含 'source_idx' 欄位，用於 trace 原始順序對應。\")\n",
    "        if \"position\" not in self.data:\n",
    "            raise ValueError(\"data_dict 必須包含 'position' 欄位，用於 trace 原始順序對應。\")\n",
    "    def __len__(self):\n",
    "        return len(next(iter(self.data.values())))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {}\n",
    "        for key in self.forward_keys:\n",
    "            value = self.data[key][idx]\n",
    "            value = self.transform(value)\n",
    "            value = convert_item(value, is_image=(key in self.image_keys))\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                value = value.float()\n",
    "            sample[key] = value\n",
    "\n",
    "        label = self.transform(self.data[\"label\"][idx])\n",
    "        label = convert_item(label, is_image=False)\n",
    "        if isinstance(label, torch.Tensor):\n",
    "            label = label.float()\n",
    "        sample[\"label\"] = label\n",
    "\n",
    "        # 加入 source_idx\n",
    "        source_idx = self.data[\"source_idx\"][idx]\n",
    "        sample[\"source_idx\"] = torch.tensor(source_idx, dtype=torch.long)\n",
    "        # 加入 position （假设 data_dict 中 'position' 是 (x, y) 或 [x, y]）\n",
    "        pos = self.data[\"position\"][idx]\n",
    "        sample[\"position\"] = torch.tensor(pos, dtype=torch.float)\n",
    "        return sample\n",
    "    def check_item(self, idx=0, num_lines=5):\n",
    "        expected_keys = self.forward_keys + ['label', 'source_idx', 'position']\n",
    "        sample = self[idx]\n",
    "        print(f\"🔍 Checking dataset sample: {idx}\")\n",
    "        for key in expected_keys:\n",
    "            if key not in sample:\n",
    "                print(f\"❌ 資料中缺少 key: {key}\")\n",
    "                continue\n",
    "            tensor = sample[key]\n",
    "            if isinstance(tensor, torch.Tensor):\n",
    "                try:\n",
    "                    shape = tensor.shape\n",
    "                except Exception:\n",
    "                    shape = \"N/A\"\n",
    "                dtype = tensor.dtype if hasattr(tensor, \"dtype\") else \"N/A\"\n",
    "                output_str = f\"📏 {key} shape: {shape} | dtype: {dtype}\"\n",
    "                if tensor.numel() > 0:\n",
    "                    try:\n",
    "                        tensor_float = tensor.float()\n",
    "                        mn = tensor_float.min().item()\n",
    "                        mx = tensor_float.max().item()\n",
    "                        mean = tensor_float.mean().item()\n",
    "                        std = tensor_float.std().item()\n",
    "                        output_str += f\" | min: {mn:.3f}, max: {mx:.3f}, mean: {mean:.3f}, std: {std:.3f}\"\n",
    "                    except Exception:\n",
    "                        output_str += \" | 無法計算統計數據\"\n",
    "                print(output_str)\n",
    "                if key not in self.image_keys:\n",
    "                    if tensor.ndim == 0:\n",
    "                        print(f\"--- {key} 資料為純量:\", tensor)\n",
    "                    elif tensor.ndim == 1:\n",
    "                        print(f\"--- {key} head (前 {num_lines} 個元素):\")\n",
    "                        print(tensor[:num_lines])\n",
    "                    else:\n",
    "                        print(f\"--- {key} head (前 {num_lines} 列):\")\n",
    "                        print(tensor[:num_lines])\n",
    "            else:\n",
    "                # 如果 position 存的是 list/tuple/etc，也会走这里\n",
    "                print(f\"📏 {key} (非 tensor 資料):\", tensor)\n",
    "        print(\"✅ All checks passed!\")\n",
    "\n",
    "\n",
    "full_dataset = importDataset(grouped_data, model,\n",
    "                             image_keys=['tile','subtiles'],\n",
    "                             transform=lambda x: x)\n",
    "\n",
    "full_dataset.check_item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.feature.texture import graycomatrix, graycoprops\n",
    "from skimage.filters import sobel\n",
    "import pywt\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === 工具函數 ===\n",
    "def compute_ae_reconstruction_loss(ae_model, dataloader, device, ae_type):\n",
    "    ae_model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Computing AE recon loss\"):\n",
    "            tile = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "            recon = ae_model(tile, subtiles)\n",
    "\n",
    "            if ae_type == 'center':\n",
    "                target = subtiles[:, 4]\n",
    "            else:\n",
    "                target = subtiles\n",
    "\n",
    "            loss = F.mse_loss(recon, target, reduction='none')\n",
    "            loss = loss.view(loss.shape[0], -1).mean(dim=1)\n",
    "            losses.append(loss.cpu().numpy())\n",
    "    return np.concatenate(losses)\n",
    "\n",
    "def compute_latent_stats(latents):\n",
    "    return np.concatenate([\n",
    "        latents.mean(axis=1, keepdims=True),\n",
    "        latents.std(axis=1, keepdims=True),\n",
    "        latents.min(axis=1, keepdims=True),\n",
    "        latents.max(axis=1, keepdims=True),\n",
    "    ], axis=1)\n",
    "\n",
    "\n",
    "# === Loading Label Cluster Map ===\n",
    "def load_label_cluster_map(filepath=\"dataset/label_cluster_map.pkl\", use_clusters=\"both\"):\n",
    "    cluster_map = joblib.load(filepath)\n",
    "    # keys are 'label_cluster_map_4', 'label_cluster_map_20'\n",
    "    if use_clusters == \"4\":\n",
    "        return cluster_map['label_cluster_map_4']\n",
    "    elif use_clusters == \"20\":\n",
    "        return cluster_map['label_cluster_map_20']\n",
    "    elif use_clusters == \"both\":\n",
    "        return {\n",
    "            '4': cluster_map['label_cluster_map_4'],\n",
    "            '20': cluster_map['label_cluster_map_20']\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Invalid cluster selection. Choose '4', '20', or 'both'.\")\n",
    "\n",
    "# === Helper Functions ===\n",
    "def choose_best_n_clusters(X, min_k=35, max_k=38, random_state=42):\n",
    "    best_k, best_score = min_k, -np.inf\n",
    "    for k in range(min_k, max_k + 1):\n",
    "        labels = KMeans(n_clusters=k, random_state=random_state).fit_predict(X)\n",
    "        score = silhouette_score(X, labels)\n",
    "        print(f\"Silhouette score for k={k}: {score:.4f}\")\n",
    "        if score > best_score:\n",
    "            best_score, best_k = score, k\n",
    "    print(f\"Selected best k={best_k} (score={best_score:.4f})\")\n",
    "    return best_k\n",
    "\n",
    "\n",
    "def compute_cluster_summary_stats(matrix, cluster_ids):\n",
    "    \"\"\"\n",
    "    matrix: (n_samples, n_dims)\n",
    "    cluster_ids: length n_samples, 每個 sample 所屬的群編號\n",
    "    回傳 shape=(n_samples, 4)：\n",
    "      [mean, std, min, max] 是該 sample 所屬群裡，所有 matrix 值的全局統計\n",
    "    \"\"\"\n",
    "    stats = np.zeros((matrix.shape[0], 4), dtype=float)\n",
    "    for c in np.unique(cluster_ids):\n",
    "        mask = (cluster_ids == c)\n",
    "        values = matrix[mask]            # shape=(n_c, n_dims)\n",
    "        flat = values.flatten()         # 把維度攤平成一維\n",
    "        summary = [\n",
    "            flat.mean(),\n",
    "            flat.std(),\n",
    "            flat.min(),\n",
    "            flat.max(),\n",
    "        ]\n",
    "        stats[mask] = summary           # 同一群裡的所有 sample 都用同一組 summary\n",
    "    return stats\n",
    "\n",
    "\n",
    "def compute_feature_cluster_stats(matrix, feature_cluster_ids):\n",
    "    \"\"\"\n",
    "    Given matrix shape (n_samples, n_features) and feature_cluster_ids length n_features,\n",
    "    compute per-sample [mean, std, min, max] within each feature-cluster.\n",
    "    Returns array shape (n_samples, n_clusters*4)\n",
    "    \"\"\"\n",
    "    unique_clusters = np.unique(feature_cluster_ids)\n",
    "    stats_per_cluster = []\n",
    "    for c in unique_clusters:\n",
    "        mask = (feature_cluster_ids == c)\n",
    "        cluster_vals = matrix[:, mask]  # shape (n_samples, n_feats_in_cluster)\n",
    "        mean = cluster_vals.mean(axis=1, keepdims=True)\n",
    "        std  = cluster_vals.std(axis=1, keepdims=True)\n",
    "        mn   = cluster_vals.min(axis=1, keepdims=True)\n",
    "        mx   = cluster_vals.max(axis=1, keepdims=True)\n",
    "        stats_per_cluster.append(np.hstack([mean, std, mn, mx]))\n",
    "    return np.hstack(stats_per_cluster)\n",
    "\n",
    "\n",
    "def compute_rgb_stats(dataset):\n",
    "    stats = []\n",
    "    for i in range(len(dataset)):\n",
    "        sub = dataset[i]['subtiles'][4].numpy()\n",
    "        ch_stats = []\n",
    "        for ch in range(sub.shape[0]):\n",
    "            vals = sub[ch]\n",
    "            ch_stats += [vals.mean(), vals.std(), vals.min(), vals.max()]\n",
    "        stats.append(ch_stats)\n",
    "    return np.array(stats)\n",
    "\n",
    "\n",
    "def compute_rgb_cluster_stats(dataset, cluster_ids):\n",
    "    unique = np.unique(cluster_ids)\n",
    "    stats_dict = {}\n",
    "    for c in unique:\n",
    "        idxs = np.where(cluster_ids == c)[0]\n",
    "        acc = []\n",
    "        for i in idxs:\n",
    "            acc.append(dataset[i]['subtiles'][4].numpy())\n",
    "        arr = np.stack(acc)\n",
    "        ch_stats = []\n",
    "        for ch in range(arr.shape[1]):\n",
    "            flat = arr[:, ch].flatten()\n",
    "            ch_stats += [flat.mean(), flat.std(), flat.min(), flat.max()]\n",
    "        stats_dict[c] = np.array(ch_stats)\n",
    "    return np.vstack([stats_dict[c] for c in cluster_ids])\n",
    "# === RGB Statistics Extensions ===\n",
    "# center subtile (index 4) already in compute_rgb_stats\n",
    "\n",
    "def compute_all_subtiles_rgb_stats(dataset):\n",
    "    \"\"\"\n",
    "    每個 sample 的所有 subtiles (0-8) 中，每個 channel 的 mean/std/min/max，concat 形成 (n, 9*4*C)\n",
    "    \"\"\"\n",
    "    stats = []\n",
    "    for i in range(len(dataset)):\n",
    "        subs = dataset[i]['subtiles'].numpy()  # shape (9, C, H, W)\n",
    "        sample_stats = []\n",
    "        for idx in range(subs.shape[0]):\n",
    "            for ch in range(subs.shape[1]):\n",
    "                vals = subs[idx, ch]\n",
    "                sample_stats += [vals.mean(), vals.std(), vals.min(), vals.max()]\n",
    "        stats.append(sample_stats)\n",
    "    return np.array(stats)\n",
    "\n",
    "def compute_subtiles_except_center_rgb_stats(dataset):\n",
    "    \"\"\"\n",
    "    每個 sample 的 subtiles 除了 center (index 4) 外，其餘 8 塊合併後，每 channel 的 mean/std/min/max，shape (n, C*4)\n",
    "    \"\"\"\n",
    "    stats = []\n",
    "    for i in range(len(dataset)):\n",
    "        subs = dataset[i]['subtiles'].numpy()  # (9, C, H, W)\n",
    "        exclude = np.concatenate([subs[:4], subs[5:]], axis=0)  # (8, C, H, W)\n",
    "        sample_stats = []\n",
    "        for ch in range(exclude.shape[1]):\n",
    "            vals = exclude[:, ch].flatten()\n",
    "            sample_stats += [vals.mean(), vals.std(), vals.min(), vals.max()]\n",
    "        stats.append(sample_stats)\n",
    "    return np.array(stats)\n",
    "\n",
    "def compute_tile_rgb_stats(dataset):\n",
    "    \"\"\"\n",
    "    每個 sample 的 tile (整張圖)，每 channel 的 mean/std/min/max，shape (n, C*4)\n",
    "    \"\"\"\n",
    "    stats = []\n",
    "    for i in range(len(dataset)):\n",
    "        tile = dataset[i]['tile'].numpy()  # shape (C, H, W)\n",
    "        sample_stats = []\n",
    "        for ch in range(tile.shape[0]):\n",
    "            vals = tile[ch]\n",
    "            sample_stats += [vals.mean(), vals.std(), vals.min(), vals.max()]\n",
    "        stats.append(sample_stats)\n",
    "    return np.array(stats)\n",
    "\n",
    "# === Texture & Pattern Features ===\n",
    "\n",
    "\n",
    "def compute_wavelet_stats(dataset, wavelet='db1', level=2):\n",
    "    feats = []\n",
    "    for i in range(len(dataset)):\n",
    "        patch = dataset[i]['subtiles'][4].numpy()[0]\n",
    "        coeffs = pywt.wavedec2(patch, wavelet=wavelet, level=level)\n",
    "        sample = []\n",
    "        for arr in coeffs:\n",
    "            if isinstance(arr, tuple):\n",
    "                for sub in arr:\n",
    "                    sample += [sub.mean(), sub.std()]\n",
    "            else:\n",
    "                sample += [arr.mean(), arr.std()]\n",
    "        feats.append(sample)\n",
    "    return np.array(feats)\n",
    "\n",
    "\n",
    "def compute_sobel_stats(dataset):\n",
    "    feats = []\n",
    "    for i in range(len(dataset)):\n",
    "        gray = dataset[i]['tile'].numpy().mean(axis=0)\n",
    "        edge = sobel(gray)\n",
    "        feats.append([edge.mean(), edge.std(), edge.min(), edge.max()])\n",
    "    return np.array(feats)\n",
    "\n",
    "# === Texture & Pattern Features ===\n",
    "\n",
    "def compute_hsv_stats(dataset):\n",
    "    feats = []\n",
    "    from skimage.color import rgb2hsv\n",
    "    for i in range(len(dataset)):\n",
    "        sub = dataset[i]['subtiles'][4].numpy()  # (C, H, W)\n",
    "        img = sub[:3].transpose(1,2,0)         # (H, W, 3)\n",
    "        hsv = rgb2hsv(img)\n",
    "        sample = []\n",
    "        for ch in range(3):\n",
    "            vals = hsv[:,:,ch]\n",
    "            sample += [vals.mean(), vals.std(), vals.min(), vals.max()]\n",
    "        feats.append(sample)\n",
    "    return np.array(feats)\n",
    "\n",
    "\n",
    "def compute_color_moments(dataset):\n",
    "    feats = []\n",
    "    from scipy.stats import skew, kurtosis\n",
    "    for i in range(len(dataset)):\n",
    "        sub = dataset[i]['subtiles'][4].numpy()  # (C, H, W)\n",
    "        img = sub.transpose(1,2,0)               # (H, W, C)\n",
    "        sample = []\n",
    "        for ch in range(img.shape[2]):\n",
    "            vals = img[:,:,ch].ravel()\n",
    "            sample += [vals.mean(), vals.std(), skew(vals), kurtosis(vals)]\n",
    "        feats.append(sample)\n",
    "    return np.array(feats)\n",
    "\n",
    "\n",
    "# === Subtile Contrast Features ===\n",
    "\n",
    "def compute_subtile_contrast_stats(dataset, eps=1e-7):\n",
    "    \"\"\"\n",
    "    Compute contrast between center subtile and surrounding subtiles:\n",
    "    For each sample and each channel, calculate:\n",
    "      diff = center_mean - surround_mean\n",
    "      ratio = center_mean / (surround_mean + eps)\n",
    "    Returns array (n_samples, C*2)\n",
    "    \"\"\"\n",
    "    stats = []\n",
    "    for i in range(len(dataset)):\n",
    "        subs = dataset[i]['subtiles'].numpy()  # (9, C, H, W)\n",
    "        center = subs[4]  # (C, H, W)\n",
    "        surround = np.concatenate([subs[:4], subs[5:]], axis=0)  # (8, C, H, W)\n",
    "        center_mean = center.reshape(center.shape[0], -1).mean(axis=1)\n",
    "        surround_mean = surround.reshape(surround.shape[0], surround.shape[1], -1).mean(axis=2).mean(axis=0)\n",
    "        diff = center_mean - surround_mean\n",
    "        ratio = center_mean / (surround_mean + eps)\n",
    "        stats.append(np.hstack([diff, ratio]))\n",
    "    return np.array(stats)\n",
    "\n",
    "# === H&E Color Deconvolution Features ===\n",
    "def compute_he_stats(dataset):\n",
    "    \"\"\"\n",
    "    Compute H&E stain intensity stats from center subtile RGB (3 channels):\n",
    "    Returns array (n_samples, 8): [H_mean, H_std, H_min, H_max, E_mean, E_std, E_min, E_max]\n",
    "    \"\"\"\n",
    "    from skimage.color import separate_stains, hed_from_rgb\n",
    "    stats = []\n",
    "    for i in range(len(dataset)):\n",
    "        sub = dataset[i]['subtiles'][4].numpy()  # (C, H, W)\n",
    "        # assume first 3 channels are RGB\n",
    "        rgb = sub[:3].transpose(1,2,0)\n",
    "        hed = separate_stains(rgb, hed_from_rgb)\n",
    "        h = hed[:,:,0]\n",
    "        e = hed[:,:,1]\n",
    "        sample = [\n",
    "            h.mean(), h.std(), h.min(), h.max(),\n",
    "            e.mean(), e.std(), e.min(), e.max()\n",
    "        ]\n",
    "        stats.append(sample)\n",
    "    return np.array(stats)\n",
    "\n",
    "\n",
    "# === Sliding Window Std Features ===\n",
    "\n",
    "def compute_sliding_std_stats(dataset, window_size=3, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Compute local standard deviation within a sliding window of given size on center subtile.\n",
    "    Returns array shape (n_samples, C*2) with mean and max of local std for each channel.\n",
    "    \"\"\"\n",
    "    from scipy.ndimage import uniform_filter\n",
    "\n",
    "    stats = []\n",
    "    for i in range(len(dataset)):\n",
    "        sub = dataset[i]['subtiles'][4].numpy()  # (C, H, W)\n",
    "        sample = []\n",
    "        for ch in range(sub.shape[0]):\n",
    "            arr = sub[ch]\n",
    "            # compute local mean and mean of squares\n",
    "            mean = uniform_filter(arr, size=window_size)\n",
    "            mean_sq = uniform_filter(arr * arr, size=window_size)\n",
    "            local_std = np.sqrt(np.maximum(mean_sq - mean * mean, 0))\n",
    "            sample += [local_std.mean(), local_std.max()]\n",
    "        stats.append(sample)\n",
    "    return np.array(stats)\n",
    "\n",
    "\n",
    "# === Distribution-based Features ===\n",
    "\n",
    "def compute_entropy(oof_preds, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Compute Shannon entropy for each sample's OOF prediction distribution.\n",
    "    oof_preds: (n_samples, C)\n",
    "    returns: array shape (n_samples, 1)\n",
    "    \"\"\"\n",
    "    # normalize to sum 1\n",
    "    probs = oof_preds / (oof_preds.sum(axis=1, keepdims=True) + eps)\n",
    "    ent = -np.sum(probs * np.log(probs + eps), axis=1, keepdims=True)\n",
    "    return ent\n",
    "\n",
    "\n",
    "def compute_top2_diff(oof_preds):\n",
    "    \"\"\"\n",
    "    Compute difference between the top-1 and top-2 predicted values per sample.\n",
    "    returns: array shape (n_samples, 1)\n",
    "    \"\"\"\n",
    "    # sort descending\n",
    "    sorted_preds = -np.sort(-oof_preds, axis=1)\n",
    "    diff = sorted_preds[:, 0] - sorted_preds[:, 1]\n",
    "    return diff.reshape(-1, 1)\n",
    "\n",
    "# === Pairwise Differences for All Cell Types ===\n",
    "from itertools import combinations\n",
    "\n",
    "def compute_pairwise_diff(oof_preds):\n",
    "    \"\"\"\n",
    "    Compute raw differences for every pair of cell-type predictions.\n",
    "    For each sample, returns array of length C*(C-1)/2 in order of (i<j).\n",
    "    \"\"\"\n",
    "    n_samples, C = oof_preds.shape\n",
    "    # generate list of index pairs i<j\n",
    "    idx_pairs = list(combinations(range(C), 2))\n",
    "    # stack differences for each pair\n",
    "    diffs = np.stack([oof_preds[:, i] - oof_preds[:, j] for i, j in idx_pairs], axis=1)\n",
    "    return diffs\n",
    "\n",
    "def compute_dispersion(oof_preds):\n",
    "    \"\"\"\n",
    "    Compute dispersion metric (Gini impurity) or std across cell-type predictions.\n",
    "    returns: array shape (n_samples, 1)\n",
    "    \"\"\"\n",
    "    # Gini impurity: 1 - sum(p_i^2)\n",
    "    probs = oof_preds / (oof_preds.sum(axis=1, keepdims=True) + 1e-12)\n",
    "    gini = 1 - np.sum(probs**2, axis=1)\n",
    "    return gini.reshape(-1, 1)\n",
    "\n",
    "def compute_ae_embeddings(loader, recon_model, device):\n",
    "    \"\"\"\n",
    "    Extract fused encoder embeddings from the PretrainedEncoderRegressor.\n",
    "    Returns numpy array shape (n_samples, fusion_dim).\n",
    "    \"\"\"\n",
    "    recon_model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            tiles = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "            subtiles = subtiles.contiguous()\n",
    "            tiles     = tiles.contiguous()\n",
    "            # forward up to encoder fusion\n",
    "            f_c = recon_model.enc_center(subtiles[:, 4])\n",
    "            f_n = recon_model.enc_neigh(subtiles)\n",
    "            f_t = recon_model.enc_tile(tiles)\n",
    "            fused = torch.cat([f_c, f_n, f_t], dim=1)\n",
    "            embeddings.append(fused.cpu().numpy())\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# === Main Function ===\n",
    "def generate_meta_features(\n",
    "    dataset,\n",
    "    oof_preds,\n",
    "    image_latents,\n",
    "    model_for_recon,\n",
    "    device,\n",
    "    ae_type,\n",
    "    label_cluster_map_path=\"dataset/label_cluster_map.pkl\",\n",
    "    use_clusters=\"both\"\n",
    "):\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "    recon_loss = compute_ae_reconstruction_loss(model_for_recon, loader, device, ae_type)\n",
    "\n",
    "    # 1-4: OOF preds, image latents, recon loss, latent stats\n",
    "    image_latent = compute_ae_embeddings(loader, model_for_recon, device)\n",
    "    latent_stats = compute_latent_stats(image_latent)\n",
    "\n",
    "    # # 6: Ground Truth Cell Expression Cluster Stats\n",
    "    label_map = load_label_cluster_map(label_cluster_map_path, use_clusters)\n",
    "    if use_clusters == \"both\":\n",
    "        stats4  = compute_feature_cluster_stats(oof_preds, label_map['4'])   # shape (n, 4*4)\n",
    "        stats20 = compute_feature_cluster_stats(oof_preds, label_map['20'])  # shape (n, 20*4)\n",
    "        gt_cluster_stats = np.hstack([stats4, stats20])  # (n, 16+80)\n",
    "    else:\n",
    "        gt_cluster_stats = compute_feature_cluster_stats(oof_preds, label_map)\n",
    "\n",
    "    # # 8: OOF pred clusters stats\n",
    "    # # 把 cell 當作樣本來作群聚\n",
    "    # # best_k_cells = choose_best_n_clusters(oof_preds.T, min_k=2, max_k=6)\n",
    "    # cell_cluster_ids = KMeans(n_clusters=4, random_state=42)\\\n",
    "    #                     .fit_predict(oof_preds.T)\n",
    "    # pred_cluster_stats = compute_feature_cluster_stats(oof_preds, cell_cluster_ids)\n",
    "\n",
    "    # # 9-10: Latent clusters & summary\n",
    "    # best_k_latent = choose_best_n_clusters(image_latents, min_k=2, max_k=50)\n",
    "    # latent_ids = KMeans(n_clusters=best_k_latent, random_state=42).fit_predict(image_latents)\n",
    "    # latent_summary = compute_cluster_summary_stats(image_latents, latent_ids)  # shape = (2197, 4)\n",
    "\n",
    "    # # 11-12: AE loss clusters & summary\n",
    "    # loss_vals = recon_loss.reshape(-1,1)\n",
    "    # best_k_loss = choose_best_n_clusters(loss_vals, min_k=2, max_k=50)\n",
    "    # loss_ids = KMeans(n_clusters=best_k_loss, random_state=42).fit_predict(loss_vals)\n",
    "    # loss_summary_stats = compute_cluster_summary_stats(loss_vals, loss_ids)\n",
    "\n",
    "\n",
    "    # # 13: RGB stats\n",
    "    rgb_stats = compute_rgb_stats(dataset)\n",
    "    # 新增: 所有 subtiles RGB, 除 center 以外的 subtiles RGB, 整張 tile RGB\n",
    "    rgb_all_subs = compute_all_subtiles_rgb_stats(dataset)\n",
    "    rgb_except_center = compute_subtiles_except_center_rgb_stats(dataset)\n",
    "    rgb_tile = compute_tile_rgb_stats(dataset)\n",
    "    \n",
    "    # # 14-15: Cluster-level RGB stats\n",
    "    # latent_rgb_stats = compute_rgb_cluster_stats(dataset, latent_ids)\n",
    "    # loss_rgb_stats   = compute_rgb_cluster_stats(dataset, loss_ids)\n",
    "    # concatenate all features\n",
    "    \n",
    "        # 質地 & 紋理特徵\n",
    "    wavelet_feats     = compute_wavelet_stats(dataset)\n",
    "    sobel_feats       = compute_sobel_stats(dataset)\n",
    "    \n",
    "    \n",
    "    # 新增: 顏色空間與色彩分佈特徵\n",
    "    hsv_feats         = compute_hsv_stats(dataset)\n",
    "    color_moments_feats = compute_color_moments(dataset)\n",
    "    \n",
    "    # 新增: Subtile 間對比特徵\n",
    "    contrast_feats    = compute_subtile_contrast_stats(dataset)\n",
    "    # 新增: H&E 染色成分強度特徵\n",
    "    he_feats          = compute_he_stats(dataset)\n",
    "    \n",
    "    sliding_std_stats = compute_sliding_std_stats(dataset)\n",
    "    \n",
    "    # ent = compute_entropy(oof_preds)\n",
    "    top2 = compute_top2_diff(oof_preds)\n",
    "    # dis = compute_dispersion(oof_preds)\n",
    "    \n",
    "    features = np.concatenate([\n",
    "        oof_preds,\n",
    "        image_latents,\n",
    "        image_latent,\n",
    "        recon_loss[:,None],\n",
    "        latent_stats,\n",
    "        gt_cluster_stats,\n",
    "        # pred_cluster_stats,\n",
    "        # latent_ids.reshape(-1,1),\n",
    "        # latent_summary,\n",
    "        # loss_ids.reshape(-1,1),\n",
    "        # loss_summary_stats,\n",
    "        rgb_stats,\n",
    "        # latent_rgb_stats,\n",
    "        # loss_rgb_stats\n",
    "        rgb_all_subs,\n",
    "        rgb_except_center,\n",
    "        rgb_tile,\n",
    "\n",
    "        wavelet_feats,\n",
    "        sobel_feats,\n",
    "        \n",
    "        hsv_feats,\n",
    "        color_moments_feats,\n",
    "        \n",
    "        contrast_feats,\n",
    "        he_feats,\n",
    "        sliding_std_stats,\n",
    "        \n",
    "        # ent,\n",
    "        top2,\n",
    "        # dis\n",
    "    ], axis=1)\n",
    "    print(f\"✅ Generated meta-features with shape: {features.shape}\")\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_14152/1911585000.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(trained_model_path, map_location=device))\n",
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/pretrain_model.py:310: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ae.load_state_dict(torch.load(ae_checkpoint, map_location=\"cpu\"))\n",
      "Computing AE recon loss: 100%|██████████| 131/131 [00:11<00:00, 11.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generated meta-features with shape: (8348, 1111)\n",
      "Training meta‐model target 0 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 5.62928\n",
      "[200]\tvalid_0's rmse: 5.1935\n",
      "[300]\tvalid_0's rmse: 5.10812\n",
      "[400]\tvalid_0's rmse: 5.08589\n",
      "[500]\tvalid_0's rmse: 5.07978\n",
      "[600]\tvalid_0's rmse: 5.07577\n",
      "[700]\tvalid_0's rmse: 5.07662\n",
      "[800]\tvalid_0's rmse: 5.07461\n",
      "[900]\tvalid_0's rmse: 5.07512\n",
      "Early stopping, best iteration is:\n",
      "[760]\tvalid_0's rmse: 5.07203\n",
      "Training meta‐model target 1 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 2.50659\n",
      "[200]\tvalid_0's rmse: 2.28498\n",
      "[300]\tvalid_0's rmse: 2.24173\n",
      "[400]\tvalid_0's rmse: 2.23013\n",
      "[500]\tvalid_0's rmse: 2.22742\n",
      "[600]\tvalid_0's rmse: 2.22476\n",
      "[700]\tvalid_0's rmse: 2.22518\n",
      "[800]\tvalid_0's rmse: 2.22652\n",
      "Early stopping, best iteration is:\n",
      "[630]\tvalid_0's rmse: 2.22392\n",
      "Training meta‐model target 2 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.90722\n",
      "[200]\tvalid_0's rmse: 3.50991\n",
      "[300]\tvalid_0's rmse: 3.43278\n",
      "[400]\tvalid_0's rmse: 3.41424\n",
      "[500]\tvalid_0's rmse: 3.40599\n",
      "[600]\tvalid_0's rmse: 3.404\n",
      "[700]\tvalid_0's rmse: 3.4007\n",
      "[800]\tvalid_0's rmse: 3.40066\n",
      "[900]\tvalid_0's rmse: 3.40222\n",
      "[1000]\tvalid_0's rmse: 3.40177\n",
      "Early stopping, best iteration is:\n",
      "[821]\tvalid_0's rmse: 3.40003\n",
      "Training meta‐model target 3 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.87697\n",
      "[200]\tvalid_0's rmse: 7.07054\n",
      "[300]\tvalid_0's rmse: 6.93512\n",
      "[400]\tvalid_0's rmse: 6.91232\n",
      "[500]\tvalid_0's rmse: 6.9071\n",
      "[600]\tvalid_0's rmse: 6.89867\n",
      "[700]\tvalid_0's rmse: 6.89215\n",
      "[800]\tvalid_0's rmse: 6.89046\n",
      "[900]\tvalid_0's rmse: 6.88435\n",
      "[1000]\tvalid_0's rmse: 6.88218\n",
      "[1100]\tvalid_0's rmse: 6.88041\n",
      "Early stopping, best iteration is:\n",
      "[965]\tvalid_0's rmse: 6.87996\n",
      "Training meta‐model target 4 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.56609\n",
      "[200]\tvalid_0's rmse: 6.90237\n",
      "[300]\tvalid_0's rmse: 6.77326\n",
      "[400]\tvalid_0's rmse: 6.73091\n",
      "[500]\tvalid_0's rmse: 6.70357\n",
      "[600]\tvalid_0's rmse: 6.69291\n",
      "[700]\tvalid_0's rmse: 6.68477\n",
      "[800]\tvalid_0's rmse: 6.67288\n",
      "[900]\tvalid_0's rmse: 6.66559\n",
      "[1000]\tvalid_0's rmse: 6.66112\n",
      "[1100]\tvalid_0's rmse: 6.65508\n",
      "[1200]\tvalid_0's rmse: 6.64884\n",
      "[1300]\tvalid_0's rmse: 6.64436\n",
      "[1400]\tvalid_0's rmse: 6.64121\n",
      "[1500]\tvalid_0's rmse: 6.63647\n",
      "[1600]\tvalid_0's rmse: 6.63581\n",
      "[1700]\tvalid_0's rmse: 6.63668\n",
      "Early stopping, best iteration is:\n",
      "[1595]\tvalid_0's rmse: 6.6348\n",
      "Training meta‐model target 5 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.51962\n",
      "[200]\tvalid_0's rmse: 6.75658\n",
      "[300]\tvalid_0's rmse: 6.62833\n",
      "[400]\tvalid_0's rmse: 6.60548\n",
      "[500]\tvalid_0's rmse: 6.58967\n",
      "[600]\tvalid_0's rmse: 6.58548\n",
      "[700]\tvalid_0's rmse: 6.57677\n",
      "[800]\tvalid_0's rmse: 6.57028\n",
      "[900]\tvalid_0's rmse: 6.56499\n",
      "[1000]\tvalid_0's rmse: 6.5585\n",
      "[1100]\tvalid_0's rmse: 6.55821\n",
      "[1200]\tvalid_0's rmse: 6.55353\n",
      "[1300]\tvalid_0's rmse: 6.55061\n",
      "[1400]\tvalid_0's rmse: 6.54989\n",
      "[1500]\tvalid_0's rmse: 6.54647\n",
      "[1600]\tvalid_0's rmse: 6.54648\n",
      "[1700]\tvalid_0's rmse: 6.5464\n",
      "[1800]\tvalid_0's rmse: 6.54553\n",
      "[1900]\tvalid_0's rmse: 6.54694\n",
      "Early stopping, best iteration is:\n",
      "[1786]\tvalid_0's rmse: 6.54492\n",
      "Training meta‐model target 6 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.57117\n",
      "[200]\tvalid_0's rmse: 3.3929\n",
      "[300]\tvalid_0's rmse: 3.36007\n",
      "[400]\tvalid_0's rmse: 3.35145\n",
      "[500]\tvalid_0's rmse: 3.34754\n",
      "[600]\tvalid_0's rmse: 3.34562\n",
      "[700]\tvalid_0's rmse: 3.34475\n",
      "[800]\tvalid_0's rmse: 3.34474\n",
      "[900]\tvalid_0's rmse: 3.34623\n",
      "Early stopping, best iteration is:\n",
      "[757]\tvalid_0's rmse: 3.34358\n",
      "Training meta‐model target 7 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 5.64936\n",
      "[200]\tvalid_0's rmse: 5.60818\n",
      "[300]\tvalid_0's rmse: 5.61569\n",
      "[400]\tvalid_0's rmse: 5.62079\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's rmse: 5.60484\n",
      "Training meta‐model target 8 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 8.20126\n",
      "[200]\tvalid_0's rmse: 7.35111\n",
      "[300]\tvalid_0's rmse: 7.1854\n",
      "[400]\tvalid_0's rmse: 7.14574\n",
      "[500]\tvalid_0's rmse: 7.12458\n",
      "[600]\tvalid_0's rmse: 7.10594\n",
      "[700]\tvalid_0's rmse: 7.09464\n",
      "[800]\tvalid_0's rmse: 7.08607\n",
      "[900]\tvalid_0's rmse: 7.07839\n",
      "[1000]\tvalid_0's rmse: 7.07182\n",
      "[1100]\tvalid_0's rmse: 7.06809\n",
      "[1200]\tvalid_0's rmse: 7.06331\n",
      "[1300]\tvalid_0's rmse: 7.05882\n",
      "[1400]\tvalid_0's rmse: 7.058\n",
      "[1500]\tvalid_0's rmse: 7.05293\n",
      "[1600]\tvalid_0's rmse: 7.05104\n",
      "[1700]\tvalid_0's rmse: 7.04837\n",
      "[1800]\tvalid_0's rmse: 7.04528\n",
      "[1900]\tvalid_0's rmse: 7.04279\n",
      "[2000]\tvalid_0's rmse: 7.04063\n",
      "[2100]\tvalid_0's rmse: 7.03853\n",
      "[2200]\tvalid_0's rmse: 7.03899\n",
      "[2300]\tvalid_0's rmse: 7.03683\n",
      "[2400]\tvalid_0's rmse: 7.03666\n",
      "[2500]\tvalid_0's rmse: 7.03682\n",
      "Early stopping, best iteration is:\n",
      "[2362]\tvalid_0's rmse: 7.03559\n",
      "Training meta‐model target 9 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.56198\n",
      "[200]\tvalid_0's rmse: 5.78207\n",
      "[300]\tvalid_0's rmse: 5.63304\n",
      "[400]\tvalid_0's rmse: 5.59688\n",
      "[500]\tvalid_0's rmse: 5.57503\n",
      "[600]\tvalid_0's rmse: 5.55679\n",
      "[700]\tvalid_0's rmse: 5.54878\n",
      "[800]\tvalid_0's rmse: 5.54156\n",
      "[900]\tvalid_0's rmse: 5.53117\n",
      "[1000]\tvalid_0's rmse: 5.52251\n",
      "[1100]\tvalid_0's rmse: 5.52049\n",
      "[1200]\tvalid_0's rmse: 5.51668\n",
      "[1300]\tvalid_0's rmse: 5.51751\n",
      "[1400]\tvalid_0's rmse: 5.51491\n",
      "[1500]\tvalid_0's rmse: 5.51416\n",
      "[1600]\tvalid_0's rmse: 5.51417\n",
      "Early stopping, best iteration is:\n",
      "[1447]\tvalid_0's rmse: 5.51286\n",
      "Training meta‐model target 10 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.58335\n",
      "[200]\tvalid_0's rmse: 7.02192\n",
      "[300]\tvalid_0's rmse: 6.88899\n",
      "[400]\tvalid_0's rmse: 6.8441\n",
      "[500]\tvalid_0's rmse: 6.82416\n",
      "[600]\tvalid_0's rmse: 6.81238\n",
      "[700]\tvalid_0's rmse: 6.8078\n",
      "[800]\tvalid_0's rmse: 6.79994\n",
      "[900]\tvalid_0's rmse: 6.79479\n",
      "[1000]\tvalid_0's rmse: 6.78994\n",
      "[1100]\tvalid_0's rmse: 6.78281\n",
      "[1200]\tvalid_0's rmse: 6.77952\n",
      "[1300]\tvalid_0's rmse: 6.7778\n",
      "[1400]\tvalid_0's rmse: 6.7774\n",
      "[1500]\tvalid_0's rmse: 6.77514\n",
      "[1600]\tvalid_0's rmse: 6.7741\n",
      "Early stopping, best iteration is:\n",
      "[1440]\tvalid_0's rmse: 6.77347\n",
      "Training meta‐model target 11 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.96525\n",
      "[200]\tvalid_0's rmse: 3.4672\n",
      "[300]\tvalid_0's rmse: 3.3631\n",
      "[400]\tvalid_0's rmse: 3.33325\n",
      "[500]\tvalid_0's rmse: 3.32589\n",
      "[600]\tvalid_0's rmse: 3.32125\n",
      "[700]\tvalid_0's rmse: 3.31957\n",
      "[800]\tvalid_0's rmse: 3.31909\n",
      "Early stopping, best iteration is:\n",
      "[656]\tvalid_0's rmse: 3.31784\n",
      "Training meta‐model target 12 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.11302\n",
      "[200]\tvalid_0's rmse: 6.09307\n",
      "[300]\tvalid_0's rmse: 6.0933\n",
      "[400]\tvalid_0's rmse: 6.10403\n",
      "Early stopping, best iteration is:\n",
      "[254]\tvalid_0's rmse: 6.08878\n",
      "Training meta‐model target 13 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 5.34751\n",
      "[200]\tvalid_0's rmse: 5.13353\n",
      "[300]\tvalid_0's rmse: 5.10263\n",
      "[400]\tvalid_0's rmse: 5.09773\n",
      "[500]\tvalid_0's rmse: 5.10263\n",
      "[600]\tvalid_0's rmse: 5.10973\n",
      "Early stopping, best iteration is:\n",
      "[425]\tvalid_0's rmse: 5.09702\n",
      "Training meta‐model target 14 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 5.9574\n",
      "[200]\tvalid_0's rmse: 5.29078\n",
      "[300]\tvalid_0's rmse: 5.16759\n",
      "[400]\tvalid_0's rmse: 5.13375\n",
      "[500]\tvalid_0's rmse: 5.12102\n",
      "[600]\tvalid_0's rmse: 5.11819\n",
      "[700]\tvalid_0's rmse: 5.11568\n",
      "[800]\tvalid_0's rmse: 5.11891\n",
      "Early stopping, best iteration is:\n",
      "[680]\tvalid_0's rmse: 5.11445\n",
      "Training meta‐model target 15 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.11763\n",
      "[200]\tvalid_0's rmse: 5.74066\n",
      "[300]\tvalid_0's rmse: 5.6546\n",
      "[400]\tvalid_0's rmse: 5.62692\n",
      "[500]\tvalid_0's rmse: 5.61239\n",
      "[600]\tvalid_0's rmse: 5.60035\n",
      "[700]\tvalid_0's rmse: 5.59657\n",
      "[800]\tvalid_0's rmse: 5.59559\n",
      "[900]\tvalid_0's rmse: 5.59167\n",
      "[1000]\tvalid_0's rmse: 5.58773\n",
      "[1100]\tvalid_0's rmse: 5.58292\n",
      "[1200]\tvalid_0's rmse: 5.58243\n",
      "[1300]\tvalid_0's rmse: 5.57973\n",
      "[1400]\tvalid_0's rmse: 5.57664\n",
      "[1500]\tvalid_0's rmse: 5.57663\n",
      "[1600]\tvalid_0's rmse: 5.57734\n",
      "[1700]\tvalid_0's rmse: 5.57703\n",
      "Early stopping, best iteration is:\n",
      "[1503]\tvalid_0's rmse: 5.57633\n",
      "Training meta‐model target 16 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.82283\n",
      "[200]\tvalid_0's rmse: 6.09639\n",
      "[300]\tvalid_0's rmse: 5.92526\n",
      "[400]\tvalid_0's rmse: 5.88245\n",
      "[500]\tvalid_0's rmse: 5.85867\n",
      "[600]\tvalid_0's rmse: 5.8489\n",
      "[700]\tvalid_0's rmse: 5.84444\n",
      "[800]\tvalid_0's rmse: 5.84011\n",
      "[900]\tvalid_0's rmse: 5.83652\n",
      "[1000]\tvalid_0's rmse: 5.83316\n",
      "[1100]\tvalid_0's rmse: 5.83245\n",
      "[1200]\tvalid_0's rmse: 5.82957\n",
      "[1300]\tvalid_0's rmse: 5.82576\n",
      "[1400]\tvalid_0's rmse: 5.82429\n",
      "[1500]\tvalid_0's rmse: 5.82441\n",
      "[1600]\tvalid_0's rmse: 5.82219\n",
      "[1700]\tvalid_0's rmse: 5.82158\n",
      "[1800]\tvalid_0's rmse: 5.81956\n",
      "[1900]\tvalid_0's rmse: 5.81823\n",
      "[2000]\tvalid_0's rmse: 5.819\n",
      "[2100]\tvalid_0's rmse: 5.81768\n",
      "[2200]\tvalid_0's rmse: 5.81677\n",
      "[2300]\tvalid_0's rmse: 5.81795\n",
      "Early stopping, best iteration is:\n",
      "[2188]\tvalid_0's rmse: 5.81633\n",
      "Training meta‐model target 17 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.7024\n",
      "[200]\tvalid_0's rmse: 3.27567\n",
      "[300]\tvalid_0's rmse: 3.19361\n",
      "[400]\tvalid_0's rmse: 3.17335\n",
      "[500]\tvalid_0's rmse: 3.16505\n",
      "[600]\tvalid_0's rmse: 3.16274\n",
      "[700]\tvalid_0's rmse: 3.15935\n",
      "[800]\tvalid_0's rmse: 3.15496\n",
      "[900]\tvalid_0's rmse: 3.15477\n",
      "[1000]\tvalid_0's rmse: 3.15346\n",
      "[1100]\tvalid_0's rmse: 3.15278\n",
      "[1200]\tvalid_0's rmse: 3.15243\n",
      "[1300]\tvalid_0's rmse: 3.15271\n",
      "[1400]\tvalid_0's rmse: 3.1514\n",
      "[1500]\tvalid_0's rmse: 3.1513\n",
      "[1600]\tvalid_0's rmse: 3.15112\n",
      "[1700]\tvalid_0's rmse: 3.15106\n",
      "[1800]\tvalid_0's rmse: 3.15075\n",
      "Early stopping, best iteration is:\n",
      "[1621]\tvalid_0's rmse: 3.15041\n",
      "Training meta‐model target 18 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.16375\n",
      "[200]\tvalid_0's rmse: 6.92752\n",
      "[300]\tvalid_0's rmse: 6.89158\n",
      "[400]\tvalid_0's rmse: 6.88595\n",
      "[500]\tvalid_0's rmse: 6.88398\n",
      "[600]\tvalid_0's rmse: 6.88651\n",
      "Early stopping, best iteration is:\n",
      "[464]\tvalid_0's rmse: 6.88202\n",
      "Training meta‐model target 19 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 4.90648\n",
      "[200]\tvalid_0's rmse: 4.72389\n",
      "[300]\tvalid_0's rmse: 4.68299\n",
      "[400]\tvalid_0's rmse: 4.67237\n",
      "[500]\tvalid_0's rmse: 4.66743\n",
      "[600]\tvalid_0's rmse: 4.66336\n",
      "[700]\tvalid_0's rmse: 4.66148\n",
      "[800]\tvalid_0's rmse: 4.65852\n",
      "[900]\tvalid_0's rmse: 4.65698\n",
      "[1000]\tvalid_0's rmse: 4.65393\n",
      "[1100]\tvalid_0's rmse: 4.65492\n",
      "Early stopping, best iteration is:\n",
      "[981]\tvalid_0's rmse: 4.65265\n",
      "Training meta‐model target 20 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.40041\n",
      "[200]\tvalid_0's rmse: 6.04834\n",
      "[300]\tvalid_0's rmse: 5.98503\n",
      "[400]\tvalid_0's rmse: 5.97331\n",
      "[500]\tvalid_0's rmse: 5.97575\n",
      "[600]\tvalid_0's rmse: 5.97561\n",
      "Early stopping, best iteration is:\n",
      "[405]\tvalid_0's rmse: 5.97264\n",
      "Training meta‐model target 21 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.6319\n",
      "[200]\tvalid_0's rmse: 7.37032\n",
      "[300]\tvalid_0's rmse: 7.33343\n",
      "[400]\tvalid_0's rmse: 7.32765\n",
      "[500]\tvalid_0's rmse: 7.32355\n",
      "[600]\tvalid_0's rmse: 7.31929\n",
      "[700]\tvalid_0's rmse: 7.3156\n",
      "[800]\tvalid_0's rmse: 7.31706\n",
      "[900]\tvalid_0's rmse: 7.32337\n",
      "Early stopping, best iteration is:\n",
      "[773]\tvalid_0's rmse: 7.31421\n",
      "Training meta‐model target 22 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 2.76044\n",
      "[200]\tvalid_0's rmse: 2.60316\n",
      "[300]\tvalid_0's rmse: 2.56989\n",
      "[400]\tvalid_0's rmse: 2.56086\n",
      "[500]\tvalid_0's rmse: 2.56004\n",
      "[600]\tvalid_0's rmse: 2.55988\n",
      "[700]\tvalid_0's rmse: 2.56028\n",
      "[800]\tvalid_0's rmse: 2.55849\n",
      "[900]\tvalid_0's rmse: 2.55613\n",
      "[1000]\tvalid_0's rmse: 2.55346\n",
      "[1100]\tvalid_0's rmse: 2.55396\n",
      "[1200]\tvalid_0's rmse: 2.55404\n",
      "Early stopping, best iteration is:\n",
      "[1016]\tvalid_0's rmse: 2.55295\n",
      "Training meta‐model target 23 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.10941\n",
      "[200]\tvalid_0's rmse: 5.64126\n",
      "[300]\tvalid_0's rmse: 5.54626\n",
      "[400]\tvalid_0's rmse: 5.51938\n",
      "[500]\tvalid_0's rmse: 5.51005\n",
      "[600]\tvalid_0's rmse: 5.50438\n",
      "[700]\tvalid_0's rmse: 5.50581\n",
      "[800]\tvalid_0's rmse: 5.50496\n",
      "Early stopping, best iteration is:\n",
      "[638]\tvalid_0's rmse: 5.50296\n",
      "Training meta‐model target 24 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.25374\n",
      "[200]\tvalid_0's rmse: 6.68999\n",
      "[300]\tvalid_0's rmse: 6.57134\n",
      "[400]\tvalid_0's rmse: 6.52698\n",
      "[500]\tvalid_0's rmse: 6.51334\n",
      "[600]\tvalid_0's rmse: 6.50556\n",
      "[700]\tvalid_0's rmse: 6.49598\n",
      "[800]\tvalid_0's rmse: 6.493\n",
      "[900]\tvalid_0's rmse: 6.49211\n",
      "[1000]\tvalid_0's rmse: 6.48864\n",
      "[1100]\tvalid_0's rmse: 6.49235\n",
      "[1200]\tvalid_0's rmse: 6.4929\n",
      "Early stopping, best iteration is:\n",
      "[1006]\tvalid_0's rmse: 6.48762\n",
      "Training meta‐model target 25 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.81848\n",
      "[200]\tvalid_0's rmse: 6.58717\n",
      "[300]\tvalid_0's rmse: 6.53573\n",
      "[400]\tvalid_0's rmse: 6.52326\n",
      "[500]\tvalid_0's rmse: 6.52199\n",
      "[600]\tvalid_0's rmse: 6.52508\n",
      "Early stopping, best iteration is:\n",
      "[447]\tvalid_0's rmse: 6.52065\n",
      "Training meta‐model target 26 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.58908\n",
      "[200]\tvalid_0's rmse: 6.64477\n",
      "[300]\tvalid_0's rmse: 6.45336\n",
      "[400]\tvalid_0's rmse: 6.3978\n",
      "[500]\tvalid_0's rmse: 6.37467\n",
      "[600]\tvalid_0's rmse: 6.36404\n",
      "[700]\tvalid_0's rmse: 6.35738\n",
      "[800]\tvalid_0's rmse: 6.3543\n",
      "[900]\tvalid_0's rmse: 6.3491\n",
      "[1000]\tvalid_0's rmse: 6.34666\n",
      "[1100]\tvalid_0's rmse: 6.34176\n",
      "[1200]\tvalid_0's rmse: 6.34079\n",
      "[1300]\tvalid_0's rmse: 6.34091\n",
      "Early stopping, best iteration is:\n",
      "[1165]\tvalid_0's rmse: 6.33994\n",
      "Training meta‐model target 27 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 5.87072\n",
      "[200]\tvalid_0's rmse: 5.63419\n",
      "[300]\tvalid_0's rmse: 5.58598\n",
      "[400]\tvalid_0's rmse: 5.57095\n",
      "[500]\tvalid_0's rmse: 5.57058\n",
      "[600]\tvalid_0's rmse: 5.57103\n",
      "Early stopping, best iteration is:\n",
      "[466]\tvalid_0's rmse: 5.56749\n",
      "Training meta‐model target 28 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.37755\n",
      "[200]\tvalid_0's rmse: 6.02791\n",
      "[300]\tvalid_0's rmse: 5.96983\n",
      "[400]\tvalid_0's rmse: 5.95933\n",
      "[500]\tvalid_0's rmse: 5.95411\n",
      "[600]\tvalid_0's rmse: 5.95253\n",
      "[700]\tvalid_0's rmse: 5.95096\n",
      "[800]\tvalid_0's rmse: 5.95387\n",
      "Early stopping, best iteration is:\n",
      "[679]\tvalid_0's rmse: 5.94813\n",
      "Training meta‐model target 29 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.8666\n",
      "[200]\tvalid_0's rmse: 6.13368\n",
      "[300]\tvalid_0's rmse: 6.03068\n",
      "[400]\tvalid_0's rmse: 6.01904\n",
      "[500]\tvalid_0's rmse: 6.0102\n",
      "[600]\tvalid_0's rmse: 6.00933\n",
      "[700]\tvalid_0's rmse: 6.01089\n",
      "[800]\tvalid_0's rmse: 6.00678\n",
      "[900]\tvalid_0's rmse: 6.00733\n",
      "[1000]\tvalid_0's rmse: 6.0173\n",
      "Early stopping, best iteration is:\n",
      "[847]\tvalid_0's rmse: 6.00548\n",
      "Training meta‐model target 30 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 2.72523\n",
      "[200]\tvalid_0's rmse: 2.43192\n",
      "[300]\tvalid_0's rmse: 2.37855\n",
      "[400]\tvalid_0's rmse: 2.36568\n",
      "[500]\tvalid_0's rmse: 2.36227\n",
      "[600]\tvalid_0's rmse: 2.35998\n",
      "[700]\tvalid_0's rmse: 2.36082\n",
      "Early stopping, best iteration is:\n",
      "[595]\tvalid_0's rmse: 2.35965\n",
      "Training meta‐model target 31 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 2.35656\n",
      "[200]\tvalid_0's rmse: 2.29944\n",
      "[300]\tvalid_0's rmse: 2.28869\n",
      "[400]\tvalid_0's rmse: 2.2836\n",
      "[500]\tvalid_0's rmse: 2.28257\n",
      "[600]\tvalid_0's rmse: 2.28174\n",
      "[700]\tvalid_0's rmse: 2.28201\n",
      "Early stopping, best iteration is:\n",
      "[576]\tvalid_0's rmse: 2.28121\n",
      "Training meta‐model target 32 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.34933\n",
      "[200]\tvalid_0's rmse: 7.27005\n",
      "[300]\tvalid_0's rmse: 7.26479\n",
      "[400]\tvalid_0's rmse: 7.26584\n",
      "[500]\tvalid_0's rmse: 7.26725\n",
      "Early stopping, best iteration is:\n",
      "[324]\tvalid_0's rmse: 7.26016\n",
      "Training meta‐model target 33 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 5.5962\n",
      "[200]\tvalid_0's rmse: 5.38504\n",
      "[300]\tvalid_0's rmse: 5.34936\n",
      "[400]\tvalid_0's rmse: 5.34352\n",
      "[500]\tvalid_0's rmse: 5.34348\n",
      "[600]\tvalid_0's rmse: 5.34841\n",
      "Early stopping, best iteration is:\n",
      "[440]\tvalid_0's rmse: 5.34229\n",
      "Training meta‐model target 34 …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 2.88309\n",
      "[200]\tvalid_0's rmse: 2.7987\n",
      "[300]\tvalid_0's rmse: 2.77899\n",
      "[400]\tvalid_0's rmse: 2.77554\n",
      "[500]\tvalid_0's rmse: 2.77384\n",
      "[600]\tvalid_0's rmse: 2.77268\n",
      "[700]\tvalid_0's rmse: 2.77378\n",
      "[800]\tvalid_0's rmse: 2.77352\n",
      "[900]\tvalid_0's rmse: 2.77444\n",
      "Early stopping, best iteration is:\n",
      "[777]\tvalid_0's rmse: 2.77262\n",
      "✅ Saved entire‐dataset meta‐model → meta_model_single.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import rankdata\n",
    "from python_scripts.import_data import importDataset\n",
    "from python_scripts.operate_model import predict\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from python_scripts.pretrain_model import PretrainedEncoderRegressor\n",
    "\n",
    "# --------------- Settings ---------------\n",
    "trained_model_path = 'output_folder/rank-spot/realign/whole_worflow/s_m_l/filtered_directly_rank/k-fold_mix/realign_all/Macenko_masked/results/model_epoch022.pt'\n",
    "n_samples  = len(full_dataset)\n",
    "C          = 35\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "tile_dim    = 128\n",
    "center_dim  = 128\n",
    "neighbor_dim= 128\n",
    "version = 'version2'\n",
    "\n",
    "pretrained_ae_name  = 'AE_Center_noaug'\n",
    "pretrained_ae_path  = f\"AE_model/128/{pretrained_ae_name}/best.pt\"\n",
    "ae_type            = 'center'\n",
    "device             = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# 1) Ground truth labels\n",
    "y_true = np.vstack([ full_dataset[i]['label'].cpu().numpy() for i in range(n_samples) ])\n",
    "\n",
    "# 2) Load the single model and get preds + latents on full_dataset\n",
    "net = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "net.load_state_dict(torch.load(trained_model_path, map_location=device))\n",
    "net = net.to(device).eval()\n",
    "\n",
    "full_loader = DataLoader(full_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "all_preds, all_latents = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in full_loader:\n",
    "        tiles, subtiles = batch['tile'].to(device), batch['subtiles'].to(device)\n",
    "        center = subtiles[:, 4].contiguous()\n",
    "        f_c = net.encoder_center(center)\n",
    "        f_n = net.encoder_subtile(subtiles)\n",
    "        f_t = net.encoder_tile(tiles)\n",
    "        features_cat = torch.cat([f_c, f_n, f_t], dim=1)\n",
    "        gates = net.gate_fc(features_cat)        # (B, 3), softmax over features\n",
    "        f_fused = (\n",
    "            gates[:, 0:1] * f_t +\n",
    "            gates[:, 1:2] * f_n +\n",
    "            gates[:, 2:3] * f_c\n",
    "        )  # (B, tile_dim) — 注意各 encoder 輸出維度要一致\n",
    "        out  = net.decoder(f_fused)\n",
    "        all_preds.append(out.cpu().numpy())\n",
    "        all_latents.append(features_cat.cpu().numpy())\n",
    "\n",
    "oof_preds     = np.vstack(all_preds)     # shape (n_samples, 35)\n",
    "image_latents = np.vstack(all_latents)   # shape (n_samples, fusion_dim)\n",
    "\n",
    "# 3) AE reconstruction model (unchanged)\n",
    "recon_model = PretrainedEncoderRegressor(\n",
    "    ae_checkpoint=pretrained_ae_path,\n",
    "    ae_type=ae_type,\n",
    "    tile_dim=tile_dim,\n",
    "    center_dim=center_dim,\n",
    "    neighbor_dim=neighbor_dim,\n",
    "    output_dim=C,\n",
    "    mode='reconstruction'\n",
    ").to(device)\n",
    "\n",
    "# 4) Generate meta features for the full dataset\n",
    "meta = generate_meta_features(\n",
    "    dataset         = full_dataset,\n",
    "    oof_preds       = oof_preds,\n",
    "    image_latents   = image_latents,\n",
    "    model_for_recon = recon_model,\n",
    "    device          = device,\n",
    "    ae_type         = ae_type,\n",
    "    use_clusters    = \"both\"\n",
    ")\n",
    "\n",
    "# 5) Train a single Meta‐Model on all meta features\n",
    "\n",
    "lgb_base = lgb.LGBMRegressor(\n",
    "    objective='regression',         # 等价于 'l2'\n",
    "    metric='rmse',\n",
    "    learning_rate=0.01,             # 稍微放宽到 0.01\n",
    "    n_estimators=20000,             # 上限提高，配合 early stopping\n",
    "    max_depth=8,                    # 深度可以再增加一些\n",
    "    num_leaves=127,                 # 2^7-1，与 max_depth=8 匹配\n",
    "    feature_fraction=0.8,           # 每棵树采 80% 特征\n",
    "    bagging_fraction=0.8,           # 每棵树采 80% 样本\n",
    "    bagging_freq=1,                 # 开启行抽样\n",
    "    min_data_in_leaf=30,            # 叶子上最少 20 样本\n",
    "    reg_alpha=1.0,                  # L1 正则\n",
    "    reg_lambda=1.0,                 # L2 正则\n",
    "    verbosity=-1\n",
    ")\n",
    "\n",
    "\n",
    "# 5a) Optional: split a small val‐set for early stopping\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    meta, y_true, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "meta_model = MultiOutputRegressor(lgb_base)\n",
    "meta_model.estimators_ = []\n",
    "for i in range(C):\n",
    "    print(f\"Training meta‐model target {i} …\")\n",
    "    m = lgb.LGBMRegressor(**lgb_base.get_params())\n",
    "    m.fit(\n",
    "        X_tr, y_tr[:, i],\n",
    "        eval_set=[(X_val, y_val[:, i])],\n",
    "        callbacks=[early_stopping(stopping_rounds=200), log_evaluation(period=100)]\n",
    "    )\n",
    "    meta_model.estimators_.append(m)\n",
    "\n",
    "save_folder = f\"only_lightgbm/{version}\"  # 修改為你想要的資料夾名稱\n",
    "if not os.path.exists(save_folder):   \n",
    "    os.makedirs(save_folder)\n",
    "# 6) Save the single meta‐model\n",
    "joblib.dump(meta_model, f'{save_folder}meta_model_single.pkl')\n",
    "print(\"✅ Saved entire‐dataset meta‐model → meta_model_single.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved entire‐dataset meta‐model → meta_model_single.pkl\n"
     ]
    }
   ],
   "source": [
    "# 6) Save the single meta‐model\n",
    "joblib.dump(meta_model, 'meta_model_single.pkl')\n",
    "print(\"✅ Saved entire‐dataset meta‐model → meta_model_single.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/import_data.py:280: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  raw = torch.load(pt_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 從 '<class 'list'>' 推斷樣本數量: 2088\n",
      "Model forward signature: (tile, subtiles)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from python_scripts.import_data import load_node_feature_data\n",
    "\n",
    "\n",
    "image_keys = [ 'tile', 'subtiles']\n",
    "\n",
    "model = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "\n",
    "# 用法示例\n",
    "from python_scripts.import_data import importDataset\n",
    "# 假设你的 model 已经定义好并实例化为 `model`\n",
    "test_dataset = load_node_feature_data(\"dataset/spot-rank/filtered_directly_rank/masked/test/Macenko/test_dataset.pt\", model)\n",
    "test_dataset = importDataset(\n",
    "        data_dict=test_dataset,\n",
    "        model=model,\n",
    "        image_keys=image_keys,\n",
    "        transform=lambda x: x,  # identity transform\n",
    "        print_sig=True\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_14152/3878551429.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(trained_model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 1) 对 test_dataset 用你的第 1 阶段 model 一次性算出 oof_preds 和 latents\n",
    "net = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "net.load_state_dict(torch.load(trained_model_path, map_location=device))\n",
    "net = net.to(device).eval()\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_preds, test_latents = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        tiles, subtiles = batch['tile'].to(device), batch['subtiles'].to(device)\n",
    "        center = subtiles[:, 4].contiguous()\n",
    "        f_c = net.encoder_center(center)\n",
    "        f_n = net.encoder_subtile(subtiles)\n",
    "        f_t = net.encoder_tile(tiles)\n",
    "        features_cat = torch.cat([f_c, f_n, f_t], dim=1)\n",
    "        gates = net.gate_fc(features_cat)        # (B, 3), softmax over features\n",
    "        f_fused = (\n",
    "            gates[:, 0:1] * f_t +\n",
    "            gates[:, 1:2] * f_n +\n",
    "            gates[:, 2:3] * f_c\n",
    "        )  # (B, tile_dim) — 注意各 encoder 輸出維度要一致\n",
    "        out  = net.decoder(f_fused)\n",
    "        test_preds.append(out.cpu())\n",
    "        test_latents.append(f_fused.cpu())\n",
    "        \n",
    "    test_preds = torch.cat(test_preds, dim=0).numpy()\n",
    "    test_latents = torch.cat(test_latents, dim=0).numpy()\n",
    " \n",
    "# 2) AE Recon Model 不变，算测试的 recon_loss & 必要特征\n",
    "recon_model = PretrainedEncoderRegressor(\n",
    "    ae_checkpoint=pretrained_ae_path,\n",
    "    ae_type=ae_type,\n",
    "    tile_dim=tile_dim,\n",
    "    center_dim=center_dim,\n",
    "    neighbor_dim=neighbor_dim,\n",
    "    output_dim=C,\n",
    "    mode='reconstruction'\n",
    ").to(device)\n",
    "\n",
    "meta_test = generate_meta_features(\n",
    "    dataset         = test_dataset,\n",
    "    oof_preds       = test_preds,\n",
    "    image_latents   = test_latents,\n",
    "    model_for_recon = recon_model,\n",
    "    device          = device,\n",
    "    ae_type         = ae_type,\n",
    "    use_clusters    = \"both\"\n",
    ")\n",
    "\n",
    "# 3) 直接载入并用 single‐fold 的 meta_model 预测\n",
    "meta_model = joblib.load(f'{save_folder}meta_model_single.pkl')\n",
    "final_preds = meta_model.predict(meta_test)\n",
    "\n",
    "# 4) 写出 submission\n",
    "import h5py, pandas as pd\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spot_ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"]))\n",
    "sub = pd.DataFrame(final_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, 'ID', test_spot_ids.index)\n",
    "sub.to_csv(f'{save_folder}submission_stacked.csv', index=False)\n",
    "print(\"✅ Saved submission_stacked.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Starting fold 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_35616/2946613622.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/pretrain_model.py:310: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ae.load_state_dict(torch.load(ae_checkpoint, map_location=\"cpu\"))\n",
      "Computing AE recon loss: 100%|██████████| 35/35 [00:02<00:00, 11.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for k=2: 0.5500\n",
      "Silhouette score for k=3: 0.5892\n",
      "Silhouette score for k=4: 0.5201\n",
      "Silhouette score for k=5: 0.5311\n",
      "Silhouette score for k=6: 0.5067\n",
      "Selected best k=3 (score=0.5892)\n",
      "✅ Generated meta-features with shape: (2197, 227)\n",
      "[fold 0] training target 0 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 6.4679\n",
      "[200]\tvalid_0's rmse: 6.27986\n",
      "[300]\tvalid_0's rmse: 6.21137\n",
      "[400]\tvalid_0's rmse: 6.17162\n",
      "[500]\tvalid_0's rmse: 6.15372\n",
      "[600]\tvalid_0's rmse: 6.15222\n",
      "[700]\tvalid_0's rmse: 6.16033\n",
      "[800]\tvalid_0's rmse: 6.16606\n",
      "Early stopping, best iteration is:\n",
      "[611]\tvalid_0's rmse: 6.14999\n",
      "[fold 0] training target 1 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.72637\n",
      "[200]\tvalid_0's rmse: 2.38419\n",
      "[300]\tvalid_0's rmse: 2.27991\n",
      "[400]\tvalid_0's rmse: 2.25302\n",
      "[500]\tvalid_0's rmse: 2.24256\n",
      "[600]\tvalid_0's rmse: 2.23851\n",
      "[700]\tvalid_0's rmse: 2.23599\n",
      "[800]\tvalid_0's rmse: 2.23449\n",
      "[900]\tvalid_0's rmse: 2.23727\n",
      "Early stopping, best iteration is:\n",
      "[791]\tvalid_0's rmse: 2.23409\n",
      "[fold 0] training target 2 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 4.4783\n",
      "[200]\tvalid_0's rmse: 4.33658\n",
      "[300]\tvalid_0's rmse: 4.27057\n",
      "[400]\tvalid_0's rmse: 4.24216\n",
      "[500]\tvalid_0's rmse: 4.23617\n",
      "[600]\tvalid_0's rmse: 4.22769\n",
      "[700]\tvalid_0's rmse: 4.22185\n",
      "[800]\tvalid_0's rmse: 4.22169\n",
      "[900]\tvalid_0's rmse: 4.21721\n",
      "[1000]\tvalid_0's rmse: 4.21561\n",
      "Early stopping, best iteration is:\n",
      "[861]\tvalid_0's rmse: 4.21528\n",
      "[fold 0] training target 3 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 6.86958\n",
      "[200]\tvalid_0's rmse: 6.78088\n",
      "[300]\tvalid_0's rmse: 6.75143\n",
      "[400]\tvalid_0's rmse: 6.74663\n",
      "[500]\tvalid_0's rmse: 6.76621\n",
      "Early stopping, best iteration is:\n",
      "[349]\tvalid_0's rmse: 6.7417\n",
      "[fold 0] training target 4 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.25344\n",
      "[200]\tvalid_0's rmse: 6.22301\n",
      "[300]\tvalid_0's rmse: 5.82344\n",
      "[400]\tvalid_0's rmse: 5.66066\n",
      "[500]\tvalid_0's rmse: 5.56592\n",
      "[600]\tvalid_0's rmse: 5.52801\n",
      "[700]\tvalid_0's rmse: 5.50798\n",
      "[800]\tvalid_0's rmse: 5.49388\n",
      "[900]\tvalid_0's rmse: 5.49443\n",
      "[1000]\tvalid_0's rmse: 5.48707\n",
      "[1100]\tvalid_0's rmse: 5.48587\n",
      "[1200]\tvalid_0's rmse: 5.48644\n",
      "[1300]\tvalid_0's rmse: 5.48098\n",
      "[1400]\tvalid_0's rmse: 5.48116\n",
      "[1500]\tvalid_0's rmse: 5.47934\n",
      "[1600]\tvalid_0's rmse: 5.47653\n",
      "[1700]\tvalid_0's rmse: 5.47305\n",
      "[1800]\tvalid_0's rmse: 5.47248\n",
      "[1900]\tvalid_0's rmse: 5.47189\n",
      "[2000]\tvalid_0's rmse: 5.47113\n",
      "[2100]\tvalid_0's rmse: 5.4709\n",
      "[2200]\tvalid_0's rmse: 5.47206\n",
      "Early stopping, best iteration is:\n",
      "[2012]\tvalid_0's rmse: 5.47008\n",
      "[fold 0] training target 5 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 8.1606\n",
      "[200]\tvalid_0's rmse: 6.98825\n",
      "[300]\tvalid_0's rmse: 6.55376\n",
      "[400]\tvalid_0's rmse: 6.38535\n",
      "[500]\tvalid_0's rmse: 6.29584\n",
      "[600]\tvalid_0's rmse: 6.23991\n",
      "[700]\tvalid_0's rmse: 6.20386\n",
      "[800]\tvalid_0's rmse: 6.17691\n",
      "[900]\tvalid_0's rmse: 6.15441\n",
      "[1000]\tvalid_0's rmse: 6.1323\n",
      "[1100]\tvalid_0's rmse: 6.11909\n",
      "[1200]\tvalid_0's rmse: 6.11195\n",
      "[1300]\tvalid_0's rmse: 6.10149\n",
      "[1400]\tvalid_0's rmse: 6.09578\n",
      "[1500]\tvalid_0's rmse: 6.0899\n",
      "[1600]\tvalid_0's rmse: 6.08739\n",
      "[1700]\tvalid_0's rmse: 6.08184\n",
      "[1800]\tvalid_0's rmse: 6.07722\n",
      "[1900]\tvalid_0's rmse: 6.07481\n",
      "[2000]\tvalid_0's rmse: 6.07287\n",
      "[2100]\tvalid_0's rmse: 6.07336\n",
      "[2200]\tvalid_0's rmse: 6.06998\n",
      "[2300]\tvalid_0's rmse: 6.06779\n",
      "[2400]\tvalid_0's rmse: 6.06676\n",
      "[2500]\tvalid_0's rmse: 6.06568\n",
      "[2600]\tvalid_0's rmse: 6.06579\n",
      "[2700]\tvalid_0's rmse: 6.06543\n",
      "Early stopping, best iteration is:\n",
      "[2548]\tvalid_0's rmse: 6.06465\n",
      "[fold 0] training target 6 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 4.44826\n",
      "[200]\tvalid_0's rmse: 4.20094\n",
      "[300]\tvalid_0's rmse: 4.13247\n",
      "[400]\tvalid_0's rmse: 4.10873\n",
      "[500]\tvalid_0's rmse: 4.09578\n",
      "[600]\tvalid_0's rmse: 4.08713\n",
      "[700]\tvalid_0's rmse: 4.08574\n",
      "[800]\tvalid_0's rmse: 4.08396\n",
      "Early stopping, best iteration is:\n",
      "[647]\tvalid_0's rmse: 4.08213\n",
      "[fold 0] training target 7 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.38641\n",
      "[200]\tvalid_0's rmse: 5.33827\n",
      "[300]\tvalid_0's rmse: 5.32495\n",
      "[400]\tvalid_0's rmse: 5.32559\n",
      "[500]\tvalid_0's rmse: 5.34017\n",
      "Early stopping, best iteration is:\n",
      "[369]\tvalid_0's rmse: 5.32197\n",
      "[fold 0] training target 8 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.68661\n",
      "[200]\tvalid_0's rmse: 6.73552\n",
      "[300]\tvalid_0's rmse: 6.4189\n",
      "[400]\tvalid_0's rmse: 6.2864\n",
      "[500]\tvalid_0's rmse: 6.21924\n",
      "[600]\tvalid_0's rmse: 6.19431\n",
      "[700]\tvalid_0's rmse: 6.19219\n",
      "[800]\tvalid_0's rmse: 6.18215\n",
      "[900]\tvalid_0's rmse: 6.17764\n",
      "[1000]\tvalid_0's rmse: 6.17513\n",
      "[1100]\tvalid_0's rmse: 6.17667\n",
      "[1200]\tvalid_0's rmse: 6.17426\n",
      "[1300]\tvalid_0's rmse: 6.16828\n",
      "[1400]\tvalid_0's rmse: 6.16791\n",
      "[1500]\tvalid_0's rmse: 6.1657\n",
      "[1600]\tvalid_0's rmse: 6.16385\n",
      "[1700]\tvalid_0's rmse: 6.1618\n",
      "[1800]\tvalid_0's rmse: 6.16111\n",
      "[1900]\tvalid_0's rmse: 6.16288\n",
      "[2000]\tvalid_0's rmse: 6.16266\n",
      "Early stopping, best iteration is:\n",
      "[1808]\tvalid_0's rmse: 6.16098\n",
      "[fold 0] training target 9 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 9.10774\n",
      "[200]\tvalid_0's rmse: 8.39064\n",
      "[300]\tvalid_0's rmse: 8.15342\n",
      "[400]\tvalid_0's rmse: 8.03477\n",
      "[500]\tvalid_0's rmse: 7.97941\n",
      "[600]\tvalid_0's rmse: 7.95566\n",
      "[700]\tvalid_0's rmse: 7.96163\n",
      "[800]\tvalid_0's rmse: 7.95926\n",
      "Early stopping, best iteration is:\n",
      "[609]\tvalid_0's rmse: 7.95275\n",
      "[fold 0] training target 10 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 8.50651\n",
      "[200]\tvalid_0's rmse: 8.13523\n",
      "[300]\tvalid_0's rmse: 7.99524\n",
      "[400]\tvalid_0's rmse: 7.91231\n",
      "[500]\tvalid_0's rmse: 7.87991\n",
      "[600]\tvalid_0's rmse: 7.87377\n",
      "[700]\tvalid_0's rmse: 7.86957\n",
      "[800]\tvalid_0's rmse: 7.86932\n",
      "Early stopping, best iteration is:\n",
      "[644]\tvalid_0's rmse: 7.85756\n",
      "[fold 0] training target 11 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.03787\n",
      "[200]\tvalid_0's rmse: 4.45928\n",
      "[300]\tvalid_0's rmse: 4.25658\n",
      "[400]\tvalid_0's rmse: 4.18942\n",
      "[500]\tvalid_0's rmse: 4.17441\n",
      "[600]\tvalid_0's rmse: 4.16913\n",
      "[700]\tvalid_0's rmse: 4.16923\n",
      "[800]\tvalid_0's rmse: 4.1712\n",
      "Early stopping, best iteration is:\n",
      "[644]\tvalid_0's rmse: 4.16591\n",
      "[fold 0] training target 12 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.89781\n",
      "[200]\tvalid_0's rmse: 5.86192\n",
      "[300]\tvalid_0's rmse: 5.86296\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's rmse: 5.85755\n",
      "[fold 0] training target 13 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.79806\n",
      "[200]\tvalid_0's rmse: 5.73127\n",
      "[300]\tvalid_0's rmse: 5.71865\n",
      "[400]\tvalid_0's rmse: 5.72507\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid_0's rmse: 5.71689\n",
      "[fold 0] training target 14 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.53081\n",
      "[200]\tvalid_0's rmse: 5.11301\n",
      "[300]\tvalid_0's rmse: 4.93668\n",
      "[400]\tvalid_0's rmse: 4.86542\n",
      "[500]\tvalid_0's rmse: 4.82702\n",
      "[600]\tvalid_0's rmse: 4.80333\n",
      "[700]\tvalid_0's rmse: 4.78666\n",
      "[800]\tvalid_0's rmse: 4.76851\n",
      "[900]\tvalid_0's rmse: 4.75815\n",
      "[1000]\tvalid_0's rmse: 4.74286\n",
      "[1100]\tvalid_0's rmse: 4.73694\n",
      "[1200]\tvalid_0's rmse: 4.73419\n",
      "[1300]\tvalid_0's rmse: 4.72631\n",
      "[1400]\tvalid_0's rmse: 4.72228\n",
      "[1500]\tvalid_0's rmse: 4.71604\n",
      "[1600]\tvalid_0's rmse: 4.71245\n",
      "[1700]\tvalid_0's rmse: 4.71046\n",
      "[1800]\tvalid_0's rmse: 4.71024\n",
      "[1900]\tvalid_0's rmse: 4.70858\n",
      "[2000]\tvalid_0's rmse: 4.70667\n",
      "[2100]\tvalid_0's rmse: 4.70596\n",
      "[2200]\tvalid_0's rmse: 4.70571\n",
      "[2300]\tvalid_0's rmse: 4.70377\n",
      "[2400]\tvalid_0's rmse: 4.70386\n",
      "[2500]\tvalid_0's rmse: 4.70327\n",
      "[2600]\tvalid_0's rmse: 4.7019\n",
      "[2700]\tvalid_0's rmse: 4.70195\n",
      "Early stopping, best iteration is:\n",
      "[2568]\tvalid_0's rmse: 4.70123\n",
      "[fold 0] training target 15 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.60967\n",
      "[200]\tvalid_0's rmse: 2.48952\n",
      "[300]\tvalid_0's rmse: 2.43757\n",
      "[400]\tvalid_0's rmse: 2.41192\n",
      "[500]\tvalid_0's rmse: 2.40363\n",
      "[600]\tvalid_0's rmse: 2.40248\n",
      "[700]\tvalid_0's rmse: 2.40159\n",
      "Early stopping, best iteration is:\n",
      "[547]\tvalid_0's rmse: 2.40068\n",
      "[fold 0] training target 16 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.69544\n",
      "[200]\tvalid_0's rmse: 6.97326\n",
      "[300]\tvalid_0's rmse: 6.71563\n",
      "[400]\tvalid_0's rmse: 6.62898\n",
      "[500]\tvalid_0's rmse: 6.59072\n",
      "[600]\tvalid_0's rmse: 6.57381\n",
      "[700]\tvalid_0's rmse: 6.55242\n",
      "[800]\tvalid_0's rmse: 6.53982\n",
      "[900]\tvalid_0's rmse: 6.53103\n",
      "[1000]\tvalid_0's rmse: 6.52339\n",
      "[1100]\tvalid_0's rmse: 6.51429\n",
      "[1200]\tvalid_0's rmse: 6.50468\n",
      "[1300]\tvalid_0's rmse: 6.49661\n",
      "[1400]\tvalid_0's rmse: 6.48962\n",
      "[1500]\tvalid_0's rmse: 6.48764\n",
      "[1600]\tvalid_0's rmse: 6.48545\n",
      "[1700]\tvalid_0's rmse: 6.48265\n",
      "[1800]\tvalid_0's rmse: 6.48525\n",
      "[1900]\tvalid_0's rmse: 6.48441\n",
      "Early stopping, best iteration is:\n",
      "[1704]\tvalid_0's rmse: 6.4826\n",
      "[fold 0] training target 17 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 3.79048\n",
      "[200]\tvalid_0's rmse: 3.77163\n",
      "[300]\tvalid_0's rmse: 3.76181\n",
      "[400]\tvalid_0's rmse: 3.75824\n",
      "[500]\tvalid_0's rmse: 3.75725\n",
      "[600]\tvalid_0's rmse: 3.76351\n",
      "[700]\tvalid_0's rmse: 3.76593\n",
      "Early stopping, best iteration is:\n",
      "[504]\tvalid_0's rmse: 3.75645\n",
      "[fold 0] training target 18 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 8.00557\n",
      "[200]\tvalid_0's rmse: 7.70243\n",
      "[300]\tvalid_0's rmse: 7.62185\n",
      "[400]\tvalid_0's rmse: 7.58112\n",
      "[500]\tvalid_0's rmse: 7.56092\n",
      "[600]\tvalid_0's rmse: 7.56403\n",
      "[700]\tvalid_0's rmse: 7.5734\n",
      "Early stopping, best iteration is:\n",
      "[508]\tvalid_0's rmse: 7.55849\n",
      "[fold 0] training target 19 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.4269\n",
      "[200]\tvalid_0's rmse: 5.11919\n",
      "[300]\tvalid_0's rmse: 5.01449\n",
      "[400]\tvalid_0's rmse: 4.96557\n",
      "[500]\tvalid_0's rmse: 4.94925\n",
      "[600]\tvalid_0's rmse: 4.9414\n",
      "[700]\tvalid_0's rmse: 4.93399\n",
      "[800]\tvalid_0's rmse: 4.93587\n",
      "Early stopping, best iteration is:\n",
      "[676]\tvalid_0's rmse: 4.93226\n",
      "[fold 0] training target 20 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.32446\n",
      "[200]\tvalid_0's rmse: 6.73073\n",
      "[300]\tvalid_0's rmse: 6.53688\n",
      "[400]\tvalid_0's rmse: 6.4626\n",
      "[500]\tvalid_0's rmse: 6.42963\n",
      "[600]\tvalid_0's rmse: 6.41676\n",
      "[700]\tvalid_0's rmse: 6.41349\n",
      "[800]\tvalid_0's rmse: 6.41847\n",
      "[900]\tvalid_0's rmse: 6.41254\n",
      "[1000]\tvalid_0's rmse: 6.42003\n",
      "Early stopping, best iteration is:\n",
      "[867]\tvalid_0's rmse: 6.409\n",
      "[fold 0] training target 21 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 8.14351\n",
      "[200]\tvalid_0's rmse: 7.70604\n",
      "[300]\tvalid_0's rmse: 7.556\n",
      "[400]\tvalid_0's rmse: 7.49216\n",
      "[500]\tvalid_0's rmse: 7.47353\n",
      "[600]\tvalid_0's rmse: 7.47709\n",
      "[700]\tvalid_0's rmse: 7.47483\n",
      "[800]\tvalid_0's rmse: 7.47358\n",
      "[900]\tvalid_0's rmse: 7.46984\n",
      "[1000]\tvalid_0's rmse: 7.46346\n",
      "[1100]\tvalid_0's rmse: 7.47819\n",
      "Early stopping, best iteration is:\n",
      "[989]\tvalid_0's rmse: 7.46194\n",
      "[fold 0] training target 22 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 3.3518\n",
      "[200]\tvalid_0's rmse: 3.08804\n",
      "[300]\tvalid_0's rmse: 3.02736\n",
      "[400]\tvalid_0's rmse: 3.01887\n",
      "[500]\tvalid_0's rmse: 3.01986\n",
      "[600]\tvalid_0's rmse: 3.02052\n",
      "Early stopping, best iteration is:\n",
      "[429]\tvalid_0's rmse: 3.01607\n",
      "[fold 0] training target 23 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 6.73935\n",
      "[200]\tvalid_0's rmse: 6.63321\n",
      "[300]\tvalid_0's rmse: 6.59639\n",
      "[400]\tvalid_0's rmse: 6.60402\n",
      "Early stopping, best iteration is:\n",
      "[296]\tvalid_0's rmse: 6.59478\n",
      "[fold 0] training target 24 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.77596\n",
      "[200]\tvalid_0's rmse: 7.62494\n",
      "[300]\tvalid_0's rmse: 7.56398\n",
      "[400]\tvalid_0's rmse: 7.53075\n",
      "[500]\tvalid_0's rmse: 7.52936\n",
      "[600]\tvalid_0's rmse: 7.53013\n",
      "[700]\tvalid_0's rmse: 7.53851\n",
      "Early stopping, best iteration is:\n",
      "[576]\tvalid_0's rmse: 7.52369\n",
      "[fold 0] training target 25 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.12509\n",
      "[200]\tvalid_0's rmse: 6.91167\n",
      "[300]\tvalid_0's rmse: 6.83581\n",
      "[400]\tvalid_0's rmse: 6.79851\n",
      "[500]\tvalid_0's rmse: 6.77443\n",
      "[600]\tvalid_0's rmse: 6.75406\n",
      "[700]\tvalid_0's rmse: 6.7496\n",
      "[800]\tvalid_0's rmse: 6.75137\n",
      "Early stopping, best iteration is:\n",
      "[669]\tvalid_0's rmse: 6.74552\n",
      "[fold 0] training target 26 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 8.02291\n",
      "[200]\tvalid_0's rmse: 7.01319\n",
      "[300]\tvalid_0's rmse: 6.66819\n",
      "[400]\tvalid_0's rmse: 6.53019\n",
      "[500]\tvalid_0's rmse: 6.47541\n",
      "[600]\tvalid_0's rmse: 6.43666\n",
      "[700]\tvalid_0's rmse: 6.42391\n",
      "[800]\tvalid_0's rmse: 6.41324\n",
      "[900]\tvalid_0's rmse: 6.40975\n",
      "[1000]\tvalid_0's rmse: 6.39891\n",
      "[1100]\tvalid_0's rmse: 6.38682\n",
      "[1200]\tvalid_0's rmse: 6.37889\n",
      "[1300]\tvalid_0's rmse: 6.37288\n",
      "[1400]\tvalid_0's rmse: 6.36601\n",
      "[1500]\tvalid_0's rmse: 6.35924\n",
      "[1600]\tvalid_0's rmse: 6.35168\n",
      "[1700]\tvalid_0's rmse: 6.34631\n",
      "[1800]\tvalid_0's rmse: 6.34257\n",
      "[1900]\tvalid_0's rmse: 6.34382\n",
      "[2000]\tvalid_0's rmse: 6.34075\n",
      "[2100]\tvalid_0's rmse: 6.33723\n",
      "[2200]\tvalid_0's rmse: 6.33399\n",
      "[2300]\tvalid_0's rmse: 6.33448\n",
      "[2400]\tvalid_0's rmse: 6.3328\n",
      "[2500]\tvalid_0's rmse: 6.33286\n",
      "[2600]\tvalid_0's rmse: 6.32975\n",
      "[2700]\tvalid_0's rmse: 6.3293\n",
      "[2800]\tvalid_0's rmse: 6.32963\n",
      "[2900]\tvalid_0's rmse: 6.32925\n",
      "[3000]\tvalid_0's rmse: 6.32687\n",
      "[3100]\tvalid_0's rmse: 6.32735\n",
      "[3200]\tvalid_0's rmse: 6.32613\n",
      "[3300]\tvalid_0's rmse: 6.32601\n",
      "[3400]\tvalid_0's rmse: 6.32617\n",
      "Early stopping, best iteration is:\n",
      "[3245]\tvalid_0's rmse: 6.32545\n",
      "[fold 0] training target 27 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 6.7432\n",
      "[200]\tvalid_0's rmse: 6.15762\n",
      "[300]\tvalid_0's rmse: 6.00819\n",
      "[400]\tvalid_0's rmse: 5.95888\n",
      "[500]\tvalid_0's rmse: 5.94522\n",
      "[600]\tvalid_0's rmse: 5.94734\n",
      "Early stopping, best iteration is:\n",
      "[478]\tvalid_0's rmse: 5.94123\n",
      "[fold 0] training target 28 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.31572\n",
      "[200]\tvalid_0's rmse: 7.0511\n",
      "[300]\tvalid_0's rmse: 6.93549\n",
      "[400]\tvalid_0's rmse: 6.89763\n",
      "[500]\tvalid_0's rmse: 6.88269\n",
      "[600]\tvalid_0's rmse: 6.8758\n",
      "[700]\tvalid_0's rmse: 6.8694\n",
      "[800]\tvalid_0's rmse: 6.86029\n",
      "[900]\tvalid_0's rmse: 6.86543\n",
      "[1000]\tvalid_0's rmse: 6.86373\n",
      "Early stopping, best iteration is:\n",
      "[821]\tvalid_0's rmse: 6.8557\n",
      "[fold 0] training target 29 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 4.93819\n",
      "[200]\tvalid_0's rmse: 4.87235\n",
      "[300]\tvalid_0's rmse: 4.8532\n",
      "[400]\tvalid_0's rmse: 4.85126\n",
      "[500]\tvalid_0's rmse: 4.84888\n",
      "[600]\tvalid_0's rmse: 4.85716\n",
      "Early stopping, best iteration is:\n",
      "[446]\tvalid_0's rmse: 4.84632\n",
      "[fold 0] training target 30 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 3.7234\n",
      "[200]\tvalid_0's rmse: 3.29966\n",
      "[300]\tvalid_0's rmse: 3.18448\n",
      "[400]\tvalid_0's rmse: 3.14423\n",
      "[500]\tvalid_0's rmse: 3.12999\n",
      "[600]\tvalid_0's rmse: 3.12275\n",
      "[700]\tvalid_0's rmse: 3.11733\n",
      "[800]\tvalid_0's rmse: 3.11938\n",
      "Early stopping, best iteration is:\n",
      "[696]\tvalid_0's rmse: 3.11702\n",
      "[fold 0] training target 31 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.69433\n",
      "[200]\tvalid_0's rmse: 2.65308\n",
      "[300]\tvalid_0's rmse: 2.65267\n",
      "[400]\tvalid_0's rmse: 2.65751\n",
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's rmse: 2.64932\n",
      "[fold 0] training target 32 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.72682\n",
      "[200]\tvalid_0's rmse: 7.67412\n",
      "[300]\tvalid_0's rmse: 7.64429\n",
      "[400]\tvalid_0's rmse: 7.64086\n",
      "[500]\tvalid_0's rmse: 7.64688\n",
      "[600]\tvalid_0's rmse: 7.64892\n",
      "[700]\tvalid_0's rmse: 7.6519\n",
      "Early stopping, best iteration is:\n",
      "[550]\tvalid_0's rmse: 7.63966\n",
      "[fold 0] training target 33 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.69947\n",
      "[200]\tvalid_0's rmse: 5.64388\n",
      "[300]\tvalid_0's rmse: 5.63622\n",
      "[400]\tvalid_0's rmse: 5.63685\n",
      "[500]\tvalid_0's rmse: 5.64229\n",
      "Early stopping, best iteration is:\n",
      "[358]\tvalid_0's rmse: 5.6298\n",
      "[fold 0] training target 34 on meta features …\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 3.34226\n",
      "[200]\tvalid_0's rmse: 3.22946\n",
      "[300]\tvalid_0's rmse: 3.18547\n",
      "[400]\tvalid_0's rmse: 3.16129\n",
      "[500]\tvalid_0's rmse: 3.15555\n",
      "[600]\tvalid_0's rmse: 3.14992\n",
      "[700]\tvalid_0's rmse: 3.14998\n",
      "[800]\tvalid_0's rmse: 3.14933\n",
      "[900]\tvalid_0's rmse: 3.14878\n",
      "Early stopping, best iteration is:\n",
      "[741]\tvalid_0's rmse: 3.14737\n",
      "✅ Saved fold 0 meta‐model → output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/meta_model_fold0.pkl\n",
      "⏭️ Skipping fold 1\n",
      "⏭️ Skipping fold 2\n",
      "⏭️ Skipping fold 3\n",
      "⏭️ Skipping fold 4\n",
      "⏭️ Skipping fold 5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import rankdata\n",
    "from python_scripts.import_data import importDataset\n",
    "from python_scripts.operate_model import predict\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from python_scripts.pretrain_model import PretrainedEncoderRegressor\n",
    "# ---------------- Settings ----------------\n",
    "trained_oof_model_folder = 'output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/'\n",
    "n_folds    = len([d for d in os.listdir(trained_oof_model_folder) if d.startswith('fold')])\n",
    "n_samples  = len(full_dataset)\n",
    "C          = 35\n",
    "BATCH_SIZE = 64\n",
    "start_fold = 0\n",
    "\n",
    "tile_dim = 128\n",
    "center_dim = 128\n",
    "neighbor_dim = 128\n",
    "fusion_dim = tile_dim + center_dim + neighbor_dim\n",
    "\n",
    "pretrained_ae_name = 'AE_Center_noaug'\n",
    "pretrained_ae_path = f\"AE_model/128/{pretrained_ae_name}/best.pt\"\n",
    "ae_type = 'center'\n",
    "\n",
    "# Ground truth label (全 dataset)\n",
    "y_true = np.vstack([ full_dataset[i]['label'].cpu().numpy() for i in range(n_samples) ])\n",
    "\n",
    "# Build CV splitter (must match first stage splits)\n",
    "logo = LeaveOneGroupOut()\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "lgb_base = lgb.LGBMRegressor(\n",
    "    objective='l2',\n",
    "    metric='rmse',\n",
    "    learning_rate=0.007522970004049377,\n",
    "    n_estimators=12000,\n",
    "    max_depth=11,\n",
    "    num_leaves=20,\n",
    "    colsample_bytree=0.7619407413363416,\n",
    "    subsample=0.8,\n",
    "    subsample_freq=1,\n",
    "    min_data_in_leaf=20,\n",
    "    reg_alpha=0.7480401395491829,\n",
    "    reg_lambda=0.2589860348178542,\n",
    "    verbosity=-1\n",
    "    )\n",
    "\n",
    "slide_idx = np.array(grouped_data['slide_idx'])   # shape (N,)\n",
    "\n",
    "\n",
    "for fold_id, (tr_idx, va_idx) in enumerate(\n",
    "    logo.split(X=np.zeros(n_samples), y=None, groups=slide_idx)):\n",
    "\n",
    "    if fold_id > start_fold:\n",
    "        print(f\"⏭️ Skipping fold {fold_id}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🚀 Starting fold {fold_id}...\")\n",
    "    ckpt_path = os.path.join(trained_oof_model_folder, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "\n",
    "    # === Load model and predict OOF ===\n",
    "    net = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net = net.to(device).eval()\n",
    "\n",
    "    val_ds = Subset(full_dataset, va_idx)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    preds, latents = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            tiles = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "            center = subtiles[:, 4].contiguous()\n",
    "\n",
    "            f_c = net.encoder_center(center)\n",
    "            f_n = net.encoder_subtile(subtiles)\n",
    "            f_t = net.encoder_tile(tiles)\n",
    "            fuse = torch.cat([f_c, f_n, f_t], dim=1).contiguous()\n",
    "            output = net.decoder(fuse)\n",
    "\n",
    "            preds.append(output.cpu())\n",
    "            latents.append(fuse.cpu())\n",
    "\n",
    "    preds = torch.cat(preds, dim=0).numpy()\n",
    "    latents = torch.cat(latents, dim=0).numpy()\n",
    "\n",
    "    # === AE model reconstruction loss ===\n",
    "    recon_model = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=pretrained_ae_path,\n",
    "        ae_type=ae_type,\n",
    "        tile_dim=tile_dim,\n",
    "        center_dim=center_dim,\n",
    "        neighbor_dim=neighbor_dim,\n",
    "        output_dim=C,\n",
    "        mode='reconstruction'\n",
    "    ).to(device)\n",
    "\n",
    "    meta = generate_meta_features(\n",
    "        dataset = val_ds,\n",
    "        oof_preds = preds,\n",
    "        image_latents = latents,\n",
    "        model_for_recon = recon_model,\n",
    "        device = device,\n",
    "        ae_type = ae_type,\n",
    "        use_clusters=\"4\"\n",
    "    )\n",
    "    \n",
    "    y_val = y_true[va_idx]   # shape = (len(va_idx), 35)\n",
    "\n",
    "    # 2) 再對這個 fold 的 meta 做 train/val 切分\n",
    "    X_train_tab, X_val_tab, y_train_tab, y_val_tab = train_test_split(\n",
    "        meta, y_val, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # 3) train MultiOutputRegressor with early stopping\n",
    "    meta_model = MultiOutputRegressor(lgb_base)\n",
    "    meta_model.estimators_ = []\n",
    "\n",
    "    for i in range(y_train_tab.shape[1]):\n",
    "        print(f\"[fold {fold_id}] training target {i} on meta features …\")\n",
    "        model = lgb.LGBMRegressor(**lgb_base.get_params())\n",
    "        model.fit(\n",
    "            X_train_tab, y_train_tab[:, i],\n",
    "            eval_set=[(X_val_tab, y_val_tab[:, i])],\n",
    "            callbacks=[\n",
    "                early_stopping(stopping_rounds=200),\n",
    "                log_evaluation(period=100)\n",
    "            ]\n",
    "        )\n",
    "        meta_model.estimators_.append(model)\n",
    "\n",
    "    # 4) 存下這個 fold 的 meta model\n",
    "    save_path = os.path.join(trained_oof_model_folder, f\"meta_model_fold{fold_id}.pkl\")\n",
    "    joblib.dump(meta_model, save_path)\n",
    "    print(f\"✅ Saved fold {fold_id} meta‐model → {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/import_data.py:276: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  raw = torch.load(pt_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 從 '<class 'list'>' 推斷樣本數量: 2088\n",
      "Model forward signature: (tile, subtiles)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from python_scripts.import_data import load_node_feature_data\n",
    "\n",
    "\n",
    "image_keys = [ 'tile', 'subtiles']\n",
    "\n",
    "model = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "\n",
    "# 用法示例\n",
    "from python_scripts.import_data import importDataset\n",
    "# 假设你的 model 已经定义好并实例化为 `model`\n",
    "test_dataset = load_node_feature_data(\"dataset/spot-rank/filtered_directly_rank/masked/test/Macenko/test_dataset.pt\", model)\n",
    "test_dataset = importDataset(\n",
    "        data_dict=test_dataset,\n",
    "        model=model,\n",
    "        image_keys=image_keys,\n",
    "        transform=lambda x: x,  # identity transform\n",
    "        print_sig=True\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_35616/3793311050.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/pretrain_model.py:310: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ae.load_state_dict(torch.load(ae_checkpoint, map_location=\"cpu\"))\n",
      "Computing AE recon loss: 100%|██████████| 33/33 [00:02<00:00, 12.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for k=2: 0.5554\n",
      "Silhouette score for k=3: 0.6321\n",
      "Silhouette score for k=4: 0.5934\n",
      "Silhouette score for k=5: 0.5564\n",
      "Silhouette score for k=6: 0.5140\n",
      "Selected best k=3 (score=0.6321)\n",
      "✅ Generated meta-features with shape: (2088, 307)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 307 features, but LGBMRegressor is expecting 227 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m     meta_model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(meta_model_path)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# 2) 用剛剛算出的 meta features 做預測\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     final_preds \u001b[38;5;241m=\u001b[39m \u001b[43mmeta_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# --- Save submission ---\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mh5py\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/multioutput.py:306\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe base estimator should implement a predict method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 306\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(y)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/sklearn.py:1108\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LGBMNotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimator not fitted, call fit before exploiting the model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (pd_DataFrame, dt_DataTable)):\n\u001b[0;32m-> 1108\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43m_LGBMValidateData\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 'y' being omitted = run scikit-learn's check_array() instead of check_X_y()\u001b[39;49;00m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#\u001b[39;49;00m\n\u001b[1;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Prevent scikit-learn from deleting or modifying attributes like 'feature_names_in_' and 'n_features_in_'.\u001b[39;49;00m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# These shouldn't be changed at predict() time.\u001b[39;49;00m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# allow any input type (this validation is done further down, in lgb.Dataset())\u001b[39;49;00m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# do not raise an error if Inf of NaN values are found (LightGBM handles these internally)\u001b[39;49;00m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# raise an error on 0-row inputs\u001b[39;49;00m\n\u001b[1;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# retrieve original params that possibly can be used in both training and prediction\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# and then overwrite them (considering aliases) with params that were passed directly in prediction\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m predict_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_params(stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2965\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m-> 2965\u001b[0m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2829\u001b[0m, in \u001b[0;36m_check_n_features\u001b[0;34m(estimator, X, reset)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m-> 2829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2830\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2831\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2832\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 307 features, but LGBMRegressor is expecting 227 features as input."
     ]
    }
   ],
   "source": [
    "# --- 3) Prepare test meta-features ---\n",
    "n_test = len(test_dataset)\n",
    "\n",
    "\n",
    "for fold_id in range(n_folds):\n",
    "    if fold_id > start_fold:\n",
    "        print(f\"⏭️ Skipping fold {fold_id}\")\n",
    "        continue\n",
    "    ckpt_path = os.path.join(trained_oof_model_folder, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.eval()\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_preds = []\n",
    "    test_latents = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            tiles = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "            center = subtiles[:, 4].contiguous()\n",
    "\n",
    "            f_c = net.encoder_center(center)\n",
    "            f_n = net.encoder_subtile(subtiles)\n",
    "            f_t = net.encoder_tile(tiles)\n",
    "            fuse = torch.cat([f_c, f_n, f_t], dim=1).contiguous()\n",
    "            output = net.decoder(fuse)\n",
    "\n",
    "            test_preds.append(output.cpu())\n",
    "            test_latents.append(fuse.cpu())\n",
    "\n",
    "\n",
    "    test_preds = torch.cat(test_preds, dim=0).numpy()\n",
    "    test_latents = torch.cat(test_latents, dim=0).numpy()\n",
    "# === AE model reconstruction loss ===\n",
    "    recon_model = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=pretrained_ae_path,\n",
    "        ae_type=ae_type,\n",
    "        tile_dim=tile_dim,\n",
    "        center_dim=center_dim,\n",
    "        neighbor_dim=neighbor_dim,\n",
    "        output_dim=C,\n",
    "        mode='reconstruction'\n",
    "    ).to(device)\n",
    "\n",
    "    meta = generate_meta_features(\n",
    "        dataset = test_dataset,\n",
    "        oof_preds = test_preds,\n",
    "        image_latents = test_latents,\n",
    "        model_for_recon = recon_model,\n",
    "        device = device,\n",
    "        ae_type = ae_type,\n",
    "        use_clusters=\"both\"\n",
    "    )\n",
    "    # 1) 直接載入整個 MultiOutputRegressor\n",
    "    meta_model_path = os.path.join(trained_oof_model_folder, f\"meta_model_fold{fold_id}.pkl\")\n",
    "    meta_model = joblib.load(meta_model_path)\n",
    "\n",
    "    # 2) 用剛剛算出的 meta features 做預測\n",
    "    final_preds = meta_model.predict(meta)\n",
    "\n",
    "\n",
    "# --- Save submission ---\n",
    "import h5py\n",
    "import pandas as pd\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spot_ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"]))\n",
    "sub = pd.DataFrame(final_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, 'ID', test_spot_ids.index)\n",
    "sub.to_csv(os.path.join(trained_oof_model_folder, 'submission_stacked.csv'), index=False)\n",
    "print(f\"✅ Saved stacked submission in {trained_oof_model_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Base model\n",
    "# lgb_base = lgb.LGBMRegressor(\n",
    "#     objective='l2',\n",
    "#     metric='rmse',\n",
    "#     n_estimators=12000,\n",
    "#     max_depth=15,\n",
    "#     learning_rate=0.008,\n",
    "#     num_leaves=32,\n",
    "#     colsample_bytree=0.25\n",
    "# )\n",
    "\n",
    "lgb_base = lgb.LGBMRegressor(\n",
    "    objective='l2',\n",
    "    metric='rmse',\n",
    "    learning_rate=0.007522970004049377,\n",
    "    n_estimators=12000,\n",
    "    max_depth=11,\n",
    "    num_leaves=194,\n",
    "    colsample_bytree=0.7619407413363416,\n",
    "    subsample=0.8,\n",
    "    subsample_freq=1,\n",
    "    min_data_in_leaf=20,\n",
    "    reg_alpha=0.7480401395491829,\n",
    "    reg_lambda=0.2589860348178542,\n",
    "    verbosity=-1\n",
    ")\n",
    "# 將每個 target 分別 early stopping\n",
    "meta_model = MultiOutputRegressor(lgb_base)\n",
    "\n",
    "print(\"Training LightGBM on OOF meta-features with early stopping...\")\n",
    "meta_model.estimators_ = []\n",
    "\n",
    "for i in range(y_train.shape[1]):\n",
    "    print(f\"Training target {i}...\")\n",
    "    model  = lgb.LGBMRegressor(\n",
    "        objective='l2',\n",
    "        metric='rmse',\n",
    "        learning_rate=0.007522970004049377,\n",
    "        n_estimators=12000,\n",
    "        max_depth=11,\n",
    "        num_leaves=194,\n",
    "        colsample_bytree=0.7619407413363416,\n",
    "        subsample=0.8,\n",
    "        subsample_freq=1,\n",
    "        min_data_in_leaf=20,\n",
    "        reg_alpha=0.7480401395491829,\n",
    "        reg_lambda=0.2589860348178542,\n",
    "        verbosity=-1\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train[:, i],\n",
    "        eval_set=[(X_val, y_val[:, i])],\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=200),\n",
    "            log_evaluation(period=100)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    meta_model.estimators_.append(model)\n",
    "\n",
    "# 保存模型\n",
    "joblib.dump(meta_model, os.path.join(save_root, 'meta_model.pkl'))\n",
    "\n",
    "\n",
    "# --- 3) Prepare test meta-features ---\n",
    "n_test = len(test_dataset)\n",
    "test_preds = []\n",
    "test_latents = []\n",
    "\n",
    "for fold_id in range(n_folds):\n",
    "    ckpt_path = os.path.join(save_root, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = True\n",
    "    )\n",
    "\n",
    "    net.decoder = nn.Sequential(\n",
    "        nn.Linear(64+64, 256),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "    )\n",
    "\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.eval()\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds = []\n",
    "    latents = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            tiles = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "\n",
    "            center = subtiles[:, 4].contiguous()\n",
    "            f_c = net.enc_center(center)\n",
    "            f_n = net.enc_neigh(subtiles)\n",
    "            fuse = torch.cat([f_c, f_n], dim=1)\n",
    "\n",
    "            out = net.decoder(fuse)\n",
    "\n",
    "            preds.append(out.cpu())\n",
    "            latents.append(fuse.cpu())  # image embedding (128D)\n",
    "\n",
    "    test_preds.append(torch.cat(preds, dim=0).numpy())      # shape: (n_test, 35)\n",
    "    test_latents.append(torch.cat(latents, dim=0).numpy())  # shape: (n_test, 128)\n",
    "\n",
    "# === Stack + Average ===\n",
    "test_preds = np.mean(np.stack(test_preds, axis=0), axis=0)      # (n_test, 35)\n",
    "test_latents = np.mean(np.stack(test_latents, axis=0), axis=0)  # (n_test, 128)\n",
    "\n",
    "with h5py.File(\"dataset/elucidata_ai_challenge_data.h5\", \"r\") as f:\n",
    "    test_spots = f[\"spots/Test\"]\n",
    "    spot_array = np.array(test_spots['S_7'])\n",
    "    df = pd.DataFrame(spot_array)\n",
    "\n",
    "xy = df[[\"x\", \"y\"]].to_numpy()  # shape: (n_test, 2)\n",
    "\n",
    "# 合併為最終 test meta features\n",
    "test_meta = np.concatenate([test_preds, xy, test_latents], axis=1)  # shape: (n_test, 35+2+128)\n",
    "\n",
    "\n",
    "\n",
    "final_preds = meta_model.predict(test_meta)\n",
    "\n",
    "# --- Save submission ---\n",
    "import h5py\n",
    "import pandas as pd\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spot_ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"]))\n",
    "sub = pd.DataFrame(final_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, 'ID', test_spot_ids.index)\n",
    "sub.to_csv(os.path.join(save_root, 'submission_stacked.csv'), index=False)\n",
    "print(f\"✅ Saved stacked submission in {save_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import rankdata\n",
    "from python_scripts.import_data import importDataset\n",
    "from python_scripts.operate_model import predict\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import h5py\n",
    "import pandas as pd\n",
    "# ---------------- Settings ----------------\n",
    "save_root  = save_folder  # your save_folder path\n",
    "n_folds    = len([d for d in os.listdir(save_root) if d.startswith('fold')])\n",
    "n_samples  = len(full_dataset)\n",
    "C          = 35  # num cell types\n",
    "start_fold = 0\n",
    "BATCH_SIZE = 64\n",
    "# If optimizing Spearman, convert labels to ranks\n",
    "\n",
    "# --- 1) Prepare OOF meta-features ---\n",
    "# Initialize matrix for OOF predictions\n",
    "n_samples = len(full_dataset)\n",
    "oof_preds = np.zeros((n_samples, C), dtype=np.float32)\n",
    "# True labels (raw or rank)\n",
    "# importDataset returns a dict-like sample, so label is under key 'label'\n",
    "y_true = np.vstack([ full_dataset[i]['label'].cpu().numpy() for i in range(n_samples) ])\n",
    "y_meta = y_true\n",
    "\n",
    "# Build CV splitter (must match first stage splits)\n",
    "logo = LeaveOneGroupOut()\n",
    "image_latents = np.zeros((n_samples, 128), dtype=np.float32)\n",
    "\n",
    "# Loop over folds, load best model, predict on validation indices\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "for fold_id, (tr_idx, va_idx) in enumerate(\n",
    "        logo.split(X=np.zeros(n_samples), y=None, groups=slide_idx)):\n",
    "    # Load model\n",
    "    # if fold_id > start_fold:\n",
    "    #     print(f\"⏭️ Skipping fold {fold_id}\")\n",
    "    #     continue\n",
    "    ckpt_path = os.path.join(save_root, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    print(f\"Loading model from {ckpt_path}...\")\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = True\n",
    "    )\n",
    "\n",
    "    # 2) monkey‐patch 一个新的 head\n",
    "    net.decoder  = nn.Sequential(\n",
    "        nn.Linear(64+64, 256),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "        \n",
    "    )\n",
    "    net = net.to(device)    # Alternatively, if your model requires specific args, replace with:\n",
    "    # net = VisionMLP_MultiTask(tile_dim=64, subtile_dim=64, output_dim=35).to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.to(device).eval()\n",
    "    \n",
    "    # Predict on validation set\n",
    "    val_ds = Subset(full_dataset, va_idx)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    preds = []\n",
    "    latents = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            tiles    = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "\n",
    "            center = subtiles[:, 4].contiguous()\n",
    "            f_c = net.enc_center(center)\n",
    "            f_n = net.enc_neigh(subtiles)\n",
    "            fuse = torch.cat([f_c, f_n], dim=1)\n",
    "\n",
    "            output = net.decoder(fuse)\n",
    "\n",
    "            preds.append(output.cpu())\n",
    "            latents.append(fuse.cpu())  # ⬅️ 收集 latent vector\n",
    "\n",
    "    preds = torch.cat(preds, dim=0).numpy()    # (n_val, 35)\n",
    "    latents = torch.cat(latents, dim=0).numpy()  # (n_val, 128)\n",
    "\n",
    "    oof_preds[va_idx] = preds\n",
    "    image_latents[va_idx] = latents\n",
    "\n",
    "    print(f\"Fold {fold_id}: OOF preds shape {preds.shape}, Latent shape: {latents.shape}\")\n",
    "\n",
    "\n",
    "    \n",
    "with h5py.File(\"dataset/realign/filtered_dataset.h5\", \"r\") as f:\n",
    "    train_spots = f[\"spots/Train\"]\n",
    "    \n",
    "    train_spot_tables = {}\n",
    "    \n",
    "    for slide_name in train_spots.keys():\n",
    "        spot_array = np.array(train_spots[slide_name])\n",
    "        df = pd.DataFrame(spot_array)\n",
    "        df[\"slide_name\"] = slide_name\n",
    "        train_spot_tables[slide_name] = df\n",
    "        print(f\"✅ 已讀取 slide: {slide_name}\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 2: 合併所有 slide 的資料\n",
    "# -----------------------------------------------------\n",
    "all_train_spots_df = pd.concat(train_spot_tables.values(), ignore_index=True)\n",
    "# 提取 x, y\n",
    "xy = all_train_spots_df[[\"x\", \"y\"]].to_numpy()  # shape: (8348, 2)\n",
    "\n",
    "# 合併成新的 meta feature\n",
    "meta_features = np.concatenate([oof_preds, xy, image_latents], axis=1)\n",
    "# --- 2) Train LightGBM meta-model ---\n",
    "# Choose objective: regression on rank (for Spearman) or raw (for MSE)\n",
    "# 將 meta features 拆成訓練集與 early stopping 用的驗證集\n",
    "X_train, X_val, y_train, y_val = train_test_split(meta_features, y_meta, test_size=0.2, random_state=42)\n",
    "print(\"Meta feature shape:\", X_train.shape)\n",
    "print(\"Feature std (min/max):\", np.min(np.std(X_train, axis=0)), np.max(np.std(X_train, axis=0)))\n",
    "\n",
    "\n",
    "# # Base model\n",
    "# lgb_base = lgb.LGBMRegressor(\n",
    "#     objective='l2',\n",
    "#     metric='rmse',\n",
    "#     n_estimators=12000,\n",
    "#     max_depth=15,\n",
    "#     learning_rate=0.008,\n",
    "#     num_leaves=32,\n",
    "#     colsample_bytree=0.25\n",
    "# )\n",
    "import optuna\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define Optuna objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'device': 'gpu',                # ✅ GPU 支援\n",
    "        'gpu_platform_id': 0,\n",
    "        'gpu_device_id': 0,\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.005, 0.1),\n",
    "        'max_depth': trial.suggest_int(\"max_depth\", 4, 15),\n",
    "        'num_leaves': trial.suggest_int(\"num_leaves\", 32, 256),\n",
    "        'min_data_in_leaf': trial.suggest_int(\"min_data_in_leaf\", 20, 100),\n",
    "        'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float(\"reg_alpha\", 0, 1),\n",
    "        'reg_lambda': trial.suggest_float(\"reg_lambda\", 0, 1),\n",
    "        'n_estimators': 12000\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    multi_model = MultiOutputRegressor(model)\n",
    "    multi_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = multi_model.predict(X_val)\n",
    "    rmse = np.mean([\n",
    "        np.sqrt(mean_squared_error(y_val[:, i], y_pred[:, i]))\n",
    "        for i in range(y_val.shape[1])\n",
    "    ])\n",
    "\n",
    "\n",
    "    return rmse\n",
    "\n",
    "# Run optimization\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Use best params to train final models\n",
    "best_params = study.best_trial.params\n",
    "best_params['objective'] = 'l2'\n",
    "best_params['metric'] = 'rmse'\n",
    "best_params['verbosity'] = -1\n",
    "\n",
    "# Train final models with best parameters\n",
    "meta_model = MultiOutputRegressor(lgb.LGBMRegressor(**best_params))\n",
    "meta_model.estimators_ = []\n",
    "\n",
    "print(\"Training LightGBM on OOF meta-features with best Optuna params...\")\n",
    "for i in range(y_train.shape[1]):\n",
    "    print(f\"Training target {i}...\")\n",
    "    model = lgb.LGBMRegressor(**best_params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train[:, i],\n",
    "        eval_set=[(X_val, y_val[:, i])],\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=200),\n",
    "            log_evaluation(period=100)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    meta_model.estimators_.append(model)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(meta_model, os.path.join(save_root, 'meta_model.pkl'))\n",
    "# 保存模型\n",
    "\n",
    "\n",
    "# --- 3) Prepare test meta-features ---\n",
    "n_test = len(test_dataset)\n",
    "test_preds = []\n",
    "test_latents = []\n",
    "\n",
    "for fold_id in range(n_folds):\n",
    "    ckpt_path = os.path.join(save_root, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = True\n",
    "    )\n",
    "\n",
    "    net.decoder = nn.Sequential(\n",
    "        nn.Linear(64+64, 256),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "    )\n",
    "\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.eval()\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds = []\n",
    "    latents = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            tiles = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "\n",
    "            center = subtiles[:, 4].contiguous()\n",
    "            f_c = net.enc_center(center)\n",
    "            f_n = net.enc_neigh(subtiles)\n",
    "            fuse = torch.cat([f_c, f_n], dim=1)\n",
    "\n",
    "            out = net.decoder(fuse)\n",
    "\n",
    "            preds.append(out.cpu())\n",
    "            latents.append(fuse.cpu())  # image embedding (128D)\n",
    "\n",
    "    test_preds.append(torch.cat(preds, dim=0).numpy())      # shape: (n_test, 35)\n",
    "    test_latents.append(torch.cat(latents, dim=0).numpy())  # shape: (n_test, 128)\n",
    "\n",
    "# === Stack + Average ===\n",
    "test_preds = np.mean(np.stack(test_preds, axis=0), axis=0)      # (n_test, 35)\n",
    "test_latents = np.mean(np.stack(test_latents, axis=0), axis=0)  # (n_test, 128)\n",
    "\n",
    "with h5py.File(\"dataset/elucidata_ai_challenge_data.h5\", \"r\") as f:\n",
    "    test_spots = f[\"spots/Test\"]\n",
    "    spot_array = np.array(test_spots['S_7'])\n",
    "    df = pd.DataFrame(spot_array)\n",
    "\n",
    "xy = df[[\"x\", \"y\"]].to_numpy()  # shape: (n_test, 2)\n",
    "\n",
    "# 合併為最終 test meta features\n",
    "test_meta = np.concatenate([test_preds, xy, test_latents], axis=1)  # shape: (n_test, 35+2+128)\n",
    "\n",
    "\n",
    "\n",
    "final_preds = meta_model.predict(test_meta)\n",
    "\n",
    "# --- Save submission ---\n",
    "import h5py\n",
    "import pandas as pd\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spot_ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"]))\n",
    "sub = pd.DataFrame(final_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, 'ID', test_spot_ids.index)\n",
    "sub.to_csv(os.path.join(save_root, 'submission_stacked.csv'), index=False)\n",
    "print(\"✅ Saved stacked submission.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import rankdata\n",
    "from python_scripts.import_data import importDataset\n",
    "from python_scripts.operate_model import predict\n",
    "\n",
    "# --- 配置: 只用哪些 fold 的结果来训练/预测 meta-model ---\n",
    "meta_folds = [0]  # 例如只用 fold0, fold2, fold4\n",
    "\n",
    "# 1) 准备 full_dataset, slide_idx, test_dataset 等\n",
    "full_dataset = importDataset(\n",
    "    grouped_data, model,\n",
    "    image_keys=['tile','subtiles'],\n",
    "    transform=lambda x: x\n",
    ")\n",
    "n_samples = len(full_dataset)\n",
    "C = 35  # 类别数\n",
    "\n",
    "# 2) 预留 oof_preds 和 fold_ids\n",
    "oof_preds    = np.zeros((n_samples, C), dtype=np.float32)\n",
    "oof_fold_ids = np.full(n_samples, -1, dtype=int)\n",
    "\n",
    "# 真标签\n",
    "y_true = np.vstack([ full_dataset[i]['label'].cpu().numpy() for i in range(n_samples) ])\n",
    "y_meta = y_true.copy()  # 不做 rank 时直接用 raw\n",
    "\n",
    "# 3) 生成 OOF 预测并记录 fold id\n",
    "logo = LeaveOneGroupOut()\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "for fold_id, (tr_idx, va_idx) in enumerate(\n",
    "        logo.split(X=np.zeros(n_samples), y=None, groups=slide_idx)):\n",
    "\n",
    "    # 如果当前 fold 不在我们想要的 meta_folds 列表里，就跳过\n",
    "    if fold_id not in meta_folds:\n",
    "        print(f\"⏭️ Skipping OOF for fold {fold_id}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n>>> Generating OOF for fold {fold_id}\")\n",
    "    ckpt_path = os.path.join(save_root, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = True\n",
    "    )\n",
    "\n",
    "    # 2) monkey‐patch 一个新的 head\n",
    "    net.decoder  = nn.Sequential(\n",
    "        nn.Linear(64+64, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "        \n",
    "    )\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.eval()\n",
    "\n",
    "    val_loader = DataLoader(Subset(full_dataset, va_idx), batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds = predict(net, val_loader, device)  # (n_val, C)\n",
    "\n",
    "    oof_preds[va_idx]    = preds\n",
    "    oof_fold_ids[va_idx] = fold_id\n",
    "\n",
    "    print(f\"  → Fold {fold_id} OOF preds shape: {preds.shape}\")\n",
    "# 4) 只选取 meta_folds 的行来训练 meta-model\n",
    "mask = np.isin(oof_fold_ids, meta_folds)\n",
    "X_meta = oof_preds[mask]\n",
    "y_meta_sub = y_meta[mask]\n",
    "\n",
    "print(f\"\\nTraining meta-model on folds {meta_folds}:\")\n",
    "print(f\"  使用样本数：{X_meta.shape[0]} / {n_samples}\")\n",
    "\n",
    "lgb_base = lgb.LGBMRegressor(\n",
    "    objective='regression',\n",
    "    learning_rate=0.001,\n",
    "    n_estimators=1000,\n",
    "    num_leaves=31,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    n_jobs=-1,\n",
    "    force_col_wise=True\n",
    ")\n",
    "meta_model = MultiOutputRegressor(lgb_base)\n",
    "meta_model.fit(X_meta, y_meta_sub)\n",
    "joblib.dump(meta_model, os.path.join(save_root, 'meta_model.pkl'))\n",
    "\n",
    "# 5) 准备 test_meta，只平均 meta_folds 中的预测\n",
    "n_folds = len([d for d in os.listdir(save_root) if d.startswith('fold')])\n",
    "n_test  = len(test_dataset)\n",
    "test_meta = np.zeros((n_test, C), dtype=np.float32)\n",
    "\n",
    "for fold_id in range(n_folds):\n",
    "    if fold_id not in meta_folds:\n",
    "        continue\n",
    "    ckpt_path = os.path.join(save_root, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = True\n",
    "    )\n",
    "\n",
    "    # 2) monkey‐patch 一个新的 head\n",
    "    net.decoder  = nn.Sequential(\n",
    "        nn.Linear(64+64, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "        \n",
    "    )\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.eval()\n",
    "\n",
    "    loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds = predict(net, loader, device)\n",
    "    test_meta += preds\n",
    "\n",
    "# 平均时除以参与的 folds 数目\n",
    "test_meta /= len(meta_folds)\n",
    "\n",
    "# 6) 用 meta-model 做最终预测\n",
    "final_preds = meta_model.predict(test_meta)\n",
    "\n",
    "# --- Save submission ---\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spot_ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"]))\n",
    "\n",
    "sub = pd.DataFrame(final_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, 'ID', test_spot_ids.index)\n",
    "sub.to_csv(os.path.join(save_root, 'submission_stacked.csv'), index=False)\n",
    "print(\"✅ Saved stacked submission.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import inspect\n",
    "from python_scripts.operate_model import get_model_inputs\n",
    "from python_scripts.import_data import load_node_feature_data\n",
    "\n",
    "\n",
    "image_keys = [ 'tile', 'subtiles']\n",
    "\n",
    "\n",
    "# 用法示例\n",
    "from python_scripts.import_data import importDataset\n",
    "# 假设你的 model 已经定义好并实例化为 `model`\n",
    "test_dataset = load_node_feature_data(\"dataset/spot-rank/filtered_directly_rank/masked/test/Macenko/test_dataset.pt\", model)\n",
    "test_dataset = importDataset(\n",
    "        data_dict=test_dataset,\n",
    "        model=model,\n",
    "        image_keys=image_keys,\n",
    "        transform=lambda x: x,  # identity transform\n",
    "        print_sig=True\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset.check_item(1000, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 讀 test spot index\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spots     = f[\"spots/Test\"]\n",
    "    test_spot_table= pd.DataFrame(np.array(test_spots['S_7']))\n",
    "\n",
    "fold_ckpts = sorted(glob.glob(os.path.join(save_folder, \"fold*\", \"best_model.pt\")))\n",
    "models = []\n",
    "for ckpt in fold_ckpts:\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = False\n",
    "    )\n",
    "\n",
    "    # 2) monkey‐patch 一个新的 head\n",
    "    net.decoder  = nn.Sequential(\n",
    "        nn.Linear(64+64, 256),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "        \n",
    "    )\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt, map_location=\"cpu\"))\n",
    "    net.to(device).eval()\n",
    "    models.append(net)\n",
    "\n",
    "all_fold_preds = []\n",
    "for fold_id, net in enumerate(models):\n",
    "    # 推論\n",
    "    with torch.no_grad():\n",
    "        preds = predict(net, test_loader, device)  # (N_test,35) numpy array\n",
    "\n",
    "    # 1) 存每一折的原始預測\n",
    "    df_fold = pd.DataFrame(preds, columns=[f\"C{i+1}\" for i in range(preds.shape[1])])\n",
    "    df_fold.insert(0, \"ID\", test_spot_table.index)\n",
    "    path_fold = os.path.join(save_folder, f\"submission_fold{fold_id}.csv\")\n",
    "    df_fold.to_csv(path_fold, index=False)\n",
    "    print(f\"✅ Saved fold {fold_id} predictions to {path_fold}\")\n",
    "\n",
    "    all_fold_preds.append(preds)\n",
    "\n",
    "# 2) 做 rank‐average ensemble\n",
    "all_fold_preds = np.stack(all_fold_preds, axis=0)       # (K, N_test, 35)\n",
    "ranks          = all_fold_preds.argsort(axis=2).argsort(axis=2).astype(float)\n",
    "mean_rank      = ranks.mean(axis=0)                    # (N_test,35)\n",
    "\n",
    "# 3) 存 final ensemble\n",
    "df_ens = pd.DataFrame(mean_rank, columns=[f\"C{i+1}\" for i in range(mean_rank.shape[1])])\n",
    "df_ens.insert(0, \"ID\", test_spot_table.index)\n",
    "path_ens = os.path.join(save_folder, \"submission_rank_ensemble.csv\")\n",
    "df_ens.to_csv(path_ens, index=False)\n",
    "print(f\"✅ Saved rank‐ensemble submission to {path_ens}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatialhackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
