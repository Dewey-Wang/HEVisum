{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/pretrain_model.py:310: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ae.load_state_dict(torch.load(ae_checkpoint, map_location=\"cpu\"))\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_14152/3220337273.py:319: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('output_folder/rank-spot/realign/whole_worflow/s_m_l/filtered_directly_rank/k-fold_mix/realign_all/Macenko_masked/results/model_epoch022.pt', map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable / total params = 6,639,142 / 6,639,142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionMLP_MultiTask(\n",
       "  (encoder_tile): DeepTileEncoder(\n",
       "    (layer0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU()\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "    )\n",
       "    (global_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (mid_pool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
       "    (fc): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=2560, out_features=512, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "      (5): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (6): LeakyReLU(negative_slope=0.01)\n",
       "      (7): Dropout(p=0.1, inplace=False)\n",
       "      (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (encoder_subtile): SubtileEncoder(\n",
       "    (layer0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU()\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "    )\n",
       "    (global_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (mid_pool): AdaptiveAvgPool2d(output_size=(2, 2))\n",
       "    (large_pool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
       "    (fc): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=1792, out_features=256, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "      (5): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (6): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (encoder_center): CenterSubtileEncoder(\n",
       "    (layer0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU()\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "    )\n",
       "    (global_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (mid_pool): AdaptiveAvgPool2d(output_size=(2, 2))\n",
       "    (large_pool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
       "    (fc): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=1792, out_features=256, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "      (5): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (6): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (gate_fc): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=64, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=64, out_features=3, bias=True)\n",
       "    (3): Softmax(dim=1)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): Dropout(p=0.1, inplace=False)\n",
       "    (9): Linear(in_features=64, out_features=35, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from python_scripts.pretrain_model import PretrainedEncoderRegressor\n",
    "import torch.nn as nn\n",
    "\n",
    "name = 'AE_Center_noaug'\n",
    "\n",
    "checkpoint_path = f\"AE_model/128/{name}/best.pt\"\n",
    "\n",
    "# 1) å®ä¾‹åŒ–ï¼ˆä¼šè‡ªåŠ¨åŠ è½½å¹¶å†»ç»“ encoderï¼‰\n",
    "model = PretrainedEncoderRegressor(\n",
    "    ae_checkpoint=checkpoint_path,\n",
    "    ae_type=\"center\",\n",
    "    tile_dim=128,\n",
    "    center_dim=128,\n",
    "    neighbor_dim=128,\n",
    "    output_dim=35\n",
    ")\n",
    "\n",
    "# 2) monkeyâ€patch ä¸€ä¸ªæ–°çš„ head\n",
    "model.decoder  = nn.Sequential(\n",
    "    nn.Linear(128+128+128, 256),\n",
    "    nn.LeakyReLU(0.01),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.LeakyReLU(0.01),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.LeakyReLU(0.01),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(64, 35)\n",
    "    \n",
    ")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(out_channels)\n",
    "        self.act1  = nn.SiLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        self.act2 = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.act1(self.bn1(self.conv1(x)))\n",
    "        out = self.act2(self.bn2(self.conv2(out)))\n",
    "        if self.shortcut is not None:\n",
    "            identity = self.shortcut(x)\n",
    "        return out + identity\n",
    "\n",
    "\n",
    "\n",
    "class DeepTileEncoder(nn.Module):\n",
    "    \"\"\"åŠ æ·±çš„ Tile åˆ†æ”¯ï¼šå…¨å±€ä¿¡æ¯ï¼Œå¤šå°ºåº¦æ± åŒ– + ä¸‰å±‚ MLP\"\"\"\n",
    "    def __init__(self, out_dim, in_channels=3, negative_slope=0.01):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(2)  # 78â†’39\n",
    "        )\n",
    "        self.layer1 = nn.Sequential(\n",
    "            ResidualBlock(32, 64),\n",
    "            ResidualBlock(64, 64),\n",
    "            nn.MaxPool2d(2)  # 39â†’19\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            ResidualBlock(64, 128),\n",
    "            ResidualBlock(128, 128),\n",
    "            nn.MaxPool2d(2)  # 19â†’9\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            ResidualBlock(128, 256),\n",
    "            ResidualBlock(256, 256)\n",
    "        )  # ä¿æŒ 9Ã—9\n",
    "\n",
    "        # å¤šå°ºåº¦æ± åŒ–\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))  # [B,256,1,1]\n",
    "        self.mid_pool    = nn.AdaptiveAvgPool2d((3, 3))  # [B,256,3,3]\n",
    "\n",
    "        total_dim = 256*1*1 + 256*3*3\n",
    "        # ä¸‰å±‚ MLPï¼štotal_dim â†’ 2*out_dim â†’ out_dim â†’ out_dim\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(total_dim, out_dim*4),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(out_dim*4, out_dim*2),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(out_dim*2, out_dim),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        # x: [B,256,9,9]\n",
    "        g = self.global_pool(x).contiguous().reshape(x.size(0), -1)  # [B,256]\n",
    "        m = self.mid_pool(x).contiguous().reshape(x.size(0), -1)     # [B,256*3*3]\n",
    "\n",
    "        return self.fc(torch.cat([g, m], dim=1))\n",
    "\n",
    "\n",
    "class SubtileEncoder(nn.Module):\n",
    "    \"\"\"å¤šå°ºåº¦ Subtile åˆ†æ”¯ï¼šå±€éƒ¨ä¿¡æ¯ + ä¸¤å±‚ MLP\"\"\"\n",
    "    def __init__(self, out_dim, in_channels=3, negative_slope=0.01):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(2)  # 26â†’13\n",
    "        )\n",
    "        self.layer1 = nn.Sequential(\n",
    "            ResidualBlock(32, 64),\n",
    "            ResidualBlock(64, 64),\n",
    "            nn.MaxPool2d(2)  # 13â†’6\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            ResidualBlock(64, 128),\n",
    "            ResidualBlock(128, 128)\n",
    "        )  # ä¿æŒ 6Ã—6\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.mid_pool    = nn.AdaptiveAvgPool2d((2,2))\n",
    "        self.large_pool    = nn.AdaptiveAvgPool2d((3,3))\n",
    "\n",
    "        total_dim = 128*1*1 + 128*2*2 + 128*3*3\n",
    "        # ä¸¤å±‚ MLPï¼štotal_dim â†’ out_dim*2 â†’ out_dim\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(total_dim, out_dim*2),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(out_dim*2, out_dim),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C, H, W = x.shape\n",
    "        x = x.contiguous().reshape(B*N, C, H, W)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        # g,m: [B*N, feat]\n",
    "        g = self.global_pool(x).contiguous().reshape(B, N, -1)\n",
    "        m = self.mid_pool(x).contiguous().reshape(B, N, -1)\n",
    "        l = self.large_pool(x).contiguous().reshape(B, N, -1)\n",
    "\n",
    "        # åˆå¹¶ N å¼  subtilesï¼Œå† FC\n",
    "        feat = torch.cat([g, m, l], dim=2).mean(dim=1).contiguous()  # [B, total_dim]\n",
    "        return self.fc(feat)\n",
    "class CenterSubtileEncoder(nn.Module):\n",
    "    \"\"\"å°ˆé–€è™•ç†ä¸­å¿ƒ subtile çš„ Encoder\"\"\"\n",
    "    def __init__(self, out_dim, in_channels=3, negative_slope= 0.01):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(2)  # 26â†’13\n",
    "        )\n",
    "        self.layer1 = nn.Sequential(\n",
    "            ResidualBlock(32, 64),\n",
    "            ResidualBlock(64, 64),\n",
    "            nn.MaxPool2d(2)  # 13â†’6\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            ResidualBlock(64, 128),\n",
    "            ResidualBlock(128, 128)\n",
    "        )  # 6Ã—6\n",
    "\n",
    "        # å¤šå°ºåº¦æ± åŒ–\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.mid_pool    = nn.AdaptiveAvgPool2d((2,2))\n",
    "        self.large_pool    = nn.AdaptiveAvgPool2d((3,3))\n",
    "\n",
    "        total_dim = 128*1*1 + 128*2*2 + 128*3*3\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(total_dim, out_dim*2),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(out_dim*2, out_dim),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        g = self.global_pool(x).contiguous().reshape(x.size(0), -1)\n",
    "        m = self.mid_pool(x).contiguous().reshape(x.size(0), -1)\n",
    "        l = self.large_pool(x).contiguous().reshape(x.size(0), -1)\n",
    "\n",
    "        return self.fc(torch.cat([g, m, l], dim=1)).contiguous()\n",
    "\n",
    "\n",
    "\n",
    "class VisionMLP_MultiTask(nn.Module):\n",
    "    \"\"\"æ•´é«”å¤šä»»å‹™æ¨¡å‹ï¼šèåˆ tile + subtile + centerï¼Œä½¿ç”¨å‹•æ…‹æ¬Šé‡èåˆ\"\"\"\n",
    "    def __init__(self, tile_dim=128, subtile_dim=64, output_dim=35, negative_slope=0.01):\n",
    "        super().__init__()\n",
    "        self.encoder_tile    = DeepTileEncoder(tile_dim)\n",
    "        self.encoder_subtile = SubtileEncoder(subtile_dim)\n",
    "        self.encoder_center  = CenterSubtileEncoder(subtile_dim)\n",
    "\n",
    "        # èåˆå±¤ï¼šè¼¸å…¥ä¸‰å€‹åˆ†æ”¯çš„ concatï¼Œè¼¸å‡ºä¸‰å€‹ gate\n",
    "        self.gate_fc = nn.Sequential(\n",
    "            nn.Linear(tile_dim + subtile_dim + subtile_dim, 64),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Linear(64, 3),  # å° tile, subtile, center åˆ†æ”¯è¼¸å‡º gate\n",
    "            nn.Softmax(dim=1)  # è½‰æˆæ¬Šé‡\n",
    "        )\n",
    "\n",
    "        # è¼¸å‡º decoderï¼šè¼¸å…¥ç‚º tile_dim (å› ç‚ºèåˆå¾Œåªå‰©ä¸€å€‹ vector)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(tile_dim, 256),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, tile, subtiles):\n",
    "        tile = tile.contiguous()\n",
    "        subtiles = subtiles.contiguous()\n",
    "        center = subtiles[:, 4]\n",
    "\n",
    "        f_tile = self.encoder_tile(tile)         # [B, tile_dim]\n",
    "        f_sub  = self.encoder_subtile(subtiles)  # [B, subtile_dim]\n",
    "        f_center = self.encoder_center(center)   # [B, subtile_dim]\n",
    "\n",
    "        # æ‹¼æ¥ä¸‰å€‹åˆ†æ”¯åš gating\n",
    "        features_cat = torch.cat([f_tile, f_sub, f_center], dim=1)  # [B, tile+sub+center]\n",
    "        gates = self.gate_fc(features_cat)  # [B, 3]\n",
    "\n",
    "        # å°ä¸‰å€‹åˆ†æ”¯åš weighted sum\n",
    "        f_fused = (\n",
    "            gates[:, 0:1] * f_tile + \n",
    "            gates[:, 1:2] * f_sub + \n",
    "            gates[:, 2:3] * f_center\n",
    "        )  # [B, tile_dim]ï¼ˆæ³¨æ„ï¼šéœ€ä¿è­‰ f_tile == f_sub == f_center çš„ç¶­åº¦ï¼‰\n",
    "\n",
    "        return self.decoder(f_fused)\n",
    "    \n",
    "# class VisionMLP_MultiTask(nn.Module):\n",
    "#     \"\"\"æ•´é«”å¤šä»»å‹™æ¨¡å‹ï¼šèåˆ tile + subtile + center + position ç‰¹å¾µ\"\"\"\n",
    "#     def __init__(self, tile_dim=128, subtile_dim=128, output_dim=35, negative_slope=0.01):\n",
    "#         super().__init__()\n",
    "#         self.encoder_tile    = DeepTileEncoder(tile_dim)\n",
    "#         self.encoder_subtile = SubtileEncoder(subtile_dim)\n",
    "#         self.encoder_center  = CenterSubtileEncoder(subtile_dim)\n",
    "\n",
    "#         self.feature_dim = tile_dim + subtile_dim + subtile_dim # +2 for position(x,y)\n",
    "\n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(self.feature_dim, 256),\n",
    "#             nn.LeakyReLU(negative_slope),\n",
    "#             nn.Dropout(0.1),\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.LeakyReLU(negative_slope),\n",
    "#             nn.Dropout(0.1),\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.LeakyReLU(negative_slope),\n",
    "#             nn.Dropout(0.1),\n",
    "#             nn.Linear(64, output_dim),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, tile, subtiles):\n",
    "#         tile = tile.contiguous()\n",
    "#         subtiles = subtiles.contiguous()\n",
    "#         center = subtiles[:, 4]\n",
    "\n",
    "#         f_tile = self.encoder_tile(tile)         # [B, tile_dim]\n",
    "#         f_sub  = self.encoder_subtile(subtiles)  # [B, subtile_dim]\n",
    "#         f_center = self.encoder_center(center)   # [B, subtile_dim]\n",
    "\n",
    "#         # æ‹¼æ¥ç‰¹å¾µå‘é‡èˆ‡åº§æ¨™\n",
    "#         features_cat = torch.cat([f_tile, f_sub, f_center], dim=1)  # [B, tile+sub+center+2]\n",
    "\n",
    "#         return self.decoder(features_cat)\n",
    "\n",
    "\n",
    "# ç”¨æ³•ç¤ºä¾‹\n",
    "model = VisionMLP_MultiTask(tile_dim=128, subtile_dim=128, output_dim=35)\n",
    "\n",
    "\n",
    "# â€”â€” 5) ç¡®ä¿åªæœ‰ decoder å¯è®­ç»ƒ â€”â€”  \n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total     = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Trainable / total params = {trainable:,} / {total:,}\")\n",
    "\n",
    "\n",
    "device   = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('output_folder/rank-spot/realign/whole_worflow/s_m_l/filtered_directly_rank/k-fold_mix/realign_all/Macenko_masked/results/model_epoch022.pt', map_location=\"cpu\"))\n",
    "model.to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same in multiple .pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/import_data.py:251: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d = torch.load(fpath, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded keys: dict_keys(['subtiles', 'label', 'source_idx', 'slide_idx', 'tile', 'position'])\n",
      "Samples: 8348\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import inspect\n",
    "from python_scripts.import_data import load_all_tile_data\n",
    "\n",
    "# ç”¨æ³•ç¯„ä¾‹\n",
    "#folder = \"dataset/spot-rank/version-3/only_tile_sub/original_train\"\n",
    "folder = \"dataset/spot-rank/filtered_directly_rank/masked/realign/Macenko_masked/filtered/train_data/\"\n",
    "\n",
    "grouped_data = load_all_tile_data( \n",
    "        folder_path=folder,\n",
    "        model=model,\n",
    "        fraction=1,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # grouped_data ç¾åœ¨åªæœƒæœ‰ model.forward() éœ€è¦çš„ keyï¼Œ\n",
    "    # åƒ ['tile','subtiles','neighbors','norm_coord','node_feat','adj_list','edge_feat','label','source_idx']\n",
    "print(\"Loaded keys:\", grouped_data.keys())\n",
    "print(\"Samples:\", len(next(iter(grouped_data.values()))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Checking dataset sample: 0\n",
      "ğŸ“ tile shape: torch.Size([3, 78, 78]) | dtype: torch.float32 | min: 0.157, max: 1.000, mean: 0.680, std: 0.142\n",
      "ğŸ“ subtiles shape: torch.Size([9, 3, 26, 26]) | dtype: torch.float32 | min: 0.157, max: 1.000, mean: 0.680, std: 0.142\n",
      "ğŸ“ label shape: torch.Size([35]) | dtype: torch.float32 | min: 1.000, max: 35.000, mean: 18.000, std: 10.247\n",
      "--- label head (å‰ 5 å€‹å…ƒç´ ):\n",
      "tensor([12., 24., 18.,  6., 30.])\n",
      "ğŸ“ source_idx shape: torch.Size([]) | dtype: torch.int64 | min: 0.000, max: 0.000, mean: 0.000, std: nan\n",
      "--- source_idx è³‡æ–™ç‚ºç´”é‡: tensor(0)\n",
      "ğŸ“ position shape: torch.Size([2]) | dtype: torch.float32 | min: 0.171, max: 0.632, mean: 0.401, std: 0.326\n",
      "--- position head (å‰ 5 å€‹å…ƒç´ ):\n",
      "tensor([0.6318, 0.1707])\n",
      "âœ… All checks passed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_14152/3062057575.py:79: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/miniforge3/conda-bld/libtorch_1744320376245/work/aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
      "  std = tensor_float.std().item()\n"
     ]
    }
   ],
   "source": [
    "from python_scripts.import_data import convert_item, get_model_inputs\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import inspect\n",
    "import numpy as np\n",
    "\n",
    "class importDataset(Dataset):\n",
    "    def __init__(self, data_dict, model, image_keys=None, transform=None, print_sig=False):\n",
    "        self.data = data_dict\n",
    "        self.image_keys = set(image_keys) if image_keys is not None else set()\n",
    "        self.transform = transform if transform is not None else lambda x: x\n",
    "        self.forward_keys = list(get_model_inputs(model, print_sig=print_sig).parameters.keys())\n",
    "\n",
    "        expected_length = None\n",
    "        for key, value in self.data.items():\n",
    "            if expected_length is None:\n",
    "                expected_length = len(value)\n",
    "            if len(value) != expected_length:\n",
    "                raise ValueError(f\"è³‡æ–™æ¬„ä½ '{key}' çš„é•·åº¦ ({len(value)}) èˆ‡é æœŸ ({expected_length}) ä¸ä¸€è‡´ã€‚\")\n",
    "\n",
    "        for key in self.forward_keys:\n",
    "            if key not in self.data:\n",
    "                raise ValueError(f\"data_dict ç¼ºå°‘æ¨¡å‹ forward æ‰€éœ€æ¬„ä½: '{key}'ã€‚ç›®å‰å¯ç”¨çš„æ¬„ä½: {list(self.data.keys())}\")\n",
    "        if \"label\" not in self.data:\n",
    "            raise ValueError(f\"data_dict å¿…é ˆåŒ…å« 'label' æ¬„ä½ã€‚å¯ç”¨çš„æ¬„ä½: {list(self.data.keys())}\")\n",
    "        if \"source_idx\" not in self.data:\n",
    "            raise ValueError(\"data_dict å¿…é ˆåŒ…å« 'source_idx' æ¬„ä½ï¼Œç”¨æ–¼ trace åŸå§‹é †åºå°æ‡‰ã€‚\")\n",
    "        if \"position\" not in self.data:\n",
    "            raise ValueError(\"data_dict å¿…é ˆåŒ…å« 'position' æ¬„ä½ï¼Œç”¨æ–¼ trace åŸå§‹é †åºå°æ‡‰ã€‚\")\n",
    "    def __len__(self):\n",
    "        return len(next(iter(self.data.values())))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {}\n",
    "        for key in self.forward_keys:\n",
    "            value = self.data[key][idx]\n",
    "            value = self.transform(value)\n",
    "            value = convert_item(value, is_image=(key in self.image_keys))\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                value = value.float()\n",
    "            sample[key] = value\n",
    "\n",
    "        label = self.transform(self.data[\"label\"][idx])\n",
    "        label = convert_item(label, is_image=False)\n",
    "        if isinstance(label, torch.Tensor):\n",
    "            label = label.float()\n",
    "        sample[\"label\"] = label\n",
    "\n",
    "        # åŠ å…¥ source_idx\n",
    "        source_idx = self.data[\"source_idx\"][idx]\n",
    "        sample[\"source_idx\"] = torch.tensor(source_idx, dtype=torch.long)\n",
    "        # åŠ å…¥ position ï¼ˆå‡è®¾ data_dict ä¸­ 'position' æ˜¯ (x, y) æˆ– [x, y]ï¼‰\n",
    "        pos = self.data[\"position\"][idx]\n",
    "        sample[\"position\"] = torch.tensor(pos, dtype=torch.float)\n",
    "        return sample\n",
    "    def check_item(self, idx=0, num_lines=5):\n",
    "        expected_keys = self.forward_keys + ['label', 'source_idx', 'position']\n",
    "        sample = self[idx]\n",
    "        print(f\"ğŸ” Checking dataset sample: {idx}\")\n",
    "        for key in expected_keys:\n",
    "            if key not in sample:\n",
    "                print(f\"âŒ è³‡æ–™ä¸­ç¼ºå°‘ key: {key}\")\n",
    "                continue\n",
    "            tensor = sample[key]\n",
    "            if isinstance(tensor, torch.Tensor):\n",
    "                try:\n",
    "                    shape = tensor.shape\n",
    "                except Exception:\n",
    "                    shape = \"N/A\"\n",
    "                dtype = tensor.dtype if hasattr(tensor, \"dtype\") else \"N/A\"\n",
    "                output_str = f\"ğŸ“ {key} shape: {shape} | dtype: {dtype}\"\n",
    "                if tensor.numel() > 0:\n",
    "                    try:\n",
    "                        tensor_float = tensor.float()\n",
    "                        mn = tensor_float.min().item()\n",
    "                        mx = tensor_float.max().item()\n",
    "                        mean = tensor_float.mean().item()\n",
    "                        std = tensor_float.std().item()\n",
    "                        output_str += f\" | min: {mn:.3f}, max: {mx:.3f}, mean: {mean:.3f}, std: {std:.3f}\"\n",
    "                    except Exception:\n",
    "                        output_str += \" | ç„¡æ³•è¨ˆç®—çµ±è¨ˆæ•¸æ“š\"\n",
    "                print(output_str)\n",
    "                if key not in self.image_keys:\n",
    "                    if tensor.ndim == 0:\n",
    "                        print(f\"--- {key} è³‡æ–™ç‚ºç´”é‡:\", tensor)\n",
    "                    elif tensor.ndim == 1:\n",
    "                        print(f\"--- {key} head (å‰ {num_lines} å€‹å…ƒç´ ):\")\n",
    "                        print(tensor[:num_lines])\n",
    "                    else:\n",
    "                        print(f\"--- {key} head (å‰ {num_lines} åˆ—):\")\n",
    "                        print(tensor[:num_lines])\n",
    "            else:\n",
    "                # å¦‚æœ position å­˜çš„æ˜¯ list/tuple/etcï¼Œä¹Ÿä¼šèµ°è¿™é‡Œ\n",
    "                print(f\"ğŸ“ {key} (é tensor è³‡æ–™):\", tensor)\n",
    "        print(\"âœ… All checks passed!\")\n",
    "\n",
    "\n",
    "full_dataset = importDataset(grouped_data, model,\n",
    "                             image_keys=['tile','subtiles'],\n",
    "                             transform=lambda x: x)\n",
    "\n",
    "full_dataset.check_item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage.feature.texture import graycomatrix, graycoprops\n",
    "from skimage.filters import sobel\n",
    "import pywt\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === å·¥å…·å‡½æ•¸ ===\n",
    "def compute_ae_reconstruction_loss(ae_model, dataloader, device, ae_type):\n",
    "    ae_model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Computing AE recon loss\"):\n",
    "            tile = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "            recon = ae_model(tile, subtiles)\n",
    "\n",
    "            if ae_type == 'center':\n",
    "                target = subtiles[:, 4]\n",
    "            else:\n",
    "                target = subtiles\n",
    "\n",
    "            loss = F.mse_loss(recon, target, reduction='none')\n",
    "            loss = loss.view(loss.shape[0], -1).mean(dim=1)\n",
    "            losses.append(loss.cpu().numpy())\n",
    "    return np.concatenate(losses)\n",
    "\n",
    "def compute_latent_stats(latents):\n",
    "    return np.concatenate([\n",
    "        latents.mean(axis=1, keepdims=True),\n",
    "        latents.std(axis=1, keepdims=True),\n",
    "        latents.min(axis=1, keepdims=True),\n",
    "        latents.max(axis=1, keepdims=True),\n",
    "    ], axis=1)\n",
    "\n",
    "\n",
    "# === Loading Label Cluster Map ===\n",
    "def load_label_cluster_map(filepath=\"dataset/label_cluster_map.pkl\", use_clusters=\"both\"):\n",
    "    cluster_map = joblib.load(filepath)\n",
    "    # keys are 'label_cluster_map_4', 'label_cluster_map_20'\n",
    "    if use_clusters == \"4\":\n",
    "        return cluster_map['label_cluster_map_4']\n",
    "    elif use_clusters == \"20\":\n",
    "        return cluster_map['label_cluster_map_20']\n",
    "    elif use_clusters == \"both\":\n",
    "        return {\n",
    "            '4': cluster_map['label_cluster_map_4'],\n",
    "            '20': cluster_map['label_cluster_map_20']\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"Invalid cluster selection. Choose '4', '20', or 'both'.\")\n",
    "\n",
    "# === Helper Functions ===\n",
    "def choose_best_n_clusters(X, min_k=35, max_k=38, random_state=42):\n",
    "    best_k, best_score = min_k, -np.inf\n",
    "    for k in range(min_k, max_k + 1):\n",
    "        labels = KMeans(n_clusters=k, random_state=random_state).fit_predict(X)\n",
    "        score = silhouette_score(X, labels)\n",
    "        print(f\"Silhouette score for k={k}: {score:.4f}\")\n",
    "        if score > best_score:\n",
    "            best_score, best_k = score, k\n",
    "    print(f\"Selected best k={best_k} (score={best_score:.4f})\")\n",
    "    return best_k\n",
    "\n",
    "\n",
    "def compute_cluster_summary_stats(matrix, cluster_ids):\n",
    "    \"\"\"\n",
    "    matrix: (n_samples, n_dims)\n",
    "    cluster_ids: length n_samples, æ¯å€‹ sample æ‰€å±¬çš„ç¾¤ç·¨è™Ÿ\n",
    "    å›å‚³ shape=(n_samples, 4)ï¼š\n",
    "      [mean, std, min, max] æ˜¯è©² sample æ‰€å±¬ç¾¤è£¡ï¼Œæ‰€æœ‰ matrix å€¼çš„å…¨å±€çµ±è¨ˆ\n",
    "    \"\"\"\n",
    "    stats = np.zeros((matrix.shape[0], 4), dtype=float)\n",
    "    for c in np.unique(cluster_ids):\n",
    "        mask = (cluster_ids == c)\n",
    "        values = matrix[mask]            # shape=(n_c, n_dims)\n",
    "        flat = values.flatten()         # æŠŠç¶­åº¦æ”¤å¹³æˆä¸€ç¶­\n",
    "        summary = [\n",
    "            flat.mean(),\n",
    "            flat.std(),\n",
    "            flat.min(),\n",
    "            flat.max(),\n",
    "        ]\n",
    "        stats[mask] = summary           # åŒä¸€ç¾¤è£¡çš„æ‰€æœ‰ sample éƒ½ç”¨åŒä¸€çµ„ summary\n",
    "    return stats\n",
    "\n",
    "\n",
    "def compute_feature_cluster_stats(matrix, feature_cluster_ids):\n",
    "    \"\"\"\n",
    "    Given matrix shape (n_samples, n_features) and feature_cluster_ids length n_features,\n",
    "    compute per-sample [mean, std, min, max] within each feature-cluster.\n",
    "    Returns array shape (n_samples, n_clusters*4)\n",
    "    \"\"\"\n",
    "    unique_clusters = np.unique(feature_cluster_ids)\n",
    "    stats_per_cluster = []\n",
    "    for c in unique_clusters:\n",
    "        mask = (feature_cluster_ids == c)\n",
    "        cluster_vals = matrix[:, mask]  # shape (n_samples, n_feats_in_cluster)\n",
    "        mean = cluster_vals.mean(axis=1, keepdims=True)\n",
    "        std  = cluster_vals.std(axis=1, keepdims=True)\n",
    "        mn   = cluster_vals.min(axis=1, keepdims=True)\n",
    "        mx   = cluster_vals.max(axis=1, keepdims=True)\n",
    "        stats_per_cluster.append(np.hstack([mean, std, mn, mx]))\n",
    "    return np.hstack(stats_per_cluster)\n",
    "\n",
    "\n",
    "def compute_rgb_stats(dataset):\n",
    "    stats = []\n",
    "    for i in range(len(dataset)):\n",
    "        sub = dataset[i]['subtiles'][4].numpy()\n",
    "        ch_stats = []\n",
    "        for ch in range(sub.shape[0]):\n",
    "            vals = sub[ch]\n",
    "            ch_stats += [vals.mean(), vals.std(), vals.min(), vals.max()]\n",
    "        stats.append(ch_stats)\n",
    "    return np.array(stats)\n",
    "\n",
    "\n",
    "def compute_rgb_cluster_stats(dataset, cluster_ids):\n",
    "    unique = np.unique(cluster_ids)\n",
    "    stats_dict = {}\n",
    "    for c in unique:\n",
    "        idxs = np.where(cluster_ids == c)[0]\n",
    "        acc = []\n",
    "        for i in idxs:\n",
    "            acc.append(dataset[i]['subtiles'][4].numpy())\n",
    "        arr = np.stack(acc)\n",
    "        ch_stats = []\n",
    "        for ch in range(arr.shape[1]):\n",
    "            flat = arr[:, ch].flatten()\n",
    "            ch_stats += [flat.mean(), flat.std(), flat.min(), flat.max()]\n",
    "        stats_dict[c] = np.array(ch_stats)\n",
    "    return np.vstack([stats_dict[c] for c in cluster_ids])\n",
    "# === RGB Statistics Extensions ===\n",
    "# center subtile (index 4) already in compute_rgb_stats\n",
    "\n",
    "def compute_all_subtiles_rgb_stats(dataset):\n",
    "    \"\"\"\n",
    "    æ¯å€‹ sample çš„æ‰€æœ‰ subtiles (0-8) ä¸­ï¼Œæ¯å€‹ channel çš„ mean/std/min/maxï¼Œconcat å½¢æˆ (n, 9*4*C)\n",
    "    \"\"\"\n",
    "    stats = []\n",
    "    for i in range(len(dataset)):\n",
    "        subs = dataset[i]['subtiles'].numpy()  # shape (9, C, H, W)\n",
    "        sample_stats = []\n",
    "        for idx in range(subs.shape[0]):\n",
    "            for ch in range(subs.shape[1]):\n",
    "                vals = subs[idx, ch]\n",
    "                sample_stats += [vals.mean(), vals.std(), vals.min(), vals.max()]\n",
    "        stats.append(sample_stats)\n",
    "    return np.array(stats)\n",
    "\n",
    "def compute_subtiles_except_center_rgb_stats(dataset):\n",
    "    \"\"\"\n",
    "    æ¯å€‹ sample çš„ subtiles é™¤äº† center (index 4) å¤–ï¼Œå…¶é¤˜ 8 å¡Šåˆä½µå¾Œï¼Œæ¯ channel çš„ mean/std/min/maxï¼Œshape (n, C*4)\n",
    "    \"\"\"\n",
    "    stats = []\n",
    "    for i in range(len(dataset)):\n",
    "        subs = dataset[i]['subtiles'].numpy()  # (9, C, H, W)\n",
    "        exclude = np.concatenate([subs[:4], subs[5:]], axis=0)  # (8, C, H, W)\n",
    "        sample_stats = []\n",
    "        for ch in range(exclude.shape[1]):\n",
    "            vals = exclude[:, ch].flatten()\n",
    "            sample_stats += [vals.mean(), vals.std(), vals.min(), vals.max()]\n",
    "        stats.append(sample_stats)\n",
    "    return np.array(stats)\n",
    "\n",
    "def compute_tile_rgb_stats(dataset):\n",
    "    \"\"\"\n",
    "    æ¯å€‹ sample çš„ tile (æ•´å¼µåœ–)ï¼Œæ¯ channel çš„ mean/std/min/maxï¼Œshape (n, C*4)\n",
    "    \"\"\"\n",
    "    stats = []\n",
    "    for i in range(len(dataset)):\n",
    "        tile = dataset[i]['tile'].numpy()  # shape (C, H, W)\n",
    "        sample_stats = []\n",
    "        for ch in range(tile.shape[0]):\n",
    "            vals = tile[ch]\n",
    "            sample_stats += [vals.mean(), vals.std(), vals.min(), vals.max()]\n",
    "        stats.append(sample_stats)\n",
    "    return np.array(stats)\n",
    "\n",
    "# === Texture & Pattern Features ===\n",
    "\n",
    "\n",
    "def compute_wavelet_stats(dataset, wavelet='db1', level=2):\n",
    "    feats = []\n",
    "    for i in range(len(dataset)):\n",
    "        patch = dataset[i]['subtiles'][4].numpy()[0]\n",
    "        coeffs = pywt.wavedec2(patch, wavelet=wavelet, level=level)\n",
    "        sample = []\n",
    "        for arr in coeffs:\n",
    "            if isinstance(arr, tuple):\n",
    "                for sub in arr:\n",
    "                    sample += [sub.mean(), sub.std()]\n",
    "            else:\n",
    "                sample += [arr.mean(), arr.std()]\n",
    "        feats.append(sample)\n",
    "    return np.array(feats)\n",
    "\n",
    "\n",
    "def compute_sobel_stats(dataset):\n",
    "    feats = []\n",
    "    for i in range(len(dataset)):\n",
    "        gray = dataset[i]['tile'].numpy().mean(axis=0)\n",
    "        edge = sobel(gray)\n",
    "        feats.append([edge.mean(), edge.std(), edge.min(), edge.max()])\n",
    "    return np.array(feats)\n",
    "\n",
    "# === Texture & Pattern Features ===\n",
    "\n",
    "def compute_hsv_stats(dataset):\n",
    "    feats = []\n",
    "    from skimage.color import rgb2hsv\n",
    "    for i in range(len(dataset)):\n",
    "        sub = dataset[i]['subtiles'][4].numpy()  # (C, H, W)\n",
    "        img = sub[:3].transpose(1,2,0)         # (H, W, 3)\n",
    "        hsv = rgb2hsv(img)\n",
    "        sample = []\n",
    "        for ch in range(3):\n",
    "            vals = hsv[:,:,ch]\n",
    "            sample += [vals.mean(), vals.std(), vals.min(), vals.max()]\n",
    "        feats.append(sample)\n",
    "    return np.array(feats)\n",
    "\n",
    "\n",
    "def compute_color_moments(dataset):\n",
    "    feats = []\n",
    "    from scipy.stats import skew, kurtosis\n",
    "    for i in range(len(dataset)):\n",
    "        sub = dataset[i]['subtiles'][4].numpy()  # (C, H, W)\n",
    "        img = sub.transpose(1,2,0)               # (H, W, C)\n",
    "        sample = []\n",
    "        for ch in range(img.shape[2]):\n",
    "            vals = img[:,:,ch].ravel()\n",
    "            sample += [vals.mean(), vals.std(), skew(vals), kurtosis(vals)]\n",
    "        feats.append(sample)\n",
    "    return np.array(feats)\n",
    "\n",
    "\n",
    "# === Subtile Contrast Features ===\n",
    "\n",
    "def compute_subtile_contrast_stats(dataset, eps=1e-7):\n",
    "    \"\"\"\n",
    "    Compute contrast between center subtile and surrounding subtiles:\n",
    "    For each sample and each channel, calculate:\n",
    "      diff = center_mean - surround_mean\n",
    "      ratio = center_mean / (surround_mean + eps)\n",
    "    Returns array (n_samples, C*2)\n",
    "    \"\"\"\n",
    "    stats = []\n",
    "    for i in range(len(dataset)):\n",
    "        subs = dataset[i]['subtiles'].numpy()  # (9, C, H, W)\n",
    "        center = subs[4]  # (C, H, W)\n",
    "        surround = np.concatenate([subs[:4], subs[5:]], axis=0)  # (8, C, H, W)\n",
    "        center_mean = center.reshape(center.shape[0], -1).mean(axis=1)\n",
    "        surround_mean = surround.reshape(surround.shape[0], surround.shape[1], -1).mean(axis=2).mean(axis=0)\n",
    "        diff = center_mean - surround_mean\n",
    "        ratio = center_mean / (surround_mean + eps)\n",
    "        stats.append(np.hstack([diff, ratio]))\n",
    "    return np.array(stats)\n",
    "\n",
    "# === H&E Color Deconvolution Features ===\n",
    "def compute_he_stats(dataset):\n",
    "    \"\"\"\n",
    "    Compute H&E stain intensity stats from center subtile RGB (3 channels):\n",
    "    Returns array (n_samples, 8): [H_mean, H_std, H_min, H_max, E_mean, E_std, E_min, E_max]\n",
    "    \"\"\"\n",
    "    from skimage.color import separate_stains, hed_from_rgb\n",
    "    stats = []\n",
    "    for i in range(len(dataset)):\n",
    "        sub = dataset[i]['subtiles'][4].numpy()  # (C, H, W)\n",
    "        # assume first 3 channels are RGB\n",
    "        rgb = sub[:3].transpose(1,2,0)\n",
    "        hed = separate_stains(rgb, hed_from_rgb)\n",
    "        h = hed[:,:,0]\n",
    "        e = hed[:,:,1]\n",
    "        sample = [\n",
    "            h.mean(), h.std(), h.min(), h.max(),\n",
    "            e.mean(), e.std(), e.min(), e.max()\n",
    "        ]\n",
    "        stats.append(sample)\n",
    "    return np.array(stats)\n",
    "\n",
    "\n",
    "# === Sliding Window Std Features ===\n",
    "\n",
    "def compute_sliding_std_stats(dataset, window_size=3, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Compute local standard deviation within a sliding window of given size on center subtile.\n",
    "    Returns array shape (n_samples, C*2) with mean and max of local std for each channel.\n",
    "    \"\"\"\n",
    "    from scipy.ndimage import uniform_filter\n",
    "\n",
    "    stats = []\n",
    "    for i in range(len(dataset)):\n",
    "        sub = dataset[i]['subtiles'][4].numpy()  # (C, H, W)\n",
    "        sample = []\n",
    "        for ch in range(sub.shape[0]):\n",
    "            arr = sub[ch]\n",
    "            # compute local mean and mean of squares\n",
    "            mean = uniform_filter(arr, size=window_size)\n",
    "            mean_sq = uniform_filter(arr * arr, size=window_size)\n",
    "            local_std = np.sqrt(np.maximum(mean_sq - mean * mean, 0))\n",
    "            sample += [local_std.mean(), local_std.max()]\n",
    "        stats.append(sample)\n",
    "    return np.array(stats)\n",
    "\n",
    "\n",
    "# === Distribution-based Features ===\n",
    "\n",
    "def compute_entropy(oof_preds, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Compute Shannon entropy for each sample's OOF prediction distribution.\n",
    "    oof_preds: (n_samples, C)\n",
    "    returns: array shape (n_samples, 1)\n",
    "    \"\"\"\n",
    "    # normalize to sum 1\n",
    "    probs = oof_preds / (oof_preds.sum(axis=1, keepdims=True) + eps)\n",
    "    ent = -np.sum(probs * np.log(probs + eps), axis=1, keepdims=True)\n",
    "    return ent\n",
    "\n",
    "\n",
    "def compute_top2_diff(oof_preds):\n",
    "    \"\"\"\n",
    "    Compute difference between the top-1 and top-2 predicted values per sample.\n",
    "    returns: array shape (n_samples, 1)\n",
    "    \"\"\"\n",
    "    # sort descending\n",
    "    sorted_preds = -np.sort(-oof_preds, axis=1)\n",
    "    diff = sorted_preds[:, 0] - sorted_preds[:, 1]\n",
    "    return diff.reshape(-1, 1)\n",
    "\n",
    "# === Pairwise Differences for All Cell Types ===\n",
    "from itertools import combinations\n",
    "\n",
    "def compute_pairwise_diff(oof_preds):\n",
    "    \"\"\"\n",
    "    Compute raw differences for every pair of cell-type predictions.\n",
    "    For each sample, returns array of length C*(C-1)/2 in order of (i<j).\n",
    "    \"\"\"\n",
    "    n_samples, C = oof_preds.shape\n",
    "    # generate list of index pairs i<j\n",
    "    idx_pairs = list(combinations(range(C), 2))\n",
    "    # stack differences for each pair\n",
    "    diffs = np.stack([oof_preds[:, i] - oof_preds[:, j] for i, j in idx_pairs], axis=1)\n",
    "    return diffs\n",
    "\n",
    "def compute_dispersion(oof_preds):\n",
    "    \"\"\"\n",
    "    Compute dispersion metric (Gini impurity) or std across cell-type predictions.\n",
    "    returns: array shape (n_samples, 1)\n",
    "    \"\"\"\n",
    "    # Gini impurity: 1 - sum(p_i^2)\n",
    "    probs = oof_preds / (oof_preds.sum(axis=1, keepdims=True) + 1e-12)\n",
    "    gini = 1 - np.sum(probs**2, axis=1)\n",
    "    return gini.reshape(-1, 1)\n",
    "\n",
    "def compute_ae_embeddings(loader, recon_model, device):\n",
    "    \"\"\"\n",
    "    Extract fused encoder embeddings from the PretrainedEncoderRegressor.\n",
    "    Returns numpy array shape (n_samples, fusion_dim).\n",
    "    \"\"\"\n",
    "    recon_model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            tiles = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "            subtiles = subtiles.contiguous()\n",
    "            tiles     = tiles.contiguous()\n",
    "            # forward up to encoder fusion\n",
    "            f_c = recon_model.enc_center(subtiles[:, 4])\n",
    "            f_n = recon_model.enc_neigh(subtiles)\n",
    "            f_t = recon_model.enc_tile(tiles)\n",
    "            fused = torch.cat([f_c, f_n, f_t], dim=1)\n",
    "            embeddings.append(fused.cpu().numpy())\n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "# === Main Function ===\n",
    "def generate_meta_features(\n",
    "    dataset,\n",
    "    oof_preds,\n",
    "    image_latents,\n",
    "    model_for_recon,\n",
    "    device,\n",
    "    ae_type,\n",
    "    label_cluster_map_path=\"dataset/label_cluster_map.pkl\",\n",
    "    use_clusters=\"both\"\n",
    "):\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "    recon_loss = compute_ae_reconstruction_loss(model_for_recon, loader, device, ae_type)\n",
    "\n",
    "    # 1-4: OOF preds, image latents, recon loss, latent stats\n",
    "    image_latent = compute_ae_embeddings(loader, model_for_recon, device)\n",
    "    latent_stats = compute_latent_stats(image_latent)\n",
    "\n",
    "    # # 6: Ground Truth Cell Expression Cluster Stats\n",
    "    label_map = load_label_cluster_map(label_cluster_map_path, use_clusters)\n",
    "    if use_clusters == \"both\":\n",
    "        stats4  = compute_feature_cluster_stats(oof_preds, label_map['4'])   # shape (n, 4*4)\n",
    "        stats20 = compute_feature_cluster_stats(oof_preds, label_map['20'])  # shape (n, 20*4)\n",
    "        gt_cluster_stats = np.hstack([stats4, stats20])  # (n, 16+80)\n",
    "    else:\n",
    "        gt_cluster_stats = compute_feature_cluster_stats(oof_preds, label_map)\n",
    "\n",
    "    # # 8: OOF pred clusters stats\n",
    "    # # æŠŠ cell ç•¶ä½œæ¨£æœ¬ä¾†ä½œç¾¤èš\n",
    "    # # best_k_cells = choose_best_n_clusters(oof_preds.T, min_k=2, max_k=6)\n",
    "    # cell_cluster_ids = KMeans(n_clusters=4, random_state=42)\\\n",
    "    #                     .fit_predict(oof_preds.T)\n",
    "    # pred_cluster_stats = compute_feature_cluster_stats(oof_preds, cell_cluster_ids)\n",
    "\n",
    "    # # 9-10: Latent clusters & summary\n",
    "    # best_k_latent = choose_best_n_clusters(image_latents, min_k=2, max_k=50)\n",
    "    # latent_ids = KMeans(n_clusters=best_k_latent, random_state=42).fit_predict(image_latents)\n",
    "    # latent_summary = compute_cluster_summary_stats(image_latents, latent_ids)  # shape = (2197, 4)\n",
    "\n",
    "    # # 11-12: AE loss clusters & summary\n",
    "    # loss_vals = recon_loss.reshape(-1,1)\n",
    "    # best_k_loss = choose_best_n_clusters(loss_vals, min_k=2, max_k=50)\n",
    "    # loss_ids = KMeans(n_clusters=best_k_loss, random_state=42).fit_predict(loss_vals)\n",
    "    # loss_summary_stats = compute_cluster_summary_stats(loss_vals, loss_ids)\n",
    "\n",
    "\n",
    "    # # 13: RGB stats\n",
    "    rgb_stats = compute_rgb_stats(dataset)\n",
    "    # æ–°å¢: æ‰€æœ‰ subtiles RGB, é™¤ center ä»¥å¤–çš„ subtiles RGB, æ•´å¼µ tile RGB\n",
    "    rgb_all_subs = compute_all_subtiles_rgb_stats(dataset)\n",
    "    rgb_except_center = compute_subtiles_except_center_rgb_stats(dataset)\n",
    "    rgb_tile = compute_tile_rgb_stats(dataset)\n",
    "    \n",
    "    # # 14-15: Cluster-level RGB stats\n",
    "    # latent_rgb_stats = compute_rgb_cluster_stats(dataset, latent_ids)\n",
    "    # loss_rgb_stats   = compute_rgb_cluster_stats(dataset, loss_ids)\n",
    "    # concatenate all features\n",
    "    \n",
    "        # è³ªåœ° & ç´‹ç†ç‰¹å¾µ\n",
    "    wavelet_feats     = compute_wavelet_stats(dataset)\n",
    "    sobel_feats       = compute_sobel_stats(dataset)\n",
    "    \n",
    "    \n",
    "    # æ–°å¢: é¡è‰²ç©ºé–“èˆ‡è‰²å½©åˆ†ä½ˆç‰¹å¾µ\n",
    "    hsv_feats         = compute_hsv_stats(dataset)\n",
    "    color_moments_feats = compute_color_moments(dataset)\n",
    "    \n",
    "    # æ–°å¢: Subtile é–“å°æ¯”ç‰¹å¾µ\n",
    "    contrast_feats    = compute_subtile_contrast_stats(dataset)\n",
    "    # æ–°å¢: H&E æŸ“è‰²æˆåˆ†å¼·åº¦ç‰¹å¾µ\n",
    "    he_feats          = compute_he_stats(dataset)\n",
    "    \n",
    "    sliding_std_stats = compute_sliding_std_stats(dataset)\n",
    "    \n",
    "    # ent = compute_entropy(oof_preds)\n",
    "    top2 = compute_top2_diff(oof_preds)\n",
    "    # dis = compute_dispersion(oof_preds)\n",
    "    \n",
    "    features = np.concatenate([\n",
    "        oof_preds,\n",
    "        image_latents,\n",
    "        image_latent,\n",
    "        recon_loss[:,None],\n",
    "        latent_stats,\n",
    "        gt_cluster_stats,\n",
    "        # pred_cluster_stats,\n",
    "        # latent_ids.reshape(-1,1),\n",
    "        # latent_summary,\n",
    "        # loss_ids.reshape(-1,1),\n",
    "        # loss_summary_stats,\n",
    "        rgb_stats,\n",
    "        # latent_rgb_stats,\n",
    "        # loss_rgb_stats\n",
    "        rgb_all_subs,\n",
    "        rgb_except_center,\n",
    "        rgb_tile,\n",
    "\n",
    "        wavelet_feats,\n",
    "        sobel_feats,\n",
    "        \n",
    "        hsv_feats,\n",
    "        color_moments_feats,\n",
    "        \n",
    "        contrast_feats,\n",
    "        he_feats,\n",
    "        sliding_std_stats,\n",
    "        \n",
    "        # ent,\n",
    "        top2,\n",
    "        # dis\n",
    "    ], axis=1)\n",
    "    print(f\"âœ… Generated meta-features with shape: {features.shape}\")\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_14152/1911585000.py:39: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(trained_model_path, map_location=device))\n",
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/pretrain_model.py:310: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ae.load_state_dict(torch.load(ae_checkpoint, map_location=\"cpu\"))\n",
      "Computing AE recon loss: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [00:11<00:00, 11.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Generated meta-features with shape: (8348, 1111)\n",
      "Training metaâ€model target 0 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 5.62928\n",
      "[200]\tvalid_0's rmse: 5.1935\n",
      "[300]\tvalid_0's rmse: 5.10812\n",
      "[400]\tvalid_0's rmse: 5.08589\n",
      "[500]\tvalid_0's rmse: 5.07978\n",
      "[600]\tvalid_0's rmse: 5.07577\n",
      "[700]\tvalid_0's rmse: 5.07662\n",
      "[800]\tvalid_0's rmse: 5.07461\n",
      "[900]\tvalid_0's rmse: 5.07512\n",
      "Early stopping, best iteration is:\n",
      "[760]\tvalid_0's rmse: 5.07203\n",
      "Training metaâ€model target 1 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 2.50659\n",
      "[200]\tvalid_0's rmse: 2.28498\n",
      "[300]\tvalid_0's rmse: 2.24173\n",
      "[400]\tvalid_0's rmse: 2.23013\n",
      "[500]\tvalid_0's rmse: 2.22742\n",
      "[600]\tvalid_0's rmse: 2.22476\n",
      "[700]\tvalid_0's rmse: 2.22518\n",
      "[800]\tvalid_0's rmse: 2.22652\n",
      "Early stopping, best iteration is:\n",
      "[630]\tvalid_0's rmse: 2.22392\n",
      "Training metaâ€model target 2 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.90722\n",
      "[200]\tvalid_0's rmse: 3.50991\n",
      "[300]\tvalid_0's rmse: 3.43278\n",
      "[400]\tvalid_0's rmse: 3.41424\n",
      "[500]\tvalid_0's rmse: 3.40599\n",
      "[600]\tvalid_0's rmse: 3.404\n",
      "[700]\tvalid_0's rmse: 3.4007\n",
      "[800]\tvalid_0's rmse: 3.40066\n",
      "[900]\tvalid_0's rmse: 3.40222\n",
      "[1000]\tvalid_0's rmse: 3.40177\n",
      "Early stopping, best iteration is:\n",
      "[821]\tvalid_0's rmse: 3.40003\n",
      "Training metaâ€model target 3 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.87697\n",
      "[200]\tvalid_0's rmse: 7.07054\n",
      "[300]\tvalid_0's rmse: 6.93512\n",
      "[400]\tvalid_0's rmse: 6.91232\n",
      "[500]\tvalid_0's rmse: 6.9071\n",
      "[600]\tvalid_0's rmse: 6.89867\n",
      "[700]\tvalid_0's rmse: 6.89215\n",
      "[800]\tvalid_0's rmse: 6.89046\n",
      "[900]\tvalid_0's rmse: 6.88435\n",
      "[1000]\tvalid_0's rmse: 6.88218\n",
      "[1100]\tvalid_0's rmse: 6.88041\n",
      "Early stopping, best iteration is:\n",
      "[965]\tvalid_0's rmse: 6.87996\n",
      "Training metaâ€model target 4 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.56609\n",
      "[200]\tvalid_0's rmse: 6.90237\n",
      "[300]\tvalid_0's rmse: 6.77326\n",
      "[400]\tvalid_0's rmse: 6.73091\n",
      "[500]\tvalid_0's rmse: 6.70357\n",
      "[600]\tvalid_0's rmse: 6.69291\n",
      "[700]\tvalid_0's rmse: 6.68477\n",
      "[800]\tvalid_0's rmse: 6.67288\n",
      "[900]\tvalid_0's rmse: 6.66559\n",
      "[1000]\tvalid_0's rmse: 6.66112\n",
      "[1100]\tvalid_0's rmse: 6.65508\n",
      "[1200]\tvalid_0's rmse: 6.64884\n",
      "[1300]\tvalid_0's rmse: 6.64436\n",
      "[1400]\tvalid_0's rmse: 6.64121\n",
      "[1500]\tvalid_0's rmse: 6.63647\n",
      "[1600]\tvalid_0's rmse: 6.63581\n",
      "[1700]\tvalid_0's rmse: 6.63668\n",
      "Early stopping, best iteration is:\n",
      "[1595]\tvalid_0's rmse: 6.6348\n",
      "Training metaâ€model target 5 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.51962\n",
      "[200]\tvalid_0's rmse: 6.75658\n",
      "[300]\tvalid_0's rmse: 6.62833\n",
      "[400]\tvalid_0's rmse: 6.60548\n",
      "[500]\tvalid_0's rmse: 6.58967\n",
      "[600]\tvalid_0's rmse: 6.58548\n",
      "[700]\tvalid_0's rmse: 6.57677\n",
      "[800]\tvalid_0's rmse: 6.57028\n",
      "[900]\tvalid_0's rmse: 6.56499\n",
      "[1000]\tvalid_0's rmse: 6.5585\n",
      "[1100]\tvalid_0's rmse: 6.55821\n",
      "[1200]\tvalid_0's rmse: 6.55353\n",
      "[1300]\tvalid_0's rmse: 6.55061\n",
      "[1400]\tvalid_0's rmse: 6.54989\n",
      "[1500]\tvalid_0's rmse: 6.54647\n",
      "[1600]\tvalid_0's rmse: 6.54648\n",
      "[1700]\tvalid_0's rmse: 6.5464\n",
      "[1800]\tvalid_0's rmse: 6.54553\n",
      "[1900]\tvalid_0's rmse: 6.54694\n",
      "Early stopping, best iteration is:\n",
      "[1786]\tvalid_0's rmse: 6.54492\n",
      "Training metaâ€model target 6 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.57117\n",
      "[200]\tvalid_0's rmse: 3.3929\n",
      "[300]\tvalid_0's rmse: 3.36007\n",
      "[400]\tvalid_0's rmse: 3.35145\n",
      "[500]\tvalid_0's rmse: 3.34754\n",
      "[600]\tvalid_0's rmse: 3.34562\n",
      "[700]\tvalid_0's rmse: 3.34475\n",
      "[800]\tvalid_0's rmse: 3.34474\n",
      "[900]\tvalid_0's rmse: 3.34623\n",
      "Early stopping, best iteration is:\n",
      "[757]\tvalid_0's rmse: 3.34358\n",
      "Training metaâ€model target 7 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 5.64936\n",
      "[200]\tvalid_0's rmse: 5.60818\n",
      "[300]\tvalid_0's rmse: 5.61569\n",
      "[400]\tvalid_0's rmse: 5.62079\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's rmse: 5.60484\n",
      "Training metaâ€model target 8 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 8.20126\n",
      "[200]\tvalid_0's rmse: 7.35111\n",
      "[300]\tvalid_0's rmse: 7.1854\n",
      "[400]\tvalid_0's rmse: 7.14574\n",
      "[500]\tvalid_0's rmse: 7.12458\n",
      "[600]\tvalid_0's rmse: 7.10594\n",
      "[700]\tvalid_0's rmse: 7.09464\n",
      "[800]\tvalid_0's rmse: 7.08607\n",
      "[900]\tvalid_0's rmse: 7.07839\n",
      "[1000]\tvalid_0's rmse: 7.07182\n",
      "[1100]\tvalid_0's rmse: 7.06809\n",
      "[1200]\tvalid_0's rmse: 7.06331\n",
      "[1300]\tvalid_0's rmse: 7.05882\n",
      "[1400]\tvalid_0's rmse: 7.058\n",
      "[1500]\tvalid_0's rmse: 7.05293\n",
      "[1600]\tvalid_0's rmse: 7.05104\n",
      "[1700]\tvalid_0's rmse: 7.04837\n",
      "[1800]\tvalid_0's rmse: 7.04528\n",
      "[1900]\tvalid_0's rmse: 7.04279\n",
      "[2000]\tvalid_0's rmse: 7.04063\n",
      "[2100]\tvalid_0's rmse: 7.03853\n",
      "[2200]\tvalid_0's rmse: 7.03899\n",
      "[2300]\tvalid_0's rmse: 7.03683\n",
      "[2400]\tvalid_0's rmse: 7.03666\n",
      "[2500]\tvalid_0's rmse: 7.03682\n",
      "Early stopping, best iteration is:\n",
      "[2362]\tvalid_0's rmse: 7.03559\n",
      "Training metaâ€model target 9 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.56198\n",
      "[200]\tvalid_0's rmse: 5.78207\n",
      "[300]\tvalid_0's rmse: 5.63304\n",
      "[400]\tvalid_0's rmse: 5.59688\n",
      "[500]\tvalid_0's rmse: 5.57503\n",
      "[600]\tvalid_0's rmse: 5.55679\n",
      "[700]\tvalid_0's rmse: 5.54878\n",
      "[800]\tvalid_0's rmse: 5.54156\n",
      "[900]\tvalid_0's rmse: 5.53117\n",
      "[1000]\tvalid_0's rmse: 5.52251\n",
      "[1100]\tvalid_0's rmse: 5.52049\n",
      "[1200]\tvalid_0's rmse: 5.51668\n",
      "[1300]\tvalid_0's rmse: 5.51751\n",
      "[1400]\tvalid_0's rmse: 5.51491\n",
      "[1500]\tvalid_0's rmse: 5.51416\n",
      "[1600]\tvalid_0's rmse: 5.51417\n",
      "Early stopping, best iteration is:\n",
      "[1447]\tvalid_0's rmse: 5.51286\n",
      "Training metaâ€model target 10 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.58335\n",
      "[200]\tvalid_0's rmse: 7.02192\n",
      "[300]\tvalid_0's rmse: 6.88899\n",
      "[400]\tvalid_0's rmse: 6.8441\n",
      "[500]\tvalid_0's rmse: 6.82416\n",
      "[600]\tvalid_0's rmse: 6.81238\n",
      "[700]\tvalid_0's rmse: 6.8078\n",
      "[800]\tvalid_0's rmse: 6.79994\n",
      "[900]\tvalid_0's rmse: 6.79479\n",
      "[1000]\tvalid_0's rmse: 6.78994\n",
      "[1100]\tvalid_0's rmse: 6.78281\n",
      "[1200]\tvalid_0's rmse: 6.77952\n",
      "[1300]\tvalid_0's rmse: 6.7778\n",
      "[1400]\tvalid_0's rmse: 6.7774\n",
      "[1500]\tvalid_0's rmse: 6.77514\n",
      "[1600]\tvalid_0's rmse: 6.7741\n",
      "Early stopping, best iteration is:\n",
      "[1440]\tvalid_0's rmse: 6.77347\n",
      "Training metaâ€model target 11 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.96525\n",
      "[200]\tvalid_0's rmse: 3.4672\n",
      "[300]\tvalid_0's rmse: 3.3631\n",
      "[400]\tvalid_0's rmse: 3.33325\n",
      "[500]\tvalid_0's rmse: 3.32589\n",
      "[600]\tvalid_0's rmse: 3.32125\n",
      "[700]\tvalid_0's rmse: 3.31957\n",
      "[800]\tvalid_0's rmse: 3.31909\n",
      "Early stopping, best iteration is:\n",
      "[656]\tvalid_0's rmse: 3.31784\n",
      "Training metaâ€model target 12 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.11302\n",
      "[200]\tvalid_0's rmse: 6.09307\n",
      "[300]\tvalid_0's rmse: 6.0933\n",
      "[400]\tvalid_0's rmse: 6.10403\n",
      "Early stopping, best iteration is:\n",
      "[254]\tvalid_0's rmse: 6.08878\n",
      "Training metaâ€model target 13 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 5.34751\n",
      "[200]\tvalid_0's rmse: 5.13353\n",
      "[300]\tvalid_0's rmse: 5.10263\n",
      "[400]\tvalid_0's rmse: 5.09773\n",
      "[500]\tvalid_0's rmse: 5.10263\n",
      "[600]\tvalid_0's rmse: 5.10973\n",
      "Early stopping, best iteration is:\n",
      "[425]\tvalid_0's rmse: 5.09702\n",
      "Training metaâ€model target 14 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 5.9574\n",
      "[200]\tvalid_0's rmse: 5.29078\n",
      "[300]\tvalid_0's rmse: 5.16759\n",
      "[400]\tvalid_0's rmse: 5.13375\n",
      "[500]\tvalid_0's rmse: 5.12102\n",
      "[600]\tvalid_0's rmse: 5.11819\n",
      "[700]\tvalid_0's rmse: 5.11568\n",
      "[800]\tvalid_0's rmse: 5.11891\n",
      "Early stopping, best iteration is:\n",
      "[680]\tvalid_0's rmse: 5.11445\n",
      "Training metaâ€model target 15 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.11763\n",
      "[200]\tvalid_0's rmse: 5.74066\n",
      "[300]\tvalid_0's rmse: 5.6546\n",
      "[400]\tvalid_0's rmse: 5.62692\n",
      "[500]\tvalid_0's rmse: 5.61239\n",
      "[600]\tvalid_0's rmse: 5.60035\n",
      "[700]\tvalid_0's rmse: 5.59657\n",
      "[800]\tvalid_0's rmse: 5.59559\n",
      "[900]\tvalid_0's rmse: 5.59167\n",
      "[1000]\tvalid_0's rmse: 5.58773\n",
      "[1100]\tvalid_0's rmse: 5.58292\n",
      "[1200]\tvalid_0's rmse: 5.58243\n",
      "[1300]\tvalid_0's rmse: 5.57973\n",
      "[1400]\tvalid_0's rmse: 5.57664\n",
      "[1500]\tvalid_0's rmse: 5.57663\n",
      "[1600]\tvalid_0's rmse: 5.57734\n",
      "[1700]\tvalid_0's rmse: 5.57703\n",
      "Early stopping, best iteration is:\n",
      "[1503]\tvalid_0's rmse: 5.57633\n",
      "Training metaâ€model target 16 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.82283\n",
      "[200]\tvalid_0's rmse: 6.09639\n",
      "[300]\tvalid_0's rmse: 5.92526\n",
      "[400]\tvalid_0's rmse: 5.88245\n",
      "[500]\tvalid_0's rmse: 5.85867\n",
      "[600]\tvalid_0's rmse: 5.8489\n",
      "[700]\tvalid_0's rmse: 5.84444\n",
      "[800]\tvalid_0's rmse: 5.84011\n",
      "[900]\tvalid_0's rmse: 5.83652\n",
      "[1000]\tvalid_0's rmse: 5.83316\n",
      "[1100]\tvalid_0's rmse: 5.83245\n",
      "[1200]\tvalid_0's rmse: 5.82957\n",
      "[1300]\tvalid_0's rmse: 5.82576\n",
      "[1400]\tvalid_0's rmse: 5.82429\n",
      "[1500]\tvalid_0's rmse: 5.82441\n",
      "[1600]\tvalid_0's rmse: 5.82219\n",
      "[1700]\tvalid_0's rmse: 5.82158\n",
      "[1800]\tvalid_0's rmse: 5.81956\n",
      "[1900]\tvalid_0's rmse: 5.81823\n",
      "[2000]\tvalid_0's rmse: 5.819\n",
      "[2100]\tvalid_0's rmse: 5.81768\n",
      "[2200]\tvalid_0's rmse: 5.81677\n",
      "[2300]\tvalid_0's rmse: 5.81795\n",
      "Early stopping, best iteration is:\n",
      "[2188]\tvalid_0's rmse: 5.81633\n",
      "Training metaâ€model target 17 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.7024\n",
      "[200]\tvalid_0's rmse: 3.27567\n",
      "[300]\tvalid_0's rmse: 3.19361\n",
      "[400]\tvalid_0's rmse: 3.17335\n",
      "[500]\tvalid_0's rmse: 3.16505\n",
      "[600]\tvalid_0's rmse: 3.16274\n",
      "[700]\tvalid_0's rmse: 3.15935\n",
      "[800]\tvalid_0's rmse: 3.15496\n",
      "[900]\tvalid_0's rmse: 3.15477\n",
      "[1000]\tvalid_0's rmse: 3.15346\n",
      "[1100]\tvalid_0's rmse: 3.15278\n",
      "[1200]\tvalid_0's rmse: 3.15243\n",
      "[1300]\tvalid_0's rmse: 3.15271\n",
      "[1400]\tvalid_0's rmse: 3.1514\n",
      "[1500]\tvalid_0's rmse: 3.1513\n",
      "[1600]\tvalid_0's rmse: 3.15112\n",
      "[1700]\tvalid_0's rmse: 3.15106\n",
      "[1800]\tvalid_0's rmse: 3.15075\n",
      "Early stopping, best iteration is:\n",
      "[1621]\tvalid_0's rmse: 3.15041\n",
      "Training metaâ€model target 18 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.16375\n",
      "[200]\tvalid_0's rmse: 6.92752\n",
      "[300]\tvalid_0's rmse: 6.89158\n",
      "[400]\tvalid_0's rmse: 6.88595\n",
      "[500]\tvalid_0's rmse: 6.88398\n",
      "[600]\tvalid_0's rmse: 6.88651\n",
      "Early stopping, best iteration is:\n",
      "[464]\tvalid_0's rmse: 6.88202\n",
      "Training metaâ€model target 19 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 4.90648\n",
      "[200]\tvalid_0's rmse: 4.72389\n",
      "[300]\tvalid_0's rmse: 4.68299\n",
      "[400]\tvalid_0's rmse: 4.67237\n",
      "[500]\tvalid_0's rmse: 4.66743\n",
      "[600]\tvalid_0's rmse: 4.66336\n",
      "[700]\tvalid_0's rmse: 4.66148\n",
      "[800]\tvalid_0's rmse: 4.65852\n",
      "[900]\tvalid_0's rmse: 4.65698\n",
      "[1000]\tvalid_0's rmse: 4.65393\n",
      "[1100]\tvalid_0's rmse: 4.65492\n",
      "Early stopping, best iteration is:\n",
      "[981]\tvalid_0's rmse: 4.65265\n",
      "Training metaâ€model target 20 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.40041\n",
      "[200]\tvalid_0's rmse: 6.04834\n",
      "[300]\tvalid_0's rmse: 5.98503\n",
      "[400]\tvalid_0's rmse: 5.97331\n",
      "[500]\tvalid_0's rmse: 5.97575\n",
      "[600]\tvalid_0's rmse: 5.97561\n",
      "Early stopping, best iteration is:\n",
      "[405]\tvalid_0's rmse: 5.97264\n",
      "Training metaâ€model target 21 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.6319\n",
      "[200]\tvalid_0's rmse: 7.37032\n",
      "[300]\tvalid_0's rmse: 7.33343\n",
      "[400]\tvalid_0's rmse: 7.32765\n",
      "[500]\tvalid_0's rmse: 7.32355\n",
      "[600]\tvalid_0's rmse: 7.31929\n",
      "[700]\tvalid_0's rmse: 7.3156\n",
      "[800]\tvalid_0's rmse: 7.31706\n",
      "[900]\tvalid_0's rmse: 7.32337\n",
      "Early stopping, best iteration is:\n",
      "[773]\tvalid_0's rmse: 7.31421\n",
      "Training metaâ€model target 22 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 2.76044\n",
      "[200]\tvalid_0's rmse: 2.60316\n",
      "[300]\tvalid_0's rmse: 2.56989\n",
      "[400]\tvalid_0's rmse: 2.56086\n",
      "[500]\tvalid_0's rmse: 2.56004\n",
      "[600]\tvalid_0's rmse: 2.55988\n",
      "[700]\tvalid_0's rmse: 2.56028\n",
      "[800]\tvalid_0's rmse: 2.55849\n",
      "[900]\tvalid_0's rmse: 2.55613\n",
      "[1000]\tvalid_0's rmse: 2.55346\n",
      "[1100]\tvalid_0's rmse: 2.55396\n",
      "[1200]\tvalid_0's rmse: 2.55404\n",
      "Early stopping, best iteration is:\n",
      "[1016]\tvalid_0's rmse: 2.55295\n",
      "Training metaâ€model target 23 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.10941\n",
      "[200]\tvalid_0's rmse: 5.64126\n",
      "[300]\tvalid_0's rmse: 5.54626\n",
      "[400]\tvalid_0's rmse: 5.51938\n",
      "[500]\tvalid_0's rmse: 5.51005\n",
      "[600]\tvalid_0's rmse: 5.50438\n",
      "[700]\tvalid_0's rmse: 5.50581\n",
      "[800]\tvalid_0's rmse: 5.50496\n",
      "Early stopping, best iteration is:\n",
      "[638]\tvalid_0's rmse: 5.50296\n",
      "Training metaâ€model target 24 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.25374\n",
      "[200]\tvalid_0's rmse: 6.68999\n",
      "[300]\tvalid_0's rmse: 6.57134\n",
      "[400]\tvalid_0's rmse: 6.52698\n",
      "[500]\tvalid_0's rmse: 6.51334\n",
      "[600]\tvalid_0's rmse: 6.50556\n",
      "[700]\tvalid_0's rmse: 6.49598\n",
      "[800]\tvalid_0's rmse: 6.493\n",
      "[900]\tvalid_0's rmse: 6.49211\n",
      "[1000]\tvalid_0's rmse: 6.48864\n",
      "[1100]\tvalid_0's rmse: 6.49235\n",
      "[1200]\tvalid_0's rmse: 6.4929\n",
      "Early stopping, best iteration is:\n",
      "[1006]\tvalid_0's rmse: 6.48762\n",
      "Training metaâ€model target 25 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.81848\n",
      "[200]\tvalid_0's rmse: 6.58717\n",
      "[300]\tvalid_0's rmse: 6.53573\n",
      "[400]\tvalid_0's rmse: 6.52326\n",
      "[500]\tvalid_0's rmse: 6.52199\n",
      "[600]\tvalid_0's rmse: 6.52508\n",
      "Early stopping, best iteration is:\n",
      "[447]\tvalid_0's rmse: 6.52065\n",
      "Training metaâ€model target 26 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.58908\n",
      "[200]\tvalid_0's rmse: 6.64477\n",
      "[300]\tvalid_0's rmse: 6.45336\n",
      "[400]\tvalid_0's rmse: 6.3978\n",
      "[500]\tvalid_0's rmse: 6.37467\n",
      "[600]\tvalid_0's rmse: 6.36404\n",
      "[700]\tvalid_0's rmse: 6.35738\n",
      "[800]\tvalid_0's rmse: 6.3543\n",
      "[900]\tvalid_0's rmse: 6.3491\n",
      "[1000]\tvalid_0's rmse: 6.34666\n",
      "[1100]\tvalid_0's rmse: 6.34176\n",
      "[1200]\tvalid_0's rmse: 6.34079\n",
      "[1300]\tvalid_0's rmse: 6.34091\n",
      "Early stopping, best iteration is:\n",
      "[1165]\tvalid_0's rmse: 6.33994\n",
      "Training metaâ€model target 27 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 5.87072\n",
      "[200]\tvalid_0's rmse: 5.63419\n",
      "[300]\tvalid_0's rmse: 5.58598\n",
      "[400]\tvalid_0's rmse: 5.57095\n",
      "[500]\tvalid_0's rmse: 5.57058\n",
      "[600]\tvalid_0's rmse: 5.57103\n",
      "Early stopping, best iteration is:\n",
      "[466]\tvalid_0's rmse: 5.56749\n",
      "Training metaâ€model target 28 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.37755\n",
      "[200]\tvalid_0's rmse: 6.02791\n",
      "[300]\tvalid_0's rmse: 5.96983\n",
      "[400]\tvalid_0's rmse: 5.95933\n",
      "[500]\tvalid_0's rmse: 5.95411\n",
      "[600]\tvalid_0's rmse: 5.95253\n",
      "[700]\tvalid_0's rmse: 5.95096\n",
      "[800]\tvalid_0's rmse: 5.95387\n",
      "Early stopping, best iteration is:\n",
      "[679]\tvalid_0's rmse: 5.94813\n",
      "Training metaâ€model target 29 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.8666\n",
      "[200]\tvalid_0's rmse: 6.13368\n",
      "[300]\tvalid_0's rmse: 6.03068\n",
      "[400]\tvalid_0's rmse: 6.01904\n",
      "[500]\tvalid_0's rmse: 6.0102\n",
      "[600]\tvalid_0's rmse: 6.00933\n",
      "[700]\tvalid_0's rmse: 6.01089\n",
      "[800]\tvalid_0's rmse: 6.00678\n",
      "[900]\tvalid_0's rmse: 6.00733\n",
      "[1000]\tvalid_0's rmse: 6.0173\n",
      "Early stopping, best iteration is:\n",
      "[847]\tvalid_0's rmse: 6.00548\n",
      "Training metaâ€model target 30 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 2.72523\n",
      "[200]\tvalid_0's rmse: 2.43192\n",
      "[300]\tvalid_0's rmse: 2.37855\n",
      "[400]\tvalid_0's rmse: 2.36568\n",
      "[500]\tvalid_0's rmse: 2.36227\n",
      "[600]\tvalid_0's rmse: 2.35998\n",
      "[700]\tvalid_0's rmse: 2.36082\n",
      "Early stopping, best iteration is:\n",
      "[595]\tvalid_0's rmse: 2.35965\n",
      "Training metaâ€model target 31 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 2.35656\n",
      "[200]\tvalid_0's rmse: 2.29944\n",
      "[300]\tvalid_0's rmse: 2.28869\n",
      "[400]\tvalid_0's rmse: 2.2836\n",
      "[500]\tvalid_0's rmse: 2.28257\n",
      "[600]\tvalid_0's rmse: 2.28174\n",
      "[700]\tvalid_0's rmse: 2.28201\n",
      "Early stopping, best iteration is:\n",
      "[576]\tvalid_0's rmse: 2.28121\n",
      "Training metaâ€model target 32 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.34933\n",
      "[200]\tvalid_0's rmse: 7.27005\n",
      "[300]\tvalid_0's rmse: 7.26479\n",
      "[400]\tvalid_0's rmse: 7.26584\n",
      "[500]\tvalid_0's rmse: 7.26725\n",
      "Early stopping, best iteration is:\n",
      "[324]\tvalid_0's rmse: 7.26016\n",
      "Training metaâ€model target 33 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 5.5962\n",
      "[200]\tvalid_0's rmse: 5.38504\n",
      "[300]\tvalid_0's rmse: 5.34936\n",
      "[400]\tvalid_0's rmse: 5.34352\n",
      "[500]\tvalid_0's rmse: 5.34348\n",
      "[600]\tvalid_0's rmse: 5.34841\n",
      "Early stopping, best iteration is:\n",
      "[440]\tvalid_0's rmse: 5.34229\n",
      "Training metaâ€model target 34 â€¦\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 2.88309\n",
      "[200]\tvalid_0's rmse: 2.7987\n",
      "[300]\tvalid_0's rmse: 2.77899\n",
      "[400]\tvalid_0's rmse: 2.77554\n",
      "[500]\tvalid_0's rmse: 2.77384\n",
      "[600]\tvalid_0's rmse: 2.77268\n",
      "[700]\tvalid_0's rmse: 2.77378\n",
      "[800]\tvalid_0's rmse: 2.77352\n",
      "[900]\tvalid_0's rmse: 2.77444\n",
      "Early stopping, best iteration is:\n",
      "[777]\tvalid_0's rmse: 2.77262\n",
      "âœ… Saved entireâ€dataset metaâ€model â†’ meta_model_single.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import rankdata\n",
    "from python_scripts.import_data import importDataset\n",
    "from python_scripts.operate_model import predict\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from python_scripts.pretrain_model import PretrainedEncoderRegressor\n",
    "\n",
    "# --------------- Settings ---------------\n",
    "trained_model_path = 'output_folder/rank-spot/realign/whole_worflow/s_m_l/filtered_directly_rank/k-fold_mix/realign_all/Macenko_masked/results/model_epoch022.pt'\n",
    "n_samples  = len(full_dataset)\n",
    "C          = 35\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "tile_dim    = 128\n",
    "center_dim  = 128\n",
    "neighbor_dim= 128\n",
    "version = 'version2'\n",
    "\n",
    "pretrained_ae_name  = 'AE_Center_noaug'\n",
    "pretrained_ae_path  = f\"AE_model/128/{pretrained_ae_name}/best.pt\"\n",
    "ae_type            = 'center'\n",
    "device             = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# 1) Ground truth labels\n",
    "y_true = np.vstack([ full_dataset[i]['label'].cpu().numpy() for i in range(n_samples) ])\n",
    "\n",
    "# 2) Load the single model and get preds + latents on full_dataset\n",
    "net = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "net.load_state_dict(torch.load(trained_model_path, map_location=device))\n",
    "net = net.to(device).eval()\n",
    "\n",
    "full_loader = DataLoader(full_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "all_preds, all_latents = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in full_loader:\n",
    "        tiles, subtiles = batch['tile'].to(device), batch['subtiles'].to(device)\n",
    "        center = subtiles[:, 4].contiguous()\n",
    "        f_c = net.encoder_center(center)\n",
    "        f_n = net.encoder_subtile(subtiles)\n",
    "        f_t = net.encoder_tile(tiles)\n",
    "        features_cat = torch.cat([f_c, f_n, f_t], dim=1)\n",
    "        gates = net.gate_fc(features_cat)        # (B, 3), softmax over features\n",
    "        f_fused = (\n",
    "            gates[:, 0:1] * f_t +\n",
    "            gates[:, 1:2] * f_n +\n",
    "            gates[:, 2:3] * f_c\n",
    "        )  # (B, tile_dim) â€” æ³¨æ„å„ encoder è¼¸å‡ºç¶­åº¦è¦ä¸€è‡´\n",
    "        out  = net.decoder(f_fused)\n",
    "        all_preds.append(out.cpu().numpy())\n",
    "        all_latents.append(features_cat.cpu().numpy())\n",
    "\n",
    "oof_preds     = np.vstack(all_preds)     # shape (n_samples, 35)\n",
    "image_latents = np.vstack(all_latents)   # shape (n_samples, fusion_dim)\n",
    "\n",
    "# 3) AE reconstruction model (unchanged)\n",
    "recon_model = PretrainedEncoderRegressor(\n",
    "    ae_checkpoint=pretrained_ae_path,\n",
    "    ae_type=ae_type,\n",
    "    tile_dim=tile_dim,\n",
    "    center_dim=center_dim,\n",
    "    neighbor_dim=neighbor_dim,\n",
    "    output_dim=C,\n",
    "    mode='reconstruction'\n",
    ").to(device)\n",
    "\n",
    "# 4) Generate meta features for the full dataset\n",
    "meta = generate_meta_features(\n",
    "    dataset         = full_dataset,\n",
    "    oof_preds       = oof_preds,\n",
    "    image_latents   = image_latents,\n",
    "    model_for_recon = recon_model,\n",
    "    device          = device,\n",
    "    ae_type         = ae_type,\n",
    "    use_clusters    = \"both\"\n",
    ")\n",
    "\n",
    "# 5) Train a single Metaâ€Model on all meta features\n",
    "\n",
    "lgb_base = lgb.LGBMRegressor(\n",
    "    objective='regression',         # ç­‰ä»·äº 'l2'\n",
    "    metric='rmse',\n",
    "    learning_rate=0.01,             # ç¨å¾®æ”¾å®½åˆ° 0.01\n",
    "    n_estimators=20000,             # ä¸Šé™æé«˜ï¼Œé…åˆ early stopping\n",
    "    max_depth=8,                    # æ·±åº¦å¯ä»¥å†å¢åŠ ä¸€äº›\n",
    "    num_leaves=127,                 # 2^7-1ï¼Œä¸ max_depth=8 åŒ¹é…\n",
    "    feature_fraction=0.8,           # æ¯æ£µæ ‘é‡‡ 80% ç‰¹å¾\n",
    "    bagging_fraction=0.8,           # æ¯æ£µæ ‘é‡‡ 80% æ ·æœ¬\n",
    "    bagging_freq=1,                 # å¼€å¯è¡ŒæŠ½æ ·\n",
    "    min_data_in_leaf=30,            # å¶å­ä¸Šæœ€å°‘ 20 æ ·æœ¬\n",
    "    reg_alpha=1.0,                  # L1 æ­£åˆ™\n",
    "    reg_lambda=1.0,                 # L2 æ­£åˆ™\n",
    "    verbosity=-1\n",
    ")\n",
    "\n",
    "\n",
    "# 5a) Optional: split a small valâ€set for early stopping\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    meta, y_true, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "meta_model = MultiOutputRegressor(lgb_base)\n",
    "meta_model.estimators_ = []\n",
    "for i in range(C):\n",
    "    print(f\"Training metaâ€model target {i} â€¦\")\n",
    "    m = lgb.LGBMRegressor(**lgb_base.get_params())\n",
    "    m.fit(\n",
    "        X_tr, y_tr[:, i],\n",
    "        eval_set=[(X_val, y_val[:, i])],\n",
    "        callbacks=[early_stopping(stopping_rounds=200), log_evaluation(period=100)]\n",
    "    )\n",
    "    meta_model.estimators_.append(m)\n",
    "\n",
    "save_folder = f\"only_lightgbm/{version}\"  # ä¿®æ”¹ç‚ºä½ æƒ³è¦çš„è³‡æ–™å¤¾åç¨±\n",
    "if not os.path.exists(save_folder):   \n",
    "    os.makedirs(save_folder)\n",
    "# 6) Save the single metaâ€model\n",
    "joblib.dump(meta_model, f'{save_folder}meta_model_single.pkl')\n",
    "print(\"âœ… Saved entireâ€dataset metaâ€model â†’ meta_model_single.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved entireâ€dataset metaâ€model â†’ meta_model_single.pkl\n"
     ]
    }
   ],
   "source": [
    "# 6) Save the single metaâ€model\n",
    "joblib.dump(meta_model, 'meta_model_single.pkl')\n",
    "print(\"âœ… Saved entireâ€dataset metaâ€model â†’ meta_model_single.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/import_data.py:280: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  raw = torch.load(pt_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ å¾ '<class 'list'>' æ¨æ–·æ¨£æœ¬æ•¸é‡: 2088\n",
      "Model forward signature: (tile, subtiles)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from python_scripts.import_data import load_node_feature_data\n",
    "\n",
    "\n",
    "image_keys = [ 'tile', 'subtiles']\n",
    "\n",
    "model = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "\n",
    "# ç”¨æ³•ç¤ºä¾‹\n",
    "from python_scripts.import_data import importDataset\n",
    "# å‡è®¾ä½ çš„ model å·²ç»å®šä¹‰å¥½å¹¶å®ä¾‹åŒ–ä¸º `model`\n",
    "test_dataset = load_node_feature_data(\"dataset/spot-rank/filtered_directly_rank/masked/test/Macenko/test_dataset.pt\", model)\n",
    "test_dataset = importDataset(\n",
    "        data_dict=test_dataset,\n",
    "        model=model,\n",
    "        image_keys=image_keys,\n",
    "        transform=lambda x: x,  # identity transform\n",
    "        print_sig=True\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_14152/3878551429.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(trained_model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# 1) å¯¹ test_dataset ç”¨ä½ çš„ç¬¬ 1 é˜¶æ®µ model ä¸€æ¬¡æ€§ç®—å‡º oof_preds å’Œ latents\n",
    "net = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "net.load_state_dict(torch.load(trained_model_path, map_location=device))\n",
    "net = net.to(device).eval()\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_preds, test_latents = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        tiles, subtiles = batch['tile'].to(device), batch['subtiles'].to(device)\n",
    "        center = subtiles[:, 4].contiguous()\n",
    "        f_c = net.encoder_center(center)\n",
    "        f_n = net.encoder_subtile(subtiles)\n",
    "        f_t = net.encoder_tile(tiles)\n",
    "        features_cat = torch.cat([f_c, f_n, f_t], dim=1)\n",
    "        gates = net.gate_fc(features_cat)        # (B, 3), softmax over features\n",
    "        f_fused = (\n",
    "            gates[:, 0:1] * f_t +\n",
    "            gates[:, 1:2] * f_n +\n",
    "            gates[:, 2:3] * f_c\n",
    "        )  # (B, tile_dim) â€” æ³¨æ„å„ encoder è¼¸å‡ºç¶­åº¦è¦ä¸€è‡´\n",
    "        out  = net.decoder(f_fused)\n",
    "        test_preds.append(out.cpu())\n",
    "        test_latents.append(f_fused.cpu())\n",
    "        \n",
    "    test_preds = torch.cat(test_preds, dim=0).numpy()\n",
    "    test_latents = torch.cat(test_latents, dim=0).numpy()\n",
    " \n",
    "# 2) AE Recon Model ä¸å˜ï¼Œç®—æµ‹è¯•çš„ recon_loss & å¿…è¦ç‰¹å¾\n",
    "recon_model = PretrainedEncoderRegressor(\n",
    "    ae_checkpoint=pretrained_ae_path,\n",
    "    ae_type=ae_type,\n",
    "    tile_dim=tile_dim,\n",
    "    center_dim=center_dim,\n",
    "    neighbor_dim=neighbor_dim,\n",
    "    output_dim=C,\n",
    "    mode='reconstruction'\n",
    ").to(device)\n",
    "\n",
    "meta_test = generate_meta_features(\n",
    "    dataset         = test_dataset,\n",
    "    oof_preds       = test_preds,\n",
    "    image_latents   = test_latents,\n",
    "    model_for_recon = recon_model,\n",
    "    device          = device,\n",
    "    ae_type         = ae_type,\n",
    "    use_clusters    = \"both\"\n",
    ")\n",
    "\n",
    "# 3) ç›´æ¥è½½å…¥å¹¶ç”¨ singleâ€fold çš„ meta_model é¢„æµ‹\n",
    "meta_model = joblib.load(f'{save_folder}meta_model_single.pkl')\n",
    "final_preds = meta_model.predict(meta_test)\n",
    "\n",
    "# 4) å†™å‡º submission\n",
    "import h5py, pandas as pd\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spot_ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"]))\n",
    "sub = pd.DataFrame(final_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, 'ID', test_spot_ids.index)\n",
    "sub.to_csv(f'{save_folder}submission_stacked.csv', index=False)\n",
    "print(\"âœ… Saved submission_stacked.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Starting fold 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_35616/2946613622.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/pretrain_model.py:310: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ae.load_state_dict(torch.load(ae_checkpoint, map_location=\"cpu\"))\n",
      "Computing AE recon loss: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:02<00:00, 11.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for k=2: 0.5500\n",
      "Silhouette score for k=3: 0.5892\n",
      "Silhouette score for k=4: 0.5201\n",
      "Silhouette score for k=5: 0.5311\n",
      "Silhouette score for k=6: 0.5067\n",
      "Selected best k=3 (score=0.5892)\n",
      "âœ… Generated meta-features with shape: (2197, 227)\n",
      "[fold 0] training target 0 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 6.4679\n",
      "[200]\tvalid_0's rmse: 6.27986\n",
      "[300]\tvalid_0's rmse: 6.21137\n",
      "[400]\tvalid_0's rmse: 6.17162\n",
      "[500]\tvalid_0's rmse: 6.15372\n",
      "[600]\tvalid_0's rmse: 6.15222\n",
      "[700]\tvalid_0's rmse: 6.16033\n",
      "[800]\tvalid_0's rmse: 6.16606\n",
      "Early stopping, best iteration is:\n",
      "[611]\tvalid_0's rmse: 6.14999\n",
      "[fold 0] training target 1 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.72637\n",
      "[200]\tvalid_0's rmse: 2.38419\n",
      "[300]\tvalid_0's rmse: 2.27991\n",
      "[400]\tvalid_0's rmse: 2.25302\n",
      "[500]\tvalid_0's rmse: 2.24256\n",
      "[600]\tvalid_0's rmse: 2.23851\n",
      "[700]\tvalid_0's rmse: 2.23599\n",
      "[800]\tvalid_0's rmse: 2.23449\n",
      "[900]\tvalid_0's rmse: 2.23727\n",
      "Early stopping, best iteration is:\n",
      "[791]\tvalid_0's rmse: 2.23409\n",
      "[fold 0] training target 2 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 4.4783\n",
      "[200]\tvalid_0's rmse: 4.33658\n",
      "[300]\tvalid_0's rmse: 4.27057\n",
      "[400]\tvalid_0's rmse: 4.24216\n",
      "[500]\tvalid_0's rmse: 4.23617\n",
      "[600]\tvalid_0's rmse: 4.22769\n",
      "[700]\tvalid_0's rmse: 4.22185\n",
      "[800]\tvalid_0's rmse: 4.22169\n",
      "[900]\tvalid_0's rmse: 4.21721\n",
      "[1000]\tvalid_0's rmse: 4.21561\n",
      "Early stopping, best iteration is:\n",
      "[861]\tvalid_0's rmse: 4.21528\n",
      "[fold 0] training target 3 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 6.86958\n",
      "[200]\tvalid_0's rmse: 6.78088\n",
      "[300]\tvalid_0's rmse: 6.75143\n",
      "[400]\tvalid_0's rmse: 6.74663\n",
      "[500]\tvalid_0's rmse: 6.76621\n",
      "Early stopping, best iteration is:\n",
      "[349]\tvalid_0's rmse: 6.7417\n",
      "[fold 0] training target 4 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.25344\n",
      "[200]\tvalid_0's rmse: 6.22301\n",
      "[300]\tvalid_0's rmse: 5.82344\n",
      "[400]\tvalid_0's rmse: 5.66066\n",
      "[500]\tvalid_0's rmse: 5.56592\n",
      "[600]\tvalid_0's rmse: 5.52801\n",
      "[700]\tvalid_0's rmse: 5.50798\n",
      "[800]\tvalid_0's rmse: 5.49388\n",
      "[900]\tvalid_0's rmse: 5.49443\n",
      "[1000]\tvalid_0's rmse: 5.48707\n",
      "[1100]\tvalid_0's rmse: 5.48587\n",
      "[1200]\tvalid_0's rmse: 5.48644\n",
      "[1300]\tvalid_0's rmse: 5.48098\n",
      "[1400]\tvalid_0's rmse: 5.48116\n",
      "[1500]\tvalid_0's rmse: 5.47934\n",
      "[1600]\tvalid_0's rmse: 5.47653\n",
      "[1700]\tvalid_0's rmse: 5.47305\n",
      "[1800]\tvalid_0's rmse: 5.47248\n",
      "[1900]\tvalid_0's rmse: 5.47189\n",
      "[2000]\tvalid_0's rmse: 5.47113\n",
      "[2100]\tvalid_0's rmse: 5.4709\n",
      "[2200]\tvalid_0's rmse: 5.47206\n",
      "Early stopping, best iteration is:\n",
      "[2012]\tvalid_0's rmse: 5.47008\n",
      "[fold 0] training target 5 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 8.1606\n",
      "[200]\tvalid_0's rmse: 6.98825\n",
      "[300]\tvalid_0's rmse: 6.55376\n",
      "[400]\tvalid_0's rmse: 6.38535\n",
      "[500]\tvalid_0's rmse: 6.29584\n",
      "[600]\tvalid_0's rmse: 6.23991\n",
      "[700]\tvalid_0's rmse: 6.20386\n",
      "[800]\tvalid_0's rmse: 6.17691\n",
      "[900]\tvalid_0's rmse: 6.15441\n",
      "[1000]\tvalid_0's rmse: 6.1323\n",
      "[1100]\tvalid_0's rmse: 6.11909\n",
      "[1200]\tvalid_0's rmse: 6.11195\n",
      "[1300]\tvalid_0's rmse: 6.10149\n",
      "[1400]\tvalid_0's rmse: 6.09578\n",
      "[1500]\tvalid_0's rmse: 6.0899\n",
      "[1600]\tvalid_0's rmse: 6.08739\n",
      "[1700]\tvalid_0's rmse: 6.08184\n",
      "[1800]\tvalid_0's rmse: 6.07722\n",
      "[1900]\tvalid_0's rmse: 6.07481\n",
      "[2000]\tvalid_0's rmse: 6.07287\n",
      "[2100]\tvalid_0's rmse: 6.07336\n",
      "[2200]\tvalid_0's rmse: 6.06998\n",
      "[2300]\tvalid_0's rmse: 6.06779\n",
      "[2400]\tvalid_0's rmse: 6.06676\n",
      "[2500]\tvalid_0's rmse: 6.06568\n",
      "[2600]\tvalid_0's rmse: 6.06579\n",
      "[2700]\tvalid_0's rmse: 6.06543\n",
      "Early stopping, best iteration is:\n",
      "[2548]\tvalid_0's rmse: 6.06465\n",
      "[fold 0] training target 6 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 4.44826\n",
      "[200]\tvalid_0's rmse: 4.20094\n",
      "[300]\tvalid_0's rmse: 4.13247\n",
      "[400]\tvalid_0's rmse: 4.10873\n",
      "[500]\tvalid_0's rmse: 4.09578\n",
      "[600]\tvalid_0's rmse: 4.08713\n",
      "[700]\tvalid_0's rmse: 4.08574\n",
      "[800]\tvalid_0's rmse: 4.08396\n",
      "Early stopping, best iteration is:\n",
      "[647]\tvalid_0's rmse: 4.08213\n",
      "[fold 0] training target 7 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.38641\n",
      "[200]\tvalid_0's rmse: 5.33827\n",
      "[300]\tvalid_0's rmse: 5.32495\n",
      "[400]\tvalid_0's rmse: 5.32559\n",
      "[500]\tvalid_0's rmse: 5.34017\n",
      "Early stopping, best iteration is:\n",
      "[369]\tvalid_0's rmse: 5.32197\n",
      "[fold 0] training target 8 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.68661\n",
      "[200]\tvalid_0's rmse: 6.73552\n",
      "[300]\tvalid_0's rmse: 6.4189\n",
      "[400]\tvalid_0's rmse: 6.2864\n",
      "[500]\tvalid_0's rmse: 6.21924\n",
      "[600]\tvalid_0's rmse: 6.19431\n",
      "[700]\tvalid_0's rmse: 6.19219\n",
      "[800]\tvalid_0's rmse: 6.18215\n",
      "[900]\tvalid_0's rmse: 6.17764\n",
      "[1000]\tvalid_0's rmse: 6.17513\n",
      "[1100]\tvalid_0's rmse: 6.17667\n",
      "[1200]\tvalid_0's rmse: 6.17426\n",
      "[1300]\tvalid_0's rmse: 6.16828\n",
      "[1400]\tvalid_0's rmse: 6.16791\n",
      "[1500]\tvalid_0's rmse: 6.1657\n",
      "[1600]\tvalid_0's rmse: 6.16385\n",
      "[1700]\tvalid_0's rmse: 6.1618\n",
      "[1800]\tvalid_0's rmse: 6.16111\n",
      "[1900]\tvalid_0's rmse: 6.16288\n",
      "[2000]\tvalid_0's rmse: 6.16266\n",
      "Early stopping, best iteration is:\n",
      "[1808]\tvalid_0's rmse: 6.16098\n",
      "[fold 0] training target 9 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 9.10774\n",
      "[200]\tvalid_0's rmse: 8.39064\n",
      "[300]\tvalid_0's rmse: 8.15342\n",
      "[400]\tvalid_0's rmse: 8.03477\n",
      "[500]\tvalid_0's rmse: 7.97941\n",
      "[600]\tvalid_0's rmse: 7.95566\n",
      "[700]\tvalid_0's rmse: 7.96163\n",
      "[800]\tvalid_0's rmse: 7.95926\n",
      "Early stopping, best iteration is:\n",
      "[609]\tvalid_0's rmse: 7.95275\n",
      "[fold 0] training target 10 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 8.50651\n",
      "[200]\tvalid_0's rmse: 8.13523\n",
      "[300]\tvalid_0's rmse: 7.99524\n",
      "[400]\tvalid_0's rmse: 7.91231\n",
      "[500]\tvalid_0's rmse: 7.87991\n",
      "[600]\tvalid_0's rmse: 7.87377\n",
      "[700]\tvalid_0's rmse: 7.86957\n",
      "[800]\tvalid_0's rmse: 7.86932\n",
      "Early stopping, best iteration is:\n",
      "[644]\tvalid_0's rmse: 7.85756\n",
      "[fold 0] training target 11 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.03787\n",
      "[200]\tvalid_0's rmse: 4.45928\n",
      "[300]\tvalid_0's rmse: 4.25658\n",
      "[400]\tvalid_0's rmse: 4.18942\n",
      "[500]\tvalid_0's rmse: 4.17441\n",
      "[600]\tvalid_0's rmse: 4.16913\n",
      "[700]\tvalid_0's rmse: 4.16923\n",
      "[800]\tvalid_0's rmse: 4.1712\n",
      "Early stopping, best iteration is:\n",
      "[644]\tvalid_0's rmse: 4.16591\n",
      "[fold 0] training target 12 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.89781\n",
      "[200]\tvalid_0's rmse: 5.86192\n",
      "[300]\tvalid_0's rmse: 5.86296\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's rmse: 5.85755\n",
      "[fold 0] training target 13 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.79806\n",
      "[200]\tvalid_0's rmse: 5.73127\n",
      "[300]\tvalid_0's rmse: 5.71865\n",
      "[400]\tvalid_0's rmse: 5.72507\n",
      "Early stopping, best iteration is:\n",
      "[285]\tvalid_0's rmse: 5.71689\n",
      "[fold 0] training target 14 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.53081\n",
      "[200]\tvalid_0's rmse: 5.11301\n",
      "[300]\tvalid_0's rmse: 4.93668\n",
      "[400]\tvalid_0's rmse: 4.86542\n",
      "[500]\tvalid_0's rmse: 4.82702\n",
      "[600]\tvalid_0's rmse: 4.80333\n",
      "[700]\tvalid_0's rmse: 4.78666\n",
      "[800]\tvalid_0's rmse: 4.76851\n",
      "[900]\tvalid_0's rmse: 4.75815\n",
      "[1000]\tvalid_0's rmse: 4.74286\n",
      "[1100]\tvalid_0's rmse: 4.73694\n",
      "[1200]\tvalid_0's rmse: 4.73419\n",
      "[1300]\tvalid_0's rmse: 4.72631\n",
      "[1400]\tvalid_0's rmse: 4.72228\n",
      "[1500]\tvalid_0's rmse: 4.71604\n",
      "[1600]\tvalid_0's rmse: 4.71245\n",
      "[1700]\tvalid_0's rmse: 4.71046\n",
      "[1800]\tvalid_0's rmse: 4.71024\n",
      "[1900]\tvalid_0's rmse: 4.70858\n",
      "[2000]\tvalid_0's rmse: 4.70667\n",
      "[2100]\tvalid_0's rmse: 4.70596\n",
      "[2200]\tvalid_0's rmse: 4.70571\n",
      "[2300]\tvalid_0's rmse: 4.70377\n",
      "[2400]\tvalid_0's rmse: 4.70386\n",
      "[2500]\tvalid_0's rmse: 4.70327\n",
      "[2600]\tvalid_0's rmse: 4.7019\n",
      "[2700]\tvalid_0's rmse: 4.70195\n",
      "Early stopping, best iteration is:\n",
      "[2568]\tvalid_0's rmse: 4.70123\n",
      "[fold 0] training target 15 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.60967\n",
      "[200]\tvalid_0's rmse: 2.48952\n",
      "[300]\tvalid_0's rmse: 2.43757\n",
      "[400]\tvalid_0's rmse: 2.41192\n",
      "[500]\tvalid_0's rmse: 2.40363\n",
      "[600]\tvalid_0's rmse: 2.40248\n",
      "[700]\tvalid_0's rmse: 2.40159\n",
      "Early stopping, best iteration is:\n",
      "[547]\tvalid_0's rmse: 2.40068\n",
      "[fold 0] training target 16 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.69544\n",
      "[200]\tvalid_0's rmse: 6.97326\n",
      "[300]\tvalid_0's rmse: 6.71563\n",
      "[400]\tvalid_0's rmse: 6.62898\n",
      "[500]\tvalid_0's rmse: 6.59072\n",
      "[600]\tvalid_0's rmse: 6.57381\n",
      "[700]\tvalid_0's rmse: 6.55242\n",
      "[800]\tvalid_0's rmse: 6.53982\n",
      "[900]\tvalid_0's rmse: 6.53103\n",
      "[1000]\tvalid_0's rmse: 6.52339\n",
      "[1100]\tvalid_0's rmse: 6.51429\n",
      "[1200]\tvalid_0's rmse: 6.50468\n",
      "[1300]\tvalid_0's rmse: 6.49661\n",
      "[1400]\tvalid_0's rmse: 6.48962\n",
      "[1500]\tvalid_0's rmse: 6.48764\n",
      "[1600]\tvalid_0's rmse: 6.48545\n",
      "[1700]\tvalid_0's rmse: 6.48265\n",
      "[1800]\tvalid_0's rmse: 6.48525\n",
      "[1900]\tvalid_0's rmse: 6.48441\n",
      "Early stopping, best iteration is:\n",
      "[1704]\tvalid_0's rmse: 6.4826\n",
      "[fold 0] training target 17 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 3.79048\n",
      "[200]\tvalid_0's rmse: 3.77163\n",
      "[300]\tvalid_0's rmse: 3.76181\n",
      "[400]\tvalid_0's rmse: 3.75824\n",
      "[500]\tvalid_0's rmse: 3.75725\n",
      "[600]\tvalid_0's rmse: 3.76351\n",
      "[700]\tvalid_0's rmse: 3.76593\n",
      "Early stopping, best iteration is:\n",
      "[504]\tvalid_0's rmse: 3.75645\n",
      "[fold 0] training target 18 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 8.00557\n",
      "[200]\tvalid_0's rmse: 7.70243\n",
      "[300]\tvalid_0's rmse: 7.62185\n",
      "[400]\tvalid_0's rmse: 7.58112\n",
      "[500]\tvalid_0's rmse: 7.56092\n",
      "[600]\tvalid_0's rmse: 7.56403\n",
      "[700]\tvalid_0's rmse: 7.5734\n",
      "Early stopping, best iteration is:\n",
      "[508]\tvalid_0's rmse: 7.55849\n",
      "[fold 0] training target 19 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.4269\n",
      "[200]\tvalid_0's rmse: 5.11919\n",
      "[300]\tvalid_0's rmse: 5.01449\n",
      "[400]\tvalid_0's rmse: 4.96557\n",
      "[500]\tvalid_0's rmse: 4.94925\n",
      "[600]\tvalid_0's rmse: 4.9414\n",
      "[700]\tvalid_0's rmse: 4.93399\n",
      "[800]\tvalid_0's rmse: 4.93587\n",
      "Early stopping, best iteration is:\n",
      "[676]\tvalid_0's rmse: 4.93226\n",
      "[fold 0] training target 20 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.32446\n",
      "[200]\tvalid_0's rmse: 6.73073\n",
      "[300]\tvalid_0's rmse: 6.53688\n",
      "[400]\tvalid_0's rmse: 6.4626\n",
      "[500]\tvalid_0's rmse: 6.42963\n",
      "[600]\tvalid_0's rmse: 6.41676\n",
      "[700]\tvalid_0's rmse: 6.41349\n",
      "[800]\tvalid_0's rmse: 6.41847\n",
      "[900]\tvalid_0's rmse: 6.41254\n",
      "[1000]\tvalid_0's rmse: 6.42003\n",
      "Early stopping, best iteration is:\n",
      "[867]\tvalid_0's rmse: 6.409\n",
      "[fold 0] training target 21 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 8.14351\n",
      "[200]\tvalid_0's rmse: 7.70604\n",
      "[300]\tvalid_0's rmse: 7.556\n",
      "[400]\tvalid_0's rmse: 7.49216\n",
      "[500]\tvalid_0's rmse: 7.47353\n",
      "[600]\tvalid_0's rmse: 7.47709\n",
      "[700]\tvalid_0's rmse: 7.47483\n",
      "[800]\tvalid_0's rmse: 7.47358\n",
      "[900]\tvalid_0's rmse: 7.46984\n",
      "[1000]\tvalid_0's rmse: 7.46346\n",
      "[1100]\tvalid_0's rmse: 7.47819\n",
      "Early stopping, best iteration is:\n",
      "[989]\tvalid_0's rmse: 7.46194\n",
      "[fold 0] training target 22 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 3.3518\n",
      "[200]\tvalid_0's rmse: 3.08804\n",
      "[300]\tvalid_0's rmse: 3.02736\n",
      "[400]\tvalid_0's rmse: 3.01887\n",
      "[500]\tvalid_0's rmse: 3.01986\n",
      "[600]\tvalid_0's rmse: 3.02052\n",
      "Early stopping, best iteration is:\n",
      "[429]\tvalid_0's rmse: 3.01607\n",
      "[fold 0] training target 23 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 6.73935\n",
      "[200]\tvalid_0's rmse: 6.63321\n",
      "[300]\tvalid_0's rmse: 6.59639\n",
      "[400]\tvalid_0's rmse: 6.60402\n",
      "Early stopping, best iteration is:\n",
      "[296]\tvalid_0's rmse: 6.59478\n",
      "[fold 0] training target 24 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.77596\n",
      "[200]\tvalid_0's rmse: 7.62494\n",
      "[300]\tvalid_0's rmse: 7.56398\n",
      "[400]\tvalid_0's rmse: 7.53075\n",
      "[500]\tvalid_0's rmse: 7.52936\n",
      "[600]\tvalid_0's rmse: 7.53013\n",
      "[700]\tvalid_0's rmse: 7.53851\n",
      "Early stopping, best iteration is:\n",
      "[576]\tvalid_0's rmse: 7.52369\n",
      "[fold 0] training target 25 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.12509\n",
      "[200]\tvalid_0's rmse: 6.91167\n",
      "[300]\tvalid_0's rmse: 6.83581\n",
      "[400]\tvalid_0's rmse: 6.79851\n",
      "[500]\tvalid_0's rmse: 6.77443\n",
      "[600]\tvalid_0's rmse: 6.75406\n",
      "[700]\tvalid_0's rmse: 6.7496\n",
      "[800]\tvalid_0's rmse: 6.75137\n",
      "Early stopping, best iteration is:\n",
      "[669]\tvalid_0's rmse: 6.74552\n",
      "[fold 0] training target 26 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 8.02291\n",
      "[200]\tvalid_0's rmse: 7.01319\n",
      "[300]\tvalid_0's rmse: 6.66819\n",
      "[400]\tvalid_0's rmse: 6.53019\n",
      "[500]\tvalid_0's rmse: 6.47541\n",
      "[600]\tvalid_0's rmse: 6.43666\n",
      "[700]\tvalid_0's rmse: 6.42391\n",
      "[800]\tvalid_0's rmse: 6.41324\n",
      "[900]\tvalid_0's rmse: 6.40975\n",
      "[1000]\tvalid_0's rmse: 6.39891\n",
      "[1100]\tvalid_0's rmse: 6.38682\n",
      "[1200]\tvalid_0's rmse: 6.37889\n",
      "[1300]\tvalid_0's rmse: 6.37288\n",
      "[1400]\tvalid_0's rmse: 6.36601\n",
      "[1500]\tvalid_0's rmse: 6.35924\n",
      "[1600]\tvalid_0's rmse: 6.35168\n",
      "[1700]\tvalid_0's rmse: 6.34631\n",
      "[1800]\tvalid_0's rmse: 6.34257\n",
      "[1900]\tvalid_0's rmse: 6.34382\n",
      "[2000]\tvalid_0's rmse: 6.34075\n",
      "[2100]\tvalid_0's rmse: 6.33723\n",
      "[2200]\tvalid_0's rmse: 6.33399\n",
      "[2300]\tvalid_0's rmse: 6.33448\n",
      "[2400]\tvalid_0's rmse: 6.3328\n",
      "[2500]\tvalid_0's rmse: 6.33286\n",
      "[2600]\tvalid_0's rmse: 6.32975\n",
      "[2700]\tvalid_0's rmse: 6.3293\n",
      "[2800]\tvalid_0's rmse: 6.32963\n",
      "[2900]\tvalid_0's rmse: 6.32925\n",
      "[3000]\tvalid_0's rmse: 6.32687\n",
      "[3100]\tvalid_0's rmse: 6.32735\n",
      "[3200]\tvalid_0's rmse: 6.32613\n",
      "[3300]\tvalid_0's rmse: 6.32601\n",
      "[3400]\tvalid_0's rmse: 6.32617\n",
      "Early stopping, best iteration is:\n",
      "[3245]\tvalid_0's rmse: 6.32545\n",
      "[fold 0] training target 27 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 6.7432\n",
      "[200]\tvalid_0's rmse: 6.15762\n",
      "[300]\tvalid_0's rmse: 6.00819\n",
      "[400]\tvalid_0's rmse: 5.95888\n",
      "[500]\tvalid_0's rmse: 5.94522\n",
      "[600]\tvalid_0's rmse: 5.94734\n",
      "Early stopping, best iteration is:\n",
      "[478]\tvalid_0's rmse: 5.94123\n",
      "[fold 0] training target 28 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.31572\n",
      "[200]\tvalid_0's rmse: 7.0511\n",
      "[300]\tvalid_0's rmse: 6.93549\n",
      "[400]\tvalid_0's rmse: 6.89763\n",
      "[500]\tvalid_0's rmse: 6.88269\n",
      "[600]\tvalid_0's rmse: 6.8758\n",
      "[700]\tvalid_0's rmse: 6.8694\n",
      "[800]\tvalid_0's rmse: 6.86029\n",
      "[900]\tvalid_0's rmse: 6.86543\n",
      "[1000]\tvalid_0's rmse: 6.86373\n",
      "Early stopping, best iteration is:\n",
      "[821]\tvalid_0's rmse: 6.8557\n",
      "[fold 0] training target 29 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 4.93819\n",
      "[200]\tvalid_0's rmse: 4.87235\n",
      "[300]\tvalid_0's rmse: 4.8532\n",
      "[400]\tvalid_0's rmse: 4.85126\n",
      "[500]\tvalid_0's rmse: 4.84888\n",
      "[600]\tvalid_0's rmse: 4.85716\n",
      "Early stopping, best iteration is:\n",
      "[446]\tvalid_0's rmse: 4.84632\n",
      "[fold 0] training target 30 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 3.7234\n",
      "[200]\tvalid_0's rmse: 3.29966\n",
      "[300]\tvalid_0's rmse: 3.18448\n",
      "[400]\tvalid_0's rmse: 3.14423\n",
      "[500]\tvalid_0's rmse: 3.12999\n",
      "[600]\tvalid_0's rmse: 3.12275\n",
      "[700]\tvalid_0's rmse: 3.11733\n",
      "[800]\tvalid_0's rmse: 3.11938\n",
      "Early stopping, best iteration is:\n",
      "[696]\tvalid_0's rmse: 3.11702\n",
      "[fold 0] training target 31 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.69433\n",
      "[200]\tvalid_0's rmse: 2.65308\n",
      "[300]\tvalid_0's rmse: 2.65267\n",
      "[400]\tvalid_0's rmse: 2.65751\n",
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's rmse: 2.64932\n",
      "[fold 0] training target 32 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.72682\n",
      "[200]\tvalid_0's rmse: 7.67412\n",
      "[300]\tvalid_0's rmse: 7.64429\n",
      "[400]\tvalid_0's rmse: 7.64086\n",
      "[500]\tvalid_0's rmse: 7.64688\n",
      "[600]\tvalid_0's rmse: 7.64892\n",
      "[700]\tvalid_0's rmse: 7.6519\n",
      "Early stopping, best iteration is:\n",
      "[550]\tvalid_0's rmse: 7.63966\n",
      "[fold 0] training target 33 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.69947\n",
      "[200]\tvalid_0's rmse: 5.64388\n",
      "[300]\tvalid_0's rmse: 5.63622\n",
      "[400]\tvalid_0's rmse: 5.63685\n",
      "[500]\tvalid_0's rmse: 5.64229\n",
      "Early stopping, best iteration is:\n",
      "[358]\tvalid_0's rmse: 5.6298\n",
      "[fold 0] training target 34 on meta features â€¦\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 3.34226\n",
      "[200]\tvalid_0's rmse: 3.22946\n",
      "[300]\tvalid_0's rmse: 3.18547\n",
      "[400]\tvalid_0's rmse: 3.16129\n",
      "[500]\tvalid_0's rmse: 3.15555\n",
      "[600]\tvalid_0's rmse: 3.14992\n",
      "[700]\tvalid_0's rmse: 3.14998\n",
      "[800]\tvalid_0's rmse: 3.14933\n",
      "[900]\tvalid_0's rmse: 3.14878\n",
      "Early stopping, best iteration is:\n",
      "[741]\tvalid_0's rmse: 3.14737\n",
      "âœ… Saved fold 0 metaâ€model â†’ output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/meta_model_fold0.pkl\n",
      "â­ï¸ Skipping fold 1\n",
      "â­ï¸ Skipping fold 2\n",
      "â­ï¸ Skipping fold 3\n",
      "â­ï¸ Skipping fold 4\n",
      "â­ï¸ Skipping fold 5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import rankdata\n",
    "from python_scripts.import_data import importDataset\n",
    "from python_scripts.operate_model import predict\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from python_scripts.pretrain_model import PretrainedEncoderRegressor\n",
    "# ---------------- Settings ----------------\n",
    "trained_oof_model_folder = 'output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/'\n",
    "n_folds    = len([d for d in os.listdir(trained_oof_model_folder) if d.startswith('fold')])\n",
    "n_samples  = len(full_dataset)\n",
    "C          = 35\n",
    "BATCH_SIZE = 64\n",
    "start_fold = 0\n",
    "\n",
    "tile_dim = 128\n",
    "center_dim = 128\n",
    "neighbor_dim = 128\n",
    "fusion_dim = tile_dim + center_dim + neighbor_dim\n",
    "\n",
    "pretrained_ae_name = 'AE_Center_noaug'\n",
    "pretrained_ae_path = f\"AE_model/128/{pretrained_ae_name}/best.pt\"\n",
    "ae_type = 'center'\n",
    "\n",
    "# Ground truth label (å…¨ dataset)\n",
    "y_true = np.vstack([ full_dataset[i]['label'].cpu().numpy() for i in range(n_samples) ])\n",
    "\n",
    "# Build CV splitter (must match first stage splits)\n",
    "logo = LeaveOneGroupOut()\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "lgb_base = lgb.LGBMRegressor(\n",
    "    objective='l2',\n",
    "    metric='rmse',\n",
    "    learning_rate=0.007522970004049377,\n",
    "    n_estimators=12000,\n",
    "    max_depth=11,\n",
    "    num_leaves=20,\n",
    "    colsample_bytree=0.7619407413363416,\n",
    "    subsample=0.8,\n",
    "    subsample_freq=1,\n",
    "    min_data_in_leaf=20,\n",
    "    reg_alpha=0.7480401395491829,\n",
    "    reg_lambda=0.2589860348178542,\n",
    "    verbosity=-1\n",
    "    )\n",
    "\n",
    "slide_idx = np.array(grouped_data['slide_idx'])   # shape (N,)\n",
    "\n",
    "\n",
    "for fold_id, (tr_idx, va_idx) in enumerate(\n",
    "    logo.split(X=np.zeros(n_samples), y=None, groups=slide_idx)):\n",
    "\n",
    "    if fold_id > start_fold:\n",
    "        print(f\"â­ï¸ Skipping fold {fold_id}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nğŸš€ Starting fold {fold_id}...\")\n",
    "    ckpt_path = os.path.join(trained_oof_model_folder, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "\n",
    "    # === Load model and predict OOF ===\n",
    "    net = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net = net.to(device).eval()\n",
    "\n",
    "    val_ds = Subset(full_dataset, va_idx)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    preds, latents = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            tiles = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "            center = subtiles[:, 4].contiguous()\n",
    "\n",
    "            f_c = net.encoder_center(center)\n",
    "            f_n = net.encoder_subtile(subtiles)\n",
    "            f_t = net.encoder_tile(tiles)\n",
    "            fuse = torch.cat([f_c, f_n, f_t], dim=1).contiguous()\n",
    "            output = net.decoder(fuse)\n",
    "\n",
    "            preds.append(output.cpu())\n",
    "            latents.append(fuse.cpu())\n",
    "\n",
    "    preds = torch.cat(preds, dim=0).numpy()\n",
    "    latents = torch.cat(latents, dim=0).numpy()\n",
    "\n",
    "    # === AE model reconstruction loss ===\n",
    "    recon_model = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=pretrained_ae_path,\n",
    "        ae_type=ae_type,\n",
    "        tile_dim=tile_dim,\n",
    "        center_dim=center_dim,\n",
    "        neighbor_dim=neighbor_dim,\n",
    "        output_dim=C,\n",
    "        mode='reconstruction'\n",
    "    ).to(device)\n",
    "\n",
    "    meta = generate_meta_features(\n",
    "        dataset = val_ds,\n",
    "        oof_preds = preds,\n",
    "        image_latents = latents,\n",
    "        model_for_recon = recon_model,\n",
    "        device = device,\n",
    "        ae_type = ae_type,\n",
    "        use_clusters=\"4\"\n",
    "    )\n",
    "    \n",
    "    y_val = y_true[va_idx]   # shape = (len(va_idx), 35)\n",
    "\n",
    "    # 2) å†å°é€™å€‹ fold çš„ meta åš train/val åˆ‡åˆ†\n",
    "    X_train_tab, X_val_tab, y_train_tab, y_val_tab = train_test_split(\n",
    "        meta, y_val, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # 3) train MultiOutputRegressor with early stopping\n",
    "    meta_model = MultiOutputRegressor(lgb_base)\n",
    "    meta_model.estimators_ = []\n",
    "\n",
    "    for i in range(y_train_tab.shape[1]):\n",
    "        print(f\"[fold {fold_id}] training target {i} on meta features â€¦\")\n",
    "        model = lgb.LGBMRegressor(**lgb_base.get_params())\n",
    "        model.fit(\n",
    "            X_train_tab, y_train_tab[:, i],\n",
    "            eval_set=[(X_val_tab, y_val_tab[:, i])],\n",
    "            callbacks=[\n",
    "                early_stopping(stopping_rounds=200),\n",
    "                log_evaluation(period=100)\n",
    "            ]\n",
    "        )\n",
    "        meta_model.estimators_.append(model)\n",
    "\n",
    "    # 4) å­˜ä¸‹é€™å€‹ fold çš„ meta model\n",
    "    save_path = os.path.join(trained_oof_model_folder, f\"meta_model_fold{fold_id}.pkl\")\n",
    "    joblib.dump(meta_model, save_path)\n",
    "    print(f\"âœ… Saved fold {fold_id} metaâ€model â†’ {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/import_data.py:276: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  raw = torch.load(pt_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ å¾ '<class 'list'>' æ¨æ–·æ¨£æœ¬æ•¸é‡: 2088\n",
      "Model forward signature: (tile, subtiles)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from python_scripts.import_data import load_node_feature_data\n",
    "\n",
    "\n",
    "image_keys = [ 'tile', 'subtiles']\n",
    "\n",
    "model = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "\n",
    "# ç”¨æ³•ç¤ºä¾‹\n",
    "from python_scripts.import_data import importDataset\n",
    "# å‡è®¾ä½ çš„ model å·²ç»å®šä¹‰å¥½å¹¶å®ä¾‹åŒ–ä¸º `model`\n",
    "test_dataset = load_node_feature_data(\"dataset/spot-rank/filtered_directly_rank/masked/test/Macenko/test_dataset.pt\", model)\n",
    "test_dataset = importDataset(\n",
    "        data_dict=test_dataset,\n",
    "        model=model,\n",
    "        image_keys=image_keys,\n",
    "        transform=lambda x: x,  # identity transform\n",
    "        print_sig=True\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_35616/3793311050.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/pretrain_model.py:310: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ae.load_state_dict(torch.load(ae_checkpoint, map_location=\"cpu\"))\n",
      "Computing AE recon loss: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:02<00:00, 12.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score for k=2: 0.5554\n",
      "Silhouette score for k=3: 0.6321\n",
      "Silhouette score for k=4: 0.5934\n",
      "Silhouette score for k=5: 0.5564\n",
      "Silhouette score for k=6: 0.5140\n",
      "Selected best k=3 (score=0.6321)\n",
      "âœ… Generated meta-features with shape: (2088, 307)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 307 features, but LGBMRegressor is expecting 227 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m     meta_model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(meta_model_path)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# 2) ç”¨å‰›å‰›ç®—å‡ºçš„ meta features åšé æ¸¬\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m     final_preds \u001b[38;5;241m=\u001b[39m \u001b[43mmeta_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# --- Save submission ---\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mh5py\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/multioutput.py:306\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe base estimator should implement a predict method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 306\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(y)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/sklearn.py:1108\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LGBMNotFittedError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimator not fitted, call fit before exploiting the model.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (pd_DataFrame, dt_DataTable)):\n\u001b[0;32m-> 1108\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43m_LGBMValidateData\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 'y' being omitted = run scikit-learn's check_array() instead of check_X_y()\u001b[39;49;00m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#\u001b[39;49;00m\n\u001b[1;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Prevent scikit-learn from deleting or modifying attributes like 'feature_names_in_' and 'n_features_in_'.\u001b[39;49;00m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# These shouldn't be changed at predict() time.\u001b[39;49;00m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# allow any input type (this validation is done further down, in lgb.Dataset())\u001b[39;49;00m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# do not raise an error if Inf of NaN values are found (LightGBM handles these internally)\u001b[39;49;00m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# raise an error on 0-row inputs\u001b[39;49;00m\n\u001b[1;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# retrieve original params that possibly can be used in both training and prediction\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# and then overwrite them (considering aliases) with params that were passed directly in prediction\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m predict_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_params(stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2965\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m-> 2965\u001b[0m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2829\u001b[0m, in \u001b[0;36m_check_n_features\u001b[0;34m(estimator, X, reset)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m-> 2829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2830\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2831\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2832\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 307 features, but LGBMRegressor is expecting 227 features as input."
     ]
    }
   ],
   "source": [
    "# --- 3) Prepare test meta-features ---\n",
    "n_test = len(test_dataset)\n",
    "\n",
    "\n",
    "for fold_id in range(n_folds):\n",
    "    if fold_id > start_fold:\n",
    "        print(f\"â­ï¸ Skipping fold {fold_id}\")\n",
    "        continue\n",
    "    ckpt_path = os.path.join(trained_oof_model_folder, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.eval()\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_preds = []\n",
    "    test_latents = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            tiles = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "            center = subtiles[:, 4].contiguous()\n",
    "\n",
    "            f_c = net.encoder_center(center)\n",
    "            f_n = net.encoder_subtile(subtiles)\n",
    "            f_t = net.encoder_tile(tiles)\n",
    "            fuse = torch.cat([f_c, f_n, f_t], dim=1).contiguous()\n",
    "            output = net.decoder(fuse)\n",
    "\n",
    "            test_preds.append(output.cpu())\n",
    "            test_latents.append(fuse.cpu())\n",
    "\n",
    "\n",
    "    test_preds = torch.cat(test_preds, dim=0).numpy()\n",
    "    test_latents = torch.cat(test_latents, dim=0).numpy()\n",
    "# === AE model reconstruction loss ===\n",
    "    recon_model = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=pretrained_ae_path,\n",
    "        ae_type=ae_type,\n",
    "        tile_dim=tile_dim,\n",
    "        center_dim=center_dim,\n",
    "        neighbor_dim=neighbor_dim,\n",
    "        output_dim=C,\n",
    "        mode='reconstruction'\n",
    "    ).to(device)\n",
    "\n",
    "    meta = generate_meta_features(\n",
    "        dataset = test_dataset,\n",
    "        oof_preds = test_preds,\n",
    "        image_latents = test_latents,\n",
    "        model_for_recon = recon_model,\n",
    "        device = device,\n",
    "        ae_type = ae_type,\n",
    "        use_clusters=\"both\"\n",
    "    )\n",
    "    # 1) ç›´æ¥è¼‰å…¥æ•´å€‹ MultiOutputRegressor\n",
    "    meta_model_path = os.path.join(trained_oof_model_folder, f\"meta_model_fold{fold_id}.pkl\")\n",
    "    meta_model = joblib.load(meta_model_path)\n",
    "\n",
    "    # 2) ç”¨å‰›å‰›ç®—å‡ºçš„ meta features åšé æ¸¬\n",
    "    final_preds = meta_model.predict(meta)\n",
    "\n",
    "\n",
    "# --- Save submission ---\n",
    "import h5py\n",
    "import pandas as pd\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spot_ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"]))\n",
    "sub = pd.DataFrame(final_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, 'ID', test_spot_ids.index)\n",
    "sub.to_csv(os.path.join(trained_oof_model_folder, 'submission_stacked.csv'), index=False)\n",
    "print(f\"âœ… Saved stacked submission in {trained_oof_model_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Base model\n",
    "# lgb_base = lgb.LGBMRegressor(\n",
    "#     objective='l2',\n",
    "#     metric='rmse',\n",
    "#     n_estimators=12000,\n",
    "#     max_depth=15,\n",
    "#     learning_rate=0.008,\n",
    "#     num_leaves=32,\n",
    "#     colsample_bytree=0.25\n",
    "# )\n",
    "\n",
    "lgb_base = lgb.LGBMRegressor(\n",
    "    objective='l2',\n",
    "    metric='rmse',\n",
    "    learning_rate=0.007522970004049377,\n",
    "    n_estimators=12000,\n",
    "    max_depth=11,\n",
    "    num_leaves=194,\n",
    "    colsample_bytree=0.7619407413363416,\n",
    "    subsample=0.8,\n",
    "    subsample_freq=1,\n",
    "    min_data_in_leaf=20,\n",
    "    reg_alpha=0.7480401395491829,\n",
    "    reg_lambda=0.2589860348178542,\n",
    "    verbosity=-1\n",
    ")\n",
    "# å°‡æ¯å€‹ target åˆ†åˆ¥ early stopping\n",
    "meta_model = MultiOutputRegressor(lgb_base)\n",
    "\n",
    "print(\"Training LightGBM on OOF meta-features with early stopping...\")\n",
    "meta_model.estimators_ = []\n",
    "\n",
    "for i in range(y_train.shape[1]):\n",
    "    print(f\"Training target {i}...\")\n",
    "    model  = lgb.LGBMRegressor(\n",
    "        objective='l2',\n",
    "        metric='rmse',\n",
    "        learning_rate=0.007522970004049377,\n",
    "        n_estimators=12000,\n",
    "        max_depth=11,\n",
    "        num_leaves=194,\n",
    "        colsample_bytree=0.7619407413363416,\n",
    "        subsample=0.8,\n",
    "        subsample_freq=1,\n",
    "        min_data_in_leaf=20,\n",
    "        reg_alpha=0.7480401395491829,\n",
    "        reg_lambda=0.2589860348178542,\n",
    "        verbosity=-1\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train[:, i],\n",
    "        eval_set=[(X_val, y_val[:, i])],\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=200),\n",
    "            log_evaluation(period=100)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    meta_model.estimators_.append(model)\n",
    "\n",
    "# ä¿å­˜æ¨¡å‹\n",
    "joblib.dump(meta_model, os.path.join(save_root, 'meta_model.pkl'))\n",
    "\n",
    "\n",
    "# --- 3) Prepare test meta-features ---\n",
    "n_test = len(test_dataset)\n",
    "test_preds = []\n",
    "test_latents = []\n",
    "\n",
    "for fold_id in range(n_folds):\n",
    "    ckpt_path = os.path.join(save_root, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = True\n",
    "    )\n",
    "\n",
    "    net.decoder = nn.Sequential(\n",
    "        nn.Linear(64+64, 256),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "    )\n",
    "\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.eval()\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds = []\n",
    "    latents = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            tiles = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "\n",
    "            center = subtiles[:, 4].contiguous()\n",
    "            f_c = net.enc_center(center)\n",
    "            f_n = net.enc_neigh(subtiles)\n",
    "            fuse = torch.cat([f_c, f_n], dim=1)\n",
    "\n",
    "            out = net.decoder(fuse)\n",
    "\n",
    "            preds.append(out.cpu())\n",
    "            latents.append(fuse.cpu())  # image embedding (128D)\n",
    "\n",
    "    test_preds.append(torch.cat(preds, dim=0).numpy())      # shape: (n_test, 35)\n",
    "    test_latents.append(torch.cat(latents, dim=0).numpy())  # shape: (n_test, 128)\n",
    "\n",
    "# === Stack + Average ===\n",
    "test_preds = np.mean(np.stack(test_preds, axis=0), axis=0)      # (n_test, 35)\n",
    "test_latents = np.mean(np.stack(test_latents, axis=0), axis=0)  # (n_test, 128)\n",
    "\n",
    "with h5py.File(\"dataset/elucidata_ai_challenge_data.h5\", \"r\") as f:\n",
    "    test_spots = f[\"spots/Test\"]\n",
    "    spot_array = np.array(test_spots['S_7'])\n",
    "    df = pd.DataFrame(spot_array)\n",
    "\n",
    "xy = df[[\"x\", \"y\"]].to_numpy()  # shape: (n_test, 2)\n",
    "\n",
    "# åˆä½µç‚ºæœ€çµ‚ test meta features\n",
    "test_meta = np.concatenate([test_preds, xy, test_latents], axis=1)  # shape: (n_test, 35+2+128)\n",
    "\n",
    "\n",
    "\n",
    "final_preds = meta_model.predict(test_meta)\n",
    "\n",
    "# --- Save submission ---\n",
    "import h5py\n",
    "import pandas as pd\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spot_ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"]))\n",
    "sub = pd.DataFrame(final_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, 'ID', test_spot_ids.index)\n",
    "sub.to_csv(os.path.join(save_root, 'submission_stacked.csv'), index=False)\n",
    "print(f\"âœ… Saved stacked submission in {save_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import rankdata\n",
    "from python_scripts.import_data import importDataset\n",
    "from python_scripts.operate_model import predict\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import h5py\n",
    "import pandas as pd\n",
    "# ---------------- Settings ----------------\n",
    "save_root  = save_folder  # your save_folder path\n",
    "n_folds    = len([d for d in os.listdir(save_root) if d.startswith('fold')])\n",
    "n_samples  = len(full_dataset)\n",
    "C          = 35  # num cell types\n",
    "start_fold = 0\n",
    "BATCH_SIZE = 64\n",
    "# If optimizing Spearman, convert labels to ranks\n",
    "\n",
    "# --- 1) Prepare OOF meta-features ---\n",
    "# Initialize matrix for OOF predictions\n",
    "n_samples = len(full_dataset)\n",
    "oof_preds = np.zeros((n_samples, C), dtype=np.float32)\n",
    "# True labels (raw or rank)\n",
    "# importDataset returns a dict-like sample, so label is under key 'label'\n",
    "y_true = np.vstack([ full_dataset[i]['label'].cpu().numpy() for i in range(n_samples) ])\n",
    "y_meta = y_true\n",
    "\n",
    "# Build CV splitter (must match first stage splits)\n",
    "logo = LeaveOneGroupOut()\n",
    "image_latents = np.zeros((n_samples, 128), dtype=np.float32)\n",
    "\n",
    "# Loop over folds, load best model, predict on validation indices\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "for fold_id, (tr_idx, va_idx) in enumerate(\n",
    "        logo.split(X=np.zeros(n_samples), y=None, groups=slide_idx)):\n",
    "    # Load model\n",
    "    # if fold_id > start_fold:\n",
    "    #     print(f\"â­ï¸ Skipping fold {fold_id}\")\n",
    "    #     continue\n",
    "    ckpt_path = os.path.join(save_root, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    print(f\"Loading model from {ckpt_path}...\")\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = True\n",
    "    )\n",
    "\n",
    "    # 2) monkeyâ€patch ä¸€ä¸ªæ–°çš„ head\n",
    "    net.decoder  = nn.Sequential(\n",
    "        nn.Linear(64+64, 256),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "        \n",
    "    )\n",
    "    net = net.to(device)    # Alternatively, if your model requires specific args, replace with:\n",
    "    # net = VisionMLP_MultiTask(tile_dim=64, subtile_dim=64, output_dim=35).to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.to(device).eval()\n",
    "    \n",
    "    # Predict on validation set\n",
    "    val_ds = Subset(full_dataset, va_idx)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    preds = []\n",
    "    latents = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            tiles    = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "\n",
    "            center = subtiles[:, 4].contiguous()\n",
    "            f_c = net.enc_center(center)\n",
    "            f_n = net.enc_neigh(subtiles)\n",
    "            fuse = torch.cat([f_c, f_n], dim=1)\n",
    "\n",
    "            output = net.decoder(fuse)\n",
    "\n",
    "            preds.append(output.cpu())\n",
    "            latents.append(fuse.cpu())  # â¬…ï¸ æ”¶é›† latent vector\n",
    "\n",
    "    preds = torch.cat(preds, dim=0).numpy()    # (n_val, 35)\n",
    "    latents = torch.cat(latents, dim=0).numpy()  # (n_val, 128)\n",
    "\n",
    "    oof_preds[va_idx] = preds\n",
    "    image_latents[va_idx] = latents\n",
    "\n",
    "    print(f\"Fold {fold_id}: OOF preds shape {preds.shape}, Latent shape: {latents.shape}\")\n",
    "\n",
    "\n",
    "    \n",
    "with h5py.File(\"dataset/realign/filtered_dataset.h5\", \"r\") as f:\n",
    "    train_spots = f[\"spots/Train\"]\n",
    "    \n",
    "    train_spot_tables = {}\n",
    "    \n",
    "    for slide_name in train_spots.keys():\n",
    "        spot_array = np.array(train_spots[slide_name])\n",
    "        df = pd.DataFrame(spot_array)\n",
    "        df[\"slide_name\"] = slide_name\n",
    "        train_spot_tables[slide_name] = df\n",
    "        print(f\"âœ… å·²è®€å– slide: {slide_name}\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 2: åˆä½µæ‰€æœ‰ slide çš„è³‡æ–™\n",
    "# -----------------------------------------------------\n",
    "all_train_spots_df = pd.concat(train_spot_tables.values(), ignore_index=True)\n",
    "# æå– x, y\n",
    "xy = all_train_spots_df[[\"x\", \"y\"]].to_numpy()  # shape: (8348, 2)\n",
    "\n",
    "# åˆä½µæˆæ–°çš„ meta feature\n",
    "meta_features = np.concatenate([oof_preds, xy, image_latents], axis=1)\n",
    "# --- 2) Train LightGBM meta-model ---\n",
    "# Choose objective: regression on rank (for Spearman) or raw (for MSE)\n",
    "# å°‡ meta features æ‹†æˆè¨“ç·´é›†èˆ‡ early stopping ç”¨çš„é©—è­‰é›†\n",
    "X_train, X_val, y_train, y_val = train_test_split(meta_features, y_meta, test_size=0.2, random_state=42)\n",
    "print(\"Meta feature shape:\", X_train.shape)\n",
    "print(\"Feature std (min/max):\", np.min(np.std(X_train, axis=0)), np.max(np.std(X_train, axis=0)))\n",
    "\n",
    "\n",
    "# # Base model\n",
    "# lgb_base = lgb.LGBMRegressor(\n",
    "#     objective='l2',\n",
    "#     metric='rmse',\n",
    "#     n_estimators=12000,\n",
    "#     max_depth=15,\n",
    "#     learning_rate=0.008,\n",
    "#     num_leaves=32,\n",
    "#     colsample_bytree=0.25\n",
    "# )\n",
    "import optuna\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define Optuna objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'device': 'gpu',                # âœ… GPU æ”¯æ´\n",
    "        'gpu_platform_id': 0,\n",
    "        'gpu_device_id': 0,\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.005, 0.1),\n",
    "        'max_depth': trial.suggest_int(\"max_depth\", 4, 15),\n",
    "        'num_leaves': trial.suggest_int(\"num_leaves\", 32, 256),\n",
    "        'min_data_in_leaf': trial.suggest_int(\"min_data_in_leaf\", 20, 100),\n",
    "        'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float(\"reg_alpha\", 0, 1),\n",
    "        'reg_lambda': trial.suggest_float(\"reg_lambda\", 0, 1),\n",
    "        'n_estimators': 12000\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    multi_model = MultiOutputRegressor(model)\n",
    "    multi_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = multi_model.predict(X_val)\n",
    "    rmse = np.mean([\n",
    "        np.sqrt(mean_squared_error(y_val[:, i], y_pred[:, i]))\n",
    "        for i in range(y_val.shape[1])\n",
    "    ])\n",
    "\n",
    "\n",
    "    return rmse\n",
    "\n",
    "# Run optimization\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Use best params to train final models\n",
    "best_params = study.best_trial.params\n",
    "best_params['objective'] = 'l2'\n",
    "best_params['metric'] = 'rmse'\n",
    "best_params['verbosity'] = -1\n",
    "\n",
    "# Train final models with best parameters\n",
    "meta_model = MultiOutputRegressor(lgb.LGBMRegressor(**best_params))\n",
    "meta_model.estimators_ = []\n",
    "\n",
    "print(\"Training LightGBM on OOF meta-features with best Optuna params...\")\n",
    "for i in range(y_train.shape[1]):\n",
    "    print(f\"Training target {i}...\")\n",
    "    model = lgb.LGBMRegressor(**best_params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train[:, i],\n",
    "        eval_set=[(X_val, y_val[:, i])],\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=200),\n",
    "            log_evaluation(period=100)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    meta_model.estimators_.append(model)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(meta_model, os.path.join(save_root, 'meta_model.pkl'))\n",
    "# ä¿å­˜æ¨¡å‹\n",
    "\n",
    "\n",
    "# --- 3) Prepare test meta-features ---\n",
    "n_test = len(test_dataset)\n",
    "test_preds = []\n",
    "test_latents = []\n",
    "\n",
    "for fold_id in range(n_folds):\n",
    "    ckpt_path = os.path.join(save_root, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = True\n",
    "    )\n",
    "\n",
    "    net.decoder = nn.Sequential(\n",
    "        nn.Linear(64+64, 256),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "    )\n",
    "\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.eval()\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds = []\n",
    "    latents = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            tiles = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "\n",
    "            center = subtiles[:, 4].contiguous()\n",
    "            f_c = net.enc_center(center)\n",
    "            f_n = net.enc_neigh(subtiles)\n",
    "            fuse = torch.cat([f_c, f_n], dim=1)\n",
    "\n",
    "            out = net.decoder(fuse)\n",
    "\n",
    "            preds.append(out.cpu())\n",
    "            latents.append(fuse.cpu())  # image embedding (128D)\n",
    "\n",
    "    test_preds.append(torch.cat(preds, dim=0).numpy())      # shape: (n_test, 35)\n",
    "    test_latents.append(torch.cat(latents, dim=0).numpy())  # shape: (n_test, 128)\n",
    "\n",
    "# === Stack + Average ===\n",
    "test_preds = np.mean(np.stack(test_preds, axis=0), axis=0)      # (n_test, 35)\n",
    "test_latents = np.mean(np.stack(test_latents, axis=0), axis=0)  # (n_test, 128)\n",
    "\n",
    "with h5py.File(\"dataset/elucidata_ai_challenge_data.h5\", \"r\") as f:\n",
    "    test_spots = f[\"spots/Test\"]\n",
    "    spot_array = np.array(test_spots['S_7'])\n",
    "    df = pd.DataFrame(spot_array)\n",
    "\n",
    "xy = df[[\"x\", \"y\"]].to_numpy()  # shape: (n_test, 2)\n",
    "\n",
    "# åˆä½µç‚ºæœ€çµ‚ test meta features\n",
    "test_meta = np.concatenate([test_preds, xy, test_latents], axis=1)  # shape: (n_test, 35+2+128)\n",
    "\n",
    "\n",
    "\n",
    "final_preds = meta_model.predict(test_meta)\n",
    "\n",
    "# --- Save submission ---\n",
    "import h5py\n",
    "import pandas as pd\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spot_ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"]))\n",
    "sub = pd.DataFrame(final_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, 'ID', test_spot_ids.index)\n",
    "sub.to_csv(os.path.join(save_root, 'submission_stacked.csv'), index=False)\n",
    "print(\"âœ… Saved stacked submission.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import rankdata\n",
    "from python_scripts.import_data import importDataset\n",
    "from python_scripts.operate_model import predict\n",
    "\n",
    "# --- é…ç½®: åªç”¨å“ªäº› fold çš„ç»“æœæ¥è®­ç»ƒ/é¢„æµ‹ meta-model ---\n",
    "meta_folds = [0]  # ä¾‹å¦‚åªç”¨ fold0, fold2, fold4\n",
    "\n",
    "# 1) å‡†å¤‡ full_dataset, slide_idx, test_dataset ç­‰\n",
    "full_dataset = importDataset(\n",
    "    grouped_data, model,\n",
    "    image_keys=['tile','subtiles'],\n",
    "    transform=lambda x: x\n",
    ")\n",
    "n_samples = len(full_dataset)\n",
    "C = 35  # ç±»åˆ«æ•°\n",
    "\n",
    "# 2) é¢„ç•™ oof_preds å’Œ fold_ids\n",
    "oof_preds    = np.zeros((n_samples, C), dtype=np.float32)\n",
    "oof_fold_ids = np.full(n_samples, -1, dtype=int)\n",
    "\n",
    "# çœŸæ ‡ç­¾\n",
    "y_true = np.vstack([ full_dataset[i]['label'].cpu().numpy() for i in range(n_samples) ])\n",
    "y_meta = y_true.copy()  # ä¸åš rank æ—¶ç›´æ¥ç”¨ raw\n",
    "\n",
    "# 3) ç”Ÿæˆ OOF é¢„æµ‹å¹¶è®°å½• fold id\n",
    "logo = LeaveOneGroupOut()\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "for fold_id, (tr_idx, va_idx) in enumerate(\n",
    "        logo.split(X=np.zeros(n_samples), y=None, groups=slide_idx)):\n",
    "\n",
    "    # å¦‚æœå½“å‰ fold ä¸åœ¨æˆ‘ä»¬æƒ³è¦çš„ meta_folds åˆ—è¡¨é‡Œï¼Œå°±è·³è¿‡\n",
    "    if fold_id not in meta_folds:\n",
    "        print(f\"â­ï¸ Skipping OOF for fold {fold_id}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n>>> Generating OOF for fold {fold_id}\")\n",
    "    ckpt_path = os.path.join(save_root, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = True\n",
    "    )\n",
    "\n",
    "    # 2) monkeyâ€patch ä¸€ä¸ªæ–°çš„ head\n",
    "    net.decoder  = nn.Sequential(\n",
    "        nn.Linear(64+64, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "        \n",
    "    )\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.eval()\n",
    "\n",
    "    val_loader = DataLoader(Subset(full_dataset, va_idx), batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds = predict(net, val_loader, device)  # (n_val, C)\n",
    "\n",
    "    oof_preds[va_idx]    = preds\n",
    "    oof_fold_ids[va_idx] = fold_id\n",
    "\n",
    "    print(f\"  â†’ Fold {fold_id} OOF preds shape: {preds.shape}\")\n",
    "# 4) åªé€‰å– meta_folds çš„è¡Œæ¥è®­ç»ƒ meta-model\n",
    "mask = np.isin(oof_fold_ids, meta_folds)\n",
    "X_meta = oof_preds[mask]\n",
    "y_meta_sub = y_meta[mask]\n",
    "\n",
    "print(f\"\\nTraining meta-model on folds {meta_folds}:\")\n",
    "print(f\"  ä½¿ç”¨æ ·æœ¬æ•°ï¼š{X_meta.shape[0]} / {n_samples}\")\n",
    "\n",
    "lgb_base = lgb.LGBMRegressor(\n",
    "    objective='regression',\n",
    "    learning_rate=0.001,\n",
    "    n_estimators=1000,\n",
    "    num_leaves=31,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    n_jobs=-1,\n",
    "    force_col_wise=True\n",
    ")\n",
    "meta_model = MultiOutputRegressor(lgb_base)\n",
    "meta_model.fit(X_meta, y_meta_sub)\n",
    "joblib.dump(meta_model, os.path.join(save_root, 'meta_model.pkl'))\n",
    "\n",
    "# 5) å‡†å¤‡ test_metaï¼Œåªå¹³å‡ meta_folds ä¸­çš„é¢„æµ‹\n",
    "n_folds = len([d for d in os.listdir(save_root) if d.startswith('fold')])\n",
    "n_test  = len(test_dataset)\n",
    "test_meta = np.zeros((n_test, C), dtype=np.float32)\n",
    "\n",
    "for fold_id in range(n_folds):\n",
    "    if fold_id not in meta_folds:\n",
    "        continue\n",
    "    ckpt_path = os.path.join(save_root, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = True\n",
    "    )\n",
    "\n",
    "    # 2) monkeyâ€patch ä¸€ä¸ªæ–°çš„ head\n",
    "    net.decoder  = nn.Sequential(\n",
    "        nn.Linear(64+64, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "        \n",
    "    )\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.eval()\n",
    "\n",
    "    loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds = predict(net, loader, device)\n",
    "    test_meta += preds\n",
    "\n",
    "# å¹³å‡æ—¶é™¤ä»¥å‚ä¸çš„ folds æ•°ç›®\n",
    "test_meta /= len(meta_folds)\n",
    "\n",
    "# 6) ç”¨ meta-model åšæœ€ç»ˆé¢„æµ‹\n",
    "final_preds = meta_model.predict(test_meta)\n",
    "\n",
    "# --- Save submission ---\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spot_ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"]))\n",
    "\n",
    "sub = pd.DataFrame(final_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, 'ID', test_spot_ids.index)\n",
    "sub.to_csv(os.path.join(save_root, 'submission_stacked.csv'), index=False)\n",
    "print(\"âœ… Saved stacked submission.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import inspect\n",
    "from python_scripts.operate_model import get_model_inputs\n",
    "from python_scripts.import_data import load_node_feature_data\n",
    "\n",
    "\n",
    "image_keys = [ 'tile', 'subtiles']\n",
    "\n",
    "\n",
    "# ç”¨æ³•ç¤ºä¾‹\n",
    "from python_scripts.import_data import importDataset\n",
    "# å‡è®¾ä½ çš„ model å·²ç»å®šä¹‰å¥½å¹¶å®ä¾‹åŒ–ä¸º `model`\n",
    "test_dataset = load_node_feature_data(\"dataset/spot-rank/filtered_directly_rank/masked/test/Macenko/test_dataset.pt\", model)\n",
    "test_dataset = importDataset(\n",
    "        data_dict=test_dataset,\n",
    "        model=model,\n",
    "        image_keys=image_keys,\n",
    "        transform=lambda x: x,  # identity transform\n",
    "        print_sig=True\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset.check_item(1000, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# è®€ test spot index\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spots     = f[\"spots/Test\"]\n",
    "    test_spot_table= pd.DataFrame(np.array(test_spots['S_7']))\n",
    "\n",
    "fold_ckpts = sorted(glob.glob(os.path.join(save_folder, \"fold*\", \"best_model.pt\")))\n",
    "models = []\n",
    "for ckpt in fold_ckpts:\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = False\n",
    "    )\n",
    "\n",
    "    # 2) monkeyâ€patch ä¸€ä¸ªæ–°çš„ head\n",
    "    net.decoder  = nn.Sequential(\n",
    "        nn.Linear(64+64, 256),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "        \n",
    "    )\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt, map_location=\"cpu\"))\n",
    "    net.to(device).eval()\n",
    "    models.append(net)\n",
    "\n",
    "all_fold_preds = []\n",
    "for fold_id, net in enumerate(models):\n",
    "    # æ¨è«–\n",
    "    with torch.no_grad():\n",
    "        preds = predict(net, test_loader, device)  # (N_test,35) numpy array\n",
    "\n",
    "    # 1) å­˜æ¯ä¸€æŠ˜çš„åŸå§‹é æ¸¬\n",
    "    df_fold = pd.DataFrame(preds, columns=[f\"C{i+1}\" for i in range(preds.shape[1])])\n",
    "    df_fold.insert(0, \"ID\", test_spot_table.index)\n",
    "    path_fold = os.path.join(save_folder, f\"submission_fold{fold_id}.csv\")\n",
    "    df_fold.to_csv(path_fold, index=False)\n",
    "    print(f\"âœ… Saved fold {fold_id} predictions to {path_fold}\")\n",
    "\n",
    "    all_fold_preds.append(preds)\n",
    "\n",
    "# 2) åš rankâ€average ensemble\n",
    "all_fold_preds = np.stack(all_fold_preds, axis=0)       # (K, N_test, 35)\n",
    "ranks          = all_fold_preds.argsort(axis=2).argsort(axis=2).astype(float)\n",
    "mean_rank      = ranks.mean(axis=0)                    # (N_test,35)\n",
    "\n",
    "# 3) å­˜ final ensemble\n",
    "df_ens = pd.DataFrame(mean_rank, columns=[f\"C{i+1}\" for i in range(mean_rank.shape[1])])\n",
    "df_ens.insert(0, \"ID\", test_spot_table.index)\n",
    "path_ens = os.path.join(save_folder, \"submission_rank_ensemble.csv\")\n",
    "df_ens.to_csv(path_ens, index=False)\n",
    "print(f\"âœ… Saved rankâ€ensemble submission to {path_ens}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatialhackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
