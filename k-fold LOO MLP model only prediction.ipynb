{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable / total params = 6,679,843 / 6,679,843\n",
      "Trainable / total params = 6,679,843 / 6,679,843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionMLP_MultiTask(\n",
       "  (encoder_tile): DeepTileEncoder(\n",
       "    (layer0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU()\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "    )\n",
       "    (global_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (mid_pool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
       "    (fc): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=2560, out_features=512, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "      (5): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (6): LeakyReLU(negative_slope=0.01)\n",
       "      (7): Dropout(p=0.1, inplace=False)\n",
       "      (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (encoder_subtile): SubtileEncoder(\n",
       "    (layer0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU()\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "    )\n",
       "    (global_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (mid_pool): AdaptiveAvgPool2d(output_size=(2, 2))\n",
       "    (large_pool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
       "    (fc): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=1792, out_features=256, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "      (5): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (6): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (encoder_center): CenterSubtileEncoder(\n",
       "    (layer0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU()\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "    )\n",
       "    (global_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (mid_pool): AdaptiveAvgPool2d(output_size=(2, 2))\n",
       "    (large_pool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
       "    (fc): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=1792, out_features=256, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "      (5): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (6): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=256, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): Dropout(p=0.1, inplace=False)\n",
       "    (9): Linear(in_features=64, out_features=35, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(out_channels)\n",
    "        self.act1  = nn.SiLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        self.act2 = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.act1(self.bn1(self.conv1(x)))\n",
    "        out = self.act2(self.bn2(self.conv2(out)))\n",
    "        if self.shortcut is not None:\n",
    "            identity = self.shortcut(x)\n",
    "        return out + identity\n",
    "\n",
    "\n",
    "\n",
    "class DeepTileEncoder(nn.Module):\n",
    "    \"\"\"Âä†Ê∑±ÁöÑ Tile ÂàÜÊîØÔºöÂÖ®Â±Ä‰ø°ÊÅØÔºåÂ§öÂ∞∫Â∫¶Ê±†Âåñ + ‰∏âÂ±Ç MLP\"\"\"\n",
    "    def __init__(self, out_dim, in_channels=3, negative_slope=0.01):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(2)  # 78‚Üí39\n",
    "        )\n",
    "        self.layer1 = nn.Sequential(\n",
    "            ResidualBlock(32, 64),\n",
    "            ResidualBlock(64, 64),\n",
    "            nn.MaxPool2d(2)  # 39‚Üí19\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            ResidualBlock(64, 128),\n",
    "            ResidualBlock(128, 128),\n",
    "            nn.MaxPool2d(2)  # 19‚Üí9\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            ResidualBlock(128, 256),\n",
    "            ResidualBlock(256, 256)\n",
    "        )  # ‰øùÊåÅ 9√ó9\n",
    "\n",
    "        # Â§öÂ∞∫Â∫¶Ê±†Âåñ\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))  # [B,256,1,1]\n",
    "        self.mid_pool    = nn.AdaptiveAvgPool2d((3, 3))  # [B,256,3,3]\n",
    "\n",
    "        total_dim = 256*1*1 + 256*3*3\n",
    "        # ‰∏âÂ±Ç MLPÔºötotal_dim ‚Üí 2*out_dim ‚Üí out_dim ‚Üí out_dim\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(total_dim, out_dim*4),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(out_dim*4, out_dim*2),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(out_dim*2, out_dim),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        # x: [B,256,9,9]\n",
    "        g = self.global_pool(x).contiguous().reshape(x.size(0), -1)  # [B,256]\n",
    "        m = self.mid_pool(x).contiguous().reshape(x.size(0), -1)     # [B,256*3*3]\n",
    "\n",
    "        return self.fc(torch.cat([g, m], dim=1))\n",
    "\n",
    "\n",
    "class SubtileEncoder(nn.Module):\n",
    "    \"\"\"Â§öÂ∞∫Â∫¶ Subtile ÂàÜÊîØÔºöÂ±ÄÈÉ®‰ø°ÊÅØ + ‰∏§Â±Ç MLP\"\"\"\n",
    "    def __init__(self, out_dim, in_channels=3, negative_slope=0.01):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(2)  # 26‚Üí13\n",
    "        )\n",
    "        self.layer1 = nn.Sequential(\n",
    "            ResidualBlock(32, 64),\n",
    "            ResidualBlock(64, 64),\n",
    "            nn.MaxPool2d(2)  # 13‚Üí6\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            ResidualBlock(64, 128),\n",
    "            ResidualBlock(128, 128)\n",
    "        )  # ‰øùÊåÅ 6√ó6\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.mid_pool    = nn.AdaptiveAvgPool2d((2,2))\n",
    "        self.large_pool    = nn.AdaptiveAvgPool2d((3,3))\n",
    "\n",
    "        total_dim = 128*1*1 + 128*2*2 + 128*3*3\n",
    "        # ‰∏§Â±Ç MLPÔºötotal_dim ‚Üí out_dim*2 ‚Üí out_dim\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(total_dim, out_dim*2),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(out_dim*2, out_dim),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C, H, W = x.shape\n",
    "        x = x.contiguous().reshape(B*N, C, H, W)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        # g,m: [B*N, feat]\n",
    "        g = self.global_pool(x).contiguous().reshape(B, N, -1)\n",
    "        m = self.mid_pool(x).contiguous().reshape(B, N, -1)\n",
    "        l = self.large_pool(x).contiguous().reshape(B, N, -1)\n",
    "\n",
    "        # ÂêàÂπ∂ N Âº† subtilesÔºåÂÜç FC\n",
    "        feat = torch.cat([g, m, l], dim=2).mean(dim=1).contiguous()  # [B, total_dim]\n",
    "        return self.fc(feat)\n",
    "class CenterSubtileEncoder(nn.Module):\n",
    "    \"\"\"Â∞àÈñÄËôïÁêÜ‰∏≠ÂøÉ subtile ÁöÑ Encoder\"\"\"\n",
    "    def __init__(self, out_dim, in_channels=3, negative_slope= 0.01):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(2)  # 26‚Üí13\n",
    "        )\n",
    "        self.layer1 = nn.Sequential(\n",
    "            ResidualBlock(32, 64),\n",
    "            ResidualBlock(64, 64),\n",
    "            nn.MaxPool2d(2)  # 13‚Üí6\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            ResidualBlock(64, 128),\n",
    "            ResidualBlock(128, 128)\n",
    "        )  # 6√ó6\n",
    "\n",
    "        # Â§öÂ∞∫Â∫¶Ê±†Âåñ\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.mid_pool    = nn.AdaptiveAvgPool2d((2,2))\n",
    "        self.large_pool    = nn.AdaptiveAvgPool2d((3,3))\n",
    "\n",
    "        total_dim = 128*1*1 + 128*2*2 + 128*3*3\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(total_dim, out_dim*2),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(out_dim*2, out_dim),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        g = self.global_pool(x).contiguous().reshape(x.size(0), -1)\n",
    "        m = self.mid_pool(x).contiguous().reshape(x.size(0), -1)\n",
    "        l = self.large_pool(x).contiguous().reshape(x.size(0), -1)\n",
    "\n",
    "        return self.fc(torch.cat([g, m, l], dim=1)).contiguous()\n",
    "\n",
    "\n",
    "\n",
    "class VisionMLP_MultiTask(nn.Module):\n",
    "    \"\"\"Êï¥È´îÂ§ö‰ªªÂãôÊ®°ÂûãÔºöËûçÂêà tile + subtile + centerÔºå‰ΩøÁî®ÂãïÊÖãÊ¨äÈáçËûçÂêà\"\"\"\n",
    "    def __init__(self, tile_dim=128, subtile_dim=64, output_dim=35, negative_slope=0.01):\n",
    "        super().__init__()\n",
    "        self.encoder_tile    = DeepTileEncoder(tile_dim)\n",
    "        self.encoder_subtile = SubtileEncoder(subtile_dim)\n",
    "        self.encoder_center  = CenterSubtileEncoder(subtile_dim)\n",
    "\n",
    "        # Ëº∏Âá∫ decoderÔºöËº∏ÂÖ•ÁÇ∫ tile_dim (Âõ†ÁÇ∫ËûçÂêàÂæåÂè™Ââ©‰∏ÄÂÄã vector)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(tile_dim + subtile_dim + subtile_dim , 256),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, tile, subtiles):\n",
    "        tile = tile.contiguous()\n",
    "        subtiles = subtiles.contiguous()\n",
    "        center = subtiles[:, 4]\n",
    "\n",
    "        f_tile = self.encoder_tile(tile)         # [B, tile_dim]\n",
    "        f_sub  = self.encoder_subtile(subtiles)  # [B, subtile_dim]\n",
    "        f_center = self.encoder_center(center)   # [B, subtile_dim]\n",
    "\n",
    "        # ÊãºÊé•‰∏âÂÄãÂàÜÊîØÂÅö gating\n",
    "        features_cat = torch.cat([f_tile, f_sub, f_center], dim=1)  # [B, tile+sub+center]\n",
    "        return self.decoder(features_cat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Áî®Ê≥ïÁ§∫‰æã\n",
    "model = VisionMLP_MultiTask(tile_dim=128, subtile_dim=128, output_dim=35)\n",
    "\n",
    "\n",
    "# ‚Äî‚Äî 5) Á°Æ‰øùÂè™Êúâ decoder ÂèØËÆ≠ÁªÉ ‚Äî‚Äî  \n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total     = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Trainable / total params = {trainable:,} / {total:,}\")\n",
    "\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total     = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Trainable / total params = {trainable:,} / {total:,}\")\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same in multiple .pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/import_data.py:251: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d = torch.load(fpath, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded keys: dict_keys(['source_idx', 'position', 'slide_idx', 'subtiles', 'tile', 'label'])\n",
      "Samples: 8348\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import inspect\n",
    "from python_scripts.import_data import load_all_tile_data\n",
    "\n",
    "# Áî®Ê≥ïÁØÑ‰æã\n",
    "#folder = \"dataset/spot-rank/version-3/only_tile_sub/original_train\"\n",
    "folder = \"dataset/spot-rank/filtered_directly_rank/masked/realign/Macenko_4_7_masked/filtered/train_data/\"\n",
    "\n",
    "grouped_data = load_all_tile_data( \n",
    "        folder_path=folder,\n",
    "        model=model,\n",
    "        fraction=1,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # grouped_data ÁèæÂú®Âè™ÊúÉÊúâ model.forward() ÈúÄË¶ÅÁöÑ keyÔºå\n",
    "    # ÂÉè ['tile','subtiles','neighbors','norm_coord','node_feat','adj_list','edge_feat','label','source_idx']\n",
    "print(\"Loaded keys:\", grouped_data.keys())\n",
    "print(\"Samples:\", len(next(iter(grouped_data.values()))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking dataset sample: 0\n",
      "üìè tile shape: torch.Size([3, 78, 78]) | dtype: torch.float32 | min: 0.129, max: 1.000, mean: 0.653, std: 0.150\n",
      "üìè subtiles shape: torch.Size([9, 3, 26, 26]) | dtype: torch.float32 | min: 0.129, max: 1.000, mean: 0.653, std: 0.150\n",
      "üìè label shape: torch.Size([35]) | dtype: torch.float32 | min: 1.000, max: 35.000, mean: 18.000, std: 10.247\n",
      "--- label head (Ââç 5 ÂÄãÂÖÉÁ¥†):\n",
      "tensor([12., 24., 18.,  6., 30.])\n",
      "üìè source_idx shape: torch.Size([]) | dtype: torch.int64 | min: 0.000, max: 0.000, mean: 0.000, std: nan\n",
      "--- source_idx Ë≥áÊñôÁÇ∫Á¥îÈáè: tensor(0)\n",
      "üìè position shape: torch.Size([2]) | dtype: torch.float32 | min: 0.171, max: 0.632, mean: 0.401, std: 0.326\n",
      "--- position head (Ââç 5 ÂÄãÂÖÉÁ¥†):\n",
      "tensor([0.6318, 0.1707])\n",
      "‚úÖ All checks passed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/3062057575.py:79: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/miniforge3/conda-bld/libtorch_1744320376245/work/aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
      "  std = tensor_float.std().item()\n"
     ]
    }
   ],
   "source": [
    "from python_scripts.import_data import convert_item, get_model_inputs\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import inspect\n",
    "import numpy as np\n",
    "\n",
    "class importDataset(Dataset):\n",
    "    def __init__(self, data_dict, model, image_keys=None, transform=None, print_sig=False):\n",
    "        self.data = data_dict\n",
    "        self.image_keys = set(image_keys) if image_keys is not None else set()\n",
    "        self.transform = transform if transform is not None else lambda x: x\n",
    "        self.forward_keys = list(get_model_inputs(model, print_sig=print_sig).parameters.keys())\n",
    "\n",
    "        expected_length = None\n",
    "        for key, value in self.data.items():\n",
    "            if expected_length is None:\n",
    "                expected_length = len(value)\n",
    "            if len(value) != expected_length:\n",
    "                raise ValueError(f\"Ë≥áÊñôÊ¨Ñ‰Ωç '{key}' ÁöÑÈï∑Â∫¶ ({len(value)}) ËàáÈ†êÊúü ({expected_length}) ‰∏ç‰∏ÄËá¥„ÄÇ\")\n",
    "\n",
    "        for key in self.forward_keys:\n",
    "            if key not in self.data:\n",
    "                raise ValueError(f\"data_dict Áº∫Â∞ëÊ®°Âûã forward ÊâÄÈúÄÊ¨Ñ‰Ωç: '{key}'„ÄÇÁõÆÂâçÂèØÁî®ÁöÑÊ¨Ñ‰Ωç: {list(self.data.keys())}\")\n",
    "        if \"label\" not in self.data:\n",
    "            raise ValueError(f\"data_dict ÂøÖÈ†àÂåÖÂê´ 'label' Ê¨Ñ‰Ωç„ÄÇÂèØÁî®ÁöÑÊ¨Ñ‰Ωç: {list(self.data.keys())}\")\n",
    "        if \"source_idx\" not in self.data:\n",
    "            raise ValueError(\"data_dict ÂøÖÈ†àÂåÖÂê´ 'source_idx' Ê¨Ñ‰ΩçÔºåÁî®Êñº trace ÂéüÂßãÈ†ÜÂ∫èÂ∞çÊáâ„ÄÇ\")\n",
    "        if \"position\" not in self.data:\n",
    "            raise ValueError(\"data_dict ÂøÖÈ†àÂåÖÂê´ 'position' Ê¨Ñ‰ΩçÔºåÁî®Êñº trace ÂéüÂßãÈ†ÜÂ∫èÂ∞çÊáâ„ÄÇ\")\n",
    "    def __len__(self):\n",
    "        return len(next(iter(self.data.values())))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {}\n",
    "        for key in self.forward_keys:\n",
    "            value = self.data[key][idx]\n",
    "            value = self.transform(value)\n",
    "            value = convert_item(value, is_image=(key in self.image_keys))\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                value = value.float()\n",
    "            sample[key] = value\n",
    "\n",
    "        label = self.transform(self.data[\"label\"][idx])\n",
    "        label = convert_item(label, is_image=False)\n",
    "        if isinstance(label, torch.Tensor):\n",
    "            label = label.float()\n",
    "        sample[\"label\"] = label\n",
    "\n",
    "        # Âä†ÂÖ• source_idx\n",
    "        source_idx = self.data[\"source_idx\"][idx]\n",
    "        sample[\"source_idx\"] = torch.tensor(source_idx, dtype=torch.long)\n",
    "        # Âä†ÂÖ• position ÔºàÂÅáËÆæ data_dict ‰∏≠ 'position' ÊòØ (x, y) Êàñ [x, y]Ôºâ\n",
    "        pos = self.data[\"position\"][idx]\n",
    "        sample[\"position\"] = torch.tensor(pos, dtype=torch.float)\n",
    "        return sample\n",
    "    def check_item(self, idx=0, num_lines=5):\n",
    "        expected_keys = self.forward_keys + ['label', 'source_idx', 'position']\n",
    "        sample = self[idx]\n",
    "        print(f\"üîç Checking dataset sample: {idx}\")\n",
    "        for key in expected_keys:\n",
    "            if key not in sample:\n",
    "                print(f\"‚ùå Ë≥áÊñô‰∏≠Áº∫Â∞ë key: {key}\")\n",
    "                continue\n",
    "            tensor = sample[key]\n",
    "            if isinstance(tensor, torch.Tensor):\n",
    "                try:\n",
    "                    shape = tensor.shape\n",
    "                except Exception:\n",
    "                    shape = \"N/A\"\n",
    "                dtype = tensor.dtype if hasattr(tensor, \"dtype\") else \"N/A\"\n",
    "                output_str = f\"üìè {key} shape: {shape} | dtype: {dtype}\"\n",
    "                if tensor.numel() > 0:\n",
    "                    try:\n",
    "                        tensor_float = tensor.float()\n",
    "                        mn = tensor_float.min().item()\n",
    "                        mx = tensor_float.max().item()\n",
    "                        mean = tensor_float.mean().item()\n",
    "                        std = tensor_float.std().item()\n",
    "                        output_str += f\" | min: {mn:.3f}, max: {mx:.3f}, mean: {mean:.3f}, std: {std:.3f}\"\n",
    "                    except Exception:\n",
    "                        output_str += \" | ÁÑ°Ê≥ïË®àÁÆóÁµ±Ë®àÊï∏Êìö\"\n",
    "                print(output_str)\n",
    "                if key not in self.image_keys:\n",
    "                    if tensor.ndim == 0:\n",
    "                        print(f\"--- {key} Ë≥áÊñôÁÇ∫Á¥îÈáè:\", tensor)\n",
    "                    elif tensor.ndim == 1:\n",
    "                        print(f\"--- {key} head (Ââç {num_lines} ÂÄãÂÖÉÁ¥†):\")\n",
    "                        print(tensor[:num_lines])\n",
    "                    else:\n",
    "                        print(f\"--- {key} head (Ââç {num_lines} Âàó):\")\n",
    "                        print(tensor[:num_lines])\n",
    "            else:\n",
    "                # Â¶ÇÊûú position Â≠òÁöÑÊòØ list/tuple/etcÔºå‰πü‰ºöËµ∞ËøôÈáå\n",
    "                print(f\"üìè {key} (Èùû tensor Ë≥áÊñô):\", tensor)\n",
    "        print(\"‚úÖ All checks passed!\")\n",
    "\n",
    "\n",
    "full_dataset = importDataset(grouped_data, model,\n",
    "                             image_keys=['tile','subtiles'],\n",
    "                             transform=lambda x: x)\n",
    "\n",
    "full_dataset.check_item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from python_scripts.image_features import  *\n",
    "from python_scripts.prediction_features import  *\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# === Main Function with Names ===\n",
    "def generate_meta_features(dataset, model_for_recon, device, ae_type, oof_preds = None, latents = None):\n",
    "    \"\"\"\n",
    "    Generate meta-features and corresponding names.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features : np.ndarray, shape (n_samples, n_features)\n",
    "    names    : list of str, length n_features\n",
    "    \"\"\"\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    # 1) Êî∂ÈõÜÊâÄÊúâ (feats, names) Âà∞Âêå‰∏Ä‰∏™ outputs ÂàóË°®\n",
    "    outputs = []\n",
    "\n",
    "    # # AE reconstruction loss\n",
    "    feats, names = compute_ae_reconstruction_loss(model_for_recon, loader, device, ae_type)\n",
    "    feats = feats[:, None]\n",
    "    outputs.append((feats, names))\n",
    "\n",
    "    # # AE embeddings\n",
    "    feats, names = compute_ae_embeddings(loader, model_for_recon, device)\n",
    "    outputs.append((feats, names))\n",
    "    if latents is not None:\n",
    "        # ÂéüÂßã 35 Áª¥ preds\n",
    "        n_classes = latents.shape[1]\n",
    "        raw_names = [f\"trained-latents_{i}\" for i in range(n_classes)]\n",
    "        outputs.append((latents, raw_names))\n",
    "    # # # Latent stats\n",
    "    latent_feats = outputs[1][0]\n",
    "    feats, names = compute_latent_stats(latent_feats)\n",
    "    outputs.append((feats, names))\n",
    "\n",
    "    # # # RGB stats\n",
    "\n",
    "    feats, names = compute_center_subtile_rgb_stats(dataset)\n",
    "    outputs.append((feats, names))\n",
    "    feats, names = compute_subtiles_except_center_rgb_stats(dataset)\n",
    "    outputs.append((feats, names))\n",
    "    feats, names = compute_tile_rgb_stats(dataset)\n",
    "    outputs.append((feats, names))\n",
    "    feats, names = compute_subtile_contrast_stats(dataset)\n",
    "    outputs.append((feats, names))\n",
    "\n",
    "    # # # Texture & pattern features\n",
    "    feats, names = compute_wavelet_stats(dataset)\n",
    "    outputs.append((feats, names))\n",
    "    feats, names = compute_sobel_stats(dataset)\n",
    "    outputs.append((feats, names))\n",
    "\n",
    "    # Color & distribution features\n",
    "    feats, names = compute_hsv_stats(dataset)\n",
    "    outputs.append((feats, names))\n",
    "\n",
    "    # H&E stain features\n",
    "    feats, names = compute_he_stats(dataset)\n",
    "    outputs.append((feats, names))\n",
    "\n",
    "    # Sliding-window std stats\n",
    "    feats, names = compute_sliding_window_stats(dataset)\n",
    "    outputs.append((feats, names))\n",
    "\n",
    "    # # 9) OOF-based features (only if provided)\n",
    "    if oof_preds is not None:\n",
    "        # ÂéüÂßã 35 Áª¥ preds\n",
    "        n_classes = oof_preds.shape[1]\n",
    "        raw_names = [f\"oof_pred_{i}\" for i in range(n_classes)]\n",
    "        outputs.append((oof_preds, raw_names))\n",
    "\n",
    "        # # Áõ∏ÈÇªÂ∑ÆÂºÇ\n",
    "        feats, names = compute_adjacent_diffs(oof_preds, stride=1)\n",
    "        outputs.append((feats, names))\n",
    "\n",
    "        # # top-2..top-6 ÁªüËÆ°\n",
    "        feats, names = compute_lastn_stats_multi(oof_preds, max_n=35)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_topn_stats_multi(oof_preds, max_n=6)\n",
    "        outputs.append((feats, names))\n",
    "        # Êõ¥Â§öÂèØÈÄâ‚Äî‚ÄîÂè™ÈúÄÂèñÊ∂àÊ≥®ÈáäÂç≥ÂèØ\n",
    "        feats, names = compute_adj_diff_histogram(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_multi_stride_diffs(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_median_mad(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_skew_kurt(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_percentile_iqr(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_renyi_entropy(oof_preds, alpha=2)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_mass_topk(oof_preds, k=5)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_cdf_slope(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_pca_components(oof_preds, n_components=10)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_peak_stats(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_segment_stats(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_ar_coeffs(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_autocorr_features(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_second_order_diffs(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_third_order_diffs(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_relative_diffs(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_diff_ratio_of_diffs(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "\n",
    "\n",
    "    # 2) unzip Êàê feat_list Âíå name_seq\n",
    "    feat_list, name_seq = zip(*outputs)\n",
    "\n",
    "    # 3) ÈÄêÂùóÊ†°È™å feats ÂàóÊï∞‰∏é names ÈïøÂ∫¶\n",
    "    for feats, names_block in zip(feat_list, name_seq):\n",
    "        ncols = feats.shape[1] if feats.ndim == 2 else 1\n",
    "        if ncols != len(names_block):\n",
    "            raise ValueError(\n",
    "                f\"Mismatch: got {ncols} columns but {len(names_block)} names \"\n",
    "                f\"in block '{names_block[0].split('_')[0]}'\"\n",
    "            )\n",
    "        print(\n",
    "            f\"{names_block[0].split('_')[0]:12s} -> cols: {ncols:4d}, names: {len(names_block):4d} OK\"\n",
    "        )\n",
    "\n",
    "    # 4) ÊâÅÂπ≥Âåñ names Âπ∂ÊãºÊé• features\n",
    "    name_list = [nm for block in name_seq for nm in block]\n",
    "    features = np.concatenate(feat_list, axis=1)\n",
    "    print(f\"‚úÖ Generated meta-features with shape: {features.shape}\")\n",
    "\n",
    "    return features, name_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def diagnose_meta_nonfinite(meta: np.ndarray, names: list[str]):\n",
    "    \"\"\"\n",
    "    ÊåâÂêçÂ≠óÂâçÁºÄÂàÜÁªÑÔºåÁªüËÆ°ÊØèÁªÑÔºö\n",
    "      - ÂéüÂßãÁâπÂæÅÊï∞ÔºàÂàóÊï∞Ôºâ\n",
    "      - ÊÄªÂÄºÊï∞ÔºàÂàóÊï∞ √ó Ë°åÊï∞Ôºâ\n",
    "      - NaN ÂÄºÊï∞Èáè\n",
    "      - ¬±Inf ÂÄºÊï∞Èáè\n",
    "      - ÈùûÊï∞ÂÄºÔºànon-finiteÔºâÊÄªÊï∞\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    meta  : np.ndarray, shape (n_samples, n_features)\n",
    "    names : list of str, length n_features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    stats : dict[prefix, dict]  \n",
    "        ÊØè‰∏™ prefix ÂØπÂ∫î‰∏Ä‰∏™Â≠óÂÖ∏Ôºå\n",
    "        ÂåÖÂê´ 'n_feats','total_vals','n_nan','n_inf','n_nonfinite'„ÄÇ\n",
    "    \"\"\"\n",
    "    groups = defaultdict(list)\n",
    "    # ÊåâÂâçÁºÄÂàÜÁªÑ\n",
    "    for idx, nm in enumerate(names):\n",
    "        prefix = nm.split('_', 1)[0]\n",
    "        groups[prefix].append(idx)\n",
    "\n",
    "    stats = {}\n",
    "    for prefix, idxs in groups.items():\n",
    "        sub = meta[:, idxs]  # shape (n_samples, n_group_feats)\n",
    "        n_feats = sub.shape[1]\n",
    "        total_vals = sub.size\n",
    "        n_nan = np.isnan(sub).sum()\n",
    "        n_inf = np.isinf(sub).sum()\n",
    "        n_nonfinite = (~np.isfinite(sub)).sum()\n",
    "\n",
    "        stats[prefix] = {\n",
    "            'n_feats':        n_feats,\n",
    "            'total_vals':     total_vals,\n",
    "            'n_nan':          int(n_nan),\n",
    "            'n_inf':          int(n_inf),\n",
    "            'n_nonfinite':    int(n_nonfinite),\n",
    "        }\n",
    "        print(\n",
    "            f\"Group '{prefix}': \"\n",
    "            f\"features={n_feats}, \"\n",
    "            f\"values={total_vals}, \"\n",
    "            f\"non-finite={n_nonfinite} \"\n",
    "            f\"(nan={n_nan}, inf={n_inf})\"\n",
    "        )\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/pretrain_model.py:310: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ae.load_state_dict(torch.load(ae_checkpoint, map_location=\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import rankdata\n",
    "from python_scripts.import_data import importDataset\n",
    "from python_scripts.operate_model import predict\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from python_scripts.pretrain_model import PretrainedEncoderRegressor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# ---------------- Settings ----------------\n",
    "trained_oof_model_folder = 'output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/'\n",
    "n_folds    = len([d for d in os.listdir(trained_oof_model_folder) if d.startswith('fold')])\n",
    "n_samples  = len(full_dataset)\n",
    "C          = 35\n",
    "BATCH_SIZE = 64\n",
    "start_fold = 0\n",
    "\n",
    "tile_dim = 128\n",
    "center_dim = 128\n",
    "neighbor_dim = 128\n",
    "fusion_dim = tile_dim + center_dim + neighbor_dim\n",
    "META_EPOCHS = 200\n",
    "pretrained_ae_name = 'AE_Center_noaug'\n",
    "pretrained_ae_path = f\"AE_model/128/{pretrained_ae_name}/best.pt\"\n",
    "ae_type = 'center'\n",
    "\n",
    "# Ground truth label (ÂÖ® dataset)\n",
    "y_true = np.vstack([ full_dataset[i]['label'].cpu().numpy() for i in range(n_samples) ])\n",
    "\n",
    "# Build CV splitter (must match first stage splits)\n",
    "logo = LeaveOneGroupOut()\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "class DeepResMLP(nn.Module):\n",
    "    def __init__(self, in_dim=2924, hidden_dims=[1024,512,256,128], out_dim=35):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = in_dim\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(prev, h))\n",
    "            layers.append(nn.LeakyReLU(0.01))\n",
    "            layers.append(nn.BatchNorm1d(h))\n",
    "            layers.append(nn.Dropout(0.2))\n",
    "            prev = h\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.head = nn.Linear(prev, out_dim)\n",
    "\n",
    "        # ÊÆãÂ∑ÆÊ°•Ôºöin_dim‚Üífirst hidden\n",
    "        if in_dim != hidden_dims[0]:\n",
    "            self.res_proj = nn.Linear(in_dim, hidden_dims[0])\n",
    "        else:\n",
    "            self.res_proj = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B,2924], pred: [B,35]\n",
    "        # ÊÆãÂ∑ÆÊ°•Êé•\n",
    "        res = self.res_proj(x)\n",
    "        h   = self.net[0:4](x)       # Á¨¨‰∏ÄÊÆµ linear‚Üíact‚Üíbn‚Üídrop\n",
    "        h  += res                    # add residual\n",
    "        h   = self.net[4:](h)        # Ââ©‰ΩôÂ±Ç\n",
    "        delta = self.head(h)\n",
    "        return delta\n",
    "\n",
    "recon_model = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=pretrained_ae_path,\n",
    "        ae_type=ae_type,\n",
    "        tile_dim=tile_dim,\n",
    "        center_dim=center_dim,\n",
    "        neighbor_dim=neighbor_dim,\n",
    "        output_dim=C,\n",
    "        mode='reconstruction'\n",
    "    ).to(device)\n",
    "slide_idx = np.array(grouped_data['slide_idx'])   # shape (N,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per model per meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting fold 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåÄ Starting augment for meta-train ‚Ä¶\n",
      "üåÄ Starting import sugmentation data ‚Ä¶\n",
      "üåÄ Starting prepare OOF data from CNN model‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 110/110 [00:11<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "‚úÖ Generated meta-features with shape: (7028, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=2698752, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=2698752, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=28112, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=84336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=84336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=84336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=21084, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=28112, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=1686720, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=253008, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=28112, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=253008, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=84336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=759024, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=56224, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=506016, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=3036096, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=245980, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=238952, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=955808, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=140560, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=70280, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=4181660, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=70280, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=21084, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=14056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=14056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=14056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=14056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=14056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=21084, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=35140, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=231924, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=224896, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=238952, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=231924, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "‚úÖ Generated meta-features with shape: (440, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=168960, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=168960, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=1760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=5280, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=5280, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=5280, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=1320, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=1760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=105600, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=15840, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=1760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=15840, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=5280, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=47520, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=3520, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=31680, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=190080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=15400, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=14960, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=59840, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=8800, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=4400, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=261800, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=4400, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=1320, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=1320, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=2200, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=14520, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=14080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=14960, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=14520, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold0 Ep1/300 ‚Äî Train MSE: 405.319227, Val MSE: 376.475567, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=376.475567), saved.\n",
      "Fold0 Ep2/300 ‚Äî Train MSE: 280.415148, Val MSE: 178.369030, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=178.369030), saved.\n",
      "Fold0 Ep3/300 ‚Äî Train MSE: 105.109123, Val MSE: 61.640348, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=61.640348), saved.\n",
      "Fold0 Ep4/300 ‚Äî Train MSE: 49.255349, Val MSE: 49.259682, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=49.259682), saved.\n",
      "Fold0 Ep5/300 ‚Äî Train MSE: 43.230442, Val MSE: 46.381895, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=46.381895), saved.\n",
      "Fold0 Ep6/300 ‚Äî Train MSE: 42.082382, Val MSE: 48.489742, LR: 1.000e-03\n",
      "Fold0 Ep7/300 ‚Äî Train MSE: 41.195338, Val MSE: 47.441790, LR: 1.000e-03\n",
      "Fold0 Ep8/300 ‚Äî Train MSE: 40.897712, Val MSE: 45.491223, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=45.491223), saved.\n",
      "Fold0 Ep9/300 ‚Äî Train MSE: 40.880134, Val MSE: 51.667825, LR: 1.000e-03\n",
      "Fold0 Ep10/300 ‚Äî Train MSE: 40.398880, Val MSE: 46.396107, LR: 1.000e-03\n",
      "Fold0 Ep11/300 ‚Äî Train MSE: 40.101187, Val MSE: 46.773966, LR: 1.000e-03\n",
      "Fold0 Ep12/300 ‚Äî Train MSE: 39.930151, Val MSE: 45.640308, LR: 1.000e-03\n",
      "Fold0 Ep13/300 ‚Äî Train MSE: 39.608845, Val MSE: 45.346506, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=45.346506), saved.\n",
      "Fold0 Ep14/300 ‚Äî Train MSE: 39.494031, Val MSE: 45.907021, LR: 1.000e-03\n",
      "Fold0 Ep15/300 ‚Äî Train MSE: 39.330052, Val MSE: 49.723104, LR: 1.000e-03\n",
      "Fold0 Ep16/300 ‚Äî Train MSE: 39.024838, Val MSE: 47.720655, LR: 1.000e-03\n",
      "Fold0 Ep17/300 ‚Äî Train MSE: 38.784176, Val MSE: 45.065863, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=45.065863), saved.\n",
      "Fold0 Ep18/300 ‚Äî Train MSE: 38.910426, Val MSE: 49.407554, LR: 1.000e-03\n",
      "Fold0 Ep19/300 ‚Äî Train MSE: 38.583595, Val MSE: 50.397885, LR: 1.000e-03\n",
      "Fold0 Ep20/300 ‚Äî Train MSE: 38.371988, Val MSE: 52.709611, LR: 1.000e-03\n",
      "Fold0 Ep21/300 ‚Äî Train MSE: 38.300956, Val MSE: 49.894456, LR: 1.000e-03\n",
      "Fold0 Ep22/300 ‚Äî Train MSE: 37.961221, Val MSE: 50.844868, LR: 1.000e-03\n",
      "Fold0 Ep23/300 ‚Äî Train MSE: 37.981304, Val MSE: 50.313323, LR: 1.000e-03\n",
      "Fold0 Ep24/300 ‚Äî Train MSE: 37.867215, Val MSE: 52.469640, LR: 1.000e-03\n",
      "Fold0 Ep25/300 ‚Äî Train MSE: 37.693914, Val MSE: 51.589615, LR: 1.000e-03\n",
      "Fold0 Ep26/300 ‚Äî Train MSE: 37.651686, Val MSE: 50.842696, LR: 1.000e-03\n",
      "Fold0 Ep27/300 ‚Äî Train MSE: 37.508466, Val MSE: 50.492732, LR: 1.000e-03\n",
      "Fold0 Ep28/300 ‚Äî Train MSE: 37.375742, Val MSE: 47.195586, LR: 1.000e-03\n",
      "Fold0 Ep29/300 ‚Äî Train MSE: 36.958193, Val MSE: 43.744594, LR: 5.000e-04\n",
      " ‚Ü≥ New best (Val MSE=43.744594), saved.\n",
      "Fold0 Ep30/300 ‚Äî Train MSE: 36.866519, Val MSE: 49.685324, LR: 5.000e-04\n",
      "Fold0 Ep31/300 ‚Äî Train MSE: 36.737219, Val MSE: 44.341621, LR: 5.000e-04\n",
      "Fold0 Ep32/300 ‚Äî Train MSE: 36.579707, Val MSE: 50.794572, LR: 5.000e-04\n",
      "Fold0 Ep33/300 ‚Äî Train MSE: 36.534792, Val MSE: 46.279443, LR: 5.000e-04\n",
      "Fold0 Ep34/300 ‚Äî Train MSE: 36.405297, Val MSE: 50.018759, LR: 5.000e-04\n",
      "Fold0 Ep35/300 ‚Äî Train MSE: 36.561252, Val MSE: 48.942155, LR: 5.000e-04\n",
      "Fold0 Ep36/300 ‚Äî Train MSE: 36.501137, Val MSE: 47.366247, LR: 5.000e-04\n",
      "Fold0 Ep37/300 ‚Äî Train MSE: 36.292902, Val MSE: 53.794445, LR: 5.000e-04\n",
      "Fold0 Ep38/300 ‚Äî Train MSE: 36.357524, Val MSE: 52.488630, LR: 5.000e-04\n",
      "Fold0 Ep39/300 ‚Äî Train MSE: 36.443787, Val MSE: 50.614902, LR: 5.000e-04\n",
      "Fold0 Ep40/300 ‚Äî Train MSE: 36.246192, Val MSE: 52.302440, LR: 5.000e-04\n",
      "Fold0 Ep41/300 ‚Äî Train MSE: 35.892152, Val MSE: 45.917374, LR: 2.500e-04\n",
      "Fold0 Ep42/300 ‚Äî Train MSE: 36.123448, Val MSE: 54.411777, LR: 2.500e-04\n",
      "Fold0 Ep43/300 ‚Äî Train MSE: 35.864206, Val MSE: 48.892520, LR: 2.500e-04\n",
      "Fold0 Ep44/300 ‚Äî Train MSE: 35.823666, Val MSE: 52.323726, LR: 2.500e-04\n",
      "Fold0 Ep45/300 ‚Äî Train MSE: 35.755195, Val MSE: 43.294001, LR: 2.500e-04\n",
      " ‚Ü≥ New best (Val MSE=43.294001), saved.\n",
      "Fold0 Ep46/300 ‚Äî Train MSE: 35.602497, Val MSE: 48.815548, LR: 2.500e-04\n",
      "Fold0 Ep47/300 ‚Äî Train MSE: 35.668262, Val MSE: 54.944992, LR: 2.500e-04\n",
      "Fold0 Ep48/300 ‚Äî Train MSE: 35.704222, Val MSE: 53.676334, LR: 2.500e-04\n",
      "Fold0 Ep49/300 ‚Äî Train MSE: 35.597863, Val MSE: 53.268706, LR: 2.500e-04\n",
      "Fold0 Ep50/300 ‚Äî Train MSE: 35.430098, Val MSE: 48.055054, LR: 2.500e-04\n",
      "Fold0 Ep51/300 ‚Äî Train MSE: 35.369013, Val MSE: 47.576341, LR: 2.500e-04\n",
      "Fold0 Ep52/300 ‚Äî Train MSE: 35.745857, Val MSE: 47.032979, LR: 2.500e-04\n",
      "Fold0 Ep53/300 ‚Äî Train MSE: 35.441309, Val MSE: 54.629879, LR: 2.500e-04\n",
      "Fold0 Ep54/300 ‚Äî Train MSE: 35.527669, Val MSE: 48.974638, LR: 2.500e-04\n",
      "Fold0 Ep55/300 ‚Äî Train MSE: 35.400101, Val MSE: 51.540281, LR: 2.500e-04\n",
      "Fold0 Ep56/300 ‚Äî Train MSE: 35.498605, Val MSE: 49.687128, LR: 2.500e-04\n",
      "Fold0 Ep57/300 ‚Äî Train MSE: 35.227183, Val MSE: 48.977504, LR: 1.250e-04\n",
      "Fold0 Ep58/300 ‚Äî Train MSE: 35.120743, Val MSE: 49.892163, LR: 1.250e-04\n",
      "Fold0 Ep59/300 ‚Äî Train MSE: 35.145186, Val MSE: 53.374514, LR: 1.250e-04\n",
      "Fold0 Ep60/300 ‚Äî Train MSE: 35.169835, Val MSE: 49.190033, LR: 1.250e-04\n",
      "Fold0 Ep61/300 ‚Äî Train MSE: 35.139409, Val MSE: 51.825118, LR: 1.250e-04\n",
      "Fold0 Ep62/300 ‚Äî Train MSE: 35.119523, Val MSE: 44.992703, LR: 1.250e-04\n",
      "Fold0 Ep63/300 ‚Äî Train MSE: 35.197860, Val MSE: 52.696260, LR: 1.250e-04\n",
      "Fold0 Ep64/300 ‚Äî Train MSE: 35.039997, Val MSE: 52.205661, LR: 1.250e-04\n",
      "Fold0 Ep65/300 ‚Äî Train MSE: 35.043685, Val MSE: 51.613230, LR: 1.250e-04\n",
      " ‚úã Early stopping (no improvement in 20 epochs).\n",
      " Fold0 Best refined Val MSE: 43.294003\n",
      " ‚úÖ Best meta-model saved to: output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/fold0/meta_model_best.pt\n",
      "\n",
      "üöÄ Starting fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:188: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(best_path, map_location=device))\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåÄ Starting augment for meta-train ‚Ä¶\n",
      "üåÄ Starting import sugmentation data ‚Ä¶\n",
      "üåÄ Starting prepare OOF data from CNN model‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 114/114 [00:14<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "‚úÖ Generated meta-features with shape: (7260, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=2787840, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=2787840, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=29040, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=87120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=87120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=87120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=21780, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=29040, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=1742400, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=261360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=29040, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=261360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=87120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=784080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=58080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=522720, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=3136320, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=254100, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=246840, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=987360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=145200, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=72600, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=4319700, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=72600, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=21780, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=14520, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=14520, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=14520, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=14520, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=14520, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=21780, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=36300, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=239580, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=232320, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=246840, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=239580, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:01<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "‚úÖ Generated meta-features with shape: (454, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=174336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=174336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=1816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=5448, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=5448, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=5448, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=1362, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=1816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=108960, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=16344, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=1816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=16344, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=5448, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=49032, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=3632, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=32688, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=196128, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=15890, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=15436, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=61744, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=9080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=4540, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=270130, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=4540, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=1362, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=908, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=908, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=908, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=908, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=908, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=1362, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=2270, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=14982, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=14528, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=15436, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=14982, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 Ep1/300 ‚Äî Train MSE: 411.042008, Val MSE: 377.315096, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=377.315096), saved.\n",
      "Fold1 Ep2/300 ‚Äî Train MSE: 270.428721, Val MSE: 162.301475, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=162.301475), saved.\n",
      "Fold1 Ep3/300 ‚Äî Train MSE: 90.509911, Val MSE: 47.384867, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=47.384867), saved.\n",
      "Fold1 Ep4/300 ‚Äî Train MSE: 36.676492, Val MSE: 28.724335, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=28.724335), saved.\n",
      "Fold1 Ep5/300 ‚Äî Train MSE: 29.649644, Val MSE: 27.953990, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=27.953990), saved.\n",
      "Fold1 Ep6/300 ‚Äî Train MSE: 28.837453, Val MSE: 28.143556, LR: 1.000e-03\n",
      "Fold1 Ep7/300 ‚Äî Train MSE: 28.451967, Val MSE: 28.259422, LR: 1.000e-03\n",
      "Fold1 Ep8/300 ‚Äî Train MSE: 27.967031, Val MSE: 28.058649, LR: 1.000e-03\n",
      "Fold1 Ep9/300 ‚Äî Train MSE: 27.670166, Val MSE: 28.164841, LR: 1.000e-03\n",
      "Fold1 Ep10/300 ‚Äî Train MSE: 27.576628, Val MSE: 28.310839, LR: 1.000e-03\n",
      "Fold1 Ep11/300 ‚Äî Train MSE: 27.387788, Val MSE: 28.470198, LR: 1.000e-03\n",
      "Fold1 Ep12/300 ‚Äî Train MSE: 27.163057, Val MSE: 28.600309, LR: 1.000e-03\n",
      "Fold1 Ep13/300 ‚Äî Train MSE: 26.896851, Val MSE: 28.556160, LR: 1.000e-03\n",
      "Fold1 Ep14/300 ‚Äî Train MSE: 26.853828, Val MSE: 28.628547, LR: 1.000e-03\n",
      "Fold1 Ep15/300 ‚Äî Train MSE: 26.793772, Val MSE: 28.598091, LR: 1.000e-03\n",
      "Fold1 Ep16/300 ‚Äî Train MSE: 26.377228, Val MSE: 28.451778, LR: 1.000e-03\n",
      "Fold1 Ep17/300 ‚Äî Train MSE: 26.101742, Val MSE: 28.750539, LR: 5.000e-04\n",
      "Fold1 Ep18/300 ‚Äî Train MSE: 26.030771, Val MSE: 28.651863, LR: 5.000e-04\n",
      "Fold1 Ep19/300 ‚Äî Train MSE: 25.860380, Val MSE: 28.482608, LR: 5.000e-04\n",
      "Fold1 Ep20/300 ‚Äî Train MSE: 25.912880, Val MSE: 28.445969, LR: 5.000e-04\n",
      "Fold1 Ep21/300 ‚Äî Train MSE: 25.817350, Val MSE: 28.597558, LR: 5.000e-04\n",
      "Fold1 Ep22/300 ‚Äî Train MSE: 25.656372, Val MSE: 28.750928, LR: 5.000e-04\n",
      "Fold1 Ep23/300 ‚Äî Train MSE: 25.630006, Val MSE: 28.639473, LR: 5.000e-04\n",
      "Fold1 Ep24/300 ‚Äî Train MSE: 25.599515, Val MSE: 28.778249, LR: 5.000e-04\n",
      "Fold1 Ep25/300 ‚Äî Train MSE: 25.447414, Val MSE: 28.848934, LR: 5.000e-04\n",
      " ‚úã Early stopping (no improvement in 20 epochs).\n",
      " Fold1 Best refined Val MSE: 27.953989\n",
      " ‚úÖ Best meta-model saved to: output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/fold1/meta_model_best.pt\n",
      "\n",
      "üöÄ Starting fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:188: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(best_path, map_location=device))\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåÄ Starting augment for meta-train ‚Ä¶\n",
      "üåÄ Starting import sugmentation data ‚Ä¶\n",
      "üåÄ Starting prepare OOF data from CNN model‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:05<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "‚úÖ Generated meta-features with shape: (2208, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=847872, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=847872, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=8832, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=26496, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=26496, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=26496, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=6624, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=8832, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=529920, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=79488, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=8832, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=79488, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=26496, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=238464, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=17664, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=158976, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=953856, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=77280, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=75072, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=300288, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=44160, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=22080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=1313760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=22080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=6624, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=4416, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=4416, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=4416, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=4416, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=4416, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=6624, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=11040, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=72864, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=70656, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=75072, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=72864, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "‚úÖ Generated meta-features with shape: (138, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=52992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=52992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=552, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=1656, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=1656, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=1656, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=414, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=552, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=33120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=4968, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=552, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=4968, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=1656, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=14904, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=1104, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=9936, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=59616, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=4830, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=4692, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=18768, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=2760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=1380, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=82110, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=1380, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=414, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=276, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=276, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=276, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=276, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=276, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=414, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=690, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=4554, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=4416, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=4692, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=4554, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 Ep1/300 ‚Äî Train MSE: 424.875498, Val MSE: 427.288564, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=427.288564), saved.\n",
      "Fold2 Ep2/300 ‚Äî Train MSE: 418.162374, Val MSE: 413.792458, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=413.792458), saved.\n",
      "Fold2 Ep3/300 ‚Äî Train MSE: 400.164258, Val MSE: 381.396480, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=381.396480), saved.\n",
      "Fold2 Ep4/300 ‚Äî Train MSE: 361.391283, Val MSE: 327.860761, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=327.860761), saved.\n",
      "Fold2 Ep5/300 ‚Äî Train MSE: 303.020588, Val MSE: 264.346616, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=264.346616), saved.\n",
      "Fold2 Ep6/300 ‚Äî Train MSE: 234.182586, Val MSE: 194.364886, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=194.364886), saved.\n",
      "Fold2 Ep7/300 ‚Äî Train MSE: 168.792973, Val MSE: 132.308159, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=132.308159), saved.\n",
      "Fold2 Ep8/300 ‚Äî Train MSE: 117.709889, Val MSE: 94.294266, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=94.294266), saved.\n",
      "Fold2 Ep9/300 ‚Äî Train MSE: 83.275832, Val MSE: 68.708540, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=68.708540), saved.\n",
      "Fold2 Ep10/300 ‚Äî Train MSE: 64.788436, Val MSE: 58.131957, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=58.131957), saved.\n",
      "Fold2 Ep11/300 ‚Äî Train MSE: 54.239899, Val MSE: 51.936070, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=51.936070), saved.\n",
      "Fold2 Ep12/300 ‚Äî Train MSE: 49.628157, Val MSE: 48.509708, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=48.509708), saved.\n",
      "Fold2 Ep13/300 ‚Äî Train MSE: 47.386861, Val MSE: 46.928259, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=46.928259), saved.\n",
      "Fold2 Ep14/300 ‚Äî Train MSE: 45.894676, Val MSE: 46.518743, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=46.518743), saved.\n",
      "Fold2 Ep15/300 ‚Äî Train MSE: 45.121596, Val MSE: 46.187482, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=46.187482), saved.\n",
      "Fold2 Ep16/300 ‚Äî Train MSE: 44.902827, Val MSE: 46.378176, LR: 1.000e-03\n",
      "Fold2 Ep17/300 ‚Äî Train MSE: 44.676546, Val MSE: 46.273215, LR: 1.000e-03\n",
      "Fold2 Ep18/300 ‚Äî Train MSE: 43.903616, Val MSE: 46.463146, LR: 1.000e-03\n",
      "Fold2 Ep19/300 ‚Äî Train MSE: 44.049502, Val MSE: 45.994685, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=45.994685), saved.\n",
      "Fold2 Ep20/300 ‚Äî Train MSE: 43.603109, Val MSE: 46.028984, LR: 1.000e-03\n",
      "Fold2 Ep21/300 ‚Äî Train MSE: 43.775828, Val MSE: 46.435926, LR: 1.000e-03\n",
      "Fold2 Ep22/300 ‚Äî Train MSE: 43.394034, Val MSE: 46.127649, LR: 1.000e-03\n",
      "Fold2 Ep23/300 ‚Äî Train MSE: 42.798663, Val MSE: 45.857443, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=45.857443), saved.\n",
      "Fold2 Ep24/300 ‚Äî Train MSE: 42.694682, Val MSE: 46.427903, LR: 1.000e-03\n",
      "Fold2 Ep25/300 ‚Äî Train MSE: 42.659454, Val MSE: 46.028267, LR: 1.000e-03\n",
      "Fold2 Ep26/300 ‚Äî Train MSE: 42.769704, Val MSE: 46.497959, LR: 1.000e-03\n",
      "Fold2 Ep27/300 ‚Äî Train MSE: 42.281291, Val MSE: 48.150977, LR: 1.000e-03\n",
      "Fold2 Ep28/300 ‚Äî Train MSE: 42.346550, Val MSE: 45.929196, LR: 1.000e-03\n",
      "Fold2 Ep29/300 ‚Äî Train MSE: 42.164451, Val MSE: 47.086855, LR: 1.000e-03\n",
      "Fold2 Ep30/300 ‚Äî Train MSE: 41.880451, Val MSE: 47.066406, LR: 1.000e-03\n",
      "Fold2 Ep31/300 ‚Äî Train MSE: 41.859239, Val MSE: 46.816890, LR: 1.000e-03\n",
      "Fold2 Ep32/300 ‚Äî Train MSE: 41.555791, Val MSE: 46.379677, LR: 1.000e-03\n",
      "Fold2 Ep33/300 ‚Äî Train MSE: 41.442438, Val MSE: 46.311901, LR: 1.000e-03\n",
      "Fold2 Ep34/300 ‚Äî Train MSE: 41.544877, Val MSE: 47.976716, LR: 1.000e-03\n",
      "Fold2 Ep35/300 ‚Äî Train MSE: 40.547852, Val MSE: 47.024681, LR: 5.000e-04\n",
      "Fold2 Ep36/300 ‚Äî Train MSE: 40.459399, Val MSE: 46.901689, LR: 5.000e-04\n",
      "Fold2 Ep37/300 ‚Äî Train MSE: 40.528673, Val MSE: 47.895556, LR: 5.000e-04\n",
      "Fold2 Ep38/300 ‚Äî Train MSE: 40.280126, Val MSE: 48.001307, LR: 5.000e-04\n",
      "Fold2 Ep39/300 ‚Äî Train MSE: 39.883475, Val MSE: 49.401630, LR: 5.000e-04\n",
      "Fold2 Ep40/300 ‚Äî Train MSE: 40.210061, Val MSE: 49.231385, LR: 5.000e-04\n",
      "Fold2 Ep41/300 ‚Äî Train MSE: 40.104034, Val MSE: 50.426502, LR: 5.000e-04\n",
      "Fold2 Ep42/300 ‚Äî Train MSE: 39.558352, Val MSE: 47.736127, LR: 5.000e-04\n",
      "Fold2 Ep43/300 ‚Äî Train MSE: 39.582572, Val MSE: 49.392728, LR: 5.000e-04\n",
      " ‚úã Early stopping (no improvement in 20 epochs).\n",
      " Fold2 Best refined Val MSE: 45.857441\n",
      " ‚úÖ Best meta-model saved to: output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/fold2/meta_model_best.pt\n",
      "\n",
      "üöÄ Starting fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:188: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(best_path, map_location=device))\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåÄ Starting augment for meta-train ‚Ä¶\n",
      "üåÄ Starting import sugmentation data ‚Ä¶\n",
      "üåÄ Starting prepare OOF data from CNN model‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60/60 [00:09<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "‚úÖ Generated meta-features with shape: (3796, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=1457664, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=1457664, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=15184, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=45552, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=45552, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=45552, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=11388, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=15184, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=911040, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=136656, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=15184, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=136656, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=45552, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=409968, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=30368, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=273312, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=1639872, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=132860, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=129064, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=516256, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=75920, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=37960, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=2258620, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=37960, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=11388, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=7592, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=7592, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=7592, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=7592, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=7592, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=11388, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=18980, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=125268, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=121472, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=129064, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=125268, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "‚úÖ Generated meta-features with shape: (238, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=91392, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=91392, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=952, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=2856, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=2856, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=2856, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=714, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=952, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=57120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=8568, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=952, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=8568, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=2856, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=25704, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=1904, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=17136, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=102816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=8330, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=8092, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=32368, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=4760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=2380, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=141610, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=2380, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=714, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=476, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=476, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=476, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=476, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=476, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=714, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=1190, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=7854, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=7616, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=8092, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=7854, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 Ep1/300 ‚Äî Train MSE: 418.914582, Val MSE: 407.213725, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=407.213725), saved.\n",
      "Fold3 Ep2/300 ‚Äî Train MSE: 388.166473, Val MSE: 364.770517, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=364.770517), saved.\n",
      "Fold3 Ep3/300 ‚Äî Train MSE: 311.646583, Val MSE: 262.454061, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=262.454061), saved.\n",
      "Fold3 Ep4/300 ‚Äî Train MSE: 200.667073, Val MSE: 152.127018, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=152.127018), saved.\n",
      "Fold3 Ep5/300 ‚Äî Train MSE: 112.136992, Val MSE: 88.034260, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=88.034260), saved.\n",
      "Fold3 Ep6/300 ‚Äî Train MSE: 70.441844, Val MSE: 66.564086, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=66.564086), saved.\n",
      "Fold3 Ep7/300 ‚Äî Train MSE: 58.056061, Val MSE: 67.834291, LR: 1.000e-03\n",
      "Fold3 Ep8/300 ‚Äî Train MSE: 54.285114, Val MSE: 70.151232, LR: 1.000e-03\n",
      "Fold3 Ep9/300 ‚Äî Train MSE: 53.548904, Val MSE: 67.810923, LR: 1.000e-03\n",
      "Fold3 Ep10/300 ‚Äî Train MSE: 52.242772, Val MSE: 66.898035, LR: 1.000e-03\n",
      "Fold3 Ep11/300 ‚Äî Train MSE: 51.621427, Val MSE: 63.205798, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=63.205798), saved.\n",
      "Fold3 Ep12/300 ‚Äî Train MSE: 51.266704, Val MSE: 68.662003, LR: 1.000e-03\n",
      "Fold3 Ep13/300 ‚Äî Train MSE: 50.334560, Val MSE: 68.598503, LR: 1.000e-03\n",
      "Fold3 Ep14/300 ‚Äî Train MSE: 50.167292, Val MSE: 65.792184, LR: 1.000e-03\n",
      "Fold3 Ep15/300 ‚Äî Train MSE: 49.478996, Val MSE: 71.021994, LR: 1.000e-03\n",
      "Fold3 Ep16/300 ‚Äî Train MSE: 49.200998, Val MSE: 56.394203, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=56.394203), saved.\n",
      "Fold3 Ep17/300 ‚Äî Train MSE: 48.504752, Val MSE: 66.348260, LR: 1.000e-03\n",
      "Fold3 Ep18/300 ‚Äî Train MSE: 48.171194, Val MSE: 63.536637, LR: 1.000e-03\n",
      "Fold3 Ep19/300 ‚Äî Train MSE: 48.517898, Val MSE: 71.900948, LR: 1.000e-03\n",
      "Fold3 Ep20/300 ‚Äî Train MSE: 47.890244, Val MSE: 62.327182, LR: 1.000e-03\n",
      "Fold3 Ep21/300 ‚Äî Train MSE: 47.648704, Val MSE: 62.223015, LR: 1.000e-03\n",
      "Fold3 Ep22/300 ‚Äî Train MSE: 47.001265, Val MSE: 72.185787, LR: 1.000e-03\n",
      "Fold3 Ep23/300 ‚Äî Train MSE: 47.127606, Val MSE: 61.171279, LR: 1.000e-03\n",
      "Fold3 Ep24/300 ‚Äî Train MSE: 46.247573, Val MSE: 65.523059, LR: 1.000e-03\n",
      "Fold3 Ep25/300 ‚Äî Train MSE: 45.804270, Val MSE: 70.512276, LR: 1.000e-03\n",
      "Fold3 Ep26/300 ‚Äî Train MSE: 45.565318, Val MSE: 66.672635, LR: 1.000e-03\n",
      "Fold3 Ep27/300 ‚Äî Train MSE: 45.666906, Val MSE: 51.745638, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=51.745638), saved.\n",
      "Fold3 Ep28/300 ‚Äî Train MSE: 44.803730, Val MSE: 59.582771, LR: 1.000e-03\n",
      "Fold3 Ep29/300 ‚Äî Train MSE: 44.698656, Val MSE: 67.524565, LR: 1.000e-03\n",
      "Fold3 Ep30/300 ‚Äî Train MSE: 44.627138, Val MSE: 65.503809, LR: 1.000e-03\n",
      "Fold3 Ep31/300 ‚Äî Train MSE: 44.612091, Val MSE: 67.634552, LR: 1.000e-03\n",
      "Fold3 Ep32/300 ‚Äî Train MSE: 44.406499, Val MSE: 73.348730, LR: 1.000e-03\n",
      "Fold3 Ep33/300 ‚Äî Train MSE: 43.855632, Val MSE: 68.923670, LR: 1.000e-03\n",
      "Fold3 Ep34/300 ‚Äî Train MSE: 43.590181, Val MSE: 61.308837, LR: 1.000e-03\n",
      "Fold3 Ep35/300 ‚Äî Train MSE: 43.975198, Val MSE: 59.359619, LR: 1.000e-03\n",
      "Fold3 Ep36/300 ‚Äî Train MSE: 43.452924, Val MSE: 59.839339, LR: 1.000e-03\n",
      "Fold3 Ep37/300 ‚Äî Train MSE: 43.552299, Val MSE: 54.984222, LR: 1.000e-03\n",
      "Fold3 Ep38/300 ‚Äî Train MSE: 42.925046, Val MSE: 71.109993, LR: 1.000e-03\n",
      "Fold3 Ep39/300 ‚Äî Train MSE: 41.847091, Val MSE: 73.152669, LR: 5.000e-04\n",
      "Fold3 Ep40/300 ‚Äî Train MSE: 41.339319, Val MSE: 66.738403, LR: 5.000e-04\n",
      "Fold3 Ep41/300 ‚Äî Train MSE: 41.005446, Val MSE: 68.546319, LR: 5.000e-04\n",
      "Fold3 Ep42/300 ‚Äî Train MSE: 40.986274, Val MSE: 65.481867, LR: 5.000e-04\n",
      "Fold3 Ep43/300 ‚Äî Train MSE: 40.596775, Val MSE: 60.233104, LR: 5.000e-04\n",
      "Fold3 Ep44/300 ‚Äî Train MSE: 40.604684, Val MSE: 62.200803, LR: 5.000e-04\n",
      "Fold3 Ep45/300 ‚Äî Train MSE: 40.866799, Val MSE: 54.884036, LR: 5.000e-04\n",
      "Fold3 Ep46/300 ‚Äî Train MSE: 40.626732, Val MSE: 69.797407, LR: 5.000e-04\n",
      "Fold3 Ep47/300 ‚Äî Train MSE: 40.387554, Val MSE: 63.585453, LR: 5.000e-04\n",
      " ‚úã Early stopping (no improvement in 20 epochs).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:188: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(best_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fold3 Best refined Val MSE: 51.745636\n",
      " ‚úÖ Best meta-model saved to: output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/fold3/meta_model_best.pt\n",
      "\n",
      "üöÄ Starting fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåÄ Starting augment for meta-train ‚Ä¶\n",
      "üåÄ Starting import sugmentation data ‚Ä¶\n",
      "üåÄ Starting prepare OOF data from CNN model‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 84/84 [00:14<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "‚úÖ Generated meta-features with shape: (5364, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=2059776, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=2059776, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=21456, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=64368, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=64368, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=64368, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=16092, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=21456, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=1287360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=193104, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=21456, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=193104, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=64368, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=579312, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=42912, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=386208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=2317248, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=187740, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=182376, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=729504, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=107280, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=53640, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=3191580, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=53640, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=16092, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=10728, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=10728, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=10728, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=10728, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=10728, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=16092, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=26820, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=177012, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=171648, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=182376, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=177012, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:01<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "‚úÖ Generated meta-features with shape: (336, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=129024, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=129024, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=1344, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=4032, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=4032, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=4032, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=1008, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=1344, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=80640, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=12096, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=1344, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=12096, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=4032, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=36288, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=2688, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=24192, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=145152, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=11760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=11424, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=45696, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=6720, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=3360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=199920, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=3360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=1008, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=672, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=672, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=672, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=672, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=672, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=1008, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=1680, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=11088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=10752, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=11424, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=11088, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold4 Ep1/300 ‚Äî Train MSE: 409.448090, Val MSE: 395.539264, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=395.539264), saved.\n",
      "Fold4 Ep2/300 ‚Äî Train MSE: 345.559379, Val MSE: 277.021697, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=277.021697), saved.\n",
      "Fold4 Ep3/300 ‚Äî Train MSE: 199.972403, Val MSE: 129.048939, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=129.048939), saved.\n",
      "Fold4 Ep4/300 ‚Äî Train MSE: 88.795603, Val MSE: 56.900571, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=56.900571), saved.\n",
      "Fold4 Ep5/300 ‚Äî Train MSE: 55.122899, Val MSE: 45.398594, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=45.398594), saved.\n",
      "Fold4 Ep6/300 ‚Äî Train MSE: 49.904167, Val MSE: 44.283881, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=44.283881), saved.\n",
      "Fold4 Ep7/300 ‚Äî Train MSE: 49.051342, Val MSE: 45.661766, LR: 1.000e-03\n",
      "Fold4 Ep8/300 ‚Äî Train MSE: 48.755924, Val MSE: 48.140233, LR: 1.000e-03\n",
      "Fold4 Ep9/300 ‚Äî Train MSE: 47.674203, Val MSE: 45.336952, LR: 1.000e-03\n",
      "Fold4 Ep10/300 ‚Äî Train MSE: 47.661655, Val MSE: 50.403617, LR: 1.000e-03\n",
      "Fold4 Ep11/300 ‚Äî Train MSE: 47.548027, Val MSE: 42.708090, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=42.708090), saved.\n",
      "Fold4 Ep12/300 ‚Äî Train MSE: 46.718539, Val MSE: 45.491461, LR: 1.000e-03\n",
      "Fold4 Ep13/300 ‚Äî Train MSE: 46.624525, Val MSE: 44.186682, LR: 1.000e-03\n",
      "Fold4 Ep14/300 ‚Äî Train MSE: 46.112642, Val MSE: 46.216586, LR: 1.000e-03\n",
      "Fold4 Ep15/300 ‚Äî Train MSE: 45.925780, Val MSE: 44.511060, LR: 1.000e-03\n",
      "Fold4 Ep16/300 ‚Äî Train MSE: 45.790436, Val MSE: 47.316565, LR: 1.000e-03\n",
      "Fold4 Ep17/300 ‚Äî Train MSE: 45.405570, Val MSE: 43.498940, LR: 1.000e-03\n",
      "Fold4 Ep18/300 ‚Äî Train MSE: 45.211189, Val MSE: 47.853256, LR: 1.000e-03\n",
      "Fold4 Ep19/300 ‚Äî Train MSE: 44.834048, Val MSE: 43.995840, LR: 1.000e-03\n",
      "Fold4 Ep20/300 ‚Äî Train MSE: 45.007419, Val MSE: 45.585430, LR: 1.000e-03\n",
      "Fold4 Ep21/300 ‚Äî Train MSE: 44.938082, Val MSE: 47.617001, LR: 1.000e-03\n",
      "Fold4 Ep22/300 ‚Äî Train MSE: 44.746034, Val MSE: 42.392197, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=42.392197), saved.\n",
      "Fold4 Ep23/300 ‚Äî Train MSE: 44.245796, Val MSE: 43.056427, LR: 1.000e-03\n",
      "Fold4 Ep24/300 ‚Äî Train MSE: 44.241345, Val MSE: 41.440230, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=41.440230), saved.\n",
      "Fold4 Ep25/300 ‚Äî Train MSE: 44.270781, Val MSE: 44.099629, LR: 1.000e-03\n",
      "Fold4 Ep26/300 ‚Äî Train MSE: 44.221465, Val MSE: 41.929747, LR: 1.000e-03\n",
      "Fold4 Ep27/300 ‚Äî Train MSE: 43.841376, Val MSE: 42.511040, LR: 1.000e-03\n",
      "Fold4 Ep28/300 ‚Äî Train MSE: 43.792541, Val MSE: 42.267121, LR: 1.000e-03\n",
      "Fold4 Ep29/300 ‚Äî Train MSE: 44.087381, Val MSE: 45.450030, LR: 1.000e-03\n",
      "Fold4 Ep30/300 ‚Äî Train MSE: 43.670755, Val MSE: 44.017559, LR: 1.000e-03\n",
      "Fold4 Ep31/300 ‚Äî Train MSE: 43.440652, Val MSE: 42.001779, LR: 1.000e-03\n",
      "Fold4 Ep32/300 ‚Äî Train MSE: 43.494934, Val MSE: 46.674875, LR: 1.000e-03\n",
      "Fold4 Ep33/300 ‚Äî Train MSE: 43.251238, Val MSE: 47.350958, LR: 1.000e-03\n",
      "Fold4 Ep34/300 ‚Äî Train MSE: 43.412827, Val MSE: 41.442958, LR: 1.000e-03\n",
      "Fold4 Ep35/300 ‚Äî Train MSE: 43.110215, Val MSE: 45.471550, LR: 1.000e-03\n",
      "Fold4 Ep36/300 ‚Äî Train MSE: 42.754860, Val MSE: 44.682872, LR: 5.000e-04\n",
      "Fold4 Ep37/300 ‚Äî Train MSE: 42.755917, Val MSE: 41.337475, LR: 5.000e-04\n",
      " ‚Ü≥ New best (Val MSE=41.337475), saved.\n",
      "Fold4 Ep38/300 ‚Äî Train MSE: 42.724316, Val MSE: 42.405546, LR: 5.000e-04\n",
      "Fold4 Ep39/300 ‚Äî Train MSE: 42.335950, Val MSE: 50.015306, LR: 5.000e-04\n",
      "Fold4 Ep40/300 ‚Äî Train MSE: 42.568137, Val MSE: 41.391528, LR: 5.000e-04\n",
      "Fold4 Ep41/300 ‚Äî Train MSE: 42.410700, Val MSE: 41.998839, LR: 5.000e-04\n",
      "Fold4 Ep42/300 ‚Äî Train MSE: 41.945809, Val MSE: 41.596850, LR: 5.000e-04\n",
      "Fold4 Ep43/300 ‚Äî Train MSE: 41.998798, Val MSE: 42.903039, LR: 5.000e-04\n",
      "Fold4 Ep44/300 ‚Äî Train MSE: 42.034206, Val MSE: 43.122507, LR: 5.000e-04\n",
      "Fold4 Ep45/300 ‚Äî Train MSE: 42.078937, Val MSE: 42.497092, LR: 5.000e-04\n",
      "Fold4 Ep46/300 ‚Äî Train MSE: 41.865907, Val MSE: 41.685402, LR: 5.000e-04\n",
      "Fold4 Ep47/300 ‚Äî Train MSE: 41.591963, Val MSE: 43.484322, LR: 5.000e-04\n",
      "Fold4 Ep48/300 ‚Äî Train MSE: 42.327339, Val MSE: 42.827129, LR: 5.000e-04\n",
      "Fold4 Ep49/300 ‚Äî Train MSE: 41.667126, Val MSE: 44.423568, LR: 2.500e-04\n",
      "Fold4 Ep50/300 ‚Äî Train MSE: 41.427533, Val MSE: 42.306470, LR: 2.500e-04\n",
      "Fold4 Ep51/300 ‚Äî Train MSE: 41.231605, Val MSE: 42.886311, LR: 2.500e-04\n",
      "Fold4 Ep52/300 ‚Äî Train MSE: 41.348396, Val MSE: 43.220040, LR: 2.500e-04\n",
      "Fold4 Ep53/300 ‚Äî Train MSE: 41.341356, Val MSE: 41.898339, LR: 2.500e-04\n",
      "Fold4 Ep54/300 ‚Äî Train MSE: 41.129715, Val MSE: 46.493506, LR: 2.500e-04\n",
      "Fold4 Ep55/300 ‚Äî Train MSE: 41.242563, Val MSE: 41.915489, LR: 2.500e-04\n",
      "Fold4 Ep56/300 ‚Äî Train MSE: 40.961758, Val MSE: 42.742700, LR: 2.500e-04\n",
      "Fold4 Ep57/300 ‚Äî Train MSE: 41.092153, Val MSE: 41.926985, LR: 2.500e-04\n",
      " ‚úã Early stopping (no improvement in 20 epochs).\n",
      " Fold4 Best refined Val MSE: 41.337475\n",
      " ‚úÖ Best meta-model saved to: output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/fold4/meta_model_best.pt\n",
      "\n",
      "üöÄ Starting fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:188: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(best_path, map_location=device))\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåÄ Starting augment for meta-train ‚Ä¶\n",
      "üåÄ Starting import sugmentation data ‚Ä¶\n",
      "üåÄ Starting prepare OOF data from CNN model‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:02<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "‚úÖ Generated meta-features with shape: (1048, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=402432, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=402432, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=4192, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=12576, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=12576, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=12576, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=3144, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=4192, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=251520, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=37728, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=4192, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=37728, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=12576, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=113184, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=8384, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=75456, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=452736, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=36680, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=35632, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=142528, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=20960, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=10480, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=623560, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=10480, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=3144, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=2096, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=2096, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=2096, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=2096, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=2096, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=3144, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=5240, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=34584, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=33536, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=35632, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=34584, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "‚úÖ Generated meta-features with shape: (66, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=25344, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=25344, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=198, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=15840, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=2376, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=2376, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=7128, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=528, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=4752, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=28512, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=2310, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=2244, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=8976, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=1320, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=660, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=39270, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=660, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=198, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=132, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=132, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=132, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=132, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=132, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=198, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=330, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=2178, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=2112, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=2244, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=2178, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold5 Ep1/300 ‚Äî Train MSE: 424.029936, Val MSE: 420.461090, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=420.461090), saved.\n",
      "Fold5 Ep2/300 ‚Äî Train MSE: 419.462858, Val MSE: 419.982905, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=419.982905), saved.\n",
      "Fold5 Ep3/300 ‚Äî Train MSE: 415.673991, Val MSE: 416.259880, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=416.259880), saved.\n",
      "Fold5 Ep4/300 ‚Äî Train MSE: 410.761667, Val MSE: 405.759045, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=405.759045), saved.\n",
      "Fold5 Ep5/300 ‚Äî Train MSE: 403.037614, Val MSE: 398.261005, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=398.261005), saved.\n",
      "Fold5 Ep6/300 ‚Äî Train MSE: 391.263614, Val MSE: 388.079122, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=388.079122), saved.\n",
      "Fold5 Ep7/300 ‚Äî Train MSE: 373.915523, Val MSE: 364.999288, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=364.999288), saved.\n",
      "Fold5 Ep8/300 ‚Äî Train MSE: 351.082631, Val MSE: 332.308534, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=332.308534), saved.\n",
      "Fold5 Ep9/300 ‚Äî Train MSE: 322.790691, Val MSE: 316.812773, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=316.812773), saved.\n",
      "Fold5 Ep10/300 ‚Äî Train MSE: 292.322911, Val MSE: 278.999089, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=278.999089), saved.\n",
      "Fold5 Ep11/300 ‚Äî Train MSE: 259.601216, Val MSE: 242.574106, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=242.574106), saved.\n",
      "Fold5 Ep12/300 ‚Äî Train MSE: 227.441769, Val MSE: 212.539421, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=212.539421), saved.\n",
      "Fold5 Ep13/300 ‚Äî Train MSE: 192.878903, Val MSE: 179.482289, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=179.482289), saved.\n",
      "Fold5 Ep14/300 ‚Äî Train MSE: 161.182095, Val MSE: 145.876482, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=145.876482), saved.\n",
      "Fold5 Ep15/300 ‚Äî Train MSE: 132.346726, Val MSE: 117.752209, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=117.752209), saved.\n",
      "Fold5 Ep16/300 ‚Äî Train MSE: 110.675306, Val MSE: 100.025879, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=100.025879), saved.\n",
      "Fold5 Ep17/300 ‚Äî Train MSE: 90.864666, Val MSE: 82.152054, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=82.152054), saved.\n",
      "Fold5 Ep18/300 ‚Äî Train MSE: 74.963734, Val MSE: 68.027880, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=68.027880), saved.\n",
      "Fold5 Ep19/300 ‚Äî Train MSE: 64.140707, Val MSE: 58.596362, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=58.596362), saved.\n",
      "Fold5 Ep20/300 ‚Äî Train MSE: 55.368840, Val MSE: 48.805055, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=48.805055), saved.\n",
      "Fold5 Ep21/300 ‚Äî Train MSE: 49.485498, Val MSE: 42.427496, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=42.427496), saved.\n",
      "Fold5 Ep22/300 ‚Äî Train MSE: 45.021589, Val MSE: 39.848147, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=39.848147), saved.\n",
      "Fold5 Ep23/300 ‚Äî Train MSE: 41.973190, Val MSE: 36.118574, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=36.118574), saved.\n",
      "Fold5 Ep24/300 ‚Äî Train MSE: 39.622190, Val MSE: 35.474343, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=35.474343), saved.\n",
      "Fold5 Ep25/300 ‚Äî Train MSE: 38.270136, Val MSE: 34.356011, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=34.356011), saved.\n",
      "Fold5 Ep26/300 ‚Äî Train MSE: 37.107678, Val MSE: 33.610533, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=33.610533), saved.\n",
      "Fold5 Ep27/300 ‚Äî Train MSE: 36.815968, Val MSE: 33.455972, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=33.455972), saved.\n",
      "Fold5 Ep28/300 ‚Äî Train MSE: 36.111271, Val MSE: 32.204584, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=32.204584), saved.\n",
      "Fold5 Ep29/300 ‚Äî Train MSE: 35.569427, Val MSE: 31.864080, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=31.864080), saved.\n",
      "Fold5 Ep30/300 ‚Äî Train MSE: 34.991967, Val MSE: 32.394126, LR: 1.000e-03\n",
      "Fold5 Ep31/300 ‚Äî Train MSE: 34.702356, Val MSE: 32.726984, LR: 1.000e-03\n",
      "Fold5 Ep32/300 ‚Äî Train MSE: 34.768515, Val MSE: 31.735618, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=31.735618), saved.\n",
      "Fold5 Ep33/300 ‚Äî Train MSE: 34.171928, Val MSE: 32.154216, LR: 1.000e-03\n",
      "Fold5 Ep34/300 ‚Äî Train MSE: 33.966447, Val MSE: 31.080109, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=31.080109), saved.\n",
      "Fold5 Ep35/300 ‚Äî Train MSE: 33.813769, Val MSE: 30.809229, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=30.809229), saved.\n",
      "Fold5 Ep36/300 ‚Äî Train MSE: 33.711851, Val MSE: 31.494389, LR: 1.000e-03\n",
      "Fold5 Ep37/300 ‚Äî Train MSE: 33.486901, Val MSE: 30.423432, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=30.423432), saved.\n",
      "Fold5 Ep38/300 ‚Äî Train MSE: 33.696105, Val MSE: 32.186568, LR: 1.000e-03\n",
      "Fold5 Ep39/300 ‚Äî Train MSE: 33.271398, Val MSE: 32.187177, LR: 1.000e-03\n",
      "Fold5 Ep40/300 ‚Äî Train MSE: 33.681951, Val MSE: 31.580488, LR: 1.000e-03\n",
      "Fold5 Ep41/300 ‚Äî Train MSE: 33.446337, Val MSE: 34.577254, LR: 1.000e-03\n",
      "Fold5 Ep42/300 ‚Äî Train MSE: 32.680286, Val MSE: 30.326364, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=30.326364), saved.\n",
      "Fold5 Ep43/300 ‚Äî Train MSE: 33.055475, Val MSE: 31.249943, LR: 1.000e-03\n",
      "Fold5 Ep44/300 ‚Äî Train MSE: 32.834428, Val MSE: 32.277401, LR: 1.000e-03\n",
      "Fold5 Ep45/300 ‚Äî Train MSE: 32.814575, Val MSE: 31.345410, LR: 1.000e-03\n",
      "Fold5 Ep46/300 ‚Äî Train MSE: 32.255961, Val MSE: 31.025013, LR: 1.000e-03\n",
      "Fold5 Ep47/300 ‚Äî Train MSE: 32.506352, Val MSE: 32.166782, LR: 1.000e-03\n",
      "Fold5 Ep48/300 ‚Äî Train MSE: 32.573378, Val MSE: 33.205173, LR: 1.000e-03\n",
      "Fold5 Ep49/300 ‚Äî Train MSE: 32.146598, Val MSE: 30.597903, LR: 1.000e-03\n",
      "Fold5 Ep50/300 ‚Äî Train MSE: 32.139849, Val MSE: 30.982569, LR: 1.000e-03\n",
      "Fold5 Ep51/300 ‚Äî Train MSE: 32.453147, Val MSE: 31.411769, LR: 1.000e-03\n",
      "Fold5 Ep52/300 ‚Äî Train MSE: 32.143404, Val MSE: 35.418867, LR: 1.000e-03\n",
      "Fold5 Ep53/300 ‚Äî Train MSE: 31.576393, Val MSE: 30.053784, LR: 1.000e-03\n",
      " ‚Ü≥ New best (Val MSE=30.053784), saved.\n",
      "Fold5 Ep54/300 ‚Äî Train MSE: 32.090650, Val MSE: 33.829628, LR: 1.000e-03\n",
      "Fold5 Ep55/300 ‚Äî Train MSE: 32.174108, Val MSE: 33.502847, LR: 1.000e-03\n",
      "Fold5 Ep56/300 ‚Äî Train MSE: 31.613351, Val MSE: 31.365402, LR: 1.000e-03\n",
      "Fold5 Ep57/300 ‚Äî Train MSE: 31.617901, Val MSE: 32.433196, LR: 1.000e-03\n",
      "Fold5 Ep58/300 ‚Äî Train MSE: 31.426775, Val MSE: 30.175875, LR: 1.000e-03\n",
      "Fold5 Ep59/300 ‚Äî Train MSE: 31.405470, Val MSE: 30.537172, LR: 1.000e-03\n",
      "Fold5 Ep60/300 ‚Äî Train MSE: 30.926641, Val MSE: 31.698946, LR: 1.000e-03\n",
      "Fold5 Ep61/300 ‚Äî Train MSE: 31.669958, Val MSE: 32.040487, LR: 1.000e-03\n",
      "Fold5 Ep62/300 ‚Äî Train MSE: 31.115138, Val MSE: 33.930249, LR: 1.000e-03\n",
      "Fold5 Ep63/300 ‚Äî Train MSE: 31.121071, Val MSE: 32.812684, LR: 1.000e-03\n",
      "Fold5 Ep64/300 ‚Äî Train MSE: 30.688587, Val MSE: 30.498538, LR: 1.000e-03\n",
      "Fold5 Ep65/300 ‚Äî Train MSE: 30.588210, Val MSE: 31.108165, LR: 5.000e-04\n",
      "Fold5 Ep66/300 ‚Äî Train MSE: 30.458547, Val MSE: 30.863763, LR: 5.000e-04\n",
      "Fold5 Ep67/300 ‚Äî Train MSE: 30.003309, Val MSE: 31.017948, LR: 5.000e-04\n",
      "Fold5 Ep68/300 ‚Äî Train MSE: 30.048974, Val MSE: 31.516701, LR: 5.000e-04\n",
      "Fold5 Ep69/300 ‚Äî Train MSE: 30.190342, Val MSE: 31.029204, LR: 5.000e-04\n",
      "Fold5 Ep70/300 ‚Äî Train MSE: 29.995491, Val MSE: 31.999565, LR: 5.000e-04\n",
      "Fold5 Ep71/300 ‚Äî Train MSE: 29.747059, Val MSE: 31.592111, LR: 5.000e-04\n",
      "Fold5 Ep72/300 ‚Äî Train MSE: 29.574945, Val MSE: 30.633273, LR: 5.000e-04\n",
      "Fold5 Ep73/300 ‚Äî Train MSE: 29.778231, Val MSE: 30.786776, LR: 5.000e-04\n",
      " ‚úã Early stopping (no improvement in 20 epochs).\n",
      " Fold5 Best refined Val MSE: 30.053782\n",
      " ‚úÖ Best meta-model saved to: output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/fold5/meta_model_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:188: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(best_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "META_EPOCHS = 300\n",
    "start_fold = 0\n",
    "repeats = 3\n",
    "from python_scripts.aug         import augment_grouped_data, identity, subset_grouped_data\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "def extract_feats_preds(loader, rank_preds=False):\n",
    "    all_latents, all_preds, all_labels = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            tiles    = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "            labels   = batch['label']                 # ÂÅáËÆæ batch['label'] Âú® cpu\n",
    "            center   = subtiles[:, 4].contiguous()\n",
    "\n",
    "            f_c  = net.encoder_center(center)\n",
    "            f_n  = net.encoder_subtile(subtiles)\n",
    "            f_t  = net.encoder_tile(tiles)\n",
    "            fuse = torch.cat([f_c, f_n, f_t], dim=1)\n",
    "\n",
    "            out  = net.decoder(fuse)\n",
    "\n",
    "            all_latents.append(fuse.cpu())\n",
    "            all_preds.append(out.cpu())\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    # cat & to numpy\n",
    "    latents = torch.cat(all_latents, dim=0).numpy()  # (N, D)\n",
    "    preds   = torch.cat(all_preds,   dim=0).numpy()  # (N, 35)\n",
    "    labs    = torch.cat(all_labels,  dim=0).numpy()  # (N, 35)\n",
    "\n",
    "    if rank_preds:\n",
    "        # ÂØπÊØè‰∏ÄË°å row ÂÅö rankÔºåÊï∞ÂÄºË∂äÂ§ß rank Ë∂äÂ§ßÔºõÊúÄÂ∞èÁöÑÊï∞ rank=1\n",
    "        # Ê≥®ÊÑèÔºörankdata ÈªòËÆ§ smallest‚Üí1, largest‚ÜíN\n",
    "        # Â¶ÇÊûú‰Ω†ÊÉ≥ËÆ© largest‚Üí35, smallest‚Üí1ÔºåÂàôÔºö\n",
    "        ranks = np.apply_along_axis(lambda row: rankdata(row, method='ordinal'), 1, preds)\n",
    "        preds = ranks.astype(np.float32)\n",
    "\n",
    "    return latents, preds, labs\n",
    "# Âú® loop ‰πãÂâç\n",
    "\n",
    "fold_mse = {}\n",
    "for fold_id, (tr_idx, va_idx) in enumerate(\n",
    "    logo.split(X=np.zeros(n_samples), y=None, groups=slide_idx)):\n",
    "\n",
    "    # if fold_id > start_fold:\n",
    "    #     print(f\"‚è≠Ô∏è Skipping fold {fold_id}\")\n",
    "    #     continue\n",
    "\n",
    "    print(f\"\\nüöÄ Starting fold {fold_id}...\")\n",
    "    ckpt_path = os.path.join(trained_oof_model_folder, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "\n",
    "    # === Load model and predict OOF ===\n",
    "    net = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net = net.to(device).eval()\n",
    "\n",
    "\n",
    "    \n",
    "    local_idx = np.arange(len(va_idx))\n",
    "    train_loc, val_loc = train_test_split(\n",
    "        local_idx,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        shuffle=True\n",
    "    )\n",
    "    train_meta_idx = va_idx[train_loc]   # ÁúüÂÆûÁöÑ global indices\n",
    "    val_meta_idx   = va_idx[val_loc]\n",
    "\n",
    "    # 2) ÂØπ train_meta ÂÅö augment\n",
    "    train_base = subset_grouped_data(grouped_data, train_meta_idx)\n",
    "    print(\"üåÄ Starting augment for meta-train ‚Ä¶\")\n",
    "    train_aug_ds = augment_grouped_data(\n",
    "        grouped_data=train_base,\n",
    "        image_keys=['tile','subtiles'],\n",
    "        repeats=repeats            # ‰Ω†Ë¶ÅÁöÑÂ¢ûÂº∫Ê¨°Êï∞\n",
    "    )\n",
    "    print(\"üåÄ Starting import sugmentation data ‚Ä¶\")\n",
    "\n",
    "    train_dataset = importDataset(train_aug_ds, net,\n",
    "                                image_keys=['tile','subtiles'],\n",
    "                                transform=lambda x: x)\n",
    "    train_aug_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_base = subset_grouped_data(grouped_data, val_meta_idx)\n",
    "    val_dataset = importDataset(val_base, net,\n",
    "                             image_keys=['tile','subtiles'],\n",
    "                             transform=lambda x: x)\n",
    "    val_meta_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    print(\"üåÄ Starting prepare OOF data from CNN model‚Ä¶\")\n",
    "    train_lat, train_pr, train_y = extract_feats_preds(train_aug_loader)\n",
    "    \n",
    "    val_lat,   val_pr,   val_y   = extract_feats_preds(val_meta_loader)\n",
    "\n",
    "    extra_train_feats, train_feat_names = generate_meta_features(\n",
    "        dataset=train_dataset,\n",
    "        model_for_recon=recon_model,      # ‰Ω†ÁöÑ AE Ê®°Âûã\n",
    "        device=device,\n",
    "        ae_type=ae_type,\n",
    "        oof_preds=train_pr,\n",
    "        latents=train_lat\n",
    "    )\n",
    "    diagnose_meta_nonfinite(extra_train_feats, train_feat_names)\n",
    "    extra_val_feats, val_feat_names = generate_meta_features(\n",
    "        dataset=val_dataset,\n",
    "        model_for_recon=recon_model,\n",
    "        device=device,\n",
    "        ae_type=ae_type,\n",
    "        oof_preds=val_pr,\n",
    "        latents=val_lat\n",
    "    )\n",
    "    diagnose_meta_nonfinite(extra_val_feats, val_feat_names)\n",
    "\n",
    "    # 5) Êää‰∏âÈÉ®ÂàÜÁâπÂæÅÊãºÂú®‰∏ÄËµ∑Ôºö [latents | preds | extra_feats]\n",
    "    X_feat_train = np.concatenate([train_lat, extra_train_feats], axis=1)\n",
    "    X_feat_val   = np.concatenate([val_lat, extra_val_feats  ], axis=1)\n",
    "    # ËøôÈáå D_feat = X_feat_train.shape[1]\n",
    "    D_feat = X_feat_train.shape[1]\n",
    "\n",
    "    # Êää features, predictions, labels ‰∏â‰∏™Âº†ÈáèÊîæ‰∏ÄËµ∑\n",
    "    ds_train_meta = TensorDataset(\n",
    "        torch.from_numpy(X_feat_train).float(),\n",
    "        torch.from_numpy(train_pr).float(),\n",
    "        torch.from_numpy(train_y).float()\n",
    "    )\n",
    "    ds_val_meta   = TensorDataset(\n",
    "        torch.from_numpy(X_feat_val).float(),\n",
    "        torch.from_numpy(val_pr).float(),\n",
    "        torch.from_numpy(val_y).float()\n",
    "    )\n",
    "\n",
    "    loader_train_meta = DataLoader(ds_train_meta, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    loader_val_meta   = DataLoader(ds_val_meta,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # ‚Äî‚Äî 6) ÂàùÂßãÂåñ DeepResMLP ‚Äî‚Äî \n",
    "    # ËÆ©ÂÆÉÁöÑËæìÂÖ•Áª¥Â∫¶Á≠â‰∫é D_feat\n",
    "    meta_model = DeepResMLP(in_dim=D_feat, hidden_dims=[1024,512,256,128], out_dim=C).to(device)\n",
    "\n",
    "    criterion      = nn.MSELoss()\n",
    "    optimizer_meta = torch.optim.Adam(meta_model.parameters(), lr=1e-3)\n",
    "    scheduler_meta = ReduceLROnPlateau(optimizer_meta, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "\n",
    "    best_loss, es_cnt, es_patience = float('inf'), 0, 20\n",
    "    best_path = os.path.join(trained_oof_model_folder, f\"fold{fold_id}\", \"meta_model_best.pt\")\n",
    "\n",
    "    # ‚Äî‚Äî 7) ËÆ≠ÁªÉÂæ™ÁéØ ‚Äî‚Äî  \n",
    "    for epoch in range(1, META_EPOCHS+1):\n",
    "        # ‚Äî‚Äî‚Äî ËÆ≠ÁªÉ ‚Äî‚Äî‚Äî\n",
    "        meta_model.train()\n",
    "        train_loss = 0.0\n",
    "        for feats, pr, yb in loader_train_meta:\n",
    "            feats, pr, yb = feats.to(device), pr.to(device), yb.to(device)\n",
    "            out = meta_model(feats, pr)\n",
    "            loss = criterion(out, yb)\n",
    "\n",
    "            optimizer_meta.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_meta.step()\n",
    "            train_loss += loss.item() * feats.size(0)\n",
    "        train_loss /= len(ds_train_meta)\n",
    "\n",
    "        # ‚Äî‚Äî‚Äî È™åËØÅ ‚Äî‚Äî‚Äî\n",
    "        meta_model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for feats, pr, yb in loader_val_meta:\n",
    "                feats, pr, yb = feats.to(device), pr.to(device), yb.to(device)\n",
    "                out = meta_model(feats, pr)\n",
    "                val_loss += criterion(out, yb).item() * feats.size(0)\n",
    "        val_loss /= len(ds_val_meta)\n",
    "\n",
    "        print(f\"Fold{fold_id} Ep{epoch}/{META_EPOCHS} ‚Äî \"\n",
    "            f\"Train MSE: {train_loss:.6f}, Val MSE: {val_loss:.6f}, \"\n",
    "            f\"LR: {optimizer_meta.param_groups[0]['lr']:.3e}\")\n",
    "\n",
    "        # Ë∞ÉÂ∫¶ & Êó©ÂÅú & ‰øùÂ≠òÊúÄ‰Ω≥\n",
    "        scheduler_meta.step(val_loss)\n",
    "        if val_loss < best_loss:\n",
    "            best_loss, es_cnt = val_loss, 0\n",
    "            torch.save(meta_model.state_dict(), best_path)\n",
    "            print(f\" ‚Ü≥ New best (Val MSE={best_loss:.6f}), saved.\")\n",
    "        else:\n",
    "            es_cnt += 1\n",
    "            if es_cnt >= es_patience:\n",
    "                print(f\" ‚úã Early stopping (no improvement in {es_patience} epochs).\")\n",
    "                break\n",
    "\n",
    "    # ‚Äî‚Äî 8) Âä†ËΩΩÊúÄ‰Ω≥Ê®°ÂûãÂπ∂ËØÑ‰º∞ÔºàÂèØÈÄâÔºâ ‚Äî‚Äî  \n",
    "    meta_model.load_state_dict(torch.load(best_path, map_location=device))\n",
    "    meta_model.eval()\n",
    "    with torch.no_grad():\n",
    "        feats_all = torch.from_numpy(X_feat_val).float().to(device)\n",
    "        pr_all    = torch.from_numpy(val_pr).float().to(device)\n",
    "        refined_preds = meta_model(feats_all, pr_all).cpu().numpy()\n",
    "\n",
    "    mse_val = ((refined_preds - val_y) ** 2).mean()\n",
    "    print(f\" Fold{fold_id} Best refined Val MSE: {mse_val:.6f}\")\n",
    "    print(f\" ‚úÖ Best meta-model saved to: {best_path}\")\n",
    "    fold_mse[fold_id] = mse_val\n",
    "import pandas as pd\n",
    "mse_df = pd.DataFrame.from_dict(fold_mse, orient='index', columns=['val_mse'])\n",
    "mse_df.index.name = 'fold'\n",
    "mse_df.to_csv(os.path.join(trained_oof_model_folder, \"fold_meta_mse.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/import_data.py:280: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  raw = torch.load(pt_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Âæû '<class 'list'>' Êé®Êñ∑Ê®£Êú¨Êï∏Èáè: 2088\n",
      "Model forward signature: (tile, subtiles)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from python_scripts.import_data import load_node_feature_data\n",
    "\n",
    "\n",
    "image_keys = [ 'tile', 'subtiles']\n",
    "\n",
    "model = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "\n",
    "# Áî®Ê≥ïÁ§∫‰æã\n",
    "from python_scripts.import_data import importDataset\n",
    "# ÂÅáËÆæ‰Ω†ÁöÑ model Â∑≤ÁªèÂÆö‰πâÂ•ΩÂπ∂ÂÆû‰æãÂåñ‰∏∫ `model`\n",
    "test_dataset = load_node_feature_data(\"dataset/spot-rank/filtered_directly_rank/masked/test/Macenko_4_7/test_dataset.pt\", model)\n",
    "test_dataset = importDataset(\n",
    "        data_dict=test_dataset,\n",
    "        model=model,\n",
    "        image_keys=image_keys,\n",
    "        transform=lambda x: x,  # identity transform\n",
    "        print_sig=True\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble weights per fold: [0.14668326 0.22717708 0.13848365 0.12272543 0.15362587 0.21130471]\n",
      "üçÄ Fold 0 predicting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
      "Computing AE recon loss: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:05<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "‚úÖ Generated meta-features with shape: (2088, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=501120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=225504, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=16704, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=150336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=902016, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=73080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=283968, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=41760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=1242360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=10440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=66816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(meta_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçÄ Fold 1 predicting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
      "Computing AE recon loss: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:05<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "‚úÖ Generated meta-features with shape: (2088, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=501120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=225504, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=16704, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=150336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=902016, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=73080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=283968, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=41760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=1242360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=10440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=66816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(meta_path, map_location=device))\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçÄ Fold 2 predicting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:06<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "‚úÖ Generated meta-features with shape: (2088, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=501120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=225504, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=16704, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=150336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=902016, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=73080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=283968, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=41760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=1242360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=10440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=66816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(meta_path, map_location=device))\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçÄ Fold 3 predicting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:05<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "‚úÖ Generated meta-features with shape: (2088, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=501120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=225504, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=16704, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=150336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=902016, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=73080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=283968, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=41760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=1242360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=10440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=66816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(meta_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçÄ Fold 4 predicting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
      "Computing AE recon loss: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:05<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "‚úÖ Generated meta-features with shape: (2088, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=501120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=225504, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=16704, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=150336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=902016, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=73080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=283968, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=41760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=1242360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=10440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=66816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(meta_path, map_location=device))\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçÄ Fold 5 predicting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:02<00:00, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "‚úÖ Generated meta-features with shape: (2088, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=501120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=225504, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=16704, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=150336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=902016, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=73080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=283968, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=41760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=1242360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=10440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=66816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(meta_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved stacked ensemble submission ‚Üí output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/submission_stacked.csv\n",
      "‚úÖ Saved weighted ensemble submission ‚Üí output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/submission_weighted.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 0) ÂÖàËØªÂÖ•ÂêÑ fold ÁöÑ val_mseÔºåÂπ∂ËÆ°ÁÆóÊùÉÈáç ---\n",
    "mse_df = pd.read_csv(\n",
    "    os.path.join(trained_oof_model_folder, \"fold_meta_mse.csv\"),\n",
    "    index_col=\"fold\"\n",
    ").sort_index()\n",
    "mses = mse_df[\"val_mse\"].values          # shape (n_folds,)\n",
    "weights = 1.0 / mses                      # Ë∂ä‰ΩéÁöÑ mse ÊùÉÈáçÂ§ß\n",
    "weights = weights / weights.sum()         # ÂΩí‰∏ÄÂåñÂíå‰∏∫ 1\n",
    "print(\"Ensemble weights per fold:\", weights)\n",
    "\n",
    "# --- 3) Prepare test meta-features & stacking predictions ---\n",
    "n_test = len(test_dataset)\n",
    "all_final = []\n",
    "\n",
    "for fold_id in range(n_folds):\n",
    "    # if fold_id > start_fold:\n",
    "    #     print(f\"‚è≠Ô∏è Skipping fold {fold_id}\")\n",
    "    #     continue\n",
    "    print(f\"üçÄ Fold {fold_id} predicting ...\")\n",
    "    \n",
    "    # 1) Load base model (VisionMLP_MultiTask) and get test_preds, test_latents\n",
    "    ckpt_path   = os.path.join(trained_oof_model_folder, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net         = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net = net.to(device).eval()\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    test_latents, test_preds, _ = extract_feats_preds(test_loader)\n",
    "    extra_test_feats, test_feat_names = generate_meta_features(\n",
    "        dataset=test_dataset,\n",
    "        model_for_recon=recon_model,\n",
    "        device=device,\n",
    "        ae_type=ae_type,\n",
    "        oof_preds=test_preds,\n",
    "        latents=test_latents\n",
    "    )\n",
    "    diagnose_meta_nonfinite(extra_test_feats, test_feat_names)\n",
    "\n",
    "    # 5) Êää‰∏âÈÉ®ÂàÜÁâπÂæÅÊãºÂú®‰∏ÄËµ∑Ôºö [latents | preds | extra_feats]\n",
    "    X_feat_test = np.concatenate([test_latents, extra_test_feats], axis=1)\n",
    "    # ËøôÈáå D_feat = X_feat_train.shape[1]\n",
    "    D_feat = X_feat_test.shape[1]\n",
    "\n",
    "    # Êää features, predictions, labels ‰∏â‰∏™Âº†ÈáèÊîæ‰∏ÄËµ∑\n",
    "    ds_test_meta = TensorDataset(\n",
    "        torch.from_numpy(X_feat_test).float(),\n",
    "        torch.from_numpy(test_preds).float())\n",
    "\n",
    "\n",
    "    loader_test_meta = DataLoader(ds_test_meta, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # 2) Load the trained meta-learner for this fold\n",
    "    D = test_latents.shape[1]\n",
    "    meta_model = DeepResMLP(in_dim=D_feat, hidden_dims=[1024,512,256,128], out_dim=C).to(device)\n",
    "\n",
    "    meta_path = os.path.join(\n",
    "        trained_oof_model_folder,\n",
    "        f\"fold{fold_id}\",\n",
    "        \"meta_model_best.pt\"\n",
    "    )\n",
    "    meta_model.load_state_dict(torch.load(meta_path, map_location=device))\n",
    "    meta_model.eval()\n",
    "\n",
    "    # 3) Áî® meta-learner ÂÅö refined prediction\n",
    "    with torch.no_grad():\n",
    "        feats_tensor = torch.from_numpy(X_feat_test).float().to(device)\n",
    "        preds_tensor = torch.from_numpy(test_preds).float().to(device)\n",
    "        refined_pred = meta_model(feats_tensor, preds_tensor).cpu().numpy()\n",
    "\n",
    "    all_final.append(refined_pred)\n",
    "\n",
    "# --- 4) Âä†ÊùÉ ensemble ---\n",
    "# all_refined: list of (n_test, C) arrays\n",
    "# weights: shape (n_folds,)\n",
    "final_weighted = np.zeros_like(all_final[0])\n",
    "for w, pred in zip(weights, all_final):\n",
    "    final_weighted += w * pred\n",
    "\n",
    "# --- 5) Save submissions ---\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spot_ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"]))\n",
    "\n",
    "# unweighted averageÔºà‰øùÁïôÊóßÁâàÂØπÊØîÔºâ\n",
    "final_simple = np.mean(all_final, axis=0)\n",
    "\n",
    "# ÂÜô‰∏§‰∏™Êñá‰ª∂\n",
    "for name, arr in [(\"stacked\", final_simple), (\"weighted\", final_weighted)]:\n",
    "    sub = pd.DataFrame(arr, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "    sub.insert(0, 'ID', test_spot_ids.index)\n",
    "    path = os.path.join(trained_oof_model_folder, f\"submission_{name}.csv\")\n",
    "    sub.to_csv(path, index=False)\n",
    "    print(f\"‚úÖ Saved {name} ensemble submission ‚Üí {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21.119944, 24.191807, 24.289158, ..., 12.108937,  9.812806,\n",
       "        23.269012],\n",
       "       [20.796225, 24.415634, 24.210833, ..., 12.384914,  9.888517,\n",
       "        24.08245 ],\n",
       "       [24.244806, 28.043358, 25.876398, ...,  9.660413,  9.817519,\n",
       "        19.834955],\n",
       "       ...,\n",
       "       [21.064796, 30.208473, 23.31816 , ..., 11.452721,  8.848305,\n",
       "        20.618204],\n",
       "       [20.672852, 24.048859, 23.066084, ..., 12.829765, 10.746237,\n",
       "        25.129263],\n",
       "       [18.379812, 24.315762, 22.625013, ..., 12.282604, 10.867987,\n",
       "        25.213802]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ËÆÄ test spot index\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spots     = f[\"spots/Test\"]\n",
    "    test_spot_table= pd.DataFrame(np.array(test_spots['S_7']))\n",
    "\n",
    "fold_ckpts = sorted(glob.glob(os.path.join(trained_oof_model_folder, \"fold*\", \"best_model.pt\")))\n",
    "models = []\n",
    "for ckpt in fold_ckpts:\n",
    "    net = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt, map_location=\"cpu\"))\n",
    "    net.to(device).eval()\n",
    "    models.append(net)\n",
    "\n",
    "all_fold_preds = []\n",
    "for fold_id, net in enumerate(models):\n",
    "    # Êé®Ë´ñ\n",
    "    print(f\"üçÄ Fold {fold_id} predicting ...\")\n",
    "    with torch.no_grad():\n",
    "        preds = predict(net, test_loader, device)  # (N_test,35) numpy array\n",
    "\n",
    "    # 1) Â≠òÊØè‰∏ÄÊäòÁöÑÂéüÂßãÈ†êÊ∏¨\n",
    "    df_fold = pd.DataFrame(preds, columns=[f\"C{i+1}\" for i in range(preds.shape[1])])\n",
    "    df_fold.insert(0, \"ID\", test_spot_table.index)\n",
    "    path_fold = os.path.join(trained_oof_model_folder, f\"submission_fold{fold_id}.csv\")\n",
    "    df_fold.to_csv(path_fold, index=False)\n",
    "    print(f\"‚úÖ Saved fold {fold_id} predictions to {path_fold}\")\n",
    "\n",
    "    all_fold_preds.append(preds)\n",
    "\n",
    "# 2) ÂÅö rank‚Äêaverage ensemble\n",
    "all_fold_preds = np.stack(all_fold_preds, axis=0)       # (K, N_test, 35)\n",
    "ranks          = all_fold_preds.argsort(axis=2).argsort(axis=2).astype(float)\n",
    "mean_rank      = ranks.mean(axis=0)                    # (N_test,35)\n",
    "\n",
    "# 3) Â≠ò final ensemble\n",
    "df_ens = pd.DataFrame(mean_rank, columns=[f\"C{i+1}\" for i in range(mean_rank.shape[1])])\n",
    "df_ens.insert(0, \"ID\", test_spot_table.index)\n",
    "path_ens = os.path.join(trained_oof_model_folder, \"submission_rank_ensemble.csv\")\n",
    "df_ens.to_csv(path_ens, index=False)\n",
    "print(f\"‚úÖ Saved rank‚Äêensemble submission to {path_ens}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model stacking with one meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from python_scripts.import_data import importDataset  # ÂÅáËÆæËøô‰∏™ËÉΩÁªô‰Ω† full_dataset\n",
    "from python_scripts.aug import subset_grouped_data   # Áî®Êù•ÂàáÂá∫ grouped_data\n",
    "\n",
    "# Settings\n",
    "trained_oof_model_folder = 'output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked'\n",
    "n_folds    = 6\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 64\n",
    "C          = 35  # Á±ªÂà´Êï∞ / ÊØè‰∏™È¢ÑÊµãÂêëÈáèÈïøÂ∫¶\n",
    "META_EPOCHS = 250\n",
    "tile_dim = 128\n",
    "center_dim = 128\n",
    "neighbor_dim = 128\n",
    "# 1) Load full_dataset & y_true\n",
    "n_samples = len(full_dataset)\n",
    "y_true = np.vstack([full_dataset[i]['label'].cpu().numpy() for i in range(n_samples)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçÄ Fold 0 predicting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1968516026.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçÄ Fold 1 predicting ...\n",
      "üçÄ Fold 2 predicting ...\n",
      "üçÄ Fold 3 predicting ...\n",
      "üçÄ Fold 4 predicting ...\n",
      "üçÄ Fold 5 predicting ...\n",
      "üçÄ Preparing data for meta model ...\n",
      "üçÄ Start training meta model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ‚Äî Train MSE 398.833550, Val MSE 343.151417, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 2 ‚Äî Train MSE 220.268595, Val MSE 109.576775, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 3 ‚Äî Train MSE 70.895166, Val MSE 52.277888, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 4 ‚Äî Train MSE 53.457557, Val MSE 47.230638, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 5 ‚Äî Train MSE 51.738313, Val MSE 45.111218, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 6 ‚Äî Train MSE 50.567188, Val MSE 45.199467, lr 1.000e-03\n",
      "Epoch 7 ‚Äî Train MSE 50.151351, Val MSE 46.167478, lr 1.000e-03\n",
      "Epoch 8 ‚Äî Train MSE 49.153631, Val MSE 43.752192, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 9 ‚Äî Train MSE 48.613082, Val MSE 44.310437, lr 1.000e-03\n",
      "Epoch 10 ‚Äî Train MSE 48.550224, Val MSE 43.390919, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 11 ‚Äî Train MSE 48.351976, Val MSE 44.635134, lr 1.000e-03\n",
      "Epoch 12 ‚Äî Train MSE 47.697107, Val MSE 42.686886, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 13 ‚Äî Train MSE 47.436593, Val MSE 42.415576, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 14 ‚Äî Train MSE 47.478582, Val MSE 41.678534, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 15 ‚Äî Train MSE 46.766871, Val MSE 41.855991, lr 1.000e-03\n",
      "Epoch 16 ‚Äî Train MSE 47.007778, Val MSE 41.335236, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 17 ‚Äî Train MSE 46.861905, Val MSE 42.304492, lr 1.000e-03\n",
      "Epoch 18 ‚Äî Train MSE 46.701075, Val MSE 41.140256, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 19 ‚Äî Train MSE 46.420621, Val MSE 41.438767, lr 1.000e-03\n",
      "Epoch 20 ‚Äî Train MSE 46.074126, Val MSE 42.125472, lr 1.000e-03\n",
      "Epoch 21 ‚Äî Train MSE 46.005365, Val MSE 40.819189, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 22 ‚Äî Train MSE 45.595014, Val MSE 41.124747, lr 1.000e-03\n",
      "Epoch 23 ‚Äî Train MSE 45.638896, Val MSE 40.085422, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 24 ‚Äî Train MSE 45.469965, Val MSE 39.608566, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 25 ‚Äî Train MSE 46.689905, Val MSE 42.826823, lr 1.000e-03\n",
      "Epoch 26 ‚Äî Train MSE 46.311248, Val MSE 40.674245, lr 1.000e-03\n",
      "Epoch 27 ‚Äî Train MSE 46.015575, Val MSE 41.011701, lr 1.000e-03\n",
      "Epoch 28 ‚Äî Train MSE 45.636403, Val MSE 40.539881, lr 1.000e-03\n",
      "Epoch 29 ‚Äî Train MSE 46.020378, Val MSE 41.145701, lr 1.000e-03\n",
      "Epoch 30 ‚Äî Train MSE 45.261758, Val MSE 39.752437, lr 1.000e-03\n",
      "Epoch 31 ‚Äî Train MSE 45.124922, Val MSE 39.488810, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 32 ‚Äî Train MSE 44.727973, Val MSE 39.214988, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 33 ‚Äî Train MSE 44.577897, Val MSE 39.365381, lr 1.000e-03\n",
      "Epoch 34 ‚Äî Train MSE 44.605097, Val MSE 39.479706, lr 1.000e-03\n",
      "Epoch 35 ‚Äî Train MSE 44.438441, Val MSE 39.098742, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 36 ‚Äî Train MSE 44.264860, Val MSE 39.042434, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 37 ‚Äî Train MSE 44.165181, Val MSE 39.535003, lr 1.000e-03\n",
      "Epoch 38 ‚Äî Train MSE 44.199058, Val MSE 39.012007, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 39 ‚Äî Train MSE 44.058355, Val MSE 38.893878, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 40 ‚Äî Train MSE 44.112248, Val MSE 39.286840, lr 1.000e-03\n",
      "Epoch 41 ‚Äî Train MSE 44.665875, Val MSE 38.829662, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 42 ‚Äî Train MSE 44.054323, Val MSE 38.833708, lr 1.000e-03\n",
      "Epoch 43 ‚Äî Train MSE 43.966174, Val MSE 39.516964, lr 1.000e-03\n",
      "Epoch 44 ‚Äî Train MSE 43.621622, Val MSE 38.693630, lr 1.000e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 45 ‚Äî Train MSE 45.294959, Val MSE 41.749526, lr 1.000e-03\n",
      "Epoch 46 ‚Äî Train MSE 46.082395, Val MSE 40.794412, lr 1.000e-03\n",
      "Epoch 47 ‚Äî Train MSE 44.874214, Val MSE 40.534002, lr 1.000e-03\n",
      "Epoch 48 ‚Äî Train MSE 44.859466, Val MSE 40.573526, lr 1.000e-03\n",
      "Epoch 49 ‚Äî Train MSE 44.848153, Val MSE 40.203111, lr 1.000e-03\n",
      "Epoch 50 ‚Äî Train MSE 44.571628, Val MSE 39.957169, lr 1.000e-03\n",
      "Epoch 51 ‚Äî Train MSE 44.799125, Val MSE 40.514772, lr 1.000e-03\n",
      "Epoch 52 ‚Äî Train MSE 44.444311, Val MSE 39.617058, lr 1.000e-03\n",
      "Epoch 53 ‚Äî Train MSE 44.267741, Val MSE 39.810534, lr 1.000e-03\n",
      "Epoch 54 ‚Äî Train MSE 44.509223, Val MSE 40.085464, lr 1.000e-03\n",
      "Epoch 55 ‚Äî Train MSE 43.966553, Val MSE 39.599766, lr 1.000e-03\n",
      "Epoch 56 ‚Äî Train MSE 44.069371, Val MSE 39.352422, lr 5.000e-04\n",
      "Epoch 57 ‚Äî Train MSE 43.783443, Val MSE 39.326401, lr 5.000e-04\n",
      "Epoch 58 ‚Äî Train MSE 43.674071, Val MSE 39.109002, lr 5.000e-04\n",
      "Epoch 59 ‚Äî Train MSE 43.657689, Val MSE 39.063694, lr 5.000e-04\n",
      "Epoch 60 ‚Äî Train MSE 43.690025, Val MSE 39.064317, lr 5.000e-04\n",
      "Epoch 61 ‚Äî Train MSE 43.777777, Val MSE 39.338124, lr 5.000e-04\n",
      "Epoch 62 ‚Äî Train MSE 43.469156, Val MSE 39.121436, lr 5.000e-04\n",
      "Epoch 63 ‚Äî Train MSE 43.613957, Val MSE 38.865140, lr 5.000e-04\n",
      "Epoch 64 ‚Äî Train MSE 43.281180, Val MSE 38.849506, lr 5.000e-04\n",
      " üõë Early stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1968516026.py:128: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mlp.load_state_dict(torch.load(best_path, map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingMLP(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=210, out_features=512, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=256, out_features=35, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) ÂØπÊØè‰∏™ fold Êî∂ÈõÜ OOF È¢ÑÊµã\n",
    "oof_preds = np.zeros((n_samples, n_folds, C), dtype=np.float32)\n",
    "full_loader = DataLoader(full_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=False)\n",
    "\n",
    "for fold_id, (_, va_idx) in enumerate(\n",
    "    logo.split(X=np.zeros(n_samples), y=None, groups=slide_idx)\n",
    "):\n",
    "    # a) load base model for this fold\n",
    "    print(f\"üçÄ Fold {fold_id} predicting ...\")\n",
    "    ckpt = os.path.join(trained_oof_model_folder, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net  = VisionMLP_MultiTask(tile_dim, center_dim, output_dim=C).to(device)\n",
    "    net.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "    net.eval()\n",
    "    \n",
    "    # b) Áî®Ëøô‰∏™ model Âè™ÂØπÂÆÉÁöÑ **È™åËØÅÈõÜ** ÂÅöÈ¢ÑÊµãÔºàOOFÔºâ\n",
    "    val_ds = Subset(full_dataset, va_idx)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in full_loader:\n",
    "            tiles, subtiles = batch['tile'].to(device), batch['subtiles'].to(device)\n",
    "            center = subtiles[:,4]\n",
    "            f_c = net.encoder_center(center)\n",
    "            f_n = net.encoder_subtile(subtiles)\n",
    "            f_t = net.encoder_tile(tiles)\n",
    "            fuse = torch.cat([f_c,f_n,f_t], dim=1)\n",
    "            out = net.decoder(fuse)\n",
    "            preds_list.append(out.cpu().numpy())\n",
    "    preds_fold = np.concatenate(preds_list, axis=0)  # (len(va_idx), C)\n",
    "\n",
    "    # c) Â°´ÂõûÂà∞ oof_preds[:, fold_id, :]\n",
    "    oof_preds[:, fold_id, :] = preds_fold\n",
    "\n",
    "print(\"üçÄ Preparing data for meta model ...\")\n",
    "\n",
    "# 3) reshape ‚Üí stacking ÁâπÂæÅÁü©Èòµ X_stack\n",
    "X_stack = oof_preds.reshape(n_samples, n_folds*C)    # (N, n_folds*C)\n",
    "y_stack = y_true                                   # (N, C)\n",
    "\n",
    "# 4) ÂàíÂàÜ meta‚Äêtrain / meta‚Äêval\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_stack, y_stack, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# 5) DataLoader\n",
    "ds_train = TensorDataset(torch.from_numpy(X_train).float(),\n",
    "                         torch.from_numpy(y_train).float())\n",
    "ds_val   = TensorDataset(torch.from_numpy(X_val).float(),\n",
    "                         torch.from_numpy(y_val).float())\n",
    "loader_train = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "loader_val   = DataLoader(ds_val,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# 6) ÂÆö‰πâ/ÂàùÂßãÂåñ stacking MLP\n",
    "in_dim = n_folds * C\n",
    "class StackingMLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dims=[512,256], out_dim=35, dropout=0.2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = in_dim\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(prev, h))\n",
    "            layers.append(nn.LeakyReLU(0.01))\n",
    "            layers.append(nn.BatchNorm1d(h))\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            prev = h\n",
    "        # ÊúÄÂêé‰∏ÄÂ±ÇÁõ¥Êé•ËæìÂá∫ out_dim\n",
    "        layers.append(nn.Linear(prev, out_dim))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape [B, in_dim], in_dim = n_folds * C\n",
    "        returns: Tensor of shape [B, out_dim]\n",
    "        \"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "mlp = StackingMLP(in_dim=n_folds*C, hidden_dims=[512,256], out_dim=C).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-3)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, min_lr=1e-6, verbose=True)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "best_val = float('inf')\n",
    "es_cnt, es_patience = 0, 20\n",
    "best_path = os.path.join(trained_oof_model_folder, \"stacking_meta_best.pt\")\n",
    "\n",
    "print(\"üçÄ Start training meta model ...\")\n",
    "\n",
    "# 7) ËÆ≠ÁªÉÂæ™ÁéØ\n",
    "for epoch in range(1, META_EPOCHS+1):\n",
    "    mlp.train()\n",
    "    train_loss = 0.0\n",
    "    for xb, yb in loader_train:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        out = mlp(xb)               # ÂâçÂêë\n",
    "        loss = criterion(out, yb)   # MSE\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * xb.size(0)\n",
    "    train_loss /= len(ds_train)\n",
    "\n",
    "    # È™åËØÅ\n",
    "    mlp.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader_val:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            val_loss += criterion(mlp(xb), yb).item() * xb.size(0)\n",
    "    val_loss /= len(ds_val)\n",
    "\n",
    "\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch} ‚Äî Train MSE {train_loss:.6f}, Val MSE {val_loss:.6f}, lr {current_lr:.3e}\")\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss; es_cnt = 0\n",
    "        torch.save(mlp.state_dict(), best_path)\n",
    "        print(\" ‚Ü≥ New best saved.\")\n",
    "    else:\n",
    "        es_cnt += 1\n",
    "        if es_cnt >= es_patience:\n",
    "            print(\" üõë Early stopping.\")\n",
    "            break\n",
    "\n",
    "# 8) ‰ªéÊúÄÂ•ΩÊ®°Âûã load ÂõûÊù•\n",
    "mlp.load_state_dict(torch.load(best_path, map_location=device))\n",
    "mlp.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçÄ Fold 0 predicting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/3338310424.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçÄ Fold 1 predicting ...\n",
      "üçÄ Fold 2 predicting ...\n",
      "üçÄ Fold 3 predicting ...\n",
      "üçÄ Fold 4 predicting ...\n",
      "üçÄ Fold 5 predicting ...\n",
      "üçÄ Meta model predicting ...\n",
      "‚úÖ Done single‚ÄêMLP stacking submission.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- ÊµãËØïÈò∂ÊÆµÔºöstacking ÁâπÂæÅ + ‰∏ÄÊ¨° mlp.forward() ---\n",
    "# ÂØπÊµãËØïÈõÜÊØè‰∏™ fold ÂÅöÈ¢ÑÊµãÔºåÊãº oof_preds_test (n_test, n_folds, C)Ôºåreshape ‚Üí (n_test, n_folds*C)\n",
    "oof_test = np.zeros((len(test_dataset), n_folds, C), dtype=np.float32)\n",
    "for fold_id in range(n_folds):\n",
    "    print(f\"üçÄ Fold {fold_id} predicting ...\")\n",
    "    # load each base model & predict on full test_dataset\n",
    "    ckpt = os.path.join(trained_oof_model_folder, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net  = VisionMLP_MultiTask(tile_dim, center_dim, output_dim=C).to(device)\n",
    "    net.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "    net.eval()\n",
    "\n",
    "    loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            tiles, subtiles = batch['tile'].to(device), batch['subtiles'].to(device)\n",
    "            center = subtiles[:,4]\n",
    "            fuse = torch.cat([\n",
    "                net.encoder_center(center),\n",
    "                net.encoder_subtile(subtiles),\n",
    "                net.encoder_tile(tiles)\n",
    "            ], dim=1)\n",
    "            preds_list.append(net.decoder(fuse).cpu().numpy())\n",
    "    oof_test[:, fold_id, :] = np.concatenate(preds_list, axis=0)\n",
    "\n",
    "print(\"üçÄ Meta model predicting ...\")\n",
    "X_test_stack = oof_test.reshape(len(test_dataset), n_folds*C)\n",
    "with torch.no_grad():\n",
    "    X_test_t = torch.from_numpy(X_test_stack).float().to(device)\n",
    "    final_test_preds = mlp(X_test_t).cpu().numpy()\n",
    "\n",
    "# 9) Â≠ò submission\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"])).index\n",
    "sub = pd.DataFrame(final_test_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, 'ID', ids)\n",
    "sub.to_csv(os.path.join(trained_oof_model_folder, \"submission_stacked_single_mlp.csv\"), index=False)\n",
    "print(\"‚úÖ Done single‚ÄêMLP stacking submission.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçÄ Start training meta model ...\n",
      "üçÄ Start training one LGBM per target ...\n",
      " ‚ñ∂ Training target #1/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.80957\n",
      "[200]\tvalid_0's rmse: 5.19367\n",
      "[300]\tvalid_0's rmse: 5.03413\n",
      "[400]\tvalid_0's rmse: 4.99558\n",
      "[500]\tvalid_0's rmse: 4.98487\n",
      "[600]\tvalid_0's rmse: 4.98404\n",
      "[700]\tvalid_0's rmse: 4.98417\n",
      "Early stopping, best iteration is:\n",
      "[566]\tvalid_0's rmse: 4.98222\n",
      " ‚ñ∂ Training target #2/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 2.58937\n",
      "[200]\tvalid_0's rmse: 2.26426\n",
      "[300]\tvalid_0's rmse: 2.16704\n",
      "[400]\tvalid_0's rmse: 2.13877\n",
      "[500]\tvalid_0's rmse: 2.1283\n",
      "[600]\tvalid_0's rmse: 2.12534\n",
      "[700]\tvalid_0's rmse: 2.12257\n",
      "[800]\tvalid_0's rmse: 2.12198\n",
      "[900]\tvalid_0's rmse: 2.12155\n",
      "[1000]\tvalid_0's rmse: 2.12206\n",
      "Early stopping, best iteration is:\n",
      "[892]\tvalid_0's rmse: 2.12121\n",
      " ‚ñ∂ Training target #3/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 4.09634\n",
      "[200]\tvalid_0's rmse: 3.52543\n",
      "[300]\tvalid_0's rmse: 3.37769\n",
      "[400]\tvalid_0's rmse: 3.34427\n",
      "[500]\tvalid_0's rmse: 3.33766\n",
      "[600]\tvalid_0's rmse: 3.33485\n",
      "[700]\tvalid_0's rmse: 3.33407\n",
      "[800]\tvalid_0's rmse: 3.33513\n",
      "Early stopping, best iteration is:\n",
      "[686]\tvalid_0's rmse: 3.3334\n",
      " ‚ñ∂ Training target #4/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 8.20165\n",
      "[200]\tvalid_0's rmse: 7.01577\n",
      "[300]\tvalid_0's rmse: 6.70831\n",
      "[400]\tvalid_0's rmse: 6.63517\n",
      "[500]\tvalid_0's rmse: 6.62244\n",
      "[600]\tvalid_0's rmse: 6.62169\n",
      "[700]\tvalid_0's rmse: 6.61905\n",
      "[800]\tvalid_0's rmse: 6.62346\n",
      "Early stopping, best iteration is:\n",
      "[695]\tvalid_0's rmse: 6.61806\n",
      " ‚ñ∂ Training target #5/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.7173\n",
      "[200]\tvalid_0's rmse: 6.66838\n",
      "[300]\tvalid_0's rmse: 6.35032\n",
      "[400]\tvalid_0's rmse: 6.24286\n",
      "[500]\tvalid_0's rmse: 6.2111\n",
      "[600]\tvalid_0's rmse: 6.19792\n",
      "[700]\tvalid_0's rmse: 6.1862\n",
      "[800]\tvalid_0's rmse: 6.18073\n",
      "[900]\tvalid_0's rmse: 6.18034\n",
      "[1000]\tvalid_0's rmse: 6.18071\n",
      "[1100]\tvalid_0's rmse: 6.18019\n",
      "Early stopping, best iteration is:\n",
      "[914]\tvalid_0's rmse: 6.1791\n",
      " ‚ñ∂ Training target #6/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.88352\n",
      "[200]\tvalid_0's rmse: 6.79117\n",
      "[300]\tvalid_0's rmse: 6.47416\n",
      "[400]\tvalid_0's rmse: 6.37851\n",
      "[500]\tvalid_0's rmse: 6.34054\n",
      "[600]\tvalid_0's rmse: 6.32187\n",
      "[700]\tvalid_0's rmse: 6.31667\n",
      "[800]\tvalid_0's rmse: 6.3116\n",
      "[900]\tvalid_0's rmse: 6.31055\n",
      "[1000]\tvalid_0's rmse: 6.30979\n",
      "[1100]\tvalid_0's rmse: 6.30663\n",
      "[1200]\tvalid_0's rmse: 6.30798\n",
      "[1300]\tvalid_0's rmse: 6.30814\n",
      "Early stopping, best iteration is:\n",
      "[1134]\tvalid_0's rmse: 6.30539\n",
      " ‚ñ∂ Training target #7/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.67557\n",
      "[200]\tvalid_0's rmse: 3.44097\n",
      "[300]\tvalid_0's rmse: 3.38332\n",
      "[400]\tvalid_0's rmse: 3.37214\n",
      "[500]\tvalid_0's rmse: 3.37246\n",
      "[600]\tvalid_0's rmse: 3.37353\n",
      "Early stopping, best iteration is:\n",
      "[409]\tvalid_0's rmse: 3.37135\n",
      " ‚ñ∂ Training target #8/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.65305\n",
      "[200]\tvalid_0's rmse: 5.56243\n",
      "[300]\tvalid_0's rmse: 5.54871\n",
      "[400]\tvalid_0's rmse: 5.5537\n",
      "[500]\tvalid_0's rmse: 5.56196\n",
      "Early stopping, best iteration is:\n",
      "[315]\tvalid_0's rmse: 5.54837\n",
      " ‚ñ∂ Training target #9/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 8.64605\n",
      "[200]\tvalid_0's rmse: 7.4803\n",
      "[300]\tvalid_0's rmse: 7.15783\n",
      "[400]\tvalid_0's rmse: 7.06843\n",
      "[500]\tvalid_0's rmse: 7.04112\n",
      "[600]\tvalid_0's rmse: 7.02802\n",
      "[700]\tvalid_0's rmse: 7.01882\n",
      "[800]\tvalid_0's rmse: 7.01577\n",
      "[900]\tvalid_0's rmse: 7.01531\n",
      "[1000]\tvalid_0's rmse: 7.01511\n",
      "[1100]\tvalid_0's rmse: 7.01387\n",
      "[1200]\tvalid_0's rmse: 7.01559\n",
      "Early stopping, best iteration is:\n",
      "[1075]\tvalid_0's rmse: 7.01232\n",
      " ‚ñ∂ Training target #10/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.17653\n",
      "[200]\tvalid_0's rmse: 6.20806\n",
      "[300]\tvalid_0's rmse: 5.981\n",
      "[400]\tvalid_0's rmse: 5.92642\n",
      "[500]\tvalid_0's rmse: 5.92103\n",
      "[600]\tvalid_0's rmse: 5.91982\n",
      "[700]\tvalid_0's rmse: 5.91797\n",
      "[800]\tvalid_0's rmse: 5.91826\n",
      "Early stopping, best iteration is:\n",
      "[658]\tvalid_0's rmse: 5.91482\n",
      " ‚ñ∂ Training target #11/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.78296\n",
      "[200]\tvalid_0's rmse: 7.04437\n",
      "[300]\tvalid_0's rmse: 6.81941\n",
      "[400]\tvalid_0's rmse: 6.75013\n",
      "[500]\tvalid_0's rmse: 6.72555\n",
      "[600]\tvalid_0's rmse: 6.71404\n",
      "[700]\tvalid_0's rmse: 6.70726\n",
      "[800]\tvalid_0's rmse: 6.70565\n",
      "[900]\tvalid_0's rmse: 6.70861\n",
      "[1000]\tvalid_0's rmse: 6.70967\n",
      "Early stopping, best iteration is:\n",
      "[807]\tvalid_0's rmse: 6.70446\n",
      " ‚ñ∂ Training target #12/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 4.2633\n",
      "[200]\tvalid_0's rmse: 3.62364\n",
      "[300]\tvalid_0's rmse: 3.44562\n",
      "[400]\tvalid_0's rmse: 3.39954\n",
      "[500]\tvalid_0's rmse: 3.38621\n",
      "[600]\tvalid_0's rmse: 3.37988\n",
      "[700]\tvalid_0's rmse: 3.37881\n",
      "[800]\tvalid_0's rmse: 3.37708\n",
      "[900]\tvalid_0's rmse: 3.37586\n",
      "[1000]\tvalid_0's rmse: 3.37608\n",
      "[1100]\tvalid_0's rmse: 3.37812\n",
      "Early stopping, best iteration is:\n",
      "[986]\tvalid_0's rmse: 3.3753\n",
      " ‚ñ∂ Training target #13/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.12512\n",
      "[200]\tvalid_0's rmse: 6.06792\n",
      "[300]\tvalid_0's rmse: 6.06935\n",
      "[400]\tvalid_0's rmse: 6.07591\n",
      "Early stopping, best iteration is:\n",
      "[254]\tvalid_0's rmse: 6.0633\n",
      " ‚ñ∂ Training target #14/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.46693\n",
      "[200]\tvalid_0's rmse: 5.21039\n",
      "[300]\tvalid_0's rmse: 5.16203\n",
      "[400]\tvalid_0's rmse: 5.15915\n",
      "[500]\tvalid_0's rmse: 5.16455\n",
      "Early stopping, best iteration is:\n",
      "[336]\tvalid_0's rmse: 5.15706\n",
      " ‚ñ∂ Training target #15/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.33803\n",
      "[200]\tvalid_0's rmse: 5.43604\n",
      "[300]\tvalid_0's rmse: 5.1774\n",
      "[400]\tvalid_0's rmse: 5.10034\n",
      "[500]\tvalid_0's rmse: 5.07629\n",
      "[600]\tvalid_0's rmse: 5.06675\n",
      "[700]\tvalid_0's rmse: 5.06123\n",
      "[800]\tvalid_0's rmse: 5.06196\n",
      "[900]\tvalid_0's rmse: 5.06235\n",
      "Early stopping, best iteration is:\n",
      "[701]\tvalid_0's rmse: 5.06108\n",
      " ‚ñ∂ Training target #16/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 6.24249\n",
      "[200]\tvalid_0's rmse: 5.66736\n",
      "[300]\tvalid_0's rmse: 5.51309\n",
      "[400]\tvalid_0's rmse: 5.47241\n",
      "[500]\tvalid_0's rmse: 5.46156\n",
      "[600]\tvalid_0's rmse: 5.46198\n",
      "Early stopping, best iteration is:\n",
      "[489]\tvalid_0's rmse: 5.46022\n",
      " ‚ñ∂ Training target #17/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.23501\n",
      "[200]\tvalid_0's rmse: 6.33322\n",
      "[300]\tvalid_0's rmse: 6.09611\n",
      "[400]\tvalid_0's rmse: 6.02032\n",
      "[500]\tvalid_0's rmse: 5.9925\n",
      "[600]\tvalid_0's rmse: 5.98214\n",
      "[700]\tvalid_0's rmse: 5.97779\n",
      "[800]\tvalid_0's rmse: 5.97324\n",
      "[900]\tvalid_0's rmse: 5.97057\n",
      "[1000]\tvalid_0's rmse: 5.97129\n",
      "[1100]\tvalid_0's rmse: 5.97274\n",
      "Early stopping, best iteration is:\n",
      "[926]\tvalid_0's rmse: 5.9698\n",
      " ‚ñ∂ Training target #18/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.92344\n",
      "[200]\tvalid_0's rmse: 3.33891\n",
      "[300]\tvalid_0's rmse: 3.1936\n",
      "[400]\tvalid_0's rmse: 3.16039\n",
      "[500]\tvalid_0's rmse: 3.15388\n",
      "[600]\tvalid_0's rmse: 3.15111\n",
      "[700]\tvalid_0's rmse: 3.15202\n",
      "Early stopping, best iteration is:\n",
      "[596]\tvalid_0's rmse: 3.15094\n",
      " ‚ñ∂ Training target #19/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.34135\n",
      "[200]\tvalid_0's rmse: 7.01777\n",
      "[300]\tvalid_0's rmse: 6.94866\n",
      "[400]\tvalid_0's rmse: 6.93829\n",
      "[500]\tvalid_0's rmse: 6.94053\n",
      "[600]\tvalid_0's rmse: 6.94413\n",
      "Early stopping, best iteration is:\n",
      "[403]\tvalid_0's rmse: 6.93669\n",
      " ‚ñ∂ Training target #20/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 5.03803\n",
      "[200]\tvalid_0's rmse: 4.83778\n",
      "[300]\tvalid_0's rmse: 4.78316\n",
      "[400]\tvalid_0's rmse: 4.76957\n",
      "[500]\tvalid_0's rmse: 4.76722\n",
      "[600]\tvalid_0's rmse: 4.76841\n",
      "Early stopping, best iteration is:\n",
      "[445]\tvalid_0's rmse: 4.76608\n",
      " ‚ñ∂ Training target #21/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 6.6216\n",
      "[200]\tvalid_0's rmse: 6.10619\n",
      "[300]\tvalid_0's rmse: 5.97404\n",
      "[400]\tvalid_0's rmse: 5.93998\n",
      "[500]\tvalid_0's rmse: 5.93119\n",
      "[600]\tvalid_0's rmse: 5.92652\n",
      "[700]\tvalid_0's rmse: 5.92588\n",
      "[800]\tvalid_0's rmse: 5.9245\n",
      "[900]\tvalid_0's rmse: 5.92876\n",
      "Early stopping, best iteration is:\n",
      "[798]\tvalid_0's rmse: 5.92376\n",
      " ‚ñ∂ Training target #22/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.75956\n",
      "[200]\tvalid_0's rmse: 7.35264\n",
      "[300]\tvalid_0's rmse: 7.25175\n",
      "[400]\tvalid_0's rmse: 7.2228\n",
      "[500]\tvalid_0's rmse: 7.21706\n",
      "[600]\tvalid_0's rmse: 7.21345\n",
      "[700]\tvalid_0's rmse: 7.2181\n",
      "[800]\tvalid_0's rmse: 7.21388\n",
      "Early stopping, best iteration is:\n",
      "[630]\tvalid_0's rmse: 7.21257\n",
      " ‚ñ∂ Training target #23/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.82375\n",
      "[200]\tvalid_0's rmse: 2.60096\n",
      "[300]\tvalid_0's rmse: 2.54835\n",
      "[400]\tvalid_0's rmse: 2.53885\n",
      "[500]\tvalid_0's rmse: 2.53962\n",
      "[600]\tvalid_0's rmse: 2.54082\n",
      "Early stopping, best iteration is:\n",
      "[405]\tvalid_0's rmse: 2.53852\n",
      " ‚ñ∂ Training target #24/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.37896\n",
      "[200]\tvalid_0's rmse: 5.74931\n",
      "[300]\tvalid_0's rmse: 5.59342\n",
      "[400]\tvalid_0's rmse: 5.56089\n",
      "[500]\tvalid_0's rmse: 5.55583\n",
      "[600]\tvalid_0's rmse: 5.5565\n",
      "[700]\tvalid_0's rmse: 5.5596\n",
      "Early stopping, best iteration is:\n",
      "[559]\tvalid_0's rmse: 5.55501\n",
      " ‚ñ∂ Training target #25/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.58222\n",
      "[200]\tvalid_0's rmse: 6.87418\n",
      "[300]\tvalid_0's rmse: 6.68426\n",
      "[400]\tvalid_0's rmse: 6.6332\n",
      "[500]\tvalid_0's rmse: 6.61512\n",
      "[600]\tvalid_0's rmse: 6.6118\n",
      "[700]\tvalid_0's rmse: 6.60934\n",
      "[800]\tvalid_0's rmse: 6.60876\n",
      "[900]\tvalid_0's rmse: 6.60814\n",
      "[1000]\tvalid_0's rmse: 6.61081\n",
      "[1100]\tvalid_0's rmse: 6.61534\n",
      "Early stopping, best iteration is:\n",
      "[918]\tvalid_0's rmse: 6.60638\n",
      " ‚ñ∂ Training target #26/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.91\n",
      "[200]\tvalid_0's rmse: 6.57775\n",
      "[300]\tvalid_0's rmse: 6.47922\n",
      "[400]\tvalid_0's rmse: 6.45402\n",
      "[500]\tvalid_0's rmse: 6.45096\n",
      "[600]\tvalid_0's rmse: 6.44968\n",
      "[700]\tvalid_0's rmse: 6.44988\n",
      "[800]\tvalid_0's rmse: 6.45701\n",
      "Early stopping, best iteration is:\n",
      "[641]\tvalid_0's rmse: 6.44766\n",
      " ‚ñ∂ Training target #27/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 8.12002\n",
      "[200]\tvalid_0's rmse: 6.82343\n",
      "[300]\tvalid_0's rmse: 6.44353\n",
      "[400]\tvalid_0's rmse: 6.32508\n",
      "[500]\tvalid_0's rmse: 6.27824\n",
      "[600]\tvalid_0's rmse: 6.26088\n",
      "[700]\tvalid_0's rmse: 6.25802\n",
      "[800]\tvalid_0's rmse: 6.25569\n",
      "[900]\tvalid_0's rmse: 6.25576\n",
      "[1000]\tvalid_0's rmse: 6.2574\n",
      "[1100]\tvalid_0's rmse: 6.25979\n",
      "Early stopping, best iteration is:\n",
      "[909]\tvalid_0's rmse: 6.25448\n",
      " ‚ñ∂ Training target #28/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.95725\n",
      "[200]\tvalid_0's rmse: 5.64077\n",
      "[300]\tvalid_0's rmse: 5.58146\n",
      "[400]\tvalid_0's rmse: 5.56663\n",
      "[500]\tvalid_0's rmse: 5.56868\n",
      "[600]\tvalid_0's rmse: 5.56623\n",
      "[700]\tvalid_0's rmse: 5.57063\n",
      "[800]\tvalid_0's rmse: 5.57202\n",
      "Early stopping, best iteration is:\n",
      "[600]\tvalid_0's rmse: 5.56623\n",
      " ‚ñ∂ Training target #29/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 6.54976\n",
      "[200]\tvalid_0's rmse: 6.05634\n",
      "[300]\tvalid_0's rmse: 5.94747\n",
      "[400]\tvalid_0's rmse: 5.92804\n",
      "[500]\tvalid_0's rmse: 5.92549\n",
      "[600]\tvalid_0's rmse: 5.93178\n",
      "Early stopping, best iteration is:\n",
      "[476]\tvalid_0's rmse: 5.92275\n",
      " ‚ñ∂ Training target #30/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.29486\n",
      "[200]\tvalid_0's rmse: 6.18596\n",
      "[300]\tvalid_0's rmse: 5.89076\n",
      "[400]\tvalid_0's rmse: 5.81109\n",
      "[500]\tvalid_0's rmse: 5.78786\n",
      "[600]\tvalid_0's rmse: 5.77903\n",
      "[700]\tvalid_0's rmse: 5.78003\n",
      "[800]\tvalid_0's rmse: 5.78269\n",
      "Early stopping, best iteration is:\n",
      "[628]\tvalid_0's rmse: 5.77654\n",
      " ‚ñ∂ Training target #31/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.88191\n",
      "[200]\tvalid_0's rmse: 2.48797\n",
      "[300]\tvalid_0's rmse: 2.38446\n",
      "[400]\tvalid_0's rmse: 2.35892\n",
      "[500]\tvalid_0's rmse: 2.35251\n",
      "[600]\tvalid_0's rmse: 2.35204\n",
      "[700]\tvalid_0's rmse: 2.3534\n",
      "Early stopping, best iteration is:\n",
      "[544]\tvalid_0's rmse: 2.35129\n",
      " ‚ñ∂ Training target #32/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 2.35362\n",
      "[200]\tvalid_0's rmse: 2.2714\n",
      "[300]\tvalid_0's rmse: 2.25079\n",
      "[400]\tvalid_0's rmse: 2.24801\n",
      "[500]\tvalid_0's rmse: 2.24734\n",
      "[600]\tvalid_0's rmse: 2.24763\n",
      "[700]\tvalid_0's rmse: 2.24902\n",
      "Early stopping, best iteration is:\n",
      "[545]\tvalid_0's rmse: 2.24685\n",
      " ‚ñ∂ Training target #33/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.31082\n",
      "[200]\tvalid_0's rmse: 7.18214\n",
      "[300]\tvalid_0's rmse: 7.16169\n",
      "[400]\tvalid_0's rmse: 7.16806\n",
      "[500]\tvalid_0's rmse: 7.17284\n",
      "Early stopping, best iteration is:\n",
      "[308]\tvalid_0's rmse: 7.16078\n",
      " ‚ñ∂ Training target #34/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.72499\n",
      "[200]\tvalid_0's rmse: 5.46612\n",
      "[300]\tvalid_0's rmse: 5.41951\n",
      "[400]\tvalid_0's rmse: 5.42492\n",
      "[500]\tvalid_0's rmse: 5.44309\n",
      "Early stopping, best iteration is:\n",
      "[317]\tvalid_0's rmse: 5.4175\n",
      " ‚ñ∂ Training target #35/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.90248\n",
      "[200]\tvalid_0's rmse: 2.79129\n",
      "[300]\tvalid_0's rmse: 2.7663\n",
      "[400]\tvalid_0's rmse: 2.76172\n",
      "[500]\tvalid_0's rmse: 2.76276\n",
      "Early stopping, best iteration is:\n",
      "[381]\tvalid_0's rmse: 2.76108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä LightGBM meta‚Äêmodel Val MSE: 29.343309\n",
      "‚úÖ Saved 35 LightGBM models ‚Üí output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/stacking_gbm_meta.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved GBM‚Äêstacked submission ‚Üí output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/submission_stacking_gbm.csv\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1) ÂÆö‰πâ LightGBM Âü∫Â≠¶‰π†Âô®\n",
    "params = dict(\n",
    "    objective='regression',\n",
    "    metric='rmse',\n",
    "    learning_rate=0.007522970004049377,\n",
    "    n_estimators=12000,\n",
    "    max_depth=11,\n",
    "    num_leaves=194,\n",
    "    colsample_bytree=0.7619407413363416,\n",
    "    subsample=0.8,\n",
    "    subsample_freq=1,\n",
    "    min_data_in_leaf=20,\n",
    "    reg_alpha=0.7480401395491829,\n",
    "    reg_lambda=0.2589860348178542,\n",
    "    verbosity=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2) MultiOutput ÂåÖË£Ö\n",
    "print(\"üçÄ Start training meta model ...\")\n",
    "# 3) ËÆ≠ÁªÉÔºåÂπ∂ÁªôÂÜÖÈÉ® estimator ‰º† early stopping+eval_set\n",
    "# 2) Áî®‰∏Ä‰∏™ list ‰øùÂ≠òÊØè‰∏™ÁõÆÊ†áÁöÑÊ®°Âûã\n",
    "gbm_models = []\n",
    "\n",
    "print(\"üçÄ Start training one LGBM per target ...\")\n",
    "for k in range(C):\n",
    "    print(f\" ‚ñ∂ Training target #{k+1}/{C}\")\n",
    "    m = lgb.LGBMRegressor(**params)\n",
    "    # ‰º†ÂÖ•ÂØπÂ∫îÁöÑ‰∏ÄÁª¥ label\n",
    "    m.fit(\n",
    "        X_train, y_train[:,k],\n",
    "        eval_set=[(X_val, y_val[:,k])],\n",
    "        callbacks=[\n",
    "                early_stopping(stopping_rounds=200),\n",
    "                log_evaluation(period=100)\n",
    "            ]\n",
    "    )\n",
    "    gbm_models.append(m)\n",
    "\n",
    "# 3) Âú®È™åËØÅÈõÜ‰∏äÂêàÊàêÂ§öËæìÂá∫È¢ÑÊµãÂπ∂ÁÆó MSE\n",
    "y_val_pred = np.column_stack([m.predict(X_val) for m in gbm_models])\n",
    "mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"üìä LightGBM meta‚Äêmodel Val MSE: {mse_val:.6f}\")\n",
    "\n",
    "# 4) ‰øùÂ≠òÊï¥ÁªÑÊ®°Âûã\n",
    "gbm_path = os.path.join(trained_oof_model_folder, \"stacking_gbm_meta.pkl\")\n",
    "joblib.dump(gbm_models, gbm_path)\n",
    "print(f\"‚úÖ Saved {C} LightGBM models ‚Üí {gbm_path}\")\n",
    "\n",
    "# ‚Ä¶ ÊµãËØïÊó∂ÂêåÊ†∑Âä†ËΩΩËøôÁªÑÊ®°Âûã ‚Ä¶\n",
    "gbm_models = joblib.load(gbm_path)\n",
    "final_test_preds = np.column_stack([m.predict(X_test_stack) for m in gbm_models])\n",
    "\n",
    "# 5) Â≠ò submission\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spot_ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"]))\n",
    "\n",
    "sub = pd.DataFrame(final_test_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, 'ID', test_spot_ids.index)\n",
    "sub_path = os.path.join(trained_oof_model_folder, \"submission_stacking_gbm.csv\")\n",
    "sub.to_csv(sub_path, index=False)\n",
    "print(f\"‚úÖ Saved GBM‚Äêstacked submission ‚Üí {sub_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train woth 2 k-fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from python_scripts.import_data import importDataset  # ÂÅáËÆæËøô‰∏™ËÉΩÁªô‰Ω† full_dataset\n",
    "from python_scripts.aug import subset_grouped_data   # Áî®Êù•ÂàáÂá∫ grouped_data\n",
    "\n",
    "# Settings\n",
    "# ‰Ω†ÁöÑ‰∏§Â•óÁÆ°ÈÅìÊ®°ÂûãÊâÄÂú®Êñá‰ª∂Â§π\n",
    "pipe_folders = [\n",
    "    'output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked' , \n",
    "    'output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked']\n",
    "n_pipes = len(pipe_folders)\n",
    "n_folds    = 6\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 64\n",
    "C          = 35  # Á±ªÂà´Êï∞ / ÊØè‰∏™È¢ÑÊµãÂêëÈáèÈïøÂ∫¶\n",
    "META_EPOCHS = 250\n",
    "tile_dim = 128\n",
    "center_dim = 128\n",
    "neighbor_dim = 128\n",
    "# 1) Load full_dataset & y_true\n",
    "n_samples = len(full_dataset)\n",
    "y_true = np.vstack([full_dataset[i]['label'].cpu().numpy() for i in range(n_samples)])\n",
    "oof_preds = np.zeros((n_pipes, n_folds, n_samples, C), dtype=np.float32)\n",
    "full_loader = DataLoader(full_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipe 0 Fold 0 predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/4182448203.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipe 0 Fold 1 predicting...\n",
      "Pipe 0 Fold 2 predicting...\n",
      "Pipe 0 Fold 3 predicting...\n",
      "Pipe 0 Fold 4 predicting...\n",
      "Pipe 0 Fold 5 predicting...\n",
      "Pipe 1 Fold 0 predicting...\n",
      "Pipe 1 Fold 1 predicting...\n",
      "Pipe 1 Fold 2 predicting...\n",
      "Pipe 1 Fold 3 predicting...\n",
      "Pipe 1 Fold 4 predicting...\n",
      "Pipe 1 Fold 5 predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 ‚Üí Train MSE 391.4221, Val MSE 320.4870, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 2 ‚Üí Train MSE 213.2606, Val MSE 94.9896, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 3 ‚Üí Train MSE 62.3294, Val MSE 46.4068, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 4 ‚Üí Train MSE 47.7791, Val MSE 41.9149, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 5 ‚Üí Train MSE 45.7437, Val MSE 42.7662, LR 1.00e-03\n",
      "Epoch 6 ‚Üí Train MSE 45.9071, Val MSE 40.3713, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 7 ‚Üí Train MSE 44.9099, Val MSE 41.4321, LR 1.00e-03\n",
      "Epoch 8 ‚Üí Train MSE 44.4296, Val MSE 39.5969, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 9 ‚Üí Train MSE 44.3049, Val MSE 42.6474, LR 1.00e-03\n",
      "Epoch 10 ‚Üí Train MSE 44.4582, Val MSE 41.5099, LR 1.00e-03\n",
      "Epoch 11 ‚Üí Train MSE 44.2516, Val MSE 38.7766, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 12 ‚Üí Train MSE 43.8401, Val MSE 38.6763, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 13 ‚Üí Train MSE 43.1779, Val MSE 38.1927, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 14 ‚Üí Train MSE 43.6875, Val MSE 40.0167, LR 1.00e-03\n",
      "Epoch 15 ‚Üí Train MSE 43.8981, Val MSE 38.9021, LR 1.00e-03\n",
      "Epoch 16 ‚Üí Train MSE 43.3303, Val MSE 38.0751, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 17 ‚Üí Train MSE 42.8778, Val MSE 38.3423, LR 1.00e-03\n",
      "Epoch 18 ‚Üí Train MSE 42.5694, Val MSE 37.5741, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 19 ‚Üí Train MSE 42.1233, Val MSE 37.6171, LR 1.00e-03\n",
      "Epoch 20 ‚Üí Train MSE 42.4281, Val MSE 38.4233, LR 1.00e-03\n",
      "Epoch 21 ‚Üí Train MSE 41.7702, Val MSE 36.7002, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 22 ‚Üí Train MSE 41.7573, Val MSE 37.3967, LR 1.00e-03\n",
      "Epoch 23 ‚Üí Train MSE 42.3339, Val MSE 38.7101, LR 1.00e-03\n",
      "Epoch 24 ‚Üí Train MSE 41.2635, Val MSE 36.9083, LR 1.00e-03\n",
      "Epoch 25 ‚Üí Train MSE 41.7939, Val MSE 37.2312, LR 1.00e-03\n",
      "Epoch 26 ‚Üí Train MSE 41.3758, Val MSE 37.0413, LR 1.00e-03\n",
      "Epoch 27 ‚Üí Train MSE 41.2394, Val MSE 37.6712, LR 1.00e-03\n",
      "Epoch 28 ‚Üí Train MSE 42.0604, Val MSE 36.6927, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 29 ‚Üí Train MSE 41.1877, Val MSE 36.6375, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 30 ‚Üí Train MSE 40.5297, Val MSE 36.2997, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 31 ‚Üí Train MSE 40.7056, Val MSE 36.0943, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 32 ‚Üí Train MSE 40.6065, Val MSE 36.5941, LR 1.00e-03\n",
      "Epoch 33 ‚Üí Train MSE 40.6195, Val MSE 36.0287, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 34 ‚Üí Train MSE 40.6162, Val MSE 35.8693, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 35 ‚Üí Train MSE 40.7204, Val MSE 36.0366, LR 1.00e-03\n",
      "Epoch 36 ‚Üí Train MSE 40.2189, Val MSE 35.6158, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 37 ‚Üí Train MSE 39.9235, Val MSE 35.4491, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 38 ‚Üí Train MSE 39.7395, Val MSE 35.0508, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 39 ‚Üí Train MSE 39.6754, Val MSE 35.9409, LR 1.00e-03\n",
      "Epoch 40 ‚Üí Train MSE 39.8077, Val MSE 38.2282, LR 1.00e-03\n",
      "Epoch 41 ‚Üí Train MSE 39.5890, Val MSE 35.2168, LR 1.00e-03\n",
      "Epoch 42 ‚Üí Train MSE 39.5444, Val MSE 34.8116, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 43 ‚Üí Train MSE 39.1747, Val MSE 35.0543, LR 1.00e-03\n",
      "Epoch 44 ‚Üí Train MSE 39.4593, Val MSE 35.0745, LR 1.00e-03\n",
      "Epoch 45 ‚Üí Train MSE 39.1876, Val MSE 35.1847, LR 1.00e-03\n",
      "Epoch 46 ‚Üí Train MSE 39.3076, Val MSE 36.8449, LR 1.00e-03\n",
      "Epoch 47 ‚Üí Train MSE 39.7781, Val MSE 35.7411, LR 1.00e-03\n",
      "Epoch 48 ‚Üí Train MSE 39.9253, Val MSE 35.5482, LR 1.00e-03\n",
      "Epoch 49 ‚Üí Train MSE 39.5282, Val MSE 35.0553, LR 1.00e-03\n",
      "Epoch 50 ‚Üí Train MSE 39.2569, Val MSE 35.3255, LR 1.00e-03\n",
      "Epoch 51 ‚Üí Train MSE 38.8887, Val MSE 34.9897, LR 1.00e-03\n",
      "Epoch 52 ‚Üí Train MSE 38.8372, Val MSE 34.8053, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 53 ‚Üí Train MSE 38.6716, Val MSE 34.4351, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 54 ‚Üí Train MSE 38.5419, Val MSE 34.9296, LR 1.00e-03\n",
      "Epoch 55 ‚Üí Train MSE 38.3590, Val MSE 34.5566, LR 1.00e-03\n",
      "Epoch 56 ‚Üí Train MSE 38.4416, Val MSE 35.0630, LR 1.00e-03\n",
      "Epoch 57 ‚Üí Train MSE 38.6909, Val MSE 34.5508, LR 1.00e-03\n",
      "Epoch 58 ‚Üí Train MSE 38.5832, Val MSE 34.8811, LR 1.00e-03\n",
      "Epoch 59 ‚Üí Train MSE 38.6945, Val MSE 34.9149, LR 1.00e-03\n",
      "Epoch 60 ‚Üí Train MSE 38.3309, Val MSE 34.2296, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 61 ‚Üí Train MSE 38.4665, Val MSE 34.8813, LR 1.00e-03\n",
      "Epoch 62 ‚Üí Train MSE 38.2585, Val MSE 34.4755, LR 1.00e-03\n",
      "Epoch 63 ‚Üí Train MSE 38.2106, Val MSE 34.1125, LR 1.00e-03\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 64 ‚Üí Train MSE 38.4058, Val MSE 34.4248, LR 1.00e-03\n",
      "Epoch 65 ‚Üí Train MSE 38.5215, Val MSE 151.2655, LR 1.00e-03\n",
      "Epoch 66 ‚Üí Train MSE 38.4022, Val MSE 34.1953, LR 1.00e-03\n",
      "Epoch 67 ‚Üí Train MSE 38.1361, Val MSE 34.5185, LR 1.00e-03\n",
      "Epoch 68 ‚Üí Train MSE 38.2117, Val MSE 34.6949, LR 1.00e-03\n",
      "Epoch 69 ‚Üí Train MSE 38.9071, Val MSE 35.5614, LR 1.00e-03\n",
      "Epoch 70 ‚Üí Train MSE 38.6065, Val MSE 35.1649, LR 1.00e-03\n",
      "Epoch 71 ‚Üí Train MSE 39.1059, Val MSE 35.5324, LR 1.00e-03\n",
      "Epoch 72 ‚Üí Train MSE 38.9954, Val MSE 40.4166, LR 1.00e-03\n",
      "Epoch 73 ‚Üí Train MSE 38.4927, Val MSE 34.8302, LR 1.00e-03\n",
      "Epoch 74 ‚Üí Train MSE 38.3021, Val MSE 34.3670, LR 1.00e-03\n",
      "Epoch 75 ‚Üí Train MSE 37.8818, Val MSE 34.3568, LR 5.00e-04\n",
      "Epoch 76 ‚Üí Train MSE 37.6426, Val MSE 34.1752, LR 5.00e-04\n",
      "Epoch 77 ‚Üí Train MSE 37.5763, Val MSE 33.8018, LR 5.00e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 78 ‚Üí Train MSE 37.7921, Val MSE 33.9218, LR 5.00e-04\n",
      "Epoch 79 ‚Üí Train MSE 37.8683, Val MSE 34.1284, LR 5.00e-04\n",
      "Epoch 80 ‚Üí Train MSE 37.5474, Val MSE 33.6143, LR 5.00e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 81 ‚Üí Train MSE 37.7666, Val MSE 33.8534, LR 5.00e-04\n",
      "Epoch 82 ‚Üí Train MSE 37.4755, Val MSE 33.5868, LR 5.00e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 83 ‚Üí Train MSE 37.3948, Val MSE 33.9877, LR 5.00e-04\n",
      "Epoch 84 ‚Üí Train MSE 37.3768, Val MSE 33.3200, LR 5.00e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 85 ‚Üí Train MSE 37.4490, Val MSE 33.6935, LR 5.00e-04\n",
      "Epoch 86 ‚Üí Train MSE 37.4900, Val MSE 33.9681, LR 5.00e-04\n",
      "Epoch 87 ‚Üí Train MSE 37.4481, Val MSE 33.4545, LR 5.00e-04\n",
      "Epoch 88 ‚Üí Train MSE 37.4557, Val MSE 33.4902, LR 5.00e-04\n",
      "Epoch 89 ‚Üí Train MSE 37.2206, Val MSE 33.8058, LR 5.00e-04\n",
      "Epoch 90 ‚Üí Train MSE 36.9371, Val MSE 33.3246, LR 5.00e-04\n",
      "Epoch 91 ‚Üí Train MSE 36.9658, Val MSE 33.2487, LR 5.00e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 92 ‚Üí Train MSE 37.0915, Val MSE 33.6862, LR 5.00e-04\n",
      "Epoch 93 ‚Üí Train MSE 37.1279, Val MSE 33.4870, LR 5.00e-04\n",
      "Epoch 94 ‚Üí Train MSE 37.1980, Val MSE 33.9322, LR 5.00e-04\n",
      "Epoch 95 ‚Üí Train MSE 37.1834, Val MSE 33.3086, LR 5.00e-04\n",
      "Epoch 96 ‚Üí Train MSE 37.1451, Val MSE 33.4906, LR 5.00e-04\n",
      "Epoch 97 ‚Üí Train MSE 36.9480, Val MSE 33.4452, LR 5.00e-04\n",
      "Epoch 98 ‚Üí Train MSE 36.8936, Val MSE 33.4287, LR 5.00e-04\n",
      "Epoch 99 ‚Üí Train MSE 37.3277, Val MSE 33.8518, LR 5.00e-04\n",
      "Epoch 100 ‚Üí Train MSE 37.2201, Val MSE 33.9048, LR 5.00e-04\n",
      "Epoch 101 ‚Üí Train MSE 37.4687, Val MSE 33.8204, LR 5.00e-04\n",
      "Epoch 102 ‚Üí Train MSE 37.2863, Val MSE 33.4650, LR 5.00e-04\n",
      "Epoch 103 ‚Üí Train MSE 37.1170, Val MSE 36.6737, LR 2.50e-04\n",
      "Epoch 104 ‚Üí Train MSE 37.0643, Val MSE 33.3887, LR 2.50e-04\n",
      "Epoch 105 ‚Üí Train MSE 36.9955, Val MSE 33.1722, LR 2.50e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 106 ‚Üí Train MSE 36.6839, Val MSE 33.2713, LR 2.50e-04\n",
      "Epoch 107 ‚Üí Train MSE 36.8301, Val MSE 33.3174, LR 2.50e-04\n",
      "Epoch 108 ‚Üí Train MSE 36.7640, Val MSE 33.4771, LR 2.50e-04\n",
      "Epoch 109 ‚Üí Train MSE 36.9096, Val MSE 33.3467, LR 2.50e-04\n",
      "Epoch 110 ‚Üí Train MSE 36.6644, Val MSE 33.1267, LR 2.50e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 111 ‚Üí Train MSE 36.6364, Val MSE 33.0935, LR 2.50e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 112 ‚Üí Train MSE 36.7343, Val MSE 33.1021, LR 2.50e-04\n",
      "Epoch 113 ‚Üí Train MSE 36.5709, Val MSE 33.0914, LR 2.50e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 114 ‚Üí Train MSE 36.6267, Val MSE 32.9663, LR 2.50e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 115 ‚Üí Train MSE 36.4845, Val MSE 33.1301, LR 2.50e-04\n",
      "Epoch 116 ‚Üí Train MSE 36.6843, Val MSE 33.2070, LR 2.50e-04\n",
      "Epoch 117 ‚Üí Train MSE 36.6591, Val MSE 36.0248, LR 2.50e-04\n",
      "Epoch 118 ‚Üí Train MSE 36.7968, Val MSE 33.3557, LR 2.50e-04\n",
      "Epoch 119 ‚Üí Train MSE 36.7561, Val MSE 34.3371, LR 2.50e-04\n",
      "Epoch 120 ‚Üí Train MSE 36.7936, Val MSE 33.1960, LR 2.50e-04\n",
      "Epoch 121 ‚Üí Train MSE 36.7105, Val MSE 33.0534, LR 2.50e-04\n",
      "Epoch 122 ‚Üí Train MSE 36.5298, Val MSE 32.9663, LR 2.50e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 123 ‚Üí Train MSE 36.4344, Val MSE 32.9623, LR 2.50e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 124 ‚Üí Train MSE 36.4960, Val MSE 32.8875, LR 2.50e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 125 ‚Üí Train MSE 36.5381, Val MSE 33.2453, LR 2.50e-04\n",
      "Epoch 126 ‚Üí Train MSE 36.6908, Val MSE 33.0029, LR 2.50e-04\n",
      "Epoch 127 ‚Üí Train MSE 36.5291, Val MSE 33.2611, LR 2.50e-04\n",
      "Epoch 128 ‚Üí Train MSE 36.5604, Val MSE 32.8431, LR 2.50e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 129 ‚Üí Train MSE 36.4340, Val MSE 33.1571, LR 2.50e-04\n",
      "Epoch 130 ‚Üí Train MSE 36.5515, Val MSE 33.5197, LR 2.50e-04\n",
      "Epoch 131 ‚Üí Train MSE 36.6097, Val MSE 33.2445, LR 2.50e-04\n",
      "Epoch 132 ‚Üí Train MSE 36.5943, Val MSE 32.8199, LR 2.50e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 133 ‚Üí Train MSE 36.2658, Val MSE 32.9539, LR 2.50e-04\n",
      "Epoch 134 ‚Üí Train MSE 36.5042, Val MSE 33.0231, LR 2.50e-04\n",
      "Epoch 135 ‚Üí Train MSE 36.4714, Val MSE 32.8018, LR 2.50e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 136 ‚Üí Train MSE 36.3633, Val MSE 32.7933, LR 2.50e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 137 ‚Üí Train MSE 36.5110, Val MSE 32.9806, LR 2.50e-04\n",
      "Epoch 138 ‚Üí Train MSE 36.0403, Val MSE 32.6254, LR 2.50e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 139 ‚Üí Train MSE 36.3402, Val MSE 32.8199, LR 2.50e-04\n",
      "Epoch 140 ‚Üí Train MSE 36.2049, Val MSE 32.9389, LR 2.50e-04\n",
      "Epoch 141 ‚Üí Train MSE 36.2706, Val MSE 33.0217, LR 2.50e-04\n",
      "Epoch 142 ‚Üí Train MSE 36.1126, Val MSE 32.8647, LR 2.50e-04\n",
      "Epoch 143 ‚Üí Train MSE 36.2305, Val MSE 32.7156, LR 2.50e-04\n",
      "Epoch 144 ‚Üí Train MSE 36.1716, Val MSE 32.8837, LR 2.50e-04\n",
      "Epoch 145 ‚Üí Train MSE 36.1787, Val MSE 32.8054, LR 2.50e-04\n",
      "Epoch 146 ‚Üí Train MSE 36.1562, Val MSE 32.7736, LR 2.50e-04\n",
      "Epoch 147 ‚Üí Train MSE 36.1331, Val MSE 32.7886, LR 2.50e-04\n",
      "Epoch 148 ‚Üí Train MSE 36.1445, Val MSE 32.7686, LR 2.50e-04\n",
      "Epoch 149 ‚Üí Train MSE 36.0998, Val MSE 33.0072, LR 2.50e-04\n",
      "Epoch 150 ‚Üí Train MSE 35.9771, Val MSE 32.8582, LR 1.25e-04\n",
      "Epoch 151 ‚Üí Train MSE 35.9147, Val MSE 32.5045, LR 1.25e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 152 ‚Üí Train MSE 35.8703, Val MSE 32.6049, LR 1.25e-04\n",
      "Epoch 153 ‚Üí Train MSE 35.7817, Val MSE 32.4593, LR 1.25e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 154 ‚Üí Train MSE 35.8899, Val MSE 32.5924, LR 1.25e-04\n",
      "Epoch 155 ‚Üí Train MSE 35.8708, Val MSE 32.5460, LR 1.25e-04\n",
      "Epoch 156 ‚Üí Train MSE 36.0255, Val MSE 32.4188, LR 1.25e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 157 ‚Üí Train MSE 35.8094, Val MSE 32.4058, LR 1.25e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 158 ‚Üí Train MSE 35.7589, Val MSE 32.6121, LR 1.25e-04\n",
      "Epoch 159 ‚Üí Train MSE 35.7832, Val MSE 32.7395, LR 1.25e-04\n",
      "Epoch 160 ‚Üí Train MSE 35.7826, Val MSE 32.4421, LR 1.25e-04\n",
      "Epoch 161 ‚Üí Train MSE 35.8307, Val MSE 32.7133, LR 1.25e-04\n",
      "Epoch 162 ‚Üí Train MSE 35.8376, Val MSE 32.6560, LR 1.25e-04\n",
      "Epoch 163 ‚Üí Train MSE 35.8367, Val MSE 34.4656, LR 1.25e-04\n",
      "Epoch 164 ‚Üí Train MSE 35.7040, Val MSE 32.3792, LR 1.25e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 165 ‚Üí Train MSE 35.8636, Val MSE 32.4407, LR 1.25e-04\n",
      "Epoch 166 ‚Üí Train MSE 35.6903, Val MSE 32.3613, LR 1.25e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 167 ‚Üí Train MSE 35.8575, Val MSE 32.8065, LR 1.25e-04\n",
      "Epoch 168 ‚Üí Train MSE 35.8426, Val MSE 32.3199, LR 1.25e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 169 ‚Üí Train MSE 35.8618, Val MSE 32.6151, LR 1.25e-04\n",
      "Epoch 170 ‚Üí Train MSE 35.5668, Val MSE 32.5899, LR 1.25e-04\n",
      "Epoch 171 ‚Üí Train MSE 35.8630, Val MSE 32.7773, LR 1.25e-04\n",
      "Epoch 172 ‚Üí Train MSE 35.7090, Val MSE 32.4267, LR 1.25e-04\n",
      "Epoch 173 ‚Üí Train MSE 35.6676, Val MSE 32.3602, LR 1.25e-04\n",
      "Epoch 174 ‚Üí Train MSE 35.8579, Val MSE 32.4184, LR 1.25e-04\n",
      "Epoch 175 ‚Üí Train MSE 35.7519, Val MSE 32.5317, LR 1.25e-04\n",
      "Epoch 176 ‚Üí Train MSE 35.6470, Val MSE 32.4659, LR 1.25e-04\n",
      "Epoch 177 ‚Üí Train MSE 35.6707, Val MSE 32.3097, LR 1.25e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 178 ‚Üí Train MSE 35.6766, Val MSE 32.4635, LR 1.25e-04\n",
      "Epoch 179 ‚Üí Train MSE 35.7080, Val MSE 32.5376, LR 1.25e-04\n",
      "Epoch 180 ‚Üí Train MSE 35.9391, Val MSE 32.4356, LR 1.25e-04\n",
      "Epoch 181 ‚Üí Train MSE 35.5454, Val MSE 32.5643, LR 1.25e-04\n",
      "Epoch 182 ‚Üí Train MSE 35.7031, Val MSE 32.4878, LR 1.25e-04\n",
      "Epoch 183 ‚Üí Train MSE 35.7483, Val MSE 32.6245, LR 1.25e-04\n",
      "Epoch 184 ‚Üí Train MSE 35.8428, Val MSE 32.3997, LR 1.25e-04\n",
      "Epoch 185 ‚Üí Train MSE 35.6366, Val MSE 32.4640, LR 1.25e-04\n",
      "Epoch 186 ‚Üí Train MSE 35.4882, Val MSE 32.0956, LR 1.25e-04\n",
      " ‚Ü≥ New best saved.\n",
      "Epoch 187 ‚Üí Train MSE 35.5619, Val MSE 32.3458, LR 1.25e-04\n",
      "Epoch 188 ‚Üí Train MSE 35.7474, Val MSE 32.2461, LR 1.25e-04\n",
      "Epoch 189 ‚Üí Train MSE 35.6328, Val MSE 32.4331, LR 1.25e-04\n",
      "Epoch 190 ‚Üí Train MSE 35.4665, Val MSE 32.1978, LR 1.25e-04\n",
      "Epoch 191 ‚Üí Train MSE 35.3295, Val MSE 32.2347, LR 1.25e-04\n",
      "Epoch 192 ‚Üí Train MSE 35.6762, Val MSE 32.5394, LR 1.25e-04\n",
      "Epoch 193 ‚Üí Train MSE 35.6954, Val MSE 32.7031, LR 1.25e-04\n",
      "Epoch 194 ‚Üí Train MSE 36.2182, Val MSE 33.2728, LR 1.25e-04\n",
      "Epoch 195 ‚Üí Train MSE 36.1449, Val MSE 33.1525, LR 1.25e-04\n",
      "Epoch 196 ‚Üí Train MSE 36.2476, Val MSE 32.8362, LR 1.25e-04\n",
      "Epoch 197 ‚Üí Train MSE 36.0202, Val MSE 32.5471, LR 1.25e-04\n",
      "Epoch 198 ‚Üí Train MSE 36.1264, Val MSE 32.8542, LR 6.25e-05\n",
      "Epoch 199 ‚Üí Train MSE 35.8376, Val MSE 34.6365, LR 6.25e-05\n",
      "Epoch 200 ‚Üí Train MSE 35.7622, Val MSE 32.6772, LR 6.25e-05\n",
      "Epoch 201 ‚Üí Train MSE 36.0713, Val MSE 32.6209, LR 6.25e-05\n",
      "Epoch 202 ‚Üí Train MSE 35.7390, Val MSE 32.4079, LR 6.25e-05\n",
      "Epoch 203 ‚Üí Train MSE 35.3511, Val MSE 32.1377, LR 6.25e-05\n",
      "Epoch 204 ‚Üí Train MSE 35.4250, Val MSE 32.2537, LR 6.25e-05\n",
      "Epoch 205 ‚Üí Train MSE 35.3281, Val MSE 32.3758, LR 6.25e-05\n",
      "Epoch 206 ‚Üí Train MSE 35.4466, Val MSE 32.3217, LR 6.25e-05\n",
      " üõë Early stopping.\n",
      "‚úÖ Cross-pipe stacking done. Best at output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/stacking_2meta_best.pt\n"
     ]
    }
   ],
   "source": [
    "for p, folder in enumerate(pipe_folders):\n",
    "    for fold_id in range(n_folds):\n",
    "        print(f\"Pipe {p} Fold {fold_id} predicting...\")\n",
    "        # a) load model\n",
    "        ckpt = os.path.join(folder, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "        net  = VisionMLP_MultiTask(tile_dim, center_dim, output_dim=C).to(device)\n",
    "        net.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "        net.eval()\n",
    "\n",
    "        # b) ÂÖ®Ê†∑Êú¨ forward\n",
    "        preds_full = []\n",
    "        with torch.no_grad():\n",
    "            for batch in full_loader:\n",
    "                tiles, subtiles = batch['tile'].to(device), batch['subtiles'].to(device)\n",
    "                center = subtiles[:, 4]\n",
    "                fuse = torch.cat([\n",
    "                    net.encoder_center(center),\n",
    "                    net.encoder_subtile(subtiles),\n",
    "                    net.encoder_tile(tiles)\n",
    "                ], dim=1)\n",
    "                preds_full.append(net.decoder(fuse).cpu().numpy())\n",
    "\n",
    "        preds_full = np.concatenate(preds_full, axis=0)  # (n_samples, C)\n",
    "        oof_preds[p, fold_id] = preds_full\n",
    "\n",
    "# 4) ÊûÑÈÄ† stacking ÁâπÂæÅÁü©Èòµ (n_samples, n_pipes*n_folds*C)\n",
    "#    ËΩ¨ËΩ¥‰πãÂêé reshape\n",
    "stack = oof_preds.transpose(2,0,1,3)   # (n_samples, pipe, fold, C)\n",
    "X_stack = stack.reshape(n_samples, n_pipes * n_folds * C)\n",
    "\n",
    "# 5) ÂàíÂàÜ train/val\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "    X_stack, y_true, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# 6) DataLoader\n",
    "ds_tr = TensorDataset(torch.from_numpy(X_tr).float(), torch.from_numpy(y_tr).float())\n",
    "ds_va = TensorDataset(torch.from_numpy(X_va).float(), torch.from_numpy(y_va).float())\n",
    "loader_tr = DataLoader(ds_tr, batch_size=BATCH_SIZE, shuffle=True, pin_memory=False)\n",
    "loader_va = DataLoader(ds_va, batch_size=BATCH_SIZE, shuffle=False, pin_memory=False)\n",
    "# 7) ÂÆö‰πâ Stacking MLP\n",
    "class StackingMLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dims=[1024,512,256], out_dim=35, dropout=0.2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = in_dim\n",
    "        for h in hidden_dims:\n",
    "            layers += [nn.Linear(prev,h),\n",
    "                       nn.LeakyReLU(0.01),\n",
    "                       nn.BatchNorm1d(h),\n",
    "                       nn.Dropout(dropout)]\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, out_dim))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "in_dim = n_pipes * n_folds * C\n",
    "mlp = StackingMLP(in_dim=in_dim, hidden_dims=[1024,512,256], out_dim=C).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-3)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "best_val, es_cnt, es_patience = float('inf'), 0, 20\n",
    "best_path = os.path.join(pipe_folders[1], \"stacking_2meta_best.pt\")\n",
    "\n",
    "# 8) ËÆ≠ÁªÉÂæ™ÁéØ\n",
    "for epoch in range(1, META_EPOCHS+1):\n",
    "    mlp.train()\n",
    "    tr_loss = 0.0\n",
    "    for xb, yb in loader_tr:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        out = mlp(xb)\n",
    "        loss = criterion(out, yb)\n",
    "        optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "        tr_loss += loss.item() * xb.size(0)\n",
    "    tr_loss /= len(ds_tr)\n",
    "\n",
    "    mlp.eval()\n",
    "    va_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader_va:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            va_loss += criterion(mlp(xb), yb).item() * xb.size(0)\n",
    "    va_loss /= len(ds_va)\n",
    "\n",
    "    print(f\"Epoch {epoch} ‚Üí Train MSE {tr_loss:.4f}, Val MSE {va_loss:.4f}, LR {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    scheduler.step(va_loss)\n",
    "\n",
    "    if va_loss < best_val:\n",
    "        best_val, es_cnt = va_loss, 0\n",
    "        torch.save(mlp.state_dict(), best_path)\n",
    "        print(\" ‚Ü≥ New best saved.\")\n",
    "    else:\n",
    "        es_cnt += 1\n",
    "        if es_cnt >= es_patience:\n",
    "            print(\" üõë Early stopping.\")\n",
    "            break\n",
    "\n",
    "print(\"‚úÖ Cross-pipe stacking done. Best at\", best_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/21512719.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(best_path, map_location=device)\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/21512719.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded StackingMLP from output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/stacking_2meta_best.pt onto mps\n",
      "Pipe 0 Fold 0 inference‚Ä¶\n",
      "Pipe 0 Fold 1 inference‚Ä¶\n",
      "Pipe 0 Fold 2 inference‚Ä¶\n",
      "Pipe 0 Fold 3 inference‚Ä¶\n",
      "Pipe 0 Fold 4 inference‚Ä¶\n",
      "Pipe 0 Fold 5 inference‚Ä¶\n",
      "Pipe 1 Fold 0 inference‚Ä¶\n",
      "Pipe 1 Fold 1 inference‚Ä¶\n",
      "Pipe 1 Fold 2 inference‚Ä¶\n",
      "Pipe 1 Fold 3 inference‚Ä¶\n",
      "Pipe 1 Fold 4 inference‚Ä¶\n",
      "Pipe 1 Fold 5 inference‚Ä¶\n",
      "‚úÖ Saved submission ‚Üí output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/submission_stack_multi_pipe.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1) ÂàùÂßãÂåñ ---\n",
    "n_pipes = len(pipe_folders)    # 2\n",
    "n_folds = 6\n",
    "C       = 35\n",
    "n_test  = len(test_dataset)\n",
    "\n",
    "# 1) Á°ÆÂÆö device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else\n",
    "                      \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2) Â§çÁé∞Ê®°ÂûãÁªìÊûÑ\n",
    "in_dim     = n_pipes * n_folds * C        # ‰æãÂ¶Ç 2*6*35 = 420\n",
    "hidden_dims= [1024, 512, 256]             # ‰Ω†ËÆ≠ÁªÉÊó∂Áî®ÁöÑ\n",
    "out_dim    = C\n",
    "\n",
    "mlp = StackingMLP(in_dim=in_dim,\n",
    "                  hidden_dims=hidden_dims,\n",
    "                  out_dim=out_dim).to(device)\n",
    "\n",
    "# 3) Âä†ËΩΩËÆ≠ÁªÉÂ•ΩÁöÑÊùÉÈáç\n",
    "best_path = os.path.join(pipe_folders[1], \"stacking_2meta_best.pt\")\n",
    "state = torch.load(best_path, map_location=device)\n",
    "mlp.load_state_dict(state)\n",
    "\n",
    "# 4) ÂàáÊç¢Âà∞ eval Ê®°Âºè\n",
    "mlp.eval()\n",
    "\n",
    "print(f\"‚úÖ Loaded StackingMLP from {best_path} onto {device}\")\n",
    "\n",
    "# oof_test[p, f, i, c] := Á¨¨ p ÁÆ°ÈÅìÔºåÁ¨¨ f Êäò Ê®°Âûã ÂØπ test Ê†∑Êú¨ i ÁöÑ Á¨¨ c Á±ªÈ¢ÑÊµã\n",
    "oof_test = np.zeros((n_pipes, n_folds, n_test, C), dtype=np.float32)\n",
    "\n",
    "full_test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "# --- 2) ÂØπÊØèÊù°ÁÆ°ÈÅìÁöÑÊØèÊäòÊ®°ÂûãÂÅöÂÖ®Ê†∑Êú¨È¢ÑÊµã ---\n",
    "for p, folder in enumerate(pipe_folders):\n",
    "    for fold_id in range(n_folds):\n",
    "        print(f\"Pipe {p} Fold {fold_id} inference‚Ä¶\")\n",
    "        # a) Âä†ËΩΩÂØπÂ∫îÊ®°Âûã\n",
    "        ckpt = os.path.join(folder, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "        net  = VisionMLP_MultiTask(tile_dim, center_dim, output_dim=C).to(device)\n",
    "        net.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "        net.eval()\n",
    "\n",
    "        # b) ÂÖ® test Ê†∑Êú¨‰∏äË∑ë‰∏ÄÊ¨° forward\n",
    "        preds_list = []\n",
    "        with torch.no_grad():\n",
    "            for batch in full_test_loader:\n",
    "                tiles, subtiles = batch['tile'].to(device), batch['subtiles'].to(device)\n",
    "                center = subtiles[:, 4]\n",
    "                fuse = torch.cat([\n",
    "                    net.encoder_center(center),\n",
    "                    net.encoder_subtile(subtiles),\n",
    "                    net.encoder_tile(tiles)\n",
    "                ], dim=1)\n",
    "                out = net.decoder(fuse)\n",
    "                preds_list.append(out.cpu().numpy())\n",
    "\n",
    "        preds_full = np.concatenate(preds_list, axis=0)  # (n_test, C)\n",
    "        oof_test[p, fold_id] = preds_full\n",
    "\n",
    "# --- 3) ÊûÑÈÄ† stacking ÁâπÂæÅÁü©Èòµ ---\n",
    "# ËΩ¨ËΩ¥Âà∞ (n_test, pipe, fold, C)ÔºåÂÜç reshape ‚Üí (n_test, n_pipes*n_folds*C)\n",
    "X_test_stack = oof_test.transpose(2, 0, 1, 3).reshape(n_test, n_pipes * n_folds * C)\n",
    "\n",
    "# --- 4) Áî®ËÆ≠ÁªÉÂ•ΩÁöÑ mlp ÂÅö‰∏ÄÊ¨°ÊÄßÈ¢ÑÊµã ---\n",
    "mlp.eval()\n",
    "with torch.no_grad():\n",
    "    X_t = torch.from_numpy(X_test_stack).float().to(device)\n",
    "    final_preds = mlp(X_t).cpu().numpy()  # (n_test, C)\n",
    "\n",
    "# --- 5) Â≠ò submission ---\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\", \"r\") as f:\n",
    "    ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"])).index\n",
    "\n",
    "sub = pd.DataFrame(final_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, \"ID\", ids)\n",
    "out_path = os.path.join(pipe_folders[1], \"submission_stack_multi_pipe.csv\")\n",
    "sub.to_csv(out_path, index=False)\n",
    "print(\"‚úÖ Saved submission ‚Üí\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import rankdata\n",
    "from python_scripts.import_data import importDataset\n",
    "from python_scripts.operate_model import predict\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import h5py\n",
    "import pandas as pd\n",
    "# ---------------- Settings ----------------\n",
    "save_root  = save_folder  # your save_folder path\n",
    "n_folds    = len([d for d in os.listdir(save_root) if d.startswith('fold')])\n",
    "n_samples  = len(full_dataset)\n",
    "C          = 35  # num cell types\n",
    "start_fold = 0\n",
    "BATCH_SIZE = 64\n",
    "# If optimizing Spearman, convert labels to ranks\n",
    "\n",
    "# --- 1) Prepare OOF meta-features ---\n",
    "# Initialize matrix for OOF predictions\n",
    "n_samples = len(full_dataset)\n",
    "oof_preds = np.zeros((n_samples, C), dtype=np.float32)\n",
    "# True labels (raw or rank)\n",
    "# importDataset returns a dict-like sample, so label is under key 'label'\n",
    "y_true = np.vstack([ full_dataset[i]['label'].cpu().numpy() for i in range(n_samples) ])\n",
    "y_meta = y_true\n",
    "\n",
    "# Build CV splitter (must match first stage splits)\n",
    "logo = LeaveOneGroupOut()\n",
    "image_latents = np.zeros((n_samples, 128), dtype=np.float32)\n",
    "\n",
    "# Loop over folds, load best model, predict on validation indices\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "for fold_id, (tr_idx, va_idx) in enumerate(\n",
    "        logo.split(X=np.zeros(n_samples), y=None, groups=slide_idx)):\n",
    "    # Load model\n",
    "    # if fold_id > start_fold:\n",
    "    #     print(f\"‚è≠Ô∏è Skipping fold {fold_id}\")\n",
    "    #     continue\n",
    "    ckpt_path = os.path.join(save_root, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    print(f\"Loading model from {ckpt_path}...\")\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = True\n",
    "    )\n",
    "\n",
    "    # 2) monkey‚Äêpatch ‰∏Ä‰∏™Êñ∞ÁöÑ head\n",
    "    net.decoder  = nn.Sequential(\n",
    "        nn.Linear(64+64, 256),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "        \n",
    "    )\n",
    "    net = net.to(device)    # Alternatively, if your model requires specific args, replace with:\n",
    "    # net = VisionMLP_MultiTask(tile_dim=64, subtile_dim=64, output_dim=35).to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.to(device).eval()\n",
    "    \n",
    "    # Predict on validation set\n",
    "    val_ds = Subset(full_dataset, va_idx)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    preds = []\n",
    "    latents = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            tiles    = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "\n",
    "            center = subtiles[:, 4].contiguous()\n",
    "            f_c = net.enc_center(center)\n",
    "            f_n = net.enc_neigh(subtiles)\n",
    "            fuse = torch.cat([f_c, f_n], dim=1)\n",
    "\n",
    "            output = net.decoder(fuse)\n",
    "\n",
    "            preds.append(output.cpu())\n",
    "            latents.append(fuse.cpu())  # ‚¨ÖÔ∏è Êî∂ÈõÜ latent vector\n",
    "\n",
    "    preds = torch.cat(preds, dim=0).numpy()    # (n_val, 35)\n",
    "    latents = torch.cat(latents, dim=0).numpy()  # (n_val, 128)\n",
    "\n",
    "    oof_preds[va_idx] = preds\n",
    "    image_latents[va_idx] = latents\n",
    "\n",
    "    print(f\"Fold {fold_id}: OOF preds shape {preds.shape}, Latent shape: {latents.shape}\")\n",
    "\n",
    "\n",
    "    \n",
    "with h5py.File(\"dataset/realign/filtered_dataset.h5\", \"r\") as f:\n",
    "    train_spots = f[\"spots/Train\"]\n",
    "    \n",
    "    train_spot_tables = {}\n",
    "    \n",
    "    for slide_name in train_spots.keys():\n",
    "        spot_array = np.array(train_spots[slide_name])\n",
    "        df = pd.DataFrame(spot_array)\n",
    "        df[\"slide_name\"] = slide_name\n",
    "        train_spot_tables[slide_name] = df\n",
    "        print(f\"‚úÖ Â∑≤ËÆÄÂèñ slide: {slide_name}\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 2: Âêà‰ΩµÊâÄÊúâ slide ÁöÑË≥áÊñô\n",
    "# -----------------------------------------------------\n",
    "all_train_spots_df = pd.concat(train_spot_tables.values(), ignore_index=True)\n",
    "# ÊèêÂèñ x, y\n",
    "xy = all_train_spots_df[[\"x\", \"y\"]].to_numpy()  # shape: (8348, 2)\n",
    "\n",
    "# Âêà‰ΩµÊàêÊñ∞ÁöÑ meta feature\n",
    "meta_features = np.concatenate([oof_preds, xy, image_latents], axis=1)\n",
    "# --- 2) Train LightGBM meta-model ---\n",
    "# Choose objective: regression on rank (for Spearman) or raw (for MSE)\n",
    "# Â∞á meta features ÊãÜÊàêË®ìÁ∑¥ÈõÜËàá early stopping Áî®ÁöÑÈ©óË≠âÈõÜ\n",
    "X_train, X_val, y_train, y_val = train_test_split(meta_features, y_meta, test_size=0.2, random_state=42)\n",
    "print(\"Meta feature shape:\", X_train.shape)\n",
    "print(\"Feature std (min/max):\", np.min(np.std(X_train, axis=0)), np.max(np.std(X_train, axis=0)))\n",
    "\n",
    "\n",
    "# # Base model\n",
    "# lgb_base = lgb.LGBMRegressor(\n",
    "#     objective='l2',\n",
    "#     metric='rmse',\n",
    "#     n_estimators=12000,\n",
    "#     max_depth=15,\n",
    "#     learning_rate=0.008,\n",
    "#     num_leaves=32,\n",
    "#     colsample_bytree=0.25\n",
    "# )\n",
    "import optuna\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define Optuna objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'device': 'gpu',                # ‚úÖ GPU ÊîØÊè¥\n",
    "        'gpu_platform_id': 0,\n",
    "        'gpu_device_id': 0,\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.005, 0.1),\n",
    "        'max_depth': trial.suggest_int(\"max_depth\", 4, 15),\n",
    "        'num_leaves': trial.suggest_int(\"num_leaves\", 32, 256),\n",
    "        'min_data_in_leaf': trial.suggest_int(\"min_data_in_leaf\", 20, 100),\n",
    "        'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float(\"reg_alpha\", 0, 1),\n",
    "        'reg_lambda': trial.suggest_float(\"reg_lambda\", 0, 1),\n",
    "        'n_estimators': 12000\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    multi_model = MultiOutputRegressor(model)\n",
    "    multi_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = multi_model.predict(X_val)\n",
    "    rmse = np.mean([\n",
    "        np.sqrt(mean_squared_error(y_val[:, i], y_pred[:, i]))\n",
    "        for i in range(y_val.shape[1])\n",
    "    ])\n",
    "\n",
    "\n",
    "    return rmse\n",
    "\n",
    "# Run optimization\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Use best params to train final models\n",
    "best_params = study.best_trial.params\n",
    "best_params['objective'] = 'l2'\n",
    "best_params['metric'] = 'rmse'\n",
    "best_params['verbosity'] = -1\n",
    "\n",
    "# Train final models with best parameters\n",
    "meta_model = MultiOutputRegressor(lgb.LGBMRegressor(**best_params))\n",
    "meta_model.estimators_ = []\n",
    "\n",
    "print(\"Training LightGBM on OOF meta-features with best Optuna params...\")\n",
    "for i in range(y_train.shape[1]):\n",
    "    print(f\"Training target {i}...\")\n",
    "    model = lgb.LGBMRegressor(**best_params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train[:, i],\n",
    "        eval_set=[(X_val, y_val[:, i])],\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=200),\n",
    "            log_evaluation(period=100)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    meta_model.estimators_.append(model)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(meta_model, os.path.join(save_root, 'meta_model.pkl'))\n",
    "# ‰øùÂ≠òÊ®°Âûã\n",
    "\n",
    "\n",
    "# --- 3) Prepare test meta-features ---\n",
    "n_test = len(test_dataset)\n",
    "test_preds = []\n",
    "test_latents = []\n",
    "\n",
    "for fold_id in range(n_folds):\n",
    "    ckpt_path = os.path.join(save_root, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = True\n",
    "    )\n",
    "\n",
    "    net.decoder = nn.Sequential(\n",
    "        nn.Linear(64+64, 256),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "    )\n",
    "\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.eval()\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds = []\n",
    "    latents = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            tiles = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "\n",
    "            center = subtiles[:, 4].contiguous()\n",
    "            f_c = net.enc_center(center)\n",
    "            f_n = net.enc_neigh(subtiles)\n",
    "            fuse = torch.cat([f_c, f_n], dim=1)\n",
    "\n",
    "            out = net.decoder(fuse)\n",
    "\n",
    "            preds.append(out.cpu())\n",
    "            latents.append(fuse.cpu())  # image embedding (128D)\n",
    "\n",
    "    test_preds.append(torch.cat(preds, dim=0).numpy())      # shape: (n_test, 35)\n",
    "    test_latents.append(torch.cat(latents, dim=0).numpy())  # shape: (n_test, 128)\n",
    "\n",
    "# === Stack + Average ===\n",
    "test_preds = np.mean(np.stack(test_preds, axis=0), axis=0)      # (n_test, 35)\n",
    "test_latents = np.mean(np.stack(test_latents, axis=0), axis=0)  # (n_test, 128)\n",
    "\n",
    "with h5py.File(\"dataset/elucidata_ai_challenge_data.h5\", \"r\") as f:\n",
    "    test_spots = f[\"spots/Test\"]\n",
    "    spot_array = np.array(test_spots['S_7'])\n",
    "    df = pd.DataFrame(spot_array)\n",
    "\n",
    "xy = df[[\"x\", \"y\"]].to_numpy()  # shape: (n_test, 2)\n",
    "\n",
    "# Âêà‰ΩµÁÇ∫ÊúÄÁµÇ test meta features\n",
    "test_meta = np.concatenate([test_preds, xy, test_latents], axis=1)  # shape: (n_test, 35+2+128)\n",
    "\n",
    "\n",
    "\n",
    "final_preds = meta_model.predict(test_meta)\n",
    "\n",
    "# --- Save submission ---\n",
    "import h5py\n",
    "import pandas as pd\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spot_ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"]))\n",
    "sub = pd.DataFrame(final_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, 'ID', test_spot_ids.index)\n",
    "sub.to_csv(os.path.join(save_root, 'submission_stacked.csv'), index=False)\n",
    "print(\"‚úÖ Saved stacked submission.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import rankdata\n",
    "from python_scripts.import_data import importDataset\n",
    "from python_scripts.operate_model import predict\n",
    "\n",
    "# --- ÈÖçÁΩÆ: Âè™Áî®Âì™‰∫õ fold ÁöÑÁªìÊûúÊù•ËÆ≠ÁªÉ/È¢ÑÊµã meta-model ---\n",
    "meta_folds = [0]  # ‰æãÂ¶ÇÂè™Áî® fold0, fold2, fold4\n",
    "\n",
    "# 1) ÂáÜÂ§á full_dataset, slide_idx, test_dataset Á≠â\n",
    "full_dataset = importDataset(\n",
    "    grouped_data, model,\n",
    "    image_keys=['tile','subtiles'],\n",
    "    transform=lambda x: x\n",
    ")\n",
    "n_samples = len(full_dataset)\n",
    "C = 35  # Á±ªÂà´Êï∞\n",
    "\n",
    "# 2) È¢ÑÁïô oof_preds Âíå fold_ids\n",
    "oof_preds    = np.zeros((n_samples, C), dtype=np.float32)\n",
    "oof_fold_ids = np.full(n_samples, -1, dtype=int)\n",
    "\n",
    "# ÁúüÊ†áÁ≠æ\n",
    "y_true = np.vstack([ full_dataset[i]['label'].cpu().numpy() for i in range(n_samples) ])\n",
    "y_meta = y_true.copy()  # ‰∏çÂÅö rank Êó∂Áõ¥Êé•Áî® raw\n",
    "\n",
    "# 3) ÁîüÊàê OOF È¢ÑÊµãÂπ∂ËÆ∞ÂΩï fold id\n",
    "logo = LeaveOneGroupOut()\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "for fold_id, (tr_idx, va_idx) in enumerate(\n",
    "        logo.split(X=np.zeros(n_samples), y=None, groups=slide_idx)):\n",
    "\n",
    "    # Â¶ÇÊûúÂΩìÂâç fold ‰∏çÂú®Êàë‰ª¨ÊÉ≥Ë¶ÅÁöÑ meta_folds ÂàóË°®ÈáåÔºåÂ∞±Ë∑≥Ëøá\n",
    "    if fold_id not in meta_folds:\n",
    "        print(f\"‚è≠Ô∏è Skipping OOF for fold {fold_id}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n>>> Generating OOF for fold {fold_id}\")\n",
    "    ckpt_path = os.path.join(save_root, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = True\n",
    "    )\n",
    "\n",
    "    # 2) monkey‚Äêpatch ‰∏Ä‰∏™Êñ∞ÁöÑ head\n",
    "    net.decoder  = nn.Sequential(\n",
    "        nn.Linear(64+64, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "        \n",
    "    )\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.eval()\n",
    "\n",
    "    val_loader = DataLoader(Subset(full_dataset, va_idx), batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds = predict(net, val_loader, device)  # (n_val, C)\n",
    "\n",
    "    oof_preds[va_idx]    = preds\n",
    "    oof_fold_ids[va_idx] = fold_id\n",
    "\n",
    "    print(f\"  ‚Üí Fold {fold_id} OOF preds shape: {preds.shape}\")\n",
    "# 4) Âè™ÈÄâÂèñ meta_folds ÁöÑË°åÊù•ËÆ≠ÁªÉ meta-model\n",
    "mask = np.isin(oof_fold_ids, meta_folds)\n",
    "X_meta = oof_preds[mask]\n",
    "y_meta_sub = y_meta[mask]\n",
    "\n",
    "print(f\"\\nTraining meta-model on folds {meta_folds}:\")\n",
    "print(f\"  ‰ΩøÁî®Ê†∑Êú¨Êï∞Ôºö{X_meta.shape[0]} / {n_samples}\")\n",
    "\n",
    "lgb_base = lgb.LGBMRegressor(\n",
    "    objective='regression',\n",
    "    learning_rate=0.001,\n",
    "    n_estimators=1000,\n",
    "    num_leaves=31,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    n_jobs=-1,\n",
    "    force_col_wise=True\n",
    ")\n",
    "meta_model = MultiOutputRegressor(lgb_base)\n",
    "meta_model.fit(X_meta, y_meta_sub)\n",
    "joblib.dump(meta_model, os.path.join(save_root, 'meta_model.pkl'))\n",
    "\n",
    "# 5) ÂáÜÂ§á test_metaÔºåÂè™Âπ≥Âùá meta_folds ‰∏≠ÁöÑÈ¢ÑÊµã\n",
    "n_folds = len([d for d in os.listdir(save_root) if d.startswith('fold')])\n",
    "n_test  = len(test_dataset)\n",
    "test_meta = np.zeros((n_test, C), dtype=np.float32)\n",
    "\n",
    "for fold_id in range(n_folds):\n",
    "    if fold_id not in meta_folds:\n",
    "        continue\n",
    "    ckpt_path = os.path.join(save_root, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = True\n",
    "    )\n",
    "\n",
    "    # 2) monkey‚Äêpatch ‰∏Ä‰∏™Êñ∞ÁöÑ head\n",
    "    net.decoder  = nn.Sequential(\n",
    "        nn.Linear(64+64, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "        \n",
    "    )\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.eval()\n",
    "\n",
    "    loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds = predict(net, loader, device)\n",
    "    test_meta += preds\n",
    "\n",
    "# Âπ≥ÂùáÊó∂Èô§‰ª•ÂèÇ‰∏éÁöÑ folds Êï∞ÁõÆ\n",
    "test_meta /= len(meta_folds)\n",
    "\n",
    "# 6) Áî® meta-model ÂÅöÊúÄÁªàÈ¢ÑÊµã\n",
    "final_preds = meta_model.predict(test_meta)\n",
    "\n",
    "# --- Save submission ---\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spot_ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"]))\n",
    "\n",
    "sub = pd.DataFrame(final_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, 'ID', test_spot_ids.index)\n",
    "sub.to_csv(os.path.join(save_root, 'submission_stacked.csv'), index=False)\n",
    "print(\"‚úÖ Saved stacked submission.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_23908/317847752.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt, map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved fold 0 predictions to output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/submission_fold0.csv\n",
      "‚úÖ Saved fold 1 predictions to output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/submission_fold1.csv\n",
      "‚úÖ Saved fold 2 predictions to output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/submission_fold2.csv\n",
      "‚úÖ Saved fold 3 predictions to output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/submission_fold3.csv\n",
      "‚úÖ Saved fold 4 predictions to output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/submission_fold4.csv\n",
      "‚úÖ Saved fold 5 predictions to output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/submission_fold5.csv\n",
      "‚úÖ Saved rank‚Äêensemble submission to output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/submission_rank_ensemble.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ËÆÄ test spot index\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spots     = f[\"spots/Test\"]\n",
    "    test_spot_table= pd.DataFrame(np.array(test_spots['S_7']))\n",
    "\n",
    "fold_ckpts = sorted(glob.glob(os.path.join(trained_oof_model_folder, \"fold*\", \"best_model.pt\")))\n",
    "models = []\n",
    "for ckpt in fold_ckpts:\n",
    "    net = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt, map_location=\"cpu\"))\n",
    "    net.to(device).eval()\n",
    "    models.append(net)\n",
    "\n",
    "all_fold_preds = []\n",
    "for fold_id, net in enumerate(models):\n",
    "    # Êé®Ë´ñ\n",
    "    with torch.no_grad():\n",
    "        preds = predict(net, test_loader, device)  # (N_test,35) numpy array\n",
    "\n",
    "    # 1) Â≠òÊØè‰∏ÄÊäòÁöÑÂéüÂßãÈ†êÊ∏¨\n",
    "    df_fold = pd.DataFrame(preds, columns=[f\"C{i+1}\" for i in range(preds.shape[1])])\n",
    "    df_fold.insert(0, \"ID\", test_spot_table.index)\n",
    "    path_fold = os.path.join(trained_oof_model_folder, f\"submission_fold{fold_id}.csv\")\n",
    "    df_fold.to_csv(path_fold, index=False)\n",
    "    print(f\"‚úÖ Saved fold {fold_id} predictions to {path_fold}\")\n",
    "\n",
    "    all_fold_preds.append(preds)\n",
    "\n",
    "# 2) ÂÅö rank‚Äêaverage ensemble\n",
    "all_fold_preds = np.stack(all_fold_preds, axis=0)       # (K, N_test, 35)\n",
    "ranks          = all_fold_preds.argsort(axis=2).argsort(axis=2).astype(float)\n",
    "mean_rank      = ranks.mean(axis=0)                    # (N_test,35)\n",
    "\n",
    "# 3) Â≠ò final ensemble\n",
    "df_ens = pd.DataFrame(mean_rank, columns=[f\"C{i+1}\" for i in range(mean_rank.shape[1])])\n",
    "df_ens.insert(0, \"ID\", test_spot_table.index)\n",
    "path_ens = os.path.join(trained_oof_model_folder, \"submission_rank_ensemble.csv\")\n",
    "df_ens.to_csv(path_ens, index=False)\n",
    "print(f\"‚úÖ Saved rank‚Äêensemble submission to {path_ens}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatialhackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
