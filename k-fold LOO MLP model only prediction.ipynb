{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable / total params = 6,679,843 / 6,679,843\n",
      "Trainable / total params = 6,679,843 / 6,679,843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionMLP_MultiTask(\n",
       "  (encoder_tile): DeepTileEncoder(\n",
       "    (layer0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU()\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "    )\n",
       "    (global_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (mid_pool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
       "    (fc): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=2560, out_features=512, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "      (5): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (6): LeakyReLU(negative_slope=0.01)\n",
       "      (7): Dropout(p=0.1, inplace=False)\n",
       "      (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (9): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (encoder_subtile): SubtileEncoder(\n",
       "    (layer0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU()\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "    )\n",
       "    (global_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (mid_pool): AdaptiveAvgPool2d(output_size=(2, 2))\n",
       "    (large_pool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
       "    (fc): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=1792, out_features=256, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "      (5): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (6): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (encoder_center): CenterSubtileEncoder(\n",
       "    (layer0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU()\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU()\n",
       "      )\n",
       "    )\n",
       "    (global_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (mid_pool): AdaptiveAvgPool2d(output_size=(2, 2))\n",
       "    (large_pool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
       "    (fc): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=1792, out_features=256, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Dropout(p=0.1, inplace=False)\n",
       "      (5): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (6): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=256, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): Dropout(p=0.1, inplace=False)\n",
       "    (9): Linear(in_features=64, out_features=35, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(out_channels)\n",
    "        self.act1  = nn.SiLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        self.act2 = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.act1(self.bn1(self.conv1(x)))\n",
    "        out = self.act2(self.bn2(self.conv2(out)))\n",
    "        if self.shortcut is not None:\n",
    "            identity = self.shortcut(x)\n",
    "        return out + identity\n",
    "\n",
    "\n",
    "\n",
    "class DeepTileEncoder(nn.Module):\n",
    "    \"\"\"加深的 Tile 分支：全局信息，多尺度池化 + 三层 MLP\"\"\"\n",
    "    def __init__(self, out_dim, in_channels=3, negative_slope=0.01):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(2)  # 78→39\n",
    "        )\n",
    "        self.layer1 = nn.Sequential(\n",
    "            ResidualBlock(32, 64),\n",
    "            ResidualBlock(64, 64),\n",
    "            nn.MaxPool2d(2)  # 39→19\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            ResidualBlock(64, 128),\n",
    "            ResidualBlock(128, 128),\n",
    "            nn.MaxPool2d(2)  # 19→9\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            ResidualBlock(128, 256),\n",
    "            ResidualBlock(256, 256)\n",
    "        )  # 保持 9×9\n",
    "\n",
    "        # 多尺度池化\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))  # [B,256,1,1]\n",
    "        self.mid_pool    = nn.AdaptiveAvgPool2d((3, 3))  # [B,256,3,3]\n",
    "\n",
    "        total_dim = 256*1*1 + 256*3*3\n",
    "        # 三层 MLP：total_dim → 2*out_dim → out_dim → out_dim\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(total_dim, out_dim*4),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(out_dim*4, out_dim*2),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(out_dim*2, out_dim),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        # x: [B,256,9,9]\n",
    "        g = self.global_pool(x).contiguous().reshape(x.size(0), -1)  # [B,256]\n",
    "        m = self.mid_pool(x).contiguous().reshape(x.size(0), -1)     # [B,256*3*3]\n",
    "\n",
    "        return self.fc(torch.cat([g, m], dim=1))\n",
    "\n",
    "\n",
    "class SubtileEncoder(nn.Module):\n",
    "    \"\"\"多尺度 Subtile 分支：局部信息 + 两层 MLP\"\"\"\n",
    "    def __init__(self, out_dim, in_channels=3, negative_slope=0.01):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(2)  # 26→13\n",
    "        )\n",
    "        self.layer1 = nn.Sequential(\n",
    "            ResidualBlock(32, 64),\n",
    "            ResidualBlock(64, 64),\n",
    "            nn.MaxPool2d(2)  # 13→6\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            ResidualBlock(64, 128),\n",
    "            ResidualBlock(128, 128)\n",
    "        )  # 保持 6×6\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.mid_pool    = nn.AdaptiveAvgPool2d((2,2))\n",
    "        self.large_pool    = nn.AdaptiveAvgPool2d((3,3))\n",
    "\n",
    "        total_dim = 128*1*1 + 128*2*2 + 128*3*3\n",
    "        # 两层 MLP：total_dim → out_dim*2 → out_dim\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(total_dim, out_dim*2),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(out_dim*2, out_dim),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C, H, W = x.shape\n",
    "        x = x.contiguous().reshape(B*N, C, H, W)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        # g,m: [B*N, feat]\n",
    "        g = self.global_pool(x).contiguous().reshape(B, N, -1)\n",
    "        m = self.mid_pool(x).contiguous().reshape(B, N, -1)\n",
    "        l = self.large_pool(x).contiguous().reshape(B, N, -1)\n",
    "\n",
    "        # 合并 N 张 subtiles，再 FC\n",
    "        feat = torch.cat([g, m, l], dim=2).mean(dim=1).contiguous()  # [B, total_dim]\n",
    "        return self.fc(feat)\n",
    "class CenterSubtileEncoder(nn.Module):\n",
    "    \"\"\"專門處理中心 subtile 的 Encoder\"\"\"\n",
    "    def __init__(self, out_dim, in_channels=3, negative_slope= 0.01):\n",
    "        super().__init__()\n",
    "        self.layer0 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.SiLU(),\n",
    "            nn.MaxPool2d(2)  # 26→13\n",
    "        )\n",
    "        self.layer1 = nn.Sequential(\n",
    "            ResidualBlock(32, 64),\n",
    "            ResidualBlock(64, 64),\n",
    "            nn.MaxPool2d(2)  # 13→6\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            ResidualBlock(64, 128),\n",
    "            ResidualBlock(128, 128)\n",
    "        )  # 6×6\n",
    "\n",
    "        # 多尺度池化\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.mid_pool    = nn.AdaptiveAvgPool2d((2,2))\n",
    "        self.large_pool    = nn.AdaptiveAvgPool2d((3,3))\n",
    "\n",
    "        total_dim = 128*1*1 + 128*2*2 + 128*3*3\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(total_dim, out_dim*2),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(out_dim*2, out_dim),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        g = self.global_pool(x).contiguous().reshape(x.size(0), -1)\n",
    "        m = self.mid_pool(x).contiguous().reshape(x.size(0), -1)\n",
    "        l = self.large_pool(x).contiguous().reshape(x.size(0), -1)\n",
    "\n",
    "        return self.fc(torch.cat([g, m, l], dim=1)).contiguous()\n",
    "\n",
    "\n",
    "\n",
    "class VisionMLP_MultiTask(nn.Module):\n",
    "    \"\"\"整體多任務模型：融合 tile + subtile + center，使用動態權重融合\"\"\"\n",
    "    def __init__(self, tile_dim=128, subtile_dim=64, output_dim=35, negative_slope=0.01):\n",
    "        super().__init__()\n",
    "        self.encoder_tile    = DeepTileEncoder(tile_dim)\n",
    "        self.encoder_subtile = SubtileEncoder(subtile_dim)\n",
    "        self.encoder_center  = CenterSubtileEncoder(subtile_dim)\n",
    "\n",
    "        # 輸出 decoder：輸入為 tile_dim (因為融合後只剩一個 vector)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(tile_dim + subtile_dim + subtile_dim , 256),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(negative_slope),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, tile, subtiles):\n",
    "        tile = tile.contiguous()\n",
    "        subtiles = subtiles.contiguous()\n",
    "        center = subtiles[:, 4]\n",
    "\n",
    "        f_tile = self.encoder_tile(tile)         # [B, tile_dim]\n",
    "        f_sub  = self.encoder_subtile(subtiles)  # [B, subtile_dim]\n",
    "        f_center = self.encoder_center(center)   # [B, subtile_dim]\n",
    "\n",
    "        # 拼接三個分支做 gating\n",
    "        features_cat = torch.cat([f_tile, f_sub, f_center], dim=1)  # [B, tile+sub+center]\n",
    "        return self.decoder(features_cat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 用法示例\n",
    "model = VisionMLP_MultiTask(tile_dim=128, subtile_dim=128, output_dim=35)\n",
    "\n",
    "\n",
    "# —— 5) 确保只有 decoder 可训练 ——  \n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total     = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Trainable / total params = {trainable:,} / {total:,}\")\n",
    "\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total     = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Trainable / total params = {trainable:,} / {total:,}\")\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same in multiple .pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/import_data.py:251: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d = torch.load(fpath, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded keys: dict_keys(['source_idx', 'position', 'slide_idx', 'subtiles', 'tile', 'label'])\n",
      "Samples: 8348\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import inspect\n",
    "from python_scripts.import_data import load_all_tile_data\n",
    "\n",
    "# 用法範例\n",
    "#folder = \"dataset/spot-rank/version-3/only_tile_sub/original_train\"\n",
    "folder = \"dataset/spot-rank/filtered_directly_rank/masked/realign/Macenko_4_7_masked/filtered/train_data/\"\n",
    "\n",
    "grouped_data = load_all_tile_data( \n",
    "        folder_path=folder,\n",
    "        model=model,\n",
    "        fraction=1,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # grouped_data 現在只會有 model.forward() 需要的 key，\n",
    "    # 像 ['tile','subtiles','neighbors','norm_coord','node_feat','adj_list','edge_feat','label','source_idx']\n",
    "print(\"Loaded keys:\", grouped_data.keys())\n",
    "print(\"Samples:\", len(next(iter(grouped_data.values()))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checking dataset sample: 0\n",
      "📏 tile shape: torch.Size([3, 78, 78]) | dtype: torch.float32 | min: 0.129, max: 1.000, mean: 0.653, std: 0.150\n",
      "📏 subtiles shape: torch.Size([9, 3, 26, 26]) | dtype: torch.float32 | min: 0.129, max: 1.000, mean: 0.653, std: 0.150\n",
      "📏 label shape: torch.Size([35]) | dtype: torch.float32 | min: 1.000, max: 35.000, mean: 18.000, std: 10.247\n",
      "--- label head (前 5 個元素):\n",
      "tensor([12., 24., 18.,  6., 30.])\n",
      "📏 source_idx shape: torch.Size([]) | dtype: torch.int64 | min: 0.000, max: 0.000, mean: 0.000, std: nan\n",
      "--- source_idx 資料為純量: tensor(0)\n",
      "📏 position shape: torch.Size([2]) | dtype: torch.float32 | min: 0.171, max: 0.632, mean: 0.401, std: 0.326\n",
      "--- position head (前 5 個元素):\n",
      "tensor([0.6318, 0.1707])\n",
      "✅ All checks passed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/3062057575.py:79: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/miniforge3/conda-bld/libtorch_1744320376245/work/aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
      "  std = tensor_float.std().item()\n"
     ]
    }
   ],
   "source": [
    "from python_scripts.import_data import convert_item, get_model_inputs\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import inspect\n",
    "import numpy as np\n",
    "\n",
    "class importDataset(Dataset):\n",
    "    def __init__(self, data_dict, model, image_keys=None, transform=None, print_sig=False):\n",
    "        self.data = data_dict\n",
    "        self.image_keys = set(image_keys) if image_keys is not None else set()\n",
    "        self.transform = transform if transform is not None else lambda x: x\n",
    "        self.forward_keys = list(get_model_inputs(model, print_sig=print_sig).parameters.keys())\n",
    "\n",
    "        expected_length = None\n",
    "        for key, value in self.data.items():\n",
    "            if expected_length is None:\n",
    "                expected_length = len(value)\n",
    "            if len(value) != expected_length:\n",
    "                raise ValueError(f\"資料欄位 '{key}' 的長度 ({len(value)}) 與預期 ({expected_length}) 不一致。\")\n",
    "\n",
    "        for key in self.forward_keys:\n",
    "            if key not in self.data:\n",
    "                raise ValueError(f\"data_dict 缺少模型 forward 所需欄位: '{key}'。目前可用的欄位: {list(self.data.keys())}\")\n",
    "        if \"label\" not in self.data:\n",
    "            raise ValueError(f\"data_dict 必須包含 'label' 欄位。可用的欄位: {list(self.data.keys())}\")\n",
    "        if \"source_idx\" not in self.data:\n",
    "            raise ValueError(\"data_dict 必須包含 'source_idx' 欄位，用於 trace 原始順序對應。\")\n",
    "        if \"position\" not in self.data:\n",
    "            raise ValueError(\"data_dict 必須包含 'position' 欄位，用於 trace 原始順序對應。\")\n",
    "    def __len__(self):\n",
    "        return len(next(iter(self.data.values())))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {}\n",
    "        for key in self.forward_keys:\n",
    "            value = self.data[key][idx]\n",
    "            value = self.transform(value)\n",
    "            value = convert_item(value, is_image=(key in self.image_keys))\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                value = value.float()\n",
    "            sample[key] = value\n",
    "\n",
    "        label = self.transform(self.data[\"label\"][idx])\n",
    "        label = convert_item(label, is_image=False)\n",
    "        if isinstance(label, torch.Tensor):\n",
    "            label = label.float()\n",
    "        sample[\"label\"] = label\n",
    "\n",
    "        # 加入 source_idx\n",
    "        source_idx = self.data[\"source_idx\"][idx]\n",
    "        sample[\"source_idx\"] = torch.tensor(source_idx, dtype=torch.long)\n",
    "        # 加入 position （假设 data_dict 中 'position' 是 (x, y) 或 [x, y]）\n",
    "        pos = self.data[\"position\"][idx]\n",
    "        sample[\"position\"] = torch.tensor(pos, dtype=torch.float)\n",
    "        return sample\n",
    "    def check_item(self, idx=0, num_lines=5):\n",
    "        expected_keys = self.forward_keys + ['label', 'source_idx', 'position']\n",
    "        sample = self[idx]\n",
    "        print(f\"🔍 Checking dataset sample: {idx}\")\n",
    "        for key in expected_keys:\n",
    "            if key not in sample:\n",
    "                print(f\"❌ 資料中缺少 key: {key}\")\n",
    "                continue\n",
    "            tensor = sample[key]\n",
    "            if isinstance(tensor, torch.Tensor):\n",
    "                try:\n",
    "                    shape = tensor.shape\n",
    "                except Exception:\n",
    "                    shape = \"N/A\"\n",
    "                dtype = tensor.dtype if hasattr(tensor, \"dtype\") else \"N/A\"\n",
    "                output_str = f\"📏 {key} shape: {shape} | dtype: {dtype}\"\n",
    "                if tensor.numel() > 0:\n",
    "                    try:\n",
    "                        tensor_float = tensor.float()\n",
    "                        mn = tensor_float.min().item()\n",
    "                        mx = tensor_float.max().item()\n",
    "                        mean = tensor_float.mean().item()\n",
    "                        std = tensor_float.std().item()\n",
    "                        output_str += f\" | min: {mn:.3f}, max: {mx:.3f}, mean: {mean:.3f}, std: {std:.3f}\"\n",
    "                    except Exception:\n",
    "                        output_str += \" | 無法計算統計數據\"\n",
    "                print(output_str)\n",
    "                if key not in self.image_keys:\n",
    "                    if tensor.ndim == 0:\n",
    "                        print(f\"--- {key} 資料為純量:\", tensor)\n",
    "                    elif tensor.ndim == 1:\n",
    "                        print(f\"--- {key} head (前 {num_lines} 個元素):\")\n",
    "                        print(tensor[:num_lines])\n",
    "                    else:\n",
    "                        print(f\"--- {key} head (前 {num_lines} 列):\")\n",
    "                        print(tensor[:num_lines])\n",
    "            else:\n",
    "                # 如果 position 存的是 list/tuple/etc，也会走这里\n",
    "                print(f\"📏 {key} (非 tensor 資料):\", tensor)\n",
    "        print(\"✅ All checks passed!\")\n",
    "\n",
    "\n",
    "full_dataset = importDataset(grouped_data, model,\n",
    "                             image_keys=['tile','subtiles'],\n",
    "                             transform=lambda x: x)\n",
    "\n",
    "full_dataset.check_item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from python_scripts.image_features import  *\n",
    "from python_scripts.prediction_features import  *\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# === Main Function with Names ===\n",
    "def generate_meta_features(dataset, model_for_recon, device, ae_type, oof_preds = None, latents = None):\n",
    "    \"\"\"\n",
    "    Generate meta-features and corresponding names.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features : np.ndarray, shape (n_samples, n_features)\n",
    "    names    : list of str, length n_features\n",
    "    \"\"\"\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    # 1) 收集所有 (feats, names) 到同一个 outputs 列表\n",
    "    outputs = []\n",
    "\n",
    "    # # AE reconstruction loss\n",
    "    feats, names = compute_ae_reconstruction_loss(model_for_recon, loader, device, ae_type)\n",
    "    feats = feats[:, None]\n",
    "    outputs.append((feats, names))\n",
    "\n",
    "    # # AE embeddings\n",
    "    feats, names = compute_ae_embeddings(loader, model_for_recon, device)\n",
    "    outputs.append((feats, names))\n",
    "    if latents is not None:\n",
    "        # 原始 35 维 preds\n",
    "        n_classes = latents.shape[1]\n",
    "        raw_names = [f\"trained-latents_{i}\" for i in range(n_classes)]\n",
    "        outputs.append((latents, raw_names))\n",
    "    # # # Latent stats\n",
    "    latent_feats = outputs[1][0]\n",
    "    feats, names = compute_latent_stats(latent_feats)\n",
    "    outputs.append((feats, names))\n",
    "\n",
    "    # # # RGB stats\n",
    "\n",
    "    feats, names = compute_center_subtile_rgb_stats(dataset)\n",
    "    outputs.append((feats, names))\n",
    "    feats, names = compute_subtiles_except_center_rgb_stats(dataset)\n",
    "    outputs.append((feats, names))\n",
    "    feats, names = compute_tile_rgb_stats(dataset)\n",
    "    outputs.append((feats, names))\n",
    "    feats, names = compute_subtile_contrast_stats(dataset)\n",
    "    outputs.append((feats, names))\n",
    "\n",
    "    # # # Texture & pattern features\n",
    "    feats, names = compute_wavelet_stats(dataset)\n",
    "    outputs.append((feats, names))\n",
    "    feats, names = compute_sobel_stats(dataset)\n",
    "    outputs.append((feats, names))\n",
    "\n",
    "    # Color & distribution features\n",
    "    feats, names = compute_hsv_stats(dataset)\n",
    "    outputs.append((feats, names))\n",
    "\n",
    "    # H&E stain features\n",
    "    feats, names = compute_he_stats(dataset)\n",
    "    outputs.append((feats, names))\n",
    "\n",
    "    # Sliding-window std stats\n",
    "    feats, names = compute_sliding_window_stats(dataset)\n",
    "    outputs.append((feats, names))\n",
    "\n",
    "    # # 9) OOF-based features (only if provided)\n",
    "    if oof_preds is not None:\n",
    "        # 原始 35 维 preds\n",
    "        n_classes = oof_preds.shape[1]\n",
    "        raw_names = [f\"oof_pred_{i}\" for i in range(n_classes)]\n",
    "        outputs.append((oof_preds, raw_names))\n",
    "\n",
    "        # # 相邻差异\n",
    "        feats, names = compute_adjacent_diffs(oof_preds, stride=1)\n",
    "        outputs.append((feats, names))\n",
    "\n",
    "        # # top-2..top-6 统计\n",
    "        feats, names = compute_lastn_stats_multi(oof_preds, max_n=35)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_topn_stats_multi(oof_preds, max_n=6)\n",
    "        outputs.append((feats, names))\n",
    "        # 更多可选——只需取消注释即可\n",
    "        feats, names = compute_adj_diff_histogram(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_multi_stride_diffs(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_median_mad(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_skew_kurt(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_percentile_iqr(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_renyi_entropy(oof_preds, alpha=2)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_mass_topk(oof_preds, k=5)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_cdf_slope(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_pca_components(oof_preds, n_components=10)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_peak_stats(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_segment_stats(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_ar_coeffs(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_autocorr_features(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_second_order_diffs(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_third_order_diffs(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_relative_diffs(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "        feats, names = compute_diff_ratio_of_diffs(oof_preds)\n",
    "        outputs.append((feats, names))\n",
    "\n",
    "\n",
    "    # 2) unzip 成 feat_list 和 name_seq\n",
    "    feat_list, name_seq = zip(*outputs)\n",
    "\n",
    "    # 3) 逐块校验 feats 列数与 names 长度\n",
    "    for feats, names_block in zip(feat_list, name_seq):\n",
    "        ncols = feats.shape[1] if feats.ndim == 2 else 1\n",
    "        if ncols != len(names_block):\n",
    "            raise ValueError(\n",
    "                f\"Mismatch: got {ncols} columns but {len(names_block)} names \"\n",
    "                f\"in block '{names_block[0].split('_')[0]}'\"\n",
    "            )\n",
    "        print(\n",
    "            f\"{names_block[0].split('_')[0]:12s} -> cols: {ncols:4d}, names: {len(names_block):4d} OK\"\n",
    "        )\n",
    "\n",
    "    # 4) 扁平化 names 并拼接 features\n",
    "    name_list = [nm for block in name_seq for nm in block]\n",
    "    features = np.concatenate(feat_list, axis=1)\n",
    "    print(f\"✅ Generated meta-features with shape: {features.shape}\")\n",
    "\n",
    "    return features, name_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def diagnose_meta_nonfinite(meta: np.ndarray, names: list[str]):\n",
    "    \"\"\"\n",
    "    按名字前缀分组，统计每组：\n",
    "      - 原始特征数（列数）\n",
    "      - 总值数（列数 × 行数）\n",
    "      - NaN 值数量\n",
    "      - ±Inf 值数量\n",
    "      - 非数值（non-finite）总数\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    meta  : np.ndarray, shape (n_samples, n_features)\n",
    "    names : list of str, length n_features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    stats : dict[prefix, dict]  \n",
    "        每个 prefix 对应一个字典，\n",
    "        包含 'n_feats','total_vals','n_nan','n_inf','n_nonfinite'。\n",
    "    \"\"\"\n",
    "    groups = defaultdict(list)\n",
    "    # 按前缀分组\n",
    "    for idx, nm in enumerate(names):\n",
    "        prefix = nm.split('_', 1)[0]\n",
    "        groups[prefix].append(idx)\n",
    "\n",
    "    stats = {}\n",
    "    for prefix, idxs in groups.items():\n",
    "        sub = meta[:, idxs]  # shape (n_samples, n_group_feats)\n",
    "        n_feats = sub.shape[1]\n",
    "        total_vals = sub.size\n",
    "        n_nan = np.isnan(sub).sum()\n",
    "        n_inf = np.isinf(sub).sum()\n",
    "        n_nonfinite = (~np.isfinite(sub)).sum()\n",
    "\n",
    "        stats[prefix] = {\n",
    "            'n_feats':        n_feats,\n",
    "            'total_vals':     total_vals,\n",
    "            'n_nan':          int(n_nan),\n",
    "            'n_inf':          int(n_inf),\n",
    "            'n_nonfinite':    int(n_nonfinite),\n",
    "        }\n",
    "        print(\n",
    "            f\"Group '{prefix}': \"\n",
    "            f\"features={n_feats}, \"\n",
    "            f\"values={total_vals}, \"\n",
    "            f\"non-finite={n_nonfinite} \"\n",
    "            f\"(nan={n_nan}, inf={n_inf})\"\n",
    "        )\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/pretrain_model.py:310: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ae.load_state_dict(torch.load(ae_checkpoint, map_location=\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import rankdata\n",
    "from python_scripts.import_data import importDataset\n",
    "from python_scripts.operate_model import predict\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from python_scripts.pretrain_model import PretrainedEncoderRegressor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# ---------------- Settings ----------------\n",
    "trained_oof_model_folder = 'output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/'\n",
    "n_folds    = len([d for d in os.listdir(trained_oof_model_folder) if d.startswith('fold')])\n",
    "n_samples  = len(full_dataset)\n",
    "C          = 35\n",
    "BATCH_SIZE = 64\n",
    "start_fold = 0\n",
    "\n",
    "tile_dim = 128\n",
    "center_dim = 128\n",
    "neighbor_dim = 128\n",
    "fusion_dim = tile_dim + center_dim + neighbor_dim\n",
    "META_EPOCHS = 200\n",
    "pretrained_ae_name = 'AE_Center_noaug'\n",
    "pretrained_ae_path = f\"AE_model/128/{pretrained_ae_name}/best.pt\"\n",
    "ae_type = 'center'\n",
    "\n",
    "# Ground truth label (全 dataset)\n",
    "y_true = np.vstack([ full_dataset[i]['label'].cpu().numpy() for i in range(n_samples) ])\n",
    "\n",
    "# Build CV splitter (must match first stage splits)\n",
    "logo = LeaveOneGroupOut()\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "class DeepResMLP(nn.Module):\n",
    "    def __init__(self, in_dim=2924, hidden_dims=[1024,512,256,128], out_dim=35):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = in_dim\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(prev, h))\n",
    "            layers.append(nn.LeakyReLU(0.01))\n",
    "            layers.append(nn.BatchNorm1d(h))\n",
    "            layers.append(nn.Dropout(0.2))\n",
    "            prev = h\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.head = nn.Linear(prev, out_dim)\n",
    "\n",
    "        # 残差桥：in_dim→first hidden\n",
    "        if in_dim != hidden_dims[0]:\n",
    "            self.res_proj = nn.Linear(in_dim, hidden_dims[0])\n",
    "        else:\n",
    "            self.res_proj = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B,2924], pred: [B,35]\n",
    "        # 残差桥接\n",
    "        res = self.res_proj(x)\n",
    "        h   = self.net[0:4](x)       # 第一段 linear→act→bn→drop\n",
    "        h  += res                    # add residual\n",
    "        h   = self.net[4:](h)        # 剩余层\n",
    "        delta = self.head(h)\n",
    "        return delta\n",
    "\n",
    "recon_model = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=pretrained_ae_path,\n",
    "        ae_type=ae_type,\n",
    "        tile_dim=tile_dim,\n",
    "        center_dim=center_dim,\n",
    "        neighbor_dim=neighbor_dim,\n",
    "        output_dim=C,\n",
    "        mode='reconstruction'\n",
    "    ).to(device)\n",
    "slide_idx = np.array(grouped_data['slide_idx'])   # shape (N,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per model per meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Starting fold 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌀 Starting augment for meta-train …\n",
      "🌀 Starting import sugmentation data …\n",
      "🌀 Starting prepare OOF data from CNN model…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|██████████| 110/110 [00:11<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "✅ Generated meta-features with shape: (7028, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=2698752, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=2698752, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=28112, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=84336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=84336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=84336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=21084, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=28112, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=1686720, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=253008, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=28112, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=253008, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=84336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=759024, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=56224, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=506016, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=3036096, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=245980, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=238952, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=955808, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=140560, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=70280, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=4181660, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=7028, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=70280, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=21084, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=14056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=14056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=14056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=14056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=14056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=21084, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=35140, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=231924, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=224896, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=238952, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=231924, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|██████████| 7/7 [00:01<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "✅ Generated meta-features with shape: (440, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=168960, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=168960, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=1760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=5280, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=5280, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=5280, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=1320, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=1760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=105600, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=15840, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=1760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=15840, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=5280, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=47520, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=3520, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=31680, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=190080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=15400, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=14960, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=59840, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=8800, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=4400, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=261800, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=4400, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=1320, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=1320, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=2200, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=14520, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=14080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=14960, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=14520, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold0 Ep1/300 — Train MSE: 405.319227, Val MSE: 376.475567, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=376.475567), saved.\n",
      "Fold0 Ep2/300 — Train MSE: 280.415148, Val MSE: 178.369030, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=178.369030), saved.\n",
      "Fold0 Ep3/300 — Train MSE: 105.109123, Val MSE: 61.640348, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=61.640348), saved.\n",
      "Fold0 Ep4/300 — Train MSE: 49.255349, Val MSE: 49.259682, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=49.259682), saved.\n",
      "Fold0 Ep5/300 — Train MSE: 43.230442, Val MSE: 46.381895, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=46.381895), saved.\n",
      "Fold0 Ep6/300 — Train MSE: 42.082382, Val MSE: 48.489742, LR: 1.000e-03\n",
      "Fold0 Ep7/300 — Train MSE: 41.195338, Val MSE: 47.441790, LR: 1.000e-03\n",
      "Fold0 Ep8/300 — Train MSE: 40.897712, Val MSE: 45.491223, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=45.491223), saved.\n",
      "Fold0 Ep9/300 — Train MSE: 40.880134, Val MSE: 51.667825, LR: 1.000e-03\n",
      "Fold0 Ep10/300 — Train MSE: 40.398880, Val MSE: 46.396107, LR: 1.000e-03\n",
      "Fold0 Ep11/300 — Train MSE: 40.101187, Val MSE: 46.773966, LR: 1.000e-03\n",
      "Fold0 Ep12/300 — Train MSE: 39.930151, Val MSE: 45.640308, LR: 1.000e-03\n",
      "Fold0 Ep13/300 — Train MSE: 39.608845, Val MSE: 45.346506, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=45.346506), saved.\n",
      "Fold0 Ep14/300 — Train MSE: 39.494031, Val MSE: 45.907021, LR: 1.000e-03\n",
      "Fold0 Ep15/300 — Train MSE: 39.330052, Val MSE: 49.723104, LR: 1.000e-03\n",
      "Fold0 Ep16/300 — Train MSE: 39.024838, Val MSE: 47.720655, LR: 1.000e-03\n",
      "Fold0 Ep17/300 — Train MSE: 38.784176, Val MSE: 45.065863, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=45.065863), saved.\n",
      "Fold0 Ep18/300 — Train MSE: 38.910426, Val MSE: 49.407554, LR: 1.000e-03\n",
      "Fold0 Ep19/300 — Train MSE: 38.583595, Val MSE: 50.397885, LR: 1.000e-03\n",
      "Fold0 Ep20/300 — Train MSE: 38.371988, Val MSE: 52.709611, LR: 1.000e-03\n",
      "Fold0 Ep21/300 — Train MSE: 38.300956, Val MSE: 49.894456, LR: 1.000e-03\n",
      "Fold0 Ep22/300 — Train MSE: 37.961221, Val MSE: 50.844868, LR: 1.000e-03\n",
      "Fold0 Ep23/300 — Train MSE: 37.981304, Val MSE: 50.313323, LR: 1.000e-03\n",
      "Fold0 Ep24/300 — Train MSE: 37.867215, Val MSE: 52.469640, LR: 1.000e-03\n",
      "Fold0 Ep25/300 — Train MSE: 37.693914, Val MSE: 51.589615, LR: 1.000e-03\n",
      "Fold0 Ep26/300 — Train MSE: 37.651686, Val MSE: 50.842696, LR: 1.000e-03\n",
      "Fold0 Ep27/300 — Train MSE: 37.508466, Val MSE: 50.492732, LR: 1.000e-03\n",
      "Fold0 Ep28/300 — Train MSE: 37.375742, Val MSE: 47.195586, LR: 1.000e-03\n",
      "Fold0 Ep29/300 — Train MSE: 36.958193, Val MSE: 43.744594, LR: 5.000e-04\n",
      " ↳ New best (Val MSE=43.744594), saved.\n",
      "Fold0 Ep30/300 — Train MSE: 36.866519, Val MSE: 49.685324, LR: 5.000e-04\n",
      "Fold0 Ep31/300 — Train MSE: 36.737219, Val MSE: 44.341621, LR: 5.000e-04\n",
      "Fold0 Ep32/300 — Train MSE: 36.579707, Val MSE: 50.794572, LR: 5.000e-04\n",
      "Fold0 Ep33/300 — Train MSE: 36.534792, Val MSE: 46.279443, LR: 5.000e-04\n",
      "Fold0 Ep34/300 — Train MSE: 36.405297, Val MSE: 50.018759, LR: 5.000e-04\n",
      "Fold0 Ep35/300 — Train MSE: 36.561252, Val MSE: 48.942155, LR: 5.000e-04\n",
      "Fold0 Ep36/300 — Train MSE: 36.501137, Val MSE: 47.366247, LR: 5.000e-04\n",
      "Fold0 Ep37/300 — Train MSE: 36.292902, Val MSE: 53.794445, LR: 5.000e-04\n",
      "Fold0 Ep38/300 — Train MSE: 36.357524, Val MSE: 52.488630, LR: 5.000e-04\n",
      "Fold0 Ep39/300 — Train MSE: 36.443787, Val MSE: 50.614902, LR: 5.000e-04\n",
      "Fold0 Ep40/300 — Train MSE: 36.246192, Val MSE: 52.302440, LR: 5.000e-04\n",
      "Fold0 Ep41/300 — Train MSE: 35.892152, Val MSE: 45.917374, LR: 2.500e-04\n",
      "Fold0 Ep42/300 — Train MSE: 36.123448, Val MSE: 54.411777, LR: 2.500e-04\n",
      "Fold0 Ep43/300 — Train MSE: 35.864206, Val MSE: 48.892520, LR: 2.500e-04\n",
      "Fold0 Ep44/300 — Train MSE: 35.823666, Val MSE: 52.323726, LR: 2.500e-04\n",
      "Fold0 Ep45/300 — Train MSE: 35.755195, Val MSE: 43.294001, LR: 2.500e-04\n",
      " ↳ New best (Val MSE=43.294001), saved.\n",
      "Fold0 Ep46/300 — Train MSE: 35.602497, Val MSE: 48.815548, LR: 2.500e-04\n",
      "Fold0 Ep47/300 — Train MSE: 35.668262, Val MSE: 54.944992, LR: 2.500e-04\n",
      "Fold0 Ep48/300 — Train MSE: 35.704222, Val MSE: 53.676334, LR: 2.500e-04\n",
      "Fold0 Ep49/300 — Train MSE: 35.597863, Val MSE: 53.268706, LR: 2.500e-04\n",
      "Fold0 Ep50/300 — Train MSE: 35.430098, Val MSE: 48.055054, LR: 2.500e-04\n",
      "Fold0 Ep51/300 — Train MSE: 35.369013, Val MSE: 47.576341, LR: 2.500e-04\n",
      "Fold0 Ep52/300 — Train MSE: 35.745857, Val MSE: 47.032979, LR: 2.500e-04\n",
      "Fold0 Ep53/300 — Train MSE: 35.441309, Val MSE: 54.629879, LR: 2.500e-04\n",
      "Fold0 Ep54/300 — Train MSE: 35.527669, Val MSE: 48.974638, LR: 2.500e-04\n",
      "Fold0 Ep55/300 — Train MSE: 35.400101, Val MSE: 51.540281, LR: 2.500e-04\n",
      "Fold0 Ep56/300 — Train MSE: 35.498605, Val MSE: 49.687128, LR: 2.500e-04\n",
      "Fold0 Ep57/300 — Train MSE: 35.227183, Val MSE: 48.977504, LR: 1.250e-04\n",
      "Fold0 Ep58/300 — Train MSE: 35.120743, Val MSE: 49.892163, LR: 1.250e-04\n",
      "Fold0 Ep59/300 — Train MSE: 35.145186, Val MSE: 53.374514, LR: 1.250e-04\n",
      "Fold0 Ep60/300 — Train MSE: 35.169835, Val MSE: 49.190033, LR: 1.250e-04\n",
      "Fold0 Ep61/300 — Train MSE: 35.139409, Val MSE: 51.825118, LR: 1.250e-04\n",
      "Fold0 Ep62/300 — Train MSE: 35.119523, Val MSE: 44.992703, LR: 1.250e-04\n",
      "Fold0 Ep63/300 — Train MSE: 35.197860, Val MSE: 52.696260, LR: 1.250e-04\n",
      "Fold0 Ep64/300 — Train MSE: 35.039997, Val MSE: 52.205661, LR: 1.250e-04\n",
      "Fold0 Ep65/300 — Train MSE: 35.043685, Val MSE: 51.613230, LR: 1.250e-04\n",
      " ✋ Early stopping (no improvement in 20 epochs).\n",
      " Fold0 Best refined Val MSE: 43.294003\n",
      " ✅ Best meta-model saved to: output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/fold0/meta_model_best.pt\n",
      "\n",
      "🚀 Starting fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:188: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(best_path, map_location=device))\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌀 Starting augment for meta-train …\n",
      "🌀 Starting import sugmentation data …\n",
      "🌀 Starting prepare OOF data from CNN model…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|██████████| 114/114 [00:14<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "✅ Generated meta-features with shape: (7260, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=2787840, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=2787840, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=29040, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=87120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=87120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=87120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=21780, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=29040, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=1742400, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=261360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=29040, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=261360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=87120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=784080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=58080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=522720, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=3136320, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=254100, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=246840, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=987360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=145200, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=72600, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=4319700, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=7260, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=72600, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=21780, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=14520, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=14520, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=14520, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=14520, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=14520, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=21780, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=36300, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=239580, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=232320, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=246840, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=239580, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|██████████| 8/8 [00:01<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "✅ Generated meta-features with shape: (454, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=174336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=174336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=1816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=5448, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=5448, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=5448, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=1362, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=1816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=108960, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=16344, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=1816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=16344, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=5448, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=49032, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=3632, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=32688, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=196128, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=15890, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=15436, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=61744, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=9080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=4540, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=270130, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=454, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=4540, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=1362, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=908, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=908, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=908, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=908, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=908, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=1362, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=2270, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=14982, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=14528, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=15436, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=14982, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold1 Ep1/300 — Train MSE: 411.042008, Val MSE: 377.315096, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=377.315096), saved.\n",
      "Fold1 Ep2/300 — Train MSE: 270.428721, Val MSE: 162.301475, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=162.301475), saved.\n",
      "Fold1 Ep3/300 — Train MSE: 90.509911, Val MSE: 47.384867, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=47.384867), saved.\n",
      "Fold1 Ep4/300 — Train MSE: 36.676492, Val MSE: 28.724335, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=28.724335), saved.\n",
      "Fold1 Ep5/300 — Train MSE: 29.649644, Val MSE: 27.953990, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=27.953990), saved.\n",
      "Fold1 Ep6/300 — Train MSE: 28.837453, Val MSE: 28.143556, LR: 1.000e-03\n",
      "Fold1 Ep7/300 — Train MSE: 28.451967, Val MSE: 28.259422, LR: 1.000e-03\n",
      "Fold1 Ep8/300 — Train MSE: 27.967031, Val MSE: 28.058649, LR: 1.000e-03\n",
      "Fold1 Ep9/300 — Train MSE: 27.670166, Val MSE: 28.164841, LR: 1.000e-03\n",
      "Fold1 Ep10/300 — Train MSE: 27.576628, Val MSE: 28.310839, LR: 1.000e-03\n",
      "Fold1 Ep11/300 — Train MSE: 27.387788, Val MSE: 28.470198, LR: 1.000e-03\n",
      "Fold1 Ep12/300 — Train MSE: 27.163057, Val MSE: 28.600309, LR: 1.000e-03\n",
      "Fold1 Ep13/300 — Train MSE: 26.896851, Val MSE: 28.556160, LR: 1.000e-03\n",
      "Fold1 Ep14/300 — Train MSE: 26.853828, Val MSE: 28.628547, LR: 1.000e-03\n",
      "Fold1 Ep15/300 — Train MSE: 26.793772, Val MSE: 28.598091, LR: 1.000e-03\n",
      "Fold1 Ep16/300 — Train MSE: 26.377228, Val MSE: 28.451778, LR: 1.000e-03\n",
      "Fold1 Ep17/300 — Train MSE: 26.101742, Val MSE: 28.750539, LR: 5.000e-04\n",
      "Fold1 Ep18/300 — Train MSE: 26.030771, Val MSE: 28.651863, LR: 5.000e-04\n",
      "Fold1 Ep19/300 — Train MSE: 25.860380, Val MSE: 28.482608, LR: 5.000e-04\n",
      "Fold1 Ep20/300 — Train MSE: 25.912880, Val MSE: 28.445969, LR: 5.000e-04\n",
      "Fold1 Ep21/300 — Train MSE: 25.817350, Val MSE: 28.597558, LR: 5.000e-04\n",
      "Fold1 Ep22/300 — Train MSE: 25.656372, Val MSE: 28.750928, LR: 5.000e-04\n",
      "Fold1 Ep23/300 — Train MSE: 25.630006, Val MSE: 28.639473, LR: 5.000e-04\n",
      "Fold1 Ep24/300 — Train MSE: 25.599515, Val MSE: 28.778249, LR: 5.000e-04\n",
      "Fold1 Ep25/300 — Train MSE: 25.447414, Val MSE: 28.848934, LR: 5.000e-04\n",
      " ✋ Early stopping (no improvement in 20 epochs).\n",
      " Fold1 Best refined Val MSE: 27.953989\n",
      " ✅ Best meta-model saved to: output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/fold1/meta_model_best.pt\n",
      "\n",
      "🚀 Starting fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:188: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(best_path, map_location=device))\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌀 Starting augment for meta-train …\n",
      "🌀 Starting import sugmentation data …\n",
      "🌀 Starting prepare OOF data from CNN model…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|██████████| 35/35 [00:05<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "✅ Generated meta-features with shape: (2208, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=847872, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=847872, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=8832, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=26496, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=26496, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=26496, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=6624, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=8832, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=529920, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=79488, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=8832, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=79488, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=26496, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=238464, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=17664, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=158976, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=953856, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=77280, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=75072, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=300288, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=44160, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=22080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=1313760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=2208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=22080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=6624, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=4416, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=4416, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=4416, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=4416, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=4416, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=6624, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=11040, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=72864, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=70656, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=75072, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=72864, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|██████████| 3/3 [00:00<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "✅ Generated meta-features with shape: (138, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=52992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=52992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=552, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=1656, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=1656, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=1656, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=414, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=552, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=33120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=4968, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=552, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=4968, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=1656, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=14904, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=1104, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=9936, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=59616, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=4830, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=4692, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=18768, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=2760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=1380, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=82110, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=138, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=1380, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=414, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=276, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=276, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=276, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=276, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=276, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=414, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=690, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=4554, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=4416, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=4692, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=4554, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold2 Ep1/300 — Train MSE: 424.875498, Val MSE: 427.288564, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=427.288564), saved.\n",
      "Fold2 Ep2/300 — Train MSE: 418.162374, Val MSE: 413.792458, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=413.792458), saved.\n",
      "Fold2 Ep3/300 — Train MSE: 400.164258, Val MSE: 381.396480, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=381.396480), saved.\n",
      "Fold2 Ep4/300 — Train MSE: 361.391283, Val MSE: 327.860761, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=327.860761), saved.\n",
      "Fold2 Ep5/300 — Train MSE: 303.020588, Val MSE: 264.346616, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=264.346616), saved.\n",
      "Fold2 Ep6/300 — Train MSE: 234.182586, Val MSE: 194.364886, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=194.364886), saved.\n",
      "Fold2 Ep7/300 — Train MSE: 168.792973, Val MSE: 132.308159, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=132.308159), saved.\n",
      "Fold2 Ep8/300 — Train MSE: 117.709889, Val MSE: 94.294266, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=94.294266), saved.\n",
      "Fold2 Ep9/300 — Train MSE: 83.275832, Val MSE: 68.708540, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=68.708540), saved.\n",
      "Fold2 Ep10/300 — Train MSE: 64.788436, Val MSE: 58.131957, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=58.131957), saved.\n",
      "Fold2 Ep11/300 — Train MSE: 54.239899, Val MSE: 51.936070, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=51.936070), saved.\n",
      "Fold2 Ep12/300 — Train MSE: 49.628157, Val MSE: 48.509708, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=48.509708), saved.\n",
      "Fold2 Ep13/300 — Train MSE: 47.386861, Val MSE: 46.928259, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=46.928259), saved.\n",
      "Fold2 Ep14/300 — Train MSE: 45.894676, Val MSE: 46.518743, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=46.518743), saved.\n",
      "Fold2 Ep15/300 — Train MSE: 45.121596, Val MSE: 46.187482, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=46.187482), saved.\n",
      "Fold2 Ep16/300 — Train MSE: 44.902827, Val MSE: 46.378176, LR: 1.000e-03\n",
      "Fold2 Ep17/300 — Train MSE: 44.676546, Val MSE: 46.273215, LR: 1.000e-03\n",
      "Fold2 Ep18/300 — Train MSE: 43.903616, Val MSE: 46.463146, LR: 1.000e-03\n",
      "Fold2 Ep19/300 — Train MSE: 44.049502, Val MSE: 45.994685, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=45.994685), saved.\n",
      "Fold2 Ep20/300 — Train MSE: 43.603109, Val MSE: 46.028984, LR: 1.000e-03\n",
      "Fold2 Ep21/300 — Train MSE: 43.775828, Val MSE: 46.435926, LR: 1.000e-03\n",
      "Fold2 Ep22/300 — Train MSE: 43.394034, Val MSE: 46.127649, LR: 1.000e-03\n",
      "Fold2 Ep23/300 — Train MSE: 42.798663, Val MSE: 45.857443, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=45.857443), saved.\n",
      "Fold2 Ep24/300 — Train MSE: 42.694682, Val MSE: 46.427903, LR: 1.000e-03\n",
      "Fold2 Ep25/300 — Train MSE: 42.659454, Val MSE: 46.028267, LR: 1.000e-03\n",
      "Fold2 Ep26/300 — Train MSE: 42.769704, Val MSE: 46.497959, LR: 1.000e-03\n",
      "Fold2 Ep27/300 — Train MSE: 42.281291, Val MSE: 48.150977, LR: 1.000e-03\n",
      "Fold2 Ep28/300 — Train MSE: 42.346550, Val MSE: 45.929196, LR: 1.000e-03\n",
      "Fold2 Ep29/300 — Train MSE: 42.164451, Val MSE: 47.086855, LR: 1.000e-03\n",
      "Fold2 Ep30/300 — Train MSE: 41.880451, Val MSE: 47.066406, LR: 1.000e-03\n",
      "Fold2 Ep31/300 — Train MSE: 41.859239, Val MSE: 46.816890, LR: 1.000e-03\n",
      "Fold2 Ep32/300 — Train MSE: 41.555791, Val MSE: 46.379677, LR: 1.000e-03\n",
      "Fold2 Ep33/300 — Train MSE: 41.442438, Val MSE: 46.311901, LR: 1.000e-03\n",
      "Fold2 Ep34/300 — Train MSE: 41.544877, Val MSE: 47.976716, LR: 1.000e-03\n",
      "Fold2 Ep35/300 — Train MSE: 40.547852, Val MSE: 47.024681, LR: 5.000e-04\n",
      "Fold2 Ep36/300 — Train MSE: 40.459399, Val MSE: 46.901689, LR: 5.000e-04\n",
      "Fold2 Ep37/300 — Train MSE: 40.528673, Val MSE: 47.895556, LR: 5.000e-04\n",
      "Fold2 Ep38/300 — Train MSE: 40.280126, Val MSE: 48.001307, LR: 5.000e-04\n",
      "Fold2 Ep39/300 — Train MSE: 39.883475, Val MSE: 49.401630, LR: 5.000e-04\n",
      "Fold2 Ep40/300 — Train MSE: 40.210061, Val MSE: 49.231385, LR: 5.000e-04\n",
      "Fold2 Ep41/300 — Train MSE: 40.104034, Val MSE: 50.426502, LR: 5.000e-04\n",
      "Fold2 Ep42/300 — Train MSE: 39.558352, Val MSE: 47.736127, LR: 5.000e-04\n",
      "Fold2 Ep43/300 — Train MSE: 39.582572, Val MSE: 49.392728, LR: 5.000e-04\n",
      " ✋ Early stopping (no improvement in 20 epochs).\n",
      " Fold2 Best refined Val MSE: 45.857441\n",
      " ✅ Best meta-model saved to: output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/fold2/meta_model_best.pt\n",
      "\n",
      "🚀 Starting fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:188: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(best_path, map_location=device))\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌀 Starting augment for meta-train …\n",
      "🌀 Starting import sugmentation data …\n",
      "🌀 Starting prepare OOF data from CNN model…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|██████████| 60/60 [00:09<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "✅ Generated meta-features with shape: (3796, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=1457664, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=1457664, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=15184, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=45552, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=45552, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=45552, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=11388, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=15184, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=911040, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=136656, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=15184, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=136656, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=45552, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=409968, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=30368, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=273312, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=1639872, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=132860, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=129064, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=516256, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=75920, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=37960, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=2258620, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=3796, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=37960, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=11388, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=7592, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=7592, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=7592, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=7592, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=7592, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=11388, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=18980, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=125268, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=121472, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=129064, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=125268, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|██████████| 4/4 [00:01<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "✅ Generated meta-features with shape: (238, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=91392, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=91392, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=952, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=2856, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=2856, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=2856, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=714, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=952, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=57120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=8568, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=952, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=8568, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=2856, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=25704, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=1904, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=17136, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=102816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=8330, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=8092, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=32368, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=4760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=2380, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=141610, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=238, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=2380, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=714, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=476, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=476, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=476, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=476, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=476, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=714, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=1190, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=7854, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=7616, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=8092, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=7854, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold3 Ep1/300 — Train MSE: 418.914582, Val MSE: 407.213725, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=407.213725), saved.\n",
      "Fold3 Ep2/300 — Train MSE: 388.166473, Val MSE: 364.770517, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=364.770517), saved.\n",
      "Fold3 Ep3/300 — Train MSE: 311.646583, Val MSE: 262.454061, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=262.454061), saved.\n",
      "Fold3 Ep4/300 — Train MSE: 200.667073, Val MSE: 152.127018, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=152.127018), saved.\n",
      "Fold3 Ep5/300 — Train MSE: 112.136992, Val MSE: 88.034260, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=88.034260), saved.\n",
      "Fold3 Ep6/300 — Train MSE: 70.441844, Val MSE: 66.564086, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=66.564086), saved.\n",
      "Fold3 Ep7/300 — Train MSE: 58.056061, Val MSE: 67.834291, LR: 1.000e-03\n",
      "Fold3 Ep8/300 — Train MSE: 54.285114, Val MSE: 70.151232, LR: 1.000e-03\n",
      "Fold3 Ep9/300 — Train MSE: 53.548904, Val MSE: 67.810923, LR: 1.000e-03\n",
      "Fold3 Ep10/300 — Train MSE: 52.242772, Val MSE: 66.898035, LR: 1.000e-03\n",
      "Fold3 Ep11/300 — Train MSE: 51.621427, Val MSE: 63.205798, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=63.205798), saved.\n",
      "Fold3 Ep12/300 — Train MSE: 51.266704, Val MSE: 68.662003, LR: 1.000e-03\n",
      "Fold3 Ep13/300 — Train MSE: 50.334560, Val MSE: 68.598503, LR: 1.000e-03\n",
      "Fold3 Ep14/300 — Train MSE: 50.167292, Val MSE: 65.792184, LR: 1.000e-03\n",
      "Fold3 Ep15/300 — Train MSE: 49.478996, Val MSE: 71.021994, LR: 1.000e-03\n",
      "Fold3 Ep16/300 — Train MSE: 49.200998, Val MSE: 56.394203, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=56.394203), saved.\n",
      "Fold3 Ep17/300 — Train MSE: 48.504752, Val MSE: 66.348260, LR: 1.000e-03\n",
      "Fold3 Ep18/300 — Train MSE: 48.171194, Val MSE: 63.536637, LR: 1.000e-03\n",
      "Fold3 Ep19/300 — Train MSE: 48.517898, Val MSE: 71.900948, LR: 1.000e-03\n",
      "Fold3 Ep20/300 — Train MSE: 47.890244, Val MSE: 62.327182, LR: 1.000e-03\n",
      "Fold3 Ep21/300 — Train MSE: 47.648704, Val MSE: 62.223015, LR: 1.000e-03\n",
      "Fold3 Ep22/300 — Train MSE: 47.001265, Val MSE: 72.185787, LR: 1.000e-03\n",
      "Fold3 Ep23/300 — Train MSE: 47.127606, Val MSE: 61.171279, LR: 1.000e-03\n",
      "Fold3 Ep24/300 — Train MSE: 46.247573, Val MSE: 65.523059, LR: 1.000e-03\n",
      "Fold3 Ep25/300 — Train MSE: 45.804270, Val MSE: 70.512276, LR: 1.000e-03\n",
      "Fold3 Ep26/300 — Train MSE: 45.565318, Val MSE: 66.672635, LR: 1.000e-03\n",
      "Fold3 Ep27/300 — Train MSE: 45.666906, Val MSE: 51.745638, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=51.745638), saved.\n",
      "Fold3 Ep28/300 — Train MSE: 44.803730, Val MSE: 59.582771, LR: 1.000e-03\n",
      "Fold3 Ep29/300 — Train MSE: 44.698656, Val MSE: 67.524565, LR: 1.000e-03\n",
      "Fold3 Ep30/300 — Train MSE: 44.627138, Val MSE: 65.503809, LR: 1.000e-03\n",
      "Fold3 Ep31/300 — Train MSE: 44.612091, Val MSE: 67.634552, LR: 1.000e-03\n",
      "Fold3 Ep32/300 — Train MSE: 44.406499, Val MSE: 73.348730, LR: 1.000e-03\n",
      "Fold3 Ep33/300 — Train MSE: 43.855632, Val MSE: 68.923670, LR: 1.000e-03\n",
      "Fold3 Ep34/300 — Train MSE: 43.590181, Val MSE: 61.308837, LR: 1.000e-03\n",
      "Fold3 Ep35/300 — Train MSE: 43.975198, Val MSE: 59.359619, LR: 1.000e-03\n",
      "Fold3 Ep36/300 — Train MSE: 43.452924, Val MSE: 59.839339, LR: 1.000e-03\n",
      "Fold3 Ep37/300 — Train MSE: 43.552299, Val MSE: 54.984222, LR: 1.000e-03\n",
      "Fold3 Ep38/300 — Train MSE: 42.925046, Val MSE: 71.109993, LR: 1.000e-03\n",
      "Fold3 Ep39/300 — Train MSE: 41.847091, Val MSE: 73.152669, LR: 5.000e-04\n",
      "Fold3 Ep40/300 — Train MSE: 41.339319, Val MSE: 66.738403, LR: 5.000e-04\n",
      "Fold3 Ep41/300 — Train MSE: 41.005446, Val MSE: 68.546319, LR: 5.000e-04\n",
      "Fold3 Ep42/300 — Train MSE: 40.986274, Val MSE: 65.481867, LR: 5.000e-04\n",
      "Fold3 Ep43/300 — Train MSE: 40.596775, Val MSE: 60.233104, LR: 5.000e-04\n",
      "Fold3 Ep44/300 — Train MSE: 40.604684, Val MSE: 62.200803, LR: 5.000e-04\n",
      "Fold3 Ep45/300 — Train MSE: 40.866799, Val MSE: 54.884036, LR: 5.000e-04\n",
      "Fold3 Ep46/300 — Train MSE: 40.626732, Val MSE: 69.797407, LR: 5.000e-04\n",
      "Fold3 Ep47/300 — Train MSE: 40.387554, Val MSE: 63.585453, LR: 5.000e-04\n",
      " ✋ Early stopping (no improvement in 20 epochs).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:188: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(best_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fold3 Best refined Val MSE: 51.745636\n",
      " ✅ Best meta-model saved to: output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/fold3/meta_model_best.pt\n",
      "\n",
      "🚀 Starting fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌀 Starting augment for meta-train …\n",
      "🌀 Starting import sugmentation data …\n",
      "🌀 Starting prepare OOF data from CNN model…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|██████████| 84/84 [00:14<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "✅ Generated meta-features with shape: (5364, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=2059776, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=2059776, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=21456, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=64368, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=64368, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=64368, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=16092, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=21456, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=1287360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=193104, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=21456, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=193104, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=64368, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=579312, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=42912, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=386208, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=2317248, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=187740, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=182376, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=729504, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=107280, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=53640, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=3191580, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=5364, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=53640, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=16092, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=10728, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=10728, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=10728, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=10728, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=10728, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=16092, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=26820, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=177012, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=171648, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=182376, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=177012, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|██████████| 6/6 [00:01<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "✅ Generated meta-features with shape: (336, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=129024, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=129024, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=1344, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=4032, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=4032, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=4032, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=1008, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=1344, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=80640, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=12096, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=1344, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=12096, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=4032, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=36288, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=2688, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=24192, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=145152, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=11760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=11424, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=45696, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=6720, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=3360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=199920, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=3360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=1008, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=672, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=672, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=672, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=672, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=672, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=1008, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=1680, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=11088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=10752, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=11424, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=11088, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold4 Ep1/300 — Train MSE: 409.448090, Val MSE: 395.539264, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=395.539264), saved.\n",
      "Fold4 Ep2/300 — Train MSE: 345.559379, Val MSE: 277.021697, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=277.021697), saved.\n",
      "Fold4 Ep3/300 — Train MSE: 199.972403, Val MSE: 129.048939, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=129.048939), saved.\n",
      "Fold4 Ep4/300 — Train MSE: 88.795603, Val MSE: 56.900571, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=56.900571), saved.\n",
      "Fold4 Ep5/300 — Train MSE: 55.122899, Val MSE: 45.398594, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=45.398594), saved.\n",
      "Fold4 Ep6/300 — Train MSE: 49.904167, Val MSE: 44.283881, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=44.283881), saved.\n",
      "Fold4 Ep7/300 — Train MSE: 49.051342, Val MSE: 45.661766, LR: 1.000e-03\n",
      "Fold4 Ep8/300 — Train MSE: 48.755924, Val MSE: 48.140233, LR: 1.000e-03\n",
      "Fold4 Ep9/300 — Train MSE: 47.674203, Val MSE: 45.336952, LR: 1.000e-03\n",
      "Fold4 Ep10/300 — Train MSE: 47.661655, Val MSE: 50.403617, LR: 1.000e-03\n",
      "Fold4 Ep11/300 — Train MSE: 47.548027, Val MSE: 42.708090, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=42.708090), saved.\n",
      "Fold4 Ep12/300 — Train MSE: 46.718539, Val MSE: 45.491461, LR: 1.000e-03\n",
      "Fold4 Ep13/300 — Train MSE: 46.624525, Val MSE: 44.186682, LR: 1.000e-03\n",
      "Fold4 Ep14/300 — Train MSE: 46.112642, Val MSE: 46.216586, LR: 1.000e-03\n",
      "Fold4 Ep15/300 — Train MSE: 45.925780, Val MSE: 44.511060, LR: 1.000e-03\n",
      "Fold4 Ep16/300 — Train MSE: 45.790436, Val MSE: 47.316565, LR: 1.000e-03\n",
      "Fold4 Ep17/300 — Train MSE: 45.405570, Val MSE: 43.498940, LR: 1.000e-03\n",
      "Fold4 Ep18/300 — Train MSE: 45.211189, Val MSE: 47.853256, LR: 1.000e-03\n",
      "Fold4 Ep19/300 — Train MSE: 44.834048, Val MSE: 43.995840, LR: 1.000e-03\n",
      "Fold4 Ep20/300 — Train MSE: 45.007419, Val MSE: 45.585430, LR: 1.000e-03\n",
      "Fold4 Ep21/300 — Train MSE: 44.938082, Val MSE: 47.617001, LR: 1.000e-03\n",
      "Fold4 Ep22/300 — Train MSE: 44.746034, Val MSE: 42.392197, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=42.392197), saved.\n",
      "Fold4 Ep23/300 — Train MSE: 44.245796, Val MSE: 43.056427, LR: 1.000e-03\n",
      "Fold4 Ep24/300 — Train MSE: 44.241345, Val MSE: 41.440230, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=41.440230), saved.\n",
      "Fold4 Ep25/300 — Train MSE: 44.270781, Val MSE: 44.099629, LR: 1.000e-03\n",
      "Fold4 Ep26/300 — Train MSE: 44.221465, Val MSE: 41.929747, LR: 1.000e-03\n",
      "Fold4 Ep27/300 — Train MSE: 43.841376, Val MSE: 42.511040, LR: 1.000e-03\n",
      "Fold4 Ep28/300 — Train MSE: 43.792541, Val MSE: 42.267121, LR: 1.000e-03\n",
      "Fold4 Ep29/300 — Train MSE: 44.087381, Val MSE: 45.450030, LR: 1.000e-03\n",
      "Fold4 Ep30/300 — Train MSE: 43.670755, Val MSE: 44.017559, LR: 1.000e-03\n",
      "Fold4 Ep31/300 — Train MSE: 43.440652, Val MSE: 42.001779, LR: 1.000e-03\n",
      "Fold4 Ep32/300 — Train MSE: 43.494934, Val MSE: 46.674875, LR: 1.000e-03\n",
      "Fold4 Ep33/300 — Train MSE: 43.251238, Val MSE: 47.350958, LR: 1.000e-03\n",
      "Fold4 Ep34/300 — Train MSE: 43.412827, Val MSE: 41.442958, LR: 1.000e-03\n",
      "Fold4 Ep35/300 — Train MSE: 43.110215, Val MSE: 45.471550, LR: 1.000e-03\n",
      "Fold4 Ep36/300 — Train MSE: 42.754860, Val MSE: 44.682872, LR: 5.000e-04\n",
      "Fold4 Ep37/300 — Train MSE: 42.755917, Val MSE: 41.337475, LR: 5.000e-04\n",
      " ↳ New best (Val MSE=41.337475), saved.\n",
      "Fold4 Ep38/300 — Train MSE: 42.724316, Val MSE: 42.405546, LR: 5.000e-04\n",
      "Fold4 Ep39/300 — Train MSE: 42.335950, Val MSE: 50.015306, LR: 5.000e-04\n",
      "Fold4 Ep40/300 — Train MSE: 42.568137, Val MSE: 41.391528, LR: 5.000e-04\n",
      "Fold4 Ep41/300 — Train MSE: 42.410700, Val MSE: 41.998839, LR: 5.000e-04\n",
      "Fold4 Ep42/300 — Train MSE: 41.945809, Val MSE: 41.596850, LR: 5.000e-04\n",
      "Fold4 Ep43/300 — Train MSE: 41.998798, Val MSE: 42.903039, LR: 5.000e-04\n",
      "Fold4 Ep44/300 — Train MSE: 42.034206, Val MSE: 43.122507, LR: 5.000e-04\n",
      "Fold4 Ep45/300 — Train MSE: 42.078937, Val MSE: 42.497092, LR: 5.000e-04\n",
      "Fold4 Ep46/300 — Train MSE: 41.865907, Val MSE: 41.685402, LR: 5.000e-04\n",
      "Fold4 Ep47/300 — Train MSE: 41.591963, Val MSE: 43.484322, LR: 5.000e-04\n",
      "Fold4 Ep48/300 — Train MSE: 42.327339, Val MSE: 42.827129, LR: 5.000e-04\n",
      "Fold4 Ep49/300 — Train MSE: 41.667126, Val MSE: 44.423568, LR: 2.500e-04\n",
      "Fold4 Ep50/300 — Train MSE: 41.427533, Val MSE: 42.306470, LR: 2.500e-04\n",
      "Fold4 Ep51/300 — Train MSE: 41.231605, Val MSE: 42.886311, LR: 2.500e-04\n",
      "Fold4 Ep52/300 — Train MSE: 41.348396, Val MSE: 43.220040, LR: 2.500e-04\n",
      "Fold4 Ep53/300 — Train MSE: 41.341356, Val MSE: 41.898339, LR: 2.500e-04\n",
      "Fold4 Ep54/300 — Train MSE: 41.129715, Val MSE: 46.493506, LR: 2.500e-04\n",
      "Fold4 Ep55/300 — Train MSE: 41.242563, Val MSE: 41.915489, LR: 2.500e-04\n",
      "Fold4 Ep56/300 — Train MSE: 40.961758, Val MSE: 42.742700, LR: 2.500e-04\n",
      "Fold4 Ep57/300 — Train MSE: 41.092153, Val MSE: 41.926985, LR: 2.500e-04\n",
      " ✋ Early stopping (no improvement in 20 epochs).\n",
      " Fold4 Best refined Val MSE: 41.337475\n",
      " ✅ Best meta-model saved to: output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/fold4/meta_model_best.pt\n",
      "\n",
      "🚀 Starting fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:188: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(best_path, map_location=device))\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:54: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌀 Starting augment for meta-train …\n",
      "🌀 Starting import sugmentation data …\n",
      "🌀 Starting prepare OOF data from CNN model…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|██████████| 17/17 [00:02<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "✅ Generated meta-features with shape: (1048, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=402432, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=402432, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=4192, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=12576, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=12576, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=12576, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=3144, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=4192, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=251520, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=37728, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=4192, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=37728, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=12576, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=113184, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=8384, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=75456, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=452736, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=36680, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=35632, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=142528, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=20960, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=10480, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=623560, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=1048, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=10480, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=3144, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=2096, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=2096, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=2096, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=2096, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=2096, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=3144, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=5240, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=34584, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=33536, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=35632, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=34584, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|██████████| 2/2 [00:00<00:00,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "✅ Generated meta-features with shape: (66, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=25344, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=25344, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=198, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=15840, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=2376, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=2376, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=7128, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=528, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=4752, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=28512, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=2310, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=2244, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=8976, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=1320, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=660, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=39270, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=66, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=660, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=198, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=132, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=132, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=132, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=132, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=132, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=198, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=330, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=2178, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=2112, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=2244, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=2178, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold5 Ep1/300 — Train MSE: 424.029936, Val MSE: 420.461090, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=420.461090), saved.\n",
      "Fold5 Ep2/300 — Train MSE: 419.462858, Val MSE: 419.982905, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=419.982905), saved.\n",
      "Fold5 Ep3/300 — Train MSE: 415.673991, Val MSE: 416.259880, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=416.259880), saved.\n",
      "Fold5 Ep4/300 — Train MSE: 410.761667, Val MSE: 405.759045, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=405.759045), saved.\n",
      "Fold5 Ep5/300 — Train MSE: 403.037614, Val MSE: 398.261005, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=398.261005), saved.\n",
      "Fold5 Ep6/300 — Train MSE: 391.263614, Val MSE: 388.079122, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=388.079122), saved.\n",
      "Fold5 Ep7/300 — Train MSE: 373.915523, Val MSE: 364.999288, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=364.999288), saved.\n",
      "Fold5 Ep8/300 — Train MSE: 351.082631, Val MSE: 332.308534, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=332.308534), saved.\n",
      "Fold5 Ep9/300 — Train MSE: 322.790691, Val MSE: 316.812773, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=316.812773), saved.\n",
      "Fold5 Ep10/300 — Train MSE: 292.322911, Val MSE: 278.999089, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=278.999089), saved.\n",
      "Fold5 Ep11/300 — Train MSE: 259.601216, Val MSE: 242.574106, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=242.574106), saved.\n",
      "Fold5 Ep12/300 — Train MSE: 227.441769, Val MSE: 212.539421, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=212.539421), saved.\n",
      "Fold5 Ep13/300 — Train MSE: 192.878903, Val MSE: 179.482289, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=179.482289), saved.\n",
      "Fold5 Ep14/300 — Train MSE: 161.182095, Val MSE: 145.876482, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=145.876482), saved.\n",
      "Fold5 Ep15/300 — Train MSE: 132.346726, Val MSE: 117.752209, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=117.752209), saved.\n",
      "Fold5 Ep16/300 — Train MSE: 110.675306, Val MSE: 100.025879, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=100.025879), saved.\n",
      "Fold5 Ep17/300 — Train MSE: 90.864666, Val MSE: 82.152054, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=82.152054), saved.\n",
      "Fold5 Ep18/300 — Train MSE: 74.963734, Val MSE: 68.027880, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=68.027880), saved.\n",
      "Fold5 Ep19/300 — Train MSE: 64.140707, Val MSE: 58.596362, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=58.596362), saved.\n",
      "Fold5 Ep20/300 — Train MSE: 55.368840, Val MSE: 48.805055, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=48.805055), saved.\n",
      "Fold5 Ep21/300 — Train MSE: 49.485498, Val MSE: 42.427496, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=42.427496), saved.\n",
      "Fold5 Ep22/300 — Train MSE: 45.021589, Val MSE: 39.848147, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=39.848147), saved.\n",
      "Fold5 Ep23/300 — Train MSE: 41.973190, Val MSE: 36.118574, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=36.118574), saved.\n",
      "Fold5 Ep24/300 — Train MSE: 39.622190, Val MSE: 35.474343, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=35.474343), saved.\n",
      "Fold5 Ep25/300 — Train MSE: 38.270136, Val MSE: 34.356011, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=34.356011), saved.\n",
      "Fold5 Ep26/300 — Train MSE: 37.107678, Val MSE: 33.610533, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=33.610533), saved.\n",
      "Fold5 Ep27/300 — Train MSE: 36.815968, Val MSE: 33.455972, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=33.455972), saved.\n",
      "Fold5 Ep28/300 — Train MSE: 36.111271, Val MSE: 32.204584, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=32.204584), saved.\n",
      "Fold5 Ep29/300 — Train MSE: 35.569427, Val MSE: 31.864080, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=31.864080), saved.\n",
      "Fold5 Ep30/300 — Train MSE: 34.991967, Val MSE: 32.394126, LR: 1.000e-03\n",
      "Fold5 Ep31/300 — Train MSE: 34.702356, Val MSE: 32.726984, LR: 1.000e-03\n",
      "Fold5 Ep32/300 — Train MSE: 34.768515, Val MSE: 31.735618, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=31.735618), saved.\n",
      "Fold5 Ep33/300 — Train MSE: 34.171928, Val MSE: 32.154216, LR: 1.000e-03\n",
      "Fold5 Ep34/300 — Train MSE: 33.966447, Val MSE: 31.080109, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=31.080109), saved.\n",
      "Fold5 Ep35/300 — Train MSE: 33.813769, Val MSE: 30.809229, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=30.809229), saved.\n",
      "Fold5 Ep36/300 — Train MSE: 33.711851, Val MSE: 31.494389, LR: 1.000e-03\n",
      "Fold5 Ep37/300 — Train MSE: 33.486901, Val MSE: 30.423432, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=30.423432), saved.\n",
      "Fold5 Ep38/300 — Train MSE: 33.696105, Val MSE: 32.186568, LR: 1.000e-03\n",
      "Fold5 Ep39/300 — Train MSE: 33.271398, Val MSE: 32.187177, LR: 1.000e-03\n",
      "Fold5 Ep40/300 — Train MSE: 33.681951, Val MSE: 31.580488, LR: 1.000e-03\n",
      "Fold5 Ep41/300 — Train MSE: 33.446337, Val MSE: 34.577254, LR: 1.000e-03\n",
      "Fold5 Ep42/300 — Train MSE: 32.680286, Val MSE: 30.326364, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=30.326364), saved.\n",
      "Fold5 Ep43/300 — Train MSE: 33.055475, Val MSE: 31.249943, LR: 1.000e-03\n",
      "Fold5 Ep44/300 — Train MSE: 32.834428, Val MSE: 32.277401, LR: 1.000e-03\n",
      "Fold5 Ep45/300 — Train MSE: 32.814575, Val MSE: 31.345410, LR: 1.000e-03\n",
      "Fold5 Ep46/300 — Train MSE: 32.255961, Val MSE: 31.025013, LR: 1.000e-03\n",
      "Fold5 Ep47/300 — Train MSE: 32.506352, Val MSE: 32.166782, LR: 1.000e-03\n",
      "Fold5 Ep48/300 — Train MSE: 32.573378, Val MSE: 33.205173, LR: 1.000e-03\n",
      "Fold5 Ep49/300 — Train MSE: 32.146598, Val MSE: 30.597903, LR: 1.000e-03\n",
      "Fold5 Ep50/300 — Train MSE: 32.139849, Val MSE: 30.982569, LR: 1.000e-03\n",
      "Fold5 Ep51/300 — Train MSE: 32.453147, Val MSE: 31.411769, LR: 1.000e-03\n",
      "Fold5 Ep52/300 — Train MSE: 32.143404, Val MSE: 35.418867, LR: 1.000e-03\n",
      "Fold5 Ep53/300 — Train MSE: 31.576393, Val MSE: 30.053784, LR: 1.000e-03\n",
      " ↳ New best (Val MSE=30.053784), saved.\n",
      "Fold5 Ep54/300 — Train MSE: 32.090650, Val MSE: 33.829628, LR: 1.000e-03\n",
      "Fold5 Ep55/300 — Train MSE: 32.174108, Val MSE: 33.502847, LR: 1.000e-03\n",
      "Fold5 Ep56/300 — Train MSE: 31.613351, Val MSE: 31.365402, LR: 1.000e-03\n",
      "Fold5 Ep57/300 — Train MSE: 31.617901, Val MSE: 32.433196, LR: 1.000e-03\n",
      "Fold5 Ep58/300 — Train MSE: 31.426775, Val MSE: 30.175875, LR: 1.000e-03\n",
      "Fold5 Ep59/300 — Train MSE: 31.405470, Val MSE: 30.537172, LR: 1.000e-03\n",
      "Fold5 Ep60/300 — Train MSE: 30.926641, Val MSE: 31.698946, LR: 1.000e-03\n",
      "Fold5 Ep61/300 — Train MSE: 31.669958, Val MSE: 32.040487, LR: 1.000e-03\n",
      "Fold5 Ep62/300 — Train MSE: 31.115138, Val MSE: 33.930249, LR: 1.000e-03\n",
      "Fold5 Ep63/300 — Train MSE: 31.121071, Val MSE: 32.812684, LR: 1.000e-03\n",
      "Fold5 Ep64/300 — Train MSE: 30.688587, Val MSE: 30.498538, LR: 1.000e-03\n",
      "Fold5 Ep65/300 — Train MSE: 30.588210, Val MSE: 31.108165, LR: 5.000e-04\n",
      "Fold5 Ep66/300 — Train MSE: 30.458547, Val MSE: 30.863763, LR: 5.000e-04\n",
      "Fold5 Ep67/300 — Train MSE: 30.003309, Val MSE: 31.017948, LR: 5.000e-04\n",
      "Fold5 Ep68/300 — Train MSE: 30.048974, Val MSE: 31.516701, LR: 5.000e-04\n",
      "Fold5 Ep69/300 — Train MSE: 30.190342, Val MSE: 31.029204, LR: 5.000e-04\n",
      "Fold5 Ep70/300 — Train MSE: 29.995491, Val MSE: 31.999565, LR: 5.000e-04\n",
      "Fold5 Ep71/300 — Train MSE: 29.747059, Val MSE: 31.592111, LR: 5.000e-04\n",
      "Fold5 Ep72/300 — Train MSE: 29.574945, Val MSE: 30.633273, LR: 5.000e-04\n",
      "Fold5 Ep73/300 — Train MSE: 29.778231, Val MSE: 30.786776, LR: 5.000e-04\n",
      " ✋ Early stopping (no improvement in 20 epochs).\n",
      " Fold5 Best refined Val MSE: 30.053782\n",
      " ✅ Best meta-model saved to: output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/fold5/meta_model_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1561808793.py:188: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(best_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "META_EPOCHS = 300\n",
    "start_fold = 0\n",
    "repeats = 3\n",
    "from python_scripts.aug         import augment_grouped_data, identity, subset_grouped_data\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "def extract_feats_preds(loader, rank_preds=False):\n",
    "    all_latents, all_preds, all_labels = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            tiles    = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "            labels   = batch['label']                 # 假设 batch['label'] 在 cpu\n",
    "            center   = subtiles[:, 4].contiguous()\n",
    "\n",
    "            f_c  = net.encoder_center(center)\n",
    "            f_n  = net.encoder_subtile(subtiles)\n",
    "            f_t  = net.encoder_tile(tiles)\n",
    "            fuse = torch.cat([f_c, f_n, f_t], dim=1)\n",
    "\n",
    "            out  = net.decoder(fuse)\n",
    "\n",
    "            all_latents.append(fuse.cpu())\n",
    "            all_preds.append(out.cpu())\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    # cat & to numpy\n",
    "    latents = torch.cat(all_latents, dim=0).numpy()  # (N, D)\n",
    "    preds   = torch.cat(all_preds,   dim=0).numpy()  # (N, 35)\n",
    "    labs    = torch.cat(all_labels,  dim=0).numpy()  # (N, 35)\n",
    "\n",
    "    if rank_preds:\n",
    "        # 对每一行 row 做 rank，数值越大 rank 越大；最小的数 rank=1\n",
    "        # 注意：rankdata 默认 smallest→1, largest→N\n",
    "        # 如果你想让 largest→35, smallest→1，则：\n",
    "        ranks = np.apply_along_axis(lambda row: rankdata(row, method='ordinal'), 1, preds)\n",
    "        preds = ranks.astype(np.float32)\n",
    "\n",
    "    return latents, preds, labs\n",
    "# 在 loop 之前\n",
    "\n",
    "fold_mse = {}\n",
    "for fold_id, (tr_idx, va_idx) in enumerate(\n",
    "    logo.split(X=np.zeros(n_samples), y=None, groups=slide_idx)):\n",
    "\n",
    "    # if fold_id > start_fold:\n",
    "    #     print(f\"⏭️ Skipping fold {fold_id}\")\n",
    "    #     continue\n",
    "\n",
    "    print(f\"\\n🚀 Starting fold {fold_id}...\")\n",
    "    ckpt_path = os.path.join(trained_oof_model_folder, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "\n",
    "    # === Load model and predict OOF ===\n",
    "    net = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net = net.to(device).eval()\n",
    "\n",
    "\n",
    "    \n",
    "    local_idx = np.arange(len(va_idx))\n",
    "    train_loc, val_loc = train_test_split(\n",
    "        local_idx,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        shuffle=True\n",
    "    )\n",
    "    train_meta_idx = va_idx[train_loc]   # 真实的 global indices\n",
    "    val_meta_idx   = va_idx[val_loc]\n",
    "\n",
    "    # 2) 对 train_meta 做 augment\n",
    "    train_base = subset_grouped_data(grouped_data, train_meta_idx)\n",
    "    print(\"🌀 Starting augment for meta-train …\")\n",
    "    train_aug_ds = augment_grouped_data(\n",
    "        grouped_data=train_base,\n",
    "        image_keys=['tile','subtiles'],\n",
    "        repeats=repeats            # 你要的增强次数\n",
    "    )\n",
    "    print(\"🌀 Starting import sugmentation data …\")\n",
    "\n",
    "    train_dataset = importDataset(train_aug_ds, net,\n",
    "                                image_keys=['tile','subtiles'],\n",
    "                                transform=lambda x: x)\n",
    "    train_aug_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_base = subset_grouped_data(grouped_data, val_meta_idx)\n",
    "    val_dataset = importDataset(val_base, net,\n",
    "                             image_keys=['tile','subtiles'],\n",
    "                             transform=lambda x: x)\n",
    "    val_meta_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    print(\"🌀 Starting prepare OOF data from CNN model…\")\n",
    "    train_lat, train_pr, train_y = extract_feats_preds(train_aug_loader)\n",
    "    \n",
    "    val_lat,   val_pr,   val_y   = extract_feats_preds(val_meta_loader)\n",
    "\n",
    "    extra_train_feats, train_feat_names = generate_meta_features(\n",
    "        dataset=train_dataset,\n",
    "        model_for_recon=recon_model,      # 你的 AE 模型\n",
    "        device=device,\n",
    "        ae_type=ae_type,\n",
    "        oof_preds=train_pr,\n",
    "        latents=train_lat\n",
    "    )\n",
    "    diagnose_meta_nonfinite(extra_train_feats, train_feat_names)\n",
    "    extra_val_feats, val_feat_names = generate_meta_features(\n",
    "        dataset=val_dataset,\n",
    "        model_for_recon=recon_model,\n",
    "        device=device,\n",
    "        ae_type=ae_type,\n",
    "        oof_preds=val_pr,\n",
    "        latents=val_lat\n",
    "    )\n",
    "    diagnose_meta_nonfinite(extra_val_feats, val_feat_names)\n",
    "\n",
    "    # 5) 把三部分特征拼在一起： [latents | preds | extra_feats]\n",
    "    X_feat_train = np.concatenate([train_lat, extra_train_feats], axis=1)\n",
    "    X_feat_val   = np.concatenate([val_lat, extra_val_feats  ], axis=1)\n",
    "    # 这里 D_feat = X_feat_train.shape[1]\n",
    "    D_feat = X_feat_train.shape[1]\n",
    "\n",
    "    # 把 features, predictions, labels 三个张量放一起\n",
    "    ds_train_meta = TensorDataset(\n",
    "        torch.from_numpy(X_feat_train).float(),\n",
    "        torch.from_numpy(train_pr).float(),\n",
    "        torch.from_numpy(train_y).float()\n",
    "    )\n",
    "    ds_val_meta   = TensorDataset(\n",
    "        torch.from_numpy(X_feat_val).float(),\n",
    "        torch.from_numpy(val_pr).float(),\n",
    "        torch.from_numpy(val_y).float()\n",
    "    )\n",
    "\n",
    "    loader_train_meta = DataLoader(ds_train_meta, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    loader_val_meta   = DataLoader(ds_val_meta,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # —— 6) 初始化 DeepResMLP —— \n",
    "    # 让它的输入维度等于 D_feat\n",
    "    meta_model = DeepResMLP(in_dim=D_feat, hidden_dims=[1024,512,256,128], out_dim=C).to(device)\n",
    "\n",
    "    criterion      = nn.MSELoss()\n",
    "    optimizer_meta = torch.optim.Adam(meta_model.parameters(), lr=1e-3)\n",
    "    scheduler_meta = ReduceLROnPlateau(optimizer_meta, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "\n",
    "    best_loss, es_cnt, es_patience = float('inf'), 0, 20\n",
    "    best_path = os.path.join(trained_oof_model_folder, f\"fold{fold_id}\", \"meta_model_best.pt\")\n",
    "\n",
    "    # —— 7) 训练循环 ——  \n",
    "    for epoch in range(1, META_EPOCHS+1):\n",
    "        # ——— 训练 ———\n",
    "        meta_model.train()\n",
    "        train_loss = 0.0\n",
    "        for feats, pr, yb in loader_train_meta:\n",
    "            feats, pr, yb = feats.to(device), pr.to(device), yb.to(device)\n",
    "            out = meta_model(feats, pr)\n",
    "            loss = criterion(out, yb)\n",
    "\n",
    "            optimizer_meta.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_meta.step()\n",
    "            train_loss += loss.item() * feats.size(0)\n",
    "        train_loss /= len(ds_train_meta)\n",
    "\n",
    "        # ——— 验证 ———\n",
    "        meta_model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for feats, pr, yb in loader_val_meta:\n",
    "                feats, pr, yb = feats.to(device), pr.to(device), yb.to(device)\n",
    "                out = meta_model(feats, pr)\n",
    "                val_loss += criterion(out, yb).item() * feats.size(0)\n",
    "        val_loss /= len(ds_val_meta)\n",
    "\n",
    "        print(f\"Fold{fold_id} Ep{epoch}/{META_EPOCHS} — \"\n",
    "            f\"Train MSE: {train_loss:.6f}, Val MSE: {val_loss:.6f}, \"\n",
    "            f\"LR: {optimizer_meta.param_groups[0]['lr']:.3e}\")\n",
    "\n",
    "        # 调度 & 早停 & 保存最佳\n",
    "        scheduler_meta.step(val_loss)\n",
    "        if val_loss < best_loss:\n",
    "            best_loss, es_cnt = val_loss, 0\n",
    "            torch.save(meta_model.state_dict(), best_path)\n",
    "            print(f\" ↳ New best (Val MSE={best_loss:.6f}), saved.\")\n",
    "        else:\n",
    "            es_cnt += 1\n",
    "            if es_cnt >= es_patience:\n",
    "                print(f\" ✋ Early stopping (no improvement in {es_patience} epochs).\")\n",
    "                break\n",
    "\n",
    "    # —— 8) 加载最佳模型并评估（可选） ——  \n",
    "    meta_model.load_state_dict(torch.load(best_path, map_location=device))\n",
    "    meta_model.eval()\n",
    "    with torch.no_grad():\n",
    "        feats_all = torch.from_numpy(X_feat_val).float().to(device)\n",
    "        pr_all    = torch.from_numpy(val_pr).float().to(device)\n",
    "        refined_preds = meta_model(feats_all, pr_all).cpu().numpy()\n",
    "\n",
    "    mse_val = ((refined_preds - val_y) ** 2).mean()\n",
    "    print(f\" Fold{fold_id} Best refined Val MSE: {mse_val:.6f}\")\n",
    "    print(f\" ✅ Best meta-model saved to: {best_path}\")\n",
    "    fold_mse[fold_id] = mse_val\n",
    "import pandas as pd\n",
    "mse_df = pd.DataFrame.from_dict(fold_mse, orient='index', columns=['val_mse'])\n",
    "mse_df.index.name = 'fold'\n",
    "mse_df.to_csv(os.path.join(trained_oof_model_folder, \"fold_meta_mse.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deweywang/Desktop/GitHub/HEVisum/python_scripts/import_data.py:280: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  raw = torch.load(pt_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 從 '<class 'list'>' 推斷樣本數量: 2088\n",
      "Model forward signature: (tile, subtiles)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from python_scripts.import_data import load_node_feature_data\n",
    "\n",
    "\n",
    "image_keys = [ 'tile', 'subtiles']\n",
    "\n",
    "model = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "\n",
    "# 用法示例\n",
    "from python_scripts.import_data import importDataset\n",
    "# 假设你的 model 已经定义好并实例化为 `model`\n",
    "test_dataset = load_node_feature_data(\"dataset/spot-rank/filtered_directly_rank/masked/test/Macenko_4_7/test_dataset.pt\", model)\n",
    "test_dataset = importDataset(\n",
    "        data_dict=test_dataset,\n",
    "        model=model,\n",
    "        image_keys=image_keys,\n",
    "        transform=lambda x: x,  # identity transform\n",
    "        print_sig=True\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble weights per fold: [0.14668326 0.22717708 0.13848365 0.12272543 0.15362587 0.21130471]\n",
      "🍀 Fold 0 predicting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
      "Computing AE recon loss: 100%|██████████| 33/33 [00:05<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "✅ Generated meta-features with shape: (2088, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=501120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=225504, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=16704, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=150336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=902016, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=73080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=283968, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=41760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=1242360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=10440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=66816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(meta_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍀 Fold 1 predicting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
      "Computing AE recon loss: 100%|██████████| 33/33 [00:05<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "✅ Generated meta-features with shape: (2088, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=501120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=225504, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=16704, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=150336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=902016, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=73080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=283968, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=41760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=1242360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=10440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=66816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(meta_path, map_location=device))\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍀 Fold 2 predicting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|██████████| 33/33 [00:06<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "✅ Generated meta-features with shape: (2088, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=501120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=225504, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=16704, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=150336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=902016, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=73080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=283968, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=41760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=1242360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=10440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=66816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(meta_path, map_location=device))\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍀 Fold 3 predicting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|██████████| 33/33 [00:05<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "✅ Generated meta-features with shape: (2088, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=501120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=225504, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=16704, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=150336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=902016, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=73080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=283968, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=41760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=1242360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=10440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=66816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(meta_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍀 Fold 4 predicting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
      "Computing AE recon loss: 100%|██████████| 33/33 [00:05<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "✅ Generated meta-features with shape: (2088, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=501120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=225504, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=16704, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=150336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=902016, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=73080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=283968, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=41760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=1242360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=10440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=66816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(meta_path, map_location=device))\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍀 Fold 5 predicting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing AE recon loss: 100%|██████████| 33/33 [00:02<00:00, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ae-recon-loss -> cols:    1, names:    1 OK\n",
      "ae           -> cols:  384, names:  384 OK\n",
      "trained-latents -> cols:  384, names:  384 OK\n",
      "latent       -> cols:    4, names:    4 OK\n",
      "subtile4     -> cols:   12, names:   12 OK\n",
      "exsubtiles   -> cols:   12, names:   12 OK\n",
      "tile         -> cols:   12, names:   12 OK\n",
      "contrast     -> cols:    3, names:    3 OK\n",
      "wavelet-tile -> cols:  280, names:  280 OK\n",
      "sobel-tile   -> cols:   40, names:   40 OK\n",
      "hsv-tile     -> cols:  120, names:  120 OK\n",
      "he-tile      -> cols:   80, names:   80 OK\n",
      "locstd       -> cols:  432, names:  432 OK\n",
      "oof          -> cols:   35, names:   35 OK\n",
      "adj          -> cols:   34, names:   34 OK\n",
      "last         -> cols:  136, names:  136 OK\n",
      "top          -> cols:   20, names:   20 OK\n",
      "adj-his      -> cols:   10, names:   10 OK\n",
      "diff         -> cols:  595, names:  595 OK\n",
      "mad          -> cols:    1, names:    1 OK\n",
      "skewness     -> cols:    2, names:    2 OK\n",
      "p25          -> cols:    4, names:    4 OK\n",
      "renyi        -> cols:    1, names:    1 OK\n",
      "mass         -> cols:    1, names:    1 OK\n",
      "cdf          -> cols:    1, names:    1 OK\n",
      "pca          -> cols:   10, names:   10 OK\n",
      "peak         -> cols:    3, names:    3 OK\n",
      "seg0         -> cols:   10, names:   10 OK\n",
      "arcoef       -> cols:    3, names:    3 OK\n",
      "autocorr     -> cols:    5, names:    5 OK\n",
      "diff2        -> cols:   33, names:   33 OK\n",
      "diff3        -> cols:   32, names:   32 OK\n",
      "reldiff      -> cols:   34, names:   34 OK\n",
      "dratio       -> cols:   33, names:   33 OK\n",
      "✅ Generated meta-features with shape: (2088, 2767)\n",
      "Group 'ae-recon-loss': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'ae': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'trained-latents': features=384, values=801792, non-finite=0 (nan=0, inf=0)\n",
      "Group 'latent': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'subtile4': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'exsubtiles': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'contrast': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet': features=240, values=501120, non-finite=0 (nan=0, inf=0)\n",
      "Group 'wavelet-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-tile': features=4, values=8352, non-finite=0 (nan=0, inf=0)\n",
      "Group 'sobel-subtile': features=36, values=75168, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-tile': features=12, values=25056, non-finite=0 (nan=0, inf=0)\n",
      "Group 'hsv-subtile': features=108, values=225504, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-tile': features=8, values=16704, non-finite=0 (nan=0, inf=0)\n",
      "Group 'he-subtile': features=72, values=150336, non-finite=0 (nan=0, inf=0)\n",
      "Group 'locstd': features=432, values=902016, non-finite=0 (nan=0, inf=0)\n",
      "Group 'oof': features=35, values=73080, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'last': features=136, values=283968, non-finite=0 (nan=0, inf=0)\n",
      "Group 'top': features=20, values=41760, non-finite=0 (nan=0, inf=0)\n",
      "Group 'adj-his': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff': features=595, values=1242360, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mad': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'skewness': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'kurtosis': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p25': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p50': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'p75': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'iqr': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'renyi': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'mass': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'cdf': features=1, values=2088, non-finite=0 (nan=0, inf=0)\n",
      "Group 'pca': features=10, values=20880, non-finite=0 (nan=0, inf=0)\n",
      "Group 'peak': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg0': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg1': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg2': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg3': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'seg4': features=2, values=4176, non-finite=0 (nan=0, inf=0)\n",
      "Group 'arcoef': features=3, values=6264, non-finite=0 (nan=0, inf=0)\n",
      "Group 'autocorr': features=5, values=10440, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff2': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n",
      "Group 'diff3': features=32, values=66816, non-finite=0 (nan=0, inf=0)\n",
      "Group 'reldiff': features=34, values=70992, non-finite=0 (nan=0, inf=0)\n",
      "Group 'dratio': features=33, values=68904, non-finite=0 (nan=0, inf=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/2500831635.py:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(meta_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved stacked ensemble submission → output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/submission_stacked.csv\n",
      "✅ Saved weighted ensemble submission → output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/submission_weighted.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 0) 先读入各 fold 的 val_mse，并计算权重 ---\n",
    "mse_df = pd.read_csv(\n",
    "    os.path.join(trained_oof_model_folder, \"fold_meta_mse.csv\"),\n",
    "    index_col=\"fold\"\n",
    ").sort_index()\n",
    "mses = mse_df[\"val_mse\"].values          # shape (n_folds,)\n",
    "weights = 1.0 / mses                      # 越低的 mse 权重大\n",
    "weights = weights / weights.sum()         # 归一化和为 1\n",
    "print(\"Ensemble weights per fold:\", weights)\n",
    "\n",
    "# --- 3) Prepare test meta-features & stacking predictions ---\n",
    "n_test = len(test_dataset)\n",
    "all_final = []\n",
    "\n",
    "for fold_id in range(n_folds):\n",
    "    # if fold_id > start_fold:\n",
    "    #     print(f\"⏭️ Skipping fold {fold_id}\")\n",
    "    #     continue\n",
    "    print(f\"🍀 Fold {fold_id} predicting ...\")\n",
    "    \n",
    "    # 1) Load base model (VisionMLP_MultiTask) and get test_preds, test_latents\n",
    "    ckpt_path   = os.path.join(trained_oof_model_folder, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net         = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net = net.to(device).eval()\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    test_latents, test_preds, _ = extract_feats_preds(test_loader)\n",
    "    extra_test_feats, test_feat_names = generate_meta_features(\n",
    "        dataset=test_dataset,\n",
    "        model_for_recon=recon_model,\n",
    "        device=device,\n",
    "        ae_type=ae_type,\n",
    "        oof_preds=test_preds,\n",
    "        latents=test_latents\n",
    "    )\n",
    "    diagnose_meta_nonfinite(extra_test_feats, test_feat_names)\n",
    "\n",
    "    # 5) 把三部分特征拼在一起： [latents | preds | extra_feats]\n",
    "    X_feat_test = np.concatenate([test_latents, extra_test_feats], axis=1)\n",
    "    # 这里 D_feat = X_feat_train.shape[1]\n",
    "    D_feat = X_feat_test.shape[1]\n",
    "\n",
    "    # 把 features, predictions, labels 三个张量放一起\n",
    "    ds_test_meta = TensorDataset(\n",
    "        torch.from_numpy(X_feat_test).float(),\n",
    "        torch.from_numpy(test_preds).float())\n",
    "\n",
    "\n",
    "    loader_test_meta = DataLoader(ds_test_meta, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # 2) Load the trained meta-learner for this fold\n",
    "    D = test_latents.shape[1]\n",
    "    meta_model = DeepResMLP(in_dim=D_feat, hidden_dims=[1024,512,256,128], out_dim=C).to(device)\n",
    "\n",
    "    meta_path = os.path.join(\n",
    "        trained_oof_model_folder,\n",
    "        f\"fold{fold_id}\",\n",
    "        \"meta_model_best.pt\"\n",
    "    )\n",
    "    meta_model.load_state_dict(torch.load(meta_path, map_location=device))\n",
    "    meta_model.eval()\n",
    "\n",
    "    # 3) 用 meta-learner 做 refined prediction\n",
    "    with torch.no_grad():\n",
    "        feats_tensor = torch.from_numpy(X_feat_test).float().to(device)\n",
    "        preds_tensor = torch.from_numpy(test_preds).float().to(device)\n",
    "        refined_pred = meta_model(feats_tensor, preds_tensor).cpu().numpy()\n",
    "\n",
    "    all_final.append(refined_pred)\n",
    "\n",
    "# --- 4) 加权 ensemble ---\n",
    "# all_refined: list of (n_test, C) arrays\n",
    "# weights: shape (n_folds,)\n",
    "final_weighted = np.zeros_like(all_final[0])\n",
    "for w, pred in zip(weights, all_final):\n",
    "    final_weighted += w * pred\n",
    "\n",
    "# --- 5) Save submissions ---\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spot_ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"]))\n",
    "\n",
    "# unweighted average（保留旧版对比）\n",
    "final_simple = np.mean(all_final, axis=0)\n",
    "\n",
    "# 写两个文件\n",
    "for name, arr in [(\"stacked\", final_simple), (\"weighted\", final_weighted)]:\n",
    "    sub = pd.DataFrame(arr, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "    sub.insert(0, 'ID', test_spot_ids.index)\n",
    "    path = os.path.join(trained_oof_model_folder, f\"submission_{name}.csv\")\n",
    "    sub.to_csv(path, index=False)\n",
    "    print(f\"✅ Saved {name} ensemble submission → {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21.119944, 24.191807, 24.289158, ..., 12.108937,  9.812806,\n",
       "        23.269012],\n",
       "       [20.796225, 24.415634, 24.210833, ..., 12.384914,  9.888517,\n",
       "        24.08245 ],\n",
       "       [24.244806, 28.043358, 25.876398, ...,  9.660413,  9.817519,\n",
       "        19.834955],\n",
       "       ...,\n",
       "       [21.064796, 30.208473, 23.31816 , ..., 11.452721,  8.848305,\n",
       "        20.618204],\n",
       "       [20.672852, 24.048859, 23.066084, ..., 12.829765, 10.746237,\n",
       "        25.129263],\n",
       "       [18.379812, 24.315762, 22.625013, ..., 12.282604, 10.867987,\n",
       "        25.213802]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 讀 test spot index\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spots     = f[\"spots/Test\"]\n",
    "    test_spot_table= pd.DataFrame(np.array(test_spots['S_7']))\n",
    "\n",
    "fold_ckpts = sorted(glob.glob(os.path.join(trained_oof_model_folder, \"fold*\", \"best_model.pt\")))\n",
    "models = []\n",
    "for ckpt in fold_ckpts:\n",
    "    net = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt, map_location=\"cpu\"))\n",
    "    net.to(device).eval()\n",
    "    models.append(net)\n",
    "\n",
    "all_fold_preds = []\n",
    "for fold_id, net in enumerate(models):\n",
    "    # 推論\n",
    "    print(f\"🍀 Fold {fold_id} predicting ...\")\n",
    "    with torch.no_grad():\n",
    "        preds = predict(net, test_loader, device)  # (N_test,35) numpy array\n",
    "\n",
    "    # 1) 存每一折的原始預測\n",
    "    df_fold = pd.DataFrame(preds, columns=[f\"C{i+1}\" for i in range(preds.shape[1])])\n",
    "    df_fold.insert(0, \"ID\", test_spot_table.index)\n",
    "    path_fold = os.path.join(trained_oof_model_folder, f\"submission_fold{fold_id}.csv\")\n",
    "    df_fold.to_csv(path_fold, index=False)\n",
    "    print(f\"✅ Saved fold {fold_id} predictions to {path_fold}\")\n",
    "\n",
    "    all_fold_preds.append(preds)\n",
    "\n",
    "# 2) 做 rank‐average ensemble\n",
    "all_fold_preds = np.stack(all_fold_preds, axis=0)       # (K, N_test, 35)\n",
    "ranks          = all_fold_preds.argsort(axis=2).argsort(axis=2).astype(float)\n",
    "mean_rank      = ranks.mean(axis=0)                    # (N_test,35)\n",
    "\n",
    "# 3) 存 final ensemble\n",
    "df_ens = pd.DataFrame(mean_rank, columns=[f\"C{i+1}\" for i in range(mean_rank.shape[1])])\n",
    "df_ens.insert(0, \"ID\", test_spot_table.index)\n",
    "path_ens = os.path.join(trained_oof_model_folder, \"submission_rank_ensemble.csv\")\n",
    "df_ens.to_csv(path_ens, index=False)\n",
    "print(f\"✅ Saved rank‐ensemble submission to {path_ens}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model stacking with one meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from python_scripts.import_data import importDataset  # 假设这个能给你 full_dataset\n",
    "from python_scripts.aug import subset_grouped_data   # 用来切出 grouped_data\n",
    "\n",
    "# Settings\n",
    "trained_oof_model_folder = 'output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked'\n",
    "n_folds    = 6\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 64\n",
    "C          = 35  # 类别数 / 每个预测向量长度\n",
    "META_EPOCHS = 250\n",
    "tile_dim = 128\n",
    "center_dim = 128\n",
    "neighbor_dim = 128\n",
    "# 1) Load full_dataset & y_true\n",
    "n_samples = len(full_dataset)\n",
    "y_true = np.vstack([full_dataset[i]['label'].cpu().numpy() for i in range(n_samples)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍀 Fold 0 predicting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1968516026.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍀 Fold 1 predicting ...\n",
      "🍀 Fold 2 predicting ...\n",
      "🍀 Fold 3 predicting ...\n",
      "🍀 Fold 4 predicting ...\n",
      "🍀 Fold 5 predicting ...\n",
      "🍀 Preparing data for meta model ...\n",
      "🍀 Start training meta model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Train MSE 398.833550, Val MSE 343.151417, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 2 — Train MSE 220.268595, Val MSE 109.576775, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 3 — Train MSE 70.895166, Val MSE 52.277888, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 4 — Train MSE 53.457557, Val MSE 47.230638, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 5 — Train MSE 51.738313, Val MSE 45.111218, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 6 — Train MSE 50.567188, Val MSE 45.199467, lr 1.000e-03\n",
      "Epoch 7 — Train MSE 50.151351, Val MSE 46.167478, lr 1.000e-03\n",
      "Epoch 8 — Train MSE 49.153631, Val MSE 43.752192, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 9 — Train MSE 48.613082, Val MSE 44.310437, lr 1.000e-03\n",
      "Epoch 10 — Train MSE 48.550224, Val MSE 43.390919, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 11 — Train MSE 48.351976, Val MSE 44.635134, lr 1.000e-03\n",
      "Epoch 12 — Train MSE 47.697107, Val MSE 42.686886, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 13 — Train MSE 47.436593, Val MSE 42.415576, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 14 — Train MSE 47.478582, Val MSE 41.678534, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 15 — Train MSE 46.766871, Val MSE 41.855991, lr 1.000e-03\n",
      "Epoch 16 — Train MSE 47.007778, Val MSE 41.335236, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 17 — Train MSE 46.861905, Val MSE 42.304492, lr 1.000e-03\n",
      "Epoch 18 — Train MSE 46.701075, Val MSE 41.140256, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 19 — Train MSE 46.420621, Val MSE 41.438767, lr 1.000e-03\n",
      "Epoch 20 — Train MSE 46.074126, Val MSE 42.125472, lr 1.000e-03\n",
      "Epoch 21 — Train MSE 46.005365, Val MSE 40.819189, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 22 — Train MSE 45.595014, Val MSE 41.124747, lr 1.000e-03\n",
      "Epoch 23 — Train MSE 45.638896, Val MSE 40.085422, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 24 — Train MSE 45.469965, Val MSE 39.608566, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 25 — Train MSE 46.689905, Val MSE 42.826823, lr 1.000e-03\n",
      "Epoch 26 — Train MSE 46.311248, Val MSE 40.674245, lr 1.000e-03\n",
      "Epoch 27 — Train MSE 46.015575, Val MSE 41.011701, lr 1.000e-03\n",
      "Epoch 28 — Train MSE 45.636403, Val MSE 40.539881, lr 1.000e-03\n",
      "Epoch 29 — Train MSE 46.020378, Val MSE 41.145701, lr 1.000e-03\n",
      "Epoch 30 — Train MSE 45.261758, Val MSE 39.752437, lr 1.000e-03\n",
      "Epoch 31 — Train MSE 45.124922, Val MSE 39.488810, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 32 — Train MSE 44.727973, Val MSE 39.214988, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 33 — Train MSE 44.577897, Val MSE 39.365381, lr 1.000e-03\n",
      "Epoch 34 — Train MSE 44.605097, Val MSE 39.479706, lr 1.000e-03\n",
      "Epoch 35 — Train MSE 44.438441, Val MSE 39.098742, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 36 — Train MSE 44.264860, Val MSE 39.042434, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 37 — Train MSE 44.165181, Val MSE 39.535003, lr 1.000e-03\n",
      "Epoch 38 — Train MSE 44.199058, Val MSE 39.012007, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 39 — Train MSE 44.058355, Val MSE 38.893878, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 40 — Train MSE 44.112248, Val MSE 39.286840, lr 1.000e-03\n",
      "Epoch 41 — Train MSE 44.665875, Val MSE 38.829662, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 42 — Train MSE 44.054323, Val MSE 38.833708, lr 1.000e-03\n",
      "Epoch 43 — Train MSE 43.966174, Val MSE 39.516964, lr 1.000e-03\n",
      "Epoch 44 — Train MSE 43.621622, Val MSE 38.693630, lr 1.000e-03\n",
      " ↳ New best saved.\n",
      "Epoch 45 — Train MSE 45.294959, Val MSE 41.749526, lr 1.000e-03\n",
      "Epoch 46 — Train MSE 46.082395, Val MSE 40.794412, lr 1.000e-03\n",
      "Epoch 47 — Train MSE 44.874214, Val MSE 40.534002, lr 1.000e-03\n",
      "Epoch 48 — Train MSE 44.859466, Val MSE 40.573526, lr 1.000e-03\n",
      "Epoch 49 — Train MSE 44.848153, Val MSE 40.203111, lr 1.000e-03\n",
      "Epoch 50 — Train MSE 44.571628, Val MSE 39.957169, lr 1.000e-03\n",
      "Epoch 51 — Train MSE 44.799125, Val MSE 40.514772, lr 1.000e-03\n",
      "Epoch 52 — Train MSE 44.444311, Val MSE 39.617058, lr 1.000e-03\n",
      "Epoch 53 — Train MSE 44.267741, Val MSE 39.810534, lr 1.000e-03\n",
      "Epoch 54 — Train MSE 44.509223, Val MSE 40.085464, lr 1.000e-03\n",
      "Epoch 55 — Train MSE 43.966553, Val MSE 39.599766, lr 1.000e-03\n",
      "Epoch 56 — Train MSE 44.069371, Val MSE 39.352422, lr 5.000e-04\n",
      "Epoch 57 — Train MSE 43.783443, Val MSE 39.326401, lr 5.000e-04\n",
      "Epoch 58 — Train MSE 43.674071, Val MSE 39.109002, lr 5.000e-04\n",
      "Epoch 59 — Train MSE 43.657689, Val MSE 39.063694, lr 5.000e-04\n",
      "Epoch 60 — Train MSE 43.690025, Val MSE 39.064317, lr 5.000e-04\n",
      "Epoch 61 — Train MSE 43.777777, Val MSE 39.338124, lr 5.000e-04\n",
      "Epoch 62 — Train MSE 43.469156, Val MSE 39.121436, lr 5.000e-04\n",
      "Epoch 63 — Train MSE 43.613957, Val MSE 38.865140, lr 5.000e-04\n",
      "Epoch 64 — Train MSE 43.281180, Val MSE 38.849506, lr 5.000e-04\n",
      " 🛑 Early stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/1968516026.py:128: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mlp.load_state_dict(torch.load(best_path, map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingMLP(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=210, out_features=512, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=256, out_features=35, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) 对每个 fold 收集 OOF 预测\n",
    "oof_preds = np.zeros((n_samples, n_folds, C), dtype=np.float32)\n",
    "full_loader = DataLoader(full_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=False)\n",
    "\n",
    "for fold_id, (_, va_idx) in enumerate(\n",
    "    logo.split(X=np.zeros(n_samples), y=None, groups=slide_idx)\n",
    "):\n",
    "    # a) load base model for this fold\n",
    "    print(f\"🍀 Fold {fold_id} predicting ...\")\n",
    "    ckpt = os.path.join(trained_oof_model_folder, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net  = VisionMLP_MultiTask(tile_dim, center_dim, output_dim=C).to(device)\n",
    "    net.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "    net.eval()\n",
    "    \n",
    "    # b) 用这个 model 只对它的 **验证集** 做预测（OOF）\n",
    "    val_ds = Subset(full_dataset, va_idx)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in full_loader:\n",
    "            tiles, subtiles = batch['tile'].to(device), batch['subtiles'].to(device)\n",
    "            center = subtiles[:,4]\n",
    "            f_c = net.encoder_center(center)\n",
    "            f_n = net.encoder_subtile(subtiles)\n",
    "            f_t = net.encoder_tile(tiles)\n",
    "            fuse = torch.cat([f_c,f_n,f_t], dim=1)\n",
    "            out = net.decoder(fuse)\n",
    "            preds_list.append(out.cpu().numpy())\n",
    "    preds_fold = np.concatenate(preds_list, axis=0)  # (len(va_idx), C)\n",
    "\n",
    "    # c) 填回到 oof_preds[:, fold_id, :]\n",
    "    oof_preds[:, fold_id, :] = preds_fold\n",
    "\n",
    "print(\"🍀 Preparing data for meta model ...\")\n",
    "\n",
    "# 3) reshape → stacking 特征矩阵 X_stack\n",
    "X_stack = oof_preds.reshape(n_samples, n_folds*C)    # (N, n_folds*C)\n",
    "y_stack = y_true                                   # (N, C)\n",
    "\n",
    "# 4) 划分 meta‐train / meta‐val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_stack, y_stack, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# 5) DataLoader\n",
    "ds_train = TensorDataset(torch.from_numpy(X_train).float(),\n",
    "                         torch.from_numpy(y_train).float())\n",
    "ds_val   = TensorDataset(torch.from_numpy(X_val).float(),\n",
    "                         torch.from_numpy(y_val).float())\n",
    "loader_train = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "loader_val   = DataLoader(ds_val,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# 6) 定义/初始化 stacking MLP\n",
    "in_dim = n_folds * C\n",
    "class StackingMLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dims=[512,256], out_dim=35, dropout=0.2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = in_dim\n",
    "        for h in hidden_dims:\n",
    "            layers.append(nn.Linear(prev, h))\n",
    "            layers.append(nn.LeakyReLU(0.01))\n",
    "            layers.append(nn.BatchNorm1d(h))\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            prev = h\n",
    "        # 最后一层直接输出 out_dim\n",
    "        layers.append(nn.Linear(prev, out_dim))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape [B, in_dim], in_dim = n_folds * C\n",
    "        returns: Tensor of shape [B, out_dim]\n",
    "        \"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "mlp = StackingMLP(in_dim=n_folds*C, hidden_dims=[512,256], out_dim=C).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-3)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, min_lr=1e-6, verbose=True)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "best_val = float('inf')\n",
    "es_cnt, es_patience = 0, 20\n",
    "best_path = os.path.join(trained_oof_model_folder, \"stacking_meta_best.pt\")\n",
    "\n",
    "print(\"🍀 Start training meta model ...\")\n",
    "\n",
    "# 7) 训练循环\n",
    "for epoch in range(1, META_EPOCHS+1):\n",
    "    mlp.train()\n",
    "    train_loss = 0.0\n",
    "    for xb, yb in loader_train:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        out = mlp(xb)               # 前向\n",
    "        loss = criterion(out, yb)   # MSE\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * xb.size(0)\n",
    "    train_loss /= len(ds_train)\n",
    "\n",
    "    # 验证\n",
    "    mlp.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader_val:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            val_loss += criterion(mlp(xb), yb).item() * xb.size(0)\n",
    "    val_loss /= len(ds_val)\n",
    "\n",
    "\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch} — Train MSE {train_loss:.6f}, Val MSE {val_loss:.6f}, lr {current_lr:.3e}\")\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss; es_cnt = 0\n",
    "        torch.save(mlp.state_dict(), best_path)\n",
    "        print(\" ↳ New best saved.\")\n",
    "    else:\n",
    "        es_cnt += 1\n",
    "        if es_cnt >= es_patience:\n",
    "            print(\" 🛑 Early stopping.\")\n",
    "            break\n",
    "\n",
    "# 8) 从最好模型 load 回来\n",
    "mlp.load_state_dict(torch.load(best_path, map_location=device))\n",
    "mlp.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍀 Fold 0 predicting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/3338310424.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍀 Fold 1 predicting ...\n",
      "🍀 Fold 2 predicting ...\n",
      "🍀 Fold 3 predicting ...\n",
      "🍀 Fold 4 predicting ...\n",
      "🍀 Fold 5 predicting ...\n",
      "🍀 Meta model predicting ...\n",
      "✅ Done single‐MLP stacking submission.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 测试阶段：stacking 特征 + 一次 mlp.forward() ---\n",
    "# 对测试集每个 fold 做预测，拼 oof_preds_test (n_test, n_folds, C)，reshape → (n_test, n_folds*C)\n",
    "oof_test = np.zeros((len(test_dataset), n_folds, C), dtype=np.float32)\n",
    "for fold_id in range(n_folds):\n",
    "    print(f\"🍀 Fold {fold_id} predicting ...\")\n",
    "    # load each base model & predict on full test_dataset\n",
    "    ckpt = os.path.join(trained_oof_model_folder, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net  = VisionMLP_MultiTask(tile_dim, center_dim, output_dim=C).to(device)\n",
    "    net.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "    net.eval()\n",
    "\n",
    "    loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            tiles, subtiles = batch['tile'].to(device), batch['subtiles'].to(device)\n",
    "            center = subtiles[:,4]\n",
    "            fuse = torch.cat([\n",
    "                net.encoder_center(center),\n",
    "                net.encoder_subtile(subtiles),\n",
    "                net.encoder_tile(tiles)\n",
    "            ], dim=1)\n",
    "            preds_list.append(net.decoder(fuse).cpu().numpy())\n",
    "    oof_test[:, fold_id, :] = np.concatenate(preds_list, axis=0)\n",
    "\n",
    "print(\"🍀 Meta model predicting ...\")\n",
    "X_test_stack = oof_test.reshape(len(test_dataset), n_folds*C)\n",
    "with torch.no_grad():\n",
    "    X_test_t = torch.from_numpy(X_test_stack).float().to(device)\n",
    "    final_test_preds = mlp(X_test_t).cpu().numpy()\n",
    "\n",
    "# 9) 存 submission\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"])).index\n",
    "sub = pd.DataFrame(final_test_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, 'ID', ids)\n",
    "sub.to_csv(os.path.join(trained_oof_model_folder, \"submission_stacked_single_mlp.csv\"), index=False)\n",
    "print(\"✅ Done single‐MLP stacking submission.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍀 Start training meta model ...\n",
      "🍀 Start training one LGBM per target ...\n",
      " ▶ Training target #1/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.80957\n",
      "[200]\tvalid_0's rmse: 5.19367\n",
      "[300]\tvalid_0's rmse: 5.03413\n",
      "[400]\tvalid_0's rmse: 4.99558\n",
      "[500]\tvalid_0's rmse: 4.98487\n",
      "[600]\tvalid_0's rmse: 4.98404\n",
      "[700]\tvalid_0's rmse: 4.98417\n",
      "Early stopping, best iteration is:\n",
      "[566]\tvalid_0's rmse: 4.98222\n",
      " ▶ Training target #2/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 2.58937\n",
      "[200]\tvalid_0's rmse: 2.26426\n",
      "[300]\tvalid_0's rmse: 2.16704\n",
      "[400]\tvalid_0's rmse: 2.13877\n",
      "[500]\tvalid_0's rmse: 2.1283\n",
      "[600]\tvalid_0's rmse: 2.12534\n",
      "[700]\tvalid_0's rmse: 2.12257\n",
      "[800]\tvalid_0's rmse: 2.12198\n",
      "[900]\tvalid_0's rmse: 2.12155\n",
      "[1000]\tvalid_0's rmse: 2.12206\n",
      "Early stopping, best iteration is:\n",
      "[892]\tvalid_0's rmse: 2.12121\n",
      " ▶ Training target #3/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 4.09634\n",
      "[200]\tvalid_0's rmse: 3.52543\n",
      "[300]\tvalid_0's rmse: 3.37769\n",
      "[400]\tvalid_0's rmse: 3.34427\n",
      "[500]\tvalid_0's rmse: 3.33766\n",
      "[600]\tvalid_0's rmse: 3.33485\n",
      "[700]\tvalid_0's rmse: 3.33407\n",
      "[800]\tvalid_0's rmse: 3.33513\n",
      "Early stopping, best iteration is:\n",
      "[686]\tvalid_0's rmse: 3.3334\n",
      " ▶ Training target #4/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 8.20165\n",
      "[200]\tvalid_0's rmse: 7.01577\n",
      "[300]\tvalid_0's rmse: 6.70831\n",
      "[400]\tvalid_0's rmse: 6.63517\n",
      "[500]\tvalid_0's rmse: 6.62244\n",
      "[600]\tvalid_0's rmse: 6.62169\n",
      "[700]\tvalid_0's rmse: 6.61905\n",
      "[800]\tvalid_0's rmse: 6.62346\n",
      "Early stopping, best iteration is:\n",
      "[695]\tvalid_0's rmse: 6.61806\n",
      " ▶ Training target #5/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.7173\n",
      "[200]\tvalid_0's rmse: 6.66838\n",
      "[300]\tvalid_0's rmse: 6.35032\n",
      "[400]\tvalid_0's rmse: 6.24286\n",
      "[500]\tvalid_0's rmse: 6.2111\n",
      "[600]\tvalid_0's rmse: 6.19792\n",
      "[700]\tvalid_0's rmse: 6.1862\n",
      "[800]\tvalid_0's rmse: 6.18073\n",
      "[900]\tvalid_0's rmse: 6.18034\n",
      "[1000]\tvalid_0's rmse: 6.18071\n",
      "[1100]\tvalid_0's rmse: 6.18019\n",
      "Early stopping, best iteration is:\n",
      "[914]\tvalid_0's rmse: 6.1791\n",
      " ▶ Training target #6/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.88352\n",
      "[200]\tvalid_0's rmse: 6.79117\n",
      "[300]\tvalid_0's rmse: 6.47416\n",
      "[400]\tvalid_0's rmse: 6.37851\n",
      "[500]\tvalid_0's rmse: 6.34054\n",
      "[600]\tvalid_0's rmse: 6.32187\n",
      "[700]\tvalid_0's rmse: 6.31667\n",
      "[800]\tvalid_0's rmse: 6.3116\n",
      "[900]\tvalid_0's rmse: 6.31055\n",
      "[1000]\tvalid_0's rmse: 6.30979\n",
      "[1100]\tvalid_0's rmse: 6.30663\n",
      "[1200]\tvalid_0's rmse: 6.30798\n",
      "[1300]\tvalid_0's rmse: 6.30814\n",
      "Early stopping, best iteration is:\n",
      "[1134]\tvalid_0's rmse: 6.30539\n",
      " ▶ Training target #7/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.67557\n",
      "[200]\tvalid_0's rmse: 3.44097\n",
      "[300]\tvalid_0's rmse: 3.38332\n",
      "[400]\tvalid_0's rmse: 3.37214\n",
      "[500]\tvalid_0's rmse: 3.37246\n",
      "[600]\tvalid_0's rmse: 3.37353\n",
      "Early stopping, best iteration is:\n",
      "[409]\tvalid_0's rmse: 3.37135\n",
      " ▶ Training target #8/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.65305\n",
      "[200]\tvalid_0's rmse: 5.56243\n",
      "[300]\tvalid_0's rmse: 5.54871\n",
      "[400]\tvalid_0's rmse: 5.5537\n",
      "[500]\tvalid_0's rmse: 5.56196\n",
      "Early stopping, best iteration is:\n",
      "[315]\tvalid_0's rmse: 5.54837\n",
      " ▶ Training target #9/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 8.64605\n",
      "[200]\tvalid_0's rmse: 7.4803\n",
      "[300]\tvalid_0's rmse: 7.15783\n",
      "[400]\tvalid_0's rmse: 7.06843\n",
      "[500]\tvalid_0's rmse: 7.04112\n",
      "[600]\tvalid_0's rmse: 7.02802\n",
      "[700]\tvalid_0's rmse: 7.01882\n",
      "[800]\tvalid_0's rmse: 7.01577\n",
      "[900]\tvalid_0's rmse: 7.01531\n",
      "[1000]\tvalid_0's rmse: 7.01511\n",
      "[1100]\tvalid_0's rmse: 7.01387\n",
      "[1200]\tvalid_0's rmse: 7.01559\n",
      "Early stopping, best iteration is:\n",
      "[1075]\tvalid_0's rmse: 7.01232\n",
      " ▶ Training target #10/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.17653\n",
      "[200]\tvalid_0's rmse: 6.20806\n",
      "[300]\tvalid_0's rmse: 5.981\n",
      "[400]\tvalid_0's rmse: 5.92642\n",
      "[500]\tvalid_0's rmse: 5.92103\n",
      "[600]\tvalid_0's rmse: 5.91982\n",
      "[700]\tvalid_0's rmse: 5.91797\n",
      "[800]\tvalid_0's rmse: 5.91826\n",
      "Early stopping, best iteration is:\n",
      "[658]\tvalid_0's rmse: 5.91482\n",
      " ▶ Training target #11/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.78296\n",
      "[200]\tvalid_0's rmse: 7.04437\n",
      "[300]\tvalid_0's rmse: 6.81941\n",
      "[400]\tvalid_0's rmse: 6.75013\n",
      "[500]\tvalid_0's rmse: 6.72555\n",
      "[600]\tvalid_0's rmse: 6.71404\n",
      "[700]\tvalid_0's rmse: 6.70726\n",
      "[800]\tvalid_0's rmse: 6.70565\n",
      "[900]\tvalid_0's rmse: 6.70861\n",
      "[1000]\tvalid_0's rmse: 6.70967\n",
      "Early stopping, best iteration is:\n",
      "[807]\tvalid_0's rmse: 6.70446\n",
      " ▶ Training target #12/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 4.2633\n",
      "[200]\tvalid_0's rmse: 3.62364\n",
      "[300]\tvalid_0's rmse: 3.44562\n",
      "[400]\tvalid_0's rmse: 3.39954\n",
      "[500]\tvalid_0's rmse: 3.38621\n",
      "[600]\tvalid_0's rmse: 3.37988\n",
      "[700]\tvalid_0's rmse: 3.37881\n",
      "[800]\tvalid_0's rmse: 3.37708\n",
      "[900]\tvalid_0's rmse: 3.37586\n",
      "[1000]\tvalid_0's rmse: 3.37608\n",
      "[1100]\tvalid_0's rmse: 3.37812\n",
      "Early stopping, best iteration is:\n",
      "[986]\tvalid_0's rmse: 3.3753\n",
      " ▶ Training target #13/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.12512\n",
      "[200]\tvalid_0's rmse: 6.06792\n",
      "[300]\tvalid_0's rmse: 6.06935\n",
      "[400]\tvalid_0's rmse: 6.07591\n",
      "Early stopping, best iteration is:\n",
      "[254]\tvalid_0's rmse: 6.0633\n",
      " ▶ Training target #14/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.46693\n",
      "[200]\tvalid_0's rmse: 5.21039\n",
      "[300]\tvalid_0's rmse: 5.16203\n",
      "[400]\tvalid_0's rmse: 5.15915\n",
      "[500]\tvalid_0's rmse: 5.16455\n",
      "Early stopping, best iteration is:\n",
      "[336]\tvalid_0's rmse: 5.15706\n",
      " ▶ Training target #15/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.33803\n",
      "[200]\tvalid_0's rmse: 5.43604\n",
      "[300]\tvalid_0's rmse: 5.1774\n",
      "[400]\tvalid_0's rmse: 5.10034\n",
      "[500]\tvalid_0's rmse: 5.07629\n",
      "[600]\tvalid_0's rmse: 5.06675\n",
      "[700]\tvalid_0's rmse: 5.06123\n",
      "[800]\tvalid_0's rmse: 5.06196\n",
      "[900]\tvalid_0's rmse: 5.06235\n",
      "Early stopping, best iteration is:\n",
      "[701]\tvalid_0's rmse: 5.06108\n",
      " ▶ Training target #16/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 6.24249\n",
      "[200]\tvalid_0's rmse: 5.66736\n",
      "[300]\tvalid_0's rmse: 5.51309\n",
      "[400]\tvalid_0's rmse: 5.47241\n",
      "[500]\tvalid_0's rmse: 5.46156\n",
      "[600]\tvalid_0's rmse: 5.46198\n",
      "Early stopping, best iteration is:\n",
      "[489]\tvalid_0's rmse: 5.46022\n",
      " ▶ Training target #17/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.23501\n",
      "[200]\tvalid_0's rmse: 6.33322\n",
      "[300]\tvalid_0's rmse: 6.09611\n",
      "[400]\tvalid_0's rmse: 6.02032\n",
      "[500]\tvalid_0's rmse: 5.9925\n",
      "[600]\tvalid_0's rmse: 5.98214\n",
      "[700]\tvalid_0's rmse: 5.97779\n",
      "[800]\tvalid_0's rmse: 5.97324\n",
      "[900]\tvalid_0's rmse: 5.97057\n",
      "[1000]\tvalid_0's rmse: 5.97129\n",
      "[1100]\tvalid_0's rmse: 5.97274\n",
      "Early stopping, best iteration is:\n",
      "[926]\tvalid_0's rmse: 5.9698\n",
      " ▶ Training target #18/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 3.92344\n",
      "[200]\tvalid_0's rmse: 3.33891\n",
      "[300]\tvalid_0's rmse: 3.1936\n",
      "[400]\tvalid_0's rmse: 3.16039\n",
      "[500]\tvalid_0's rmse: 3.15388\n",
      "[600]\tvalid_0's rmse: 3.15111\n",
      "[700]\tvalid_0's rmse: 3.15202\n",
      "Early stopping, best iteration is:\n",
      "[596]\tvalid_0's rmse: 3.15094\n",
      " ▶ Training target #19/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.34135\n",
      "[200]\tvalid_0's rmse: 7.01777\n",
      "[300]\tvalid_0's rmse: 6.94866\n",
      "[400]\tvalid_0's rmse: 6.93829\n",
      "[500]\tvalid_0's rmse: 6.94053\n",
      "[600]\tvalid_0's rmse: 6.94413\n",
      "Early stopping, best iteration is:\n",
      "[403]\tvalid_0's rmse: 6.93669\n",
      " ▶ Training target #20/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 5.03803\n",
      "[200]\tvalid_0's rmse: 4.83778\n",
      "[300]\tvalid_0's rmse: 4.78316\n",
      "[400]\tvalid_0's rmse: 4.76957\n",
      "[500]\tvalid_0's rmse: 4.76722\n",
      "[600]\tvalid_0's rmse: 4.76841\n",
      "Early stopping, best iteration is:\n",
      "[445]\tvalid_0's rmse: 4.76608\n",
      " ▶ Training target #21/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 6.6216\n",
      "[200]\tvalid_0's rmse: 6.10619\n",
      "[300]\tvalid_0's rmse: 5.97404\n",
      "[400]\tvalid_0's rmse: 5.93998\n",
      "[500]\tvalid_0's rmse: 5.93119\n",
      "[600]\tvalid_0's rmse: 5.92652\n",
      "[700]\tvalid_0's rmse: 5.92588\n",
      "[800]\tvalid_0's rmse: 5.9245\n",
      "[900]\tvalid_0's rmse: 5.92876\n",
      "Early stopping, best iteration is:\n",
      "[798]\tvalid_0's rmse: 5.92376\n",
      " ▶ Training target #22/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.75956\n",
      "[200]\tvalid_0's rmse: 7.35264\n",
      "[300]\tvalid_0's rmse: 7.25175\n",
      "[400]\tvalid_0's rmse: 7.2228\n",
      "[500]\tvalid_0's rmse: 7.21706\n",
      "[600]\tvalid_0's rmse: 7.21345\n",
      "[700]\tvalid_0's rmse: 7.2181\n",
      "[800]\tvalid_0's rmse: 7.21388\n",
      "Early stopping, best iteration is:\n",
      "[630]\tvalid_0's rmse: 7.21257\n",
      " ▶ Training target #23/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.82375\n",
      "[200]\tvalid_0's rmse: 2.60096\n",
      "[300]\tvalid_0's rmse: 2.54835\n",
      "[400]\tvalid_0's rmse: 2.53885\n",
      "[500]\tvalid_0's rmse: 2.53962\n",
      "[600]\tvalid_0's rmse: 2.54082\n",
      "Early stopping, best iteration is:\n",
      "[405]\tvalid_0's rmse: 2.53852\n",
      " ▶ Training target #24/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.37896\n",
      "[200]\tvalid_0's rmse: 5.74931\n",
      "[300]\tvalid_0's rmse: 5.59342\n",
      "[400]\tvalid_0's rmse: 5.56089\n",
      "[500]\tvalid_0's rmse: 5.55583\n",
      "[600]\tvalid_0's rmse: 5.5565\n",
      "[700]\tvalid_0's rmse: 5.5596\n",
      "Early stopping, best iteration is:\n",
      "[559]\tvalid_0's rmse: 5.55501\n",
      " ▶ Training target #25/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.58222\n",
      "[200]\tvalid_0's rmse: 6.87418\n",
      "[300]\tvalid_0's rmse: 6.68426\n",
      "[400]\tvalid_0's rmse: 6.6332\n",
      "[500]\tvalid_0's rmse: 6.61512\n",
      "[600]\tvalid_0's rmse: 6.6118\n",
      "[700]\tvalid_0's rmse: 6.60934\n",
      "[800]\tvalid_0's rmse: 6.60876\n",
      "[900]\tvalid_0's rmse: 6.60814\n",
      "[1000]\tvalid_0's rmse: 6.61081\n",
      "[1100]\tvalid_0's rmse: 6.61534\n",
      "Early stopping, best iteration is:\n",
      "[918]\tvalid_0's rmse: 6.60638\n",
      " ▶ Training target #26/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 6.91\n",
      "[200]\tvalid_0's rmse: 6.57775\n",
      "[300]\tvalid_0's rmse: 6.47922\n",
      "[400]\tvalid_0's rmse: 6.45402\n",
      "[500]\tvalid_0's rmse: 6.45096\n",
      "[600]\tvalid_0's rmse: 6.44968\n",
      "[700]\tvalid_0's rmse: 6.44988\n",
      "[800]\tvalid_0's rmse: 6.45701\n",
      "Early stopping, best iteration is:\n",
      "[641]\tvalid_0's rmse: 6.44766\n",
      " ▶ Training target #27/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 8.12002\n",
      "[200]\tvalid_0's rmse: 6.82343\n",
      "[300]\tvalid_0's rmse: 6.44353\n",
      "[400]\tvalid_0's rmse: 6.32508\n",
      "[500]\tvalid_0's rmse: 6.27824\n",
      "[600]\tvalid_0's rmse: 6.26088\n",
      "[700]\tvalid_0's rmse: 6.25802\n",
      "[800]\tvalid_0's rmse: 6.25569\n",
      "[900]\tvalid_0's rmse: 6.25576\n",
      "[1000]\tvalid_0's rmse: 6.2574\n",
      "[1100]\tvalid_0's rmse: 6.25979\n",
      "Early stopping, best iteration is:\n",
      "[909]\tvalid_0's rmse: 6.25448\n",
      " ▶ Training target #28/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.95725\n",
      "[200]\tvalid_0's rmse: 5.64077\n",
      "[300]\tvalid_0's rmse: 5.58146\n",
      "[400]\tvalid_0's rmse: 5.56663\n",
      "[500]\tvalid_0's rmse: 5.56868\n",
      "[600]\tvalid_0's rmse: 5.56623\n",
      "[700]\tvalid_0's rmse: 5.57063\n",
      "[800]\tvalid_0's rmse: 5.57202\n",
      "Early stopping, best iteration is:\n",
      "[600]\tvalid_0's rmse: 5.56623\n",
      " ▶ Training target #29/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 6.54976\n",
      "[200]\tvalid_0's rmse: 6.05634\n",
      "[300]\tvalid_0's rmse: 5.94747\n",
      "[400]\tvalid_0's rmse: 5.92804\n",
      "[500]\tvalid_0's rmse: 5.92549\n",
      "[600]\tvalid_0's rmse: 5.93178\n",
      "Early stopping, best iteration is:\n",
      "[476]\tvalid_0's rmse: 5.92275\n",
      " ▶ Training target #30/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 7.29486\n",
      "[200]\tvalid_0's rmse: 6.18596\n",
      "[300]\tvalid_0's rmse: 5.89076\n",
      "[400]\tvalid_0's rmse: 5.81109\n",
      "[500]\tvalid_0's rmse: 5.78786\n",
      "[600]\tvalid_0's rmse: 5.77903\n",
      "[700]\tvalid_0's rmse: 5.78003\n",
      "[800]\tvalid_0's rmse: 5.78269\n",
      "Early stopping, best iteration is:\n",
      "[628]\tvalid_0's rmse: 5.77654\n",
      " ▶ Training target #31/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.88191\n",
      "[200]\tvalid_0's rmse: 2.48797\n",
      "[300]\tvalid_0's rmse: 2.38446\n",
      "[400]\tvalid_0's rmse: 2.35892\n",
      "[500]\tvalid_0's rmse: 2.35251\n",
      "[600]\tvalid_0's rmse: 2.35204\n",
      "[700]\tvalid_0's rmse: 2.3534\n",
      "Early stopping, best iteration is:\n",
      "[544]\tvalid_0's rmse: 2.35129\n",
      " ▶ Training target #32/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 2.35362\n",
      "[200]\tvalid_0's rmse: 2.2714\n",
      "[300]\tvalid_0's rmse: 2.25079\n",
      "[400]\tvalid_0's rmse: 2.24801\n",
      "[500]\tvalid_0's rmse: 2.24734\n",
      "[600]\tvalid_0's rmse: 2.24763\n",
      "[700]\tvalid_0's rmse: 2.24902\n",
      "Early stopping, best iteration is:\n",
      "[545]\tvalid_0's rmse: 2.24685\n",
      " ▶ Training target #33/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's rmse: 7.31082\n",
      "[200]\tvalid_0's rmse: 7.18214\n",
      "[300]\tvalid_0's rmse: 7.16169\n",
      "[400]\tvalid_0's rmse: 7.16806\n",
      "[500]\tvalid_0's rmse: 7.17284\n",
      "Early stopping, best iteration is:\n",
      "[308]\tvalid_0's rmse: 7.16078\n",
      " ▶ Training target #34/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 5.72499\n",
      "[200]\tvalid_0's rmse: 5.46612\n",
      "[300]\tvalid_0's rmse: 5.41951\n",
      "[400]\tvalid_0's rmse: 5.42492\n",
      "[500]\tvalid_0's rmse: 5.44309\n",
      "Early stopping, best iteration is:\n",
      "[317]\tvalid_0's rmse: 5.4175\n",
      " ▶ Training target #35/35\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/lightgbm/basic.py:743: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 2.90248\n",
      "[200]\tvalid_0's rmse: 2.79129\n",
      "[300]\tvalid_0's rmse: 2.7663\n",
      "[400]\tvalid_0's rmse: 2.76172\n",
      "[500]\tvalid_0's rmse: 2.76276\n",
      "Early stopping, best iteration is:\n",
      "[381]\tvalid_0's rmse: 2.76108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 LightGBM meta‐model Val MSE: 29.343309\n",
      "✅ Saved 35 LightGBM models → output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/stacking_gbm_meta.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved GBM‐stacked submission → output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/submission_stacking_gbm.csv\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 1) 定义 LightGBM 基学习器\n",
    "params = dict(\n",
    "    objective='regression',\n",
    "    metric='rmse',\n",
    "    learning_rate=0.007522970004049377,\n",
    "    n_estimators=12000,\n",
    "    max_depth=11,\n",
    "    num_leaves=194,\n",
    "    colsample_bytree=0.7619407413363416,\n",
    "    subsample=0.8,\n",
    "    subsample_freq=1,\n",
    "    min_data_in_leaf=20,\n",
    "    reg_alpha=0.7480401395491829,\n",
    "    reg_lambda=0.2589860348178542,\n",
    "    verbosity=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2) MultiOutput 包装\n",
    "print(\"🍀 Start training meta model ...\")\n",
    "# 3) 训练，并给内部 estimator 传 early stopping+eval_set\n",
    "# 2) 用一个 list 保存每个目标的模型\n",
    "gbm_models = []\n",
    "\n",
    "print(\"🍀 Start training one LGBM per target ...\")\n",
    "for k in range(C):\n",
    "    print(f\" ▶ Training target #{k+1}/{C}\")\n",
    "    m = lgb.LGBMRegressor(**params)\n",
    "    # 传入对应的一维 label\n",
    "    m.fit(\n",
    "        X_train, y_train[:,k],\n",
    "        eval_set=[(X_val, y_val[:,k])],\n",
    "        callbacks=[\n",
    "                early_stopping(stopping_rounds=200),\n",
    "                log_evaluation(period=100)\n",
    "            ]\n",
    "    )\n",
    "    gbm_models.append(m)\n",
    "\n",
    "# 3) 在验证集上合成多输出预测并算 MSE\n",
    "y_val_pred = np.column_stack([m.predict(X_val) for m in gbm_models])\n",
    "mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"📊 LightGBM meta‐model Val MSE: {mse_val:.6f}\")\n",
    "\n",
    "# 4) 保存整组模型\n",
    "gbm_path = os.path.join(trained_oof_model_folder, \"stacking_gbm_meta.pkl\")\n",
    "joblib.dump(gbm_models, gbm_path)\n",
    "print(f\"✅ Saved {C} LightGBM models → {gbm_path}\")\n",
    "\n",
    "# … 测试时同样加载这组模型 …\n",
    "gbm_models = joblib.load(gbm_path)\n",
    "final_test_preds = np.column_stack([m.predict(X_test_stack) for m in gbm_models])\n",
    "\n",
    "# 5) 存 submission\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spot_ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"]))\n",
    "\n",
    "sub = pd.DataFrame(final_test_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, 'ID', test_spot_ids.index)\n",
    "sub_path = os.path.join(trained_oof_model_folder, \"submission_stacking_gbm.csv\")\n",
    "sub.to_csv(sub_path, index=False)\n",
    "print(f\"✅ Saved GBM‐stacked submission → {sub_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train woth 2 k-fold models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from python_scripts.import_data import importDataset  # 假设这个能给你 full_dataset\n",
    "from python_scripts.aug import subset_grouped_data   # 用来切出 grouped_data\n",
    "\n",
    "# Settings\n",
    "# 你的两套管道模型所在文件夹\n",
    "pipe_folders = [\n",
    "    'output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked' , \n",
    "    'output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked']\n",
    "n_pipes = len(pipe_folders)\n",
    "n_folds    = 6\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 64\n",
    "C          = 35  # 类别数 / 每个预测向量长度\n",
    "META_EPOCHS = 250\n",
    "tile_dim = 128\n",
    "center_dim = 128\n",
    "neighbor_dim = 128\n",
    "# 1) Load full_dataset & y_true\n",
    "n_samples = len(full_dataset)\n",
    "y_true = np.vstack([full_dataset[i]['label'].cpu().numpy() for i in range(n_samples)])\n",
    "oof_preds = np.zeros((n_pipes, n_folds, n_samples, C), dtype=np.float32)\n",
    "full_loader = DataLoader(full_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipe 0 Fold 0 predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/4182448203.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipe 0 Fold 1 predicting...\n",
      "Pipe 0 Fold 2 predicting...\n",
      "Pipe 0 Fold 3 predicting...\n",
      "Pipe 0 Fold 4 predicting...\n",
      "Pipe 0 Fold 5 predicting...\n",
      "Pipe 1 Fold 0 predicting...\n",
      "Pipe 1 Fold 1 predicting...\n",
      "Pipe 1 Fold 2 predicting...\n",
      "Pipe 1 Fold 3 predicting...\n",
      "Pipe 1 Fold 4 predicting...\n",
      "Pipe 1 Fold 5 predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spatialhackathon/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 → Train MSE 391.4221, Val MSE 320.4870, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 2 → Train MSE 213.2606, Val MSE 94.9896, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 3 → Train MSE 62.3294, Val MSE 46.4068, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 4 → Train MSE 47.7791, Val MSE 41.9149, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 5 → Train MSE 45.7437, Val MSE 42.7662, LR 1.00e-03\n",
      "Epoch 6 → Train MSE 45.9071, Val MSE 40.3713, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 7 → Train MSE 44.9099, Val MSE 41.4321, LR 1.00e-03\n",
      "Epoch 8 → Train MSE 44.4296, Val MSE 39.5969, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 9 → Train MSE 44.3049, Val MSE 42.6474, LR 1.00e-03\n",
      "Epoch 10 → Train MSE 44.4582, Val MSE 41.5099, LR 1.00e-03\n",
      "Epoch 11 → Train MSE 44.2516, Val MSE 38.7766, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 12 → Train MSE 43.8401, Val MSE 38.6763, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 13 → Train MSE 43.1779, Val MSE 38.1927, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 14 → Train MSE 43.6875, Val MSE 40.0167, LR 1.00e-03\n",
      "Epoch 15 → Train MSE 43.8981, Val MSE 38.9021, LR 1.00e-03\n",
      "Epoch 16 → Train MSE 43.3303, Val MSE 38.0751, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 17 → Train MSE 42.8778, Val MSE 38.3423, LR 1.00e-03\n",
      "Epoch 18 → Train MSE 42.5694, Val MSE 37.5741, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 19 → Train MSE 42.1233, Val MSE 37.6171, LR 1.00e-03\n",
      "Epoch 20 → Train MSE 42.4281, Val MSE 38.4233, LR 1.00e-03\n",
      "Epoch 21 → Train MSE 41.7702, Val MSE 36.7002, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 22 → Train MSE 41.7573, Val MSE 37.3967, LR 1.00e-03\n",
      "Epoch 23 → Train MSE 42.3339, Val MSE 38.7101, LR 1.00e-03\n",
      "Epoch 24 → Train MSE 41.2635, Val MSE 36.9083, LR 1.00e-03\n",
      "Epoch 25 → Train MSE 41.7939, Val MSE 37.2312, LR 1.00e-03\n",
      "Epoch 26 → Train MSE 41.3758, Val MSE 37.0413, LR 1.00e-03\n",
      "Epoch 27 → Train MSE 41.2394, Val MSE 37.6712, LR 1.00e-03\n",
      "Epoch 28 → Train MSE 42.0604, Val MSE 36.6927, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 29 → Train MSE 41.1877, Val MSE 36.6375, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 30 → Train MSE 40.5297, Val MSE 36.2997, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 31 → Train MSE 40.7056, Val MSE 36.0943, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 32 → Train MSE 40.6065, Val MSE 36.5941, LR 1.00e-03\n",
      "Epoch 33 → Train MSE 40.6195, Val MSE 36.0287, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 34 → Train MSE 40.6162, Val MSE 35.8693, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 35 → Train MSE 40.7204, Val MSE 36.0366, LR 1.00e-03\n",
      "Epoch 36 → Train MSE 40.2189, Val MSE 35.6158, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 37 → Train MSE 39.9235, Val MSE 35.4491, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 38 → Train MSE 39.7395, Val MSE 35.0508, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 39 → Train MSE 39.6754, Val MSE 35.9409, LR 1.00e-03\n",
      "Epoch 40 → Train MSE 39.8077, Val MSE 38.2282, LR 1.00e-03\n",
      "Epoch 41 → Train MSE 39.5890, Val MSE 35.2168, LR 1.00e-03\n",
      "Epoch 42 → Train MSE 39.5444, Val MSE 34.8116, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 43 → Train MSE 39.1747, Val MSE 35.0543, LR 1.00e-03\n",
      "Epoch 44 → Train MSE 39.4593, Val MSE 35.0745, LR 1.00e-03\n",
      "Epoch 45 → Train MSE 39.1876, Val MSE 35.1847, LR 1.00e-03\n",
      "Epoch 46 → Train MSE 39.3076, Val MSE 36.8449, LR 1.00e-03\n",
      "Epoch 47 → Train MSE 39.7781, Val MSE 35.7411, LR 1.00e-03\n",
      "Epoch 48 → Train MSE 39.9253, Val MSE 35.5482, LR 1.00e-03\n",
      "Epoch 49 → Train MSE 39.5282, Val MSE 35.0553, LR 1.00e-03\n",
      "Epoch 50 → Train MSE 39.2569, Val MSE 35.3255, LR 1.00e-03\n",
      "Epoch 51 → Train MSE 38.8887, Val MSE 34.9897, LR 1.00e-03\n",
      "Epoch 52 → Train MSE 38.8372, Val MSE 34.8053, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 53 → Train MSE 38.6716, Val MSE 34.4351, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 54 → Train MSE 38.5419, Val MSE 34.9296, LR 1.00e-03\n",
      "Epoch 55 → Train MSE 38.3590, Val MSE 34.5566, LR 1.00e-03\n",
      "Epoch 56 → Train MSE 38.4416, Val MSE 35.0630, LR 1.00e-03\n",
      "Epoch 57 → Train MSE 38.6909, Val MSE 34.5508, LR 1.00e-03\n",
      "Epoch 58 → Train MSE 38.5832, Val MSE 34.8811, LR 1.00e-03\n",
      "Epoch 59 → Train MSE 38.6945, Val MSE 34.9149, LR 1.00e-03\n",
      "Epoch 60 → Train MSE 38.3309, Val MSE 34.2296, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 61 → Train MSE 38.4665, Val MSE 34.8813, LR 1.00e-03\n",
      "Epoch 62 → Train MSE 38.2585, Val MSE 34.4755, LR 1.00e-03\n",
      "Epoch 63 → Train MSE 38.2106, Val MSE 34.1125, LR 1.00e-03\n",
      " ↳ New best saved.\n",
      "Epoch 64 → Train MSE 38.4058, Val MSE 34.4248, LR 1.00e-03\n",
      "Epoch 65 → Train MSE 38.5215, Val MSE 151.2655, LR 1.00e-03\n",
      "Epoch 66 → Train MSE 38.4022, Val MSE 34.1953, LR 1.00e-03\n",
      "Epoch 67 → Train MSE 38.1361, Val MSE 34.5185, LR 1.00e-03\n",
      "Epoch 68 → Train MSE 38.2117, Val MSE 34.6949, LR 1.00e-03\n",
      "Epoch 69 → Train MSE 38.9071, Val MSE 35.5614, LR 1.00e-03\n",
      "Epoch 70 → Train MSE 38.6065, Val MSE 35.1649, LR 1.00e-03\n",
      "Epoch 71 → Train MSE 39.1059, Val MSE 35.5324, LR 1.00e-03\n",
      "Epoch 72 → Train MSE 38.9954, Val MSE 40.4166, LR 1.00e-03\n",
      "Epoch 73 → Train MSE 38.4927, Val MSE 34.8302, LR 1.00e-03\n",
      "Epoch 74 → Train MSE 38.3021, Val MSE 34.3670, LR 1.00e-03\n",
      "Epoch 75 → Train MSE 37.8818, Val MSE 34.3568, LR 5.00e-04\n",
      "Epoch 76 → Train MSE 37.6426, Val MSE 34.1752, LR 5.00e-04\n",
      "Epoch 77 → Train MSE 37.5763, Val MSE 33.8018, LR 5.00e-04\n",
      " ↳ New best saved.\n",
      "Epoch 78 → Train MSE 37.7921, Val MSE 33.9218, LR 5.00e-04\n",
      "Epoch 79 → Train MSE 37.8683, Val MSE 34.1284, LR 5.00e-04\n",
      "Epoch 80 → Train MSE 37.5474, Val MSE 33.6143, LR 5.00e-04\n",
      " ↳ New best saved.\n",
      "Epoch 81 → Train MSE 37.7666, Val MSE 33.8534, LR 5.00e-04\n",
      "Epoch 82 → Train MSE 37.4755, Val MSE 33.5868, LR 5.00e-04\n",
      " ↳ New best saved.\n",
      "Epoch 83 → Train MSE 37.3948, Val MSE 33.9877, LR 5.00e-04\n",
      "Epoch 84 → Train MSE 37.3768, Val MSE 33.3200, LR 5.00e-04\n",
      " ↳ New best saved.\n",
      "Epoch 85 → Train MSE 37.4490, Val MSE 33.6935, LR 5.00e-04\n",
      "Epoch 86 → Train MSE 37.4900, Val MSE 33.9681, LR 5.00e-04\n",
      "Epoch 87 → Train MSE 37.4481, Val MSE 33.4545, LR 5.00e-04\n",
      "Epoch 88 → Train MSE 37.4557, Val MSE 33.4902, LR 5.00e-04\n",
      "Epoch 89 → Train MSE 37.2206, Val MSE 33.8058, LR 5.00e-04\n",
      "Epoch 90 → Train MSE 36.9371, Val MSE 33.3246, LR 5.00e-04\n",
      "Epoch 91 → Train MSE 36.9658, Val MSE 33.2487, LR 5.00e-04\n",
      " ↳ New best saved.\n",
      "Epoch 92 → Train MSE 37.0915, Val MSE 33.6862, LR 5.00e-04\n",
      "Epoch 93 → Train MSE 37.1279, Val MSE 33.4870, LR 5.00e-04\n",
      "Epoch 94 → Train MSE 37.1980, Val MSE 33.9322, LR 5.00e-04\n",
      "Epoch 95 → Train MSE 37.1834, Val MSE 33.3086, LR 5.00e-04\n",
      "Epoch 96 → Train MSE 37.1451, Val MSE 33.4906, LR 5.00e-04\n",
      "Epoch 97 → Train MSE 36.9480, Val MSE 33.4452, LR 5.00e-04\n",
      "Epoch 98 → Train MSE 36.8936, Val MSE 33.4287, LR 5.00e-04\n",
      "Epoch 99 → Train MSE 37.3277, Val MSE 33.8518, LR 5.00e-04\n",
      "Epoch 100 → Train MSE 37.2201, Val MSE 33.9048, LR 5.00e-04\n",
      "Epoch 101 → Train MSE 37.4687, Val MSE 33.8204, LR 5.00e-04\n",
      "Epoch 102 → Train MSE 37.2863, Val MSE 33.4650, LR 5.00e-04\n",
      "Epoch 103 → Train MSE 37.1170, Val MSE 36.6737, LR 2.50e-04\n",
      "Epoch 104 → Train MSE 37.0643, Val MSE 33.3887, LR 2.50e-04\n",
      "Epoch 105 → Train MSE 36.9955, Val MSE 33.1722, LR 2.50e-04\n",
      " ↳ New best saved.\n",
      "Epoch 106 → Train MSE 36.6839, Val MSE 33.2713, LR 2.50e-04\n",
      "Epoch 107 → Train MSE 36.8301, Val MSE 33.3174, LR 2.50e-04\n",
      "Epoch 108 → Train MSE 36.7640, Val MSE 33.4771, LR 2.50e-04\n",
      "Epoch 109 → Train MSE 36.9096, Val MSE 33.3467, LR 2.50e-04\n",
      "Epoch 110 → Train MSE 36.6644, Val MSE 33.1267, LR 2.50e-04\n",
      " ↳ New best saved.\n",
      "Epoch 111 → Train MSE 36.6364, Val MSE 33.0935, LR 2.50e-04\n",
      " ↳ New best saved.\n",
      "Epoch 112 → Train MSE 36.7343, Val MSE 33.1021, LR 2.50e-04\n",
      "Epoch 113 → Train MSE 36.5709, Val MSE 33.0914, LR 2.50e-04\n",
      " ↳ New best saved.\n",
      "Epoch 114 → Train MSE 36.6267, Val MSE 32.9663, LR 2.50e-04\n",
      " ↳ New best saved.\n",
      "Epoch 115 → Train MSE 36.4845, Val MSE 33.1301, LR 2.50e-04\n",
      "Epoch 116 → Train MSE 36.6843, Val MSE 33.2070, LR 2.50e-04\n",
      "Epoch 117 → Train MSE 36.6591, Val MSE 36.0248, LR 2.50e-04\n",
      "Epoch 118 → Train MSE 36.7968, Val MSE 33.3557, LR 2.50e-04\n",
      "Epoch 119 → Train MSE 36.7561, Val MSE 34.3371, LR 2.50e-04\n",
      "Epoch 120 → Train MSE 36.7936, Val MSE 33.1960, LR 2.50e-04\n",
      "Epoch 121 → Train MSE 36.7105, Val MSE 33.0534, LR 2.50e-04\n",
      "Epoch 122 → Train MSE 36.5298, Val MSE 32.9663, LR 2.50e-04\n",
      " ↳ New best saved.\n",
      "Epoch 123 → Train MSE 36.4344, Val MSE 32.9623, LR 2.50e-04\n",
      " ↳ New best saved.\n",
      "Epoch 124 → Train MSE 36.4960, Val MSE 32.8875, LR 2.50e-04\n",
      " ↳ New best saved.\n",
      "Epoch 125 → Train MSE 36.5381, Val MSE 33.2453, LR 2.50e-04\n",
      "Epoch 126 → Train MSE 36.6908, Val MSE 33.0029, LR 2.50e-04\n",
      "Epoch 127 → Train MSE 36.5291, Val MSE 33.2611, LR 2.50e-04\n",
      "Epoch 128 → Train MSE 36.5604, Val MSE 32.8431, LR 2.50e-04\n",
      " ↳ New best saved.\n",
      "Epoch 129 → Train MSE 36.4340, Val MSE 33.1571, LR 2.50e-04\n",
      "Epoch 130 → Train MSE 36.5515, Val MSE 33.5197, LR 2.50e-04\n",
      "Epoch 131 → Train MSE 36.6097, Val MSE 33.2445, LR 2.50e-04\n",
      "Epoch 132 → Train MSE 36.5943, Val MSE 32.8199, LR 2.50e-04\n",
      " ↳ New best saved.\n",
      "Epoch 133 → Train MSE 36.2658, Val MSE 32.9539, LR 2.50e-04\n",
      "Epoch 134 → Train MSE 36.5042, Val MSE 33.0231, LR 2.50e-04\n",
      "Epoch 135 → Train MSE 36.4714, Val MSE 32.8018, LR 2.50e-04\n",
      " ↳ New best saved.\n",
      "Epoch 136 → Train MSE 36.3633, Val MSE 32.7933, LR 2.50e-04\n",
      " ↳ New best saved.\n",
      "Epoch 137 → Train MSE 36.5110, Val MSE 32.9806, LR 2.50e-04\n",
      "Epoch 138 → Train MSE 36.0403, Val MSE 32.6254, LR 2.50e-04\n",
      " ↳ New best saved.\n",
      "Epoch 139 → Train MSE 36.3402, Val MSE 32.8199, LR 2.50e-04\n",
      "Epoch 140 → Train MSE 36.2049, Val MSE 32.9389, LR 2.50e-04\n",
      "Epoch 141 → Train MSE 36.2706, Val MSE 33.0217, LR 2.50e-04\n",
      "Epoch 142 → Train MSE 36.1126, Val MSE 32.8647, LR 2.50e-04\n",
      "Epoch 143 → Train MSE 36.2305, Val MSE 32.7156, LR 2.50e-04\n",
      "Epoch 144 → Train MSE 36.1716, Val MSE 32.8837, LR 2.50e-04\n",
      "Epoch 145 → Train MSE 36.1787, Val MSE 32.8054, LR 2.50e-04\n",
      "Epoch 146 → Train MSE 36.1562, Val MSE 32.7736, LR 2.50e-04\n",
      "Epoch 147 → Train MSE 36.1331, Val MSE 32.7886, LR 2.50e-04\n",
      "Epoch 148 → Train MSE 36.1445, Val MSE 32.7686, LR 2.50e-04\n",
      "Epoch 149 → Train MSE 36.0998, Val MSE 33.0072, LR 2.50e-04\n",
      "Epoch 150 → Train MSE 35.9771, Val MSE 32.8582, LR 1.25e-04\n",
      "Epoch 151 → Train MSE 35.9147, Val MSE 32.5045, LR 1.25e-04\n",
      " ↳ New best saved.\n",
      "Epoch 152 → Train MSE 35.8703, Val MSE 32.6049, LR 1.25e-04\n",
      "Epoch 153 → Train MSE 35.7817, Val MSE 32.4593, LR 1.25e-04\n",
      " ↳ New best saved.\n",
      "Epoch 154 → Train MSE 35.8899, Val MSE 32.5924, LR 1.25e-04\n",
      "Epoch 155 → Train MSE 35.8708, Val MSE 32.5460, LR 1.25e-04\n",
      "Epoch 156 → Train MSE 36.0255, Val MSE 32.4188, LR 1.25e-04\n",
      " ↳ New best saved.\n",
      "Epoch 157 → Train MSE 35.8094, Val MSE 32.4058, LR 1.25e-04\n",
      " ↳ New best saved.\n",
      "Epoch 158 → Train MSE 35.7589, Val MSE 32.6121, LR 1.25e-04\n",
      "Epoch 159 → Train MSE 35.7832, Val MSE 32.7395, LR 1.25e-04\n",
      "Epoch 160 → Train MSE 35.7826, Val MSE 32.4421, LR 1.25e-04\n",
      "Epoch 161 → Train MSE 35.8307, Val MSE 32.7133, LR 1.25e-04\n",
      "Epoch 162 → Train MSE 35.8376, Val MSE 32.6560, LR 1.25e-04\n",
      "Epoch 163 → Train MSE 35.8367, Val MSE 34.4656, LR 1.25e-04\n",
      "Epoch 164 → Train MSE 35.7040, Val MSE 32.3792, LR 1.25e-04\n",
      " ↳ New best saved.\n",
      "Epoch 165 → Train MSE 35.8636, Val MSE 32.4407, LR 1.25e-04\n",
      "Epoch 166 → Train MSE 35.6903, Val MSE 32.3613, LR 1.25e-04\n",
      " ↳ New best saved.\n",
      "Epoch 167 → Train MSE 35.8575, Val MSE 32.8065, LR 1.25e-04\n",
      "Epoch 168 → Train MSE 35.8426, Val MSE 32.3199, LR 1.25e-04\n",
      " ↳ New best saved.\n",
      "Epoch 169 → Train MSE 35.8618, Val MSE 32.6151, LR 1.25e-04\n",
      "Epoch 170 → Train MSE 35.5668, Val MSE 32.5899, LR 1.25e-04\n",
      "Epoch 171 → Train MSE 35.8630, Val MSE 32.7773, LR 1.25e-04\n",
      "Epoch 172 → Train MSE 35.7090, Val MSE 32.4267, LR 1.25e-04\n",
      "Epoch 173 → Train MSE 35.6676, Val MSE 32.3602, LR 1.25e-04\n",
      "Epoch 174 → Train MSE 35.8579, Val MSE 32.4184, LR 1.25e-04\n",
      "Epoch 175 → Train MSE 35.7519, Val MSE 32.5317, LR 1.25e-04\n",
      "Epoch 176 → Train MSE 35.6470, Val MSE 32.4659, LR 1.25e-04\n",
      "Epoch 177 → Train MSE 35.6707, Val MSE 32.3097, LR 1.25e-04\n",
      " ↳ New best saved.\n",
      "Epoch 178 → Train MSE 35.6766, Val MSE 32.4635, LR 1.25e-04\n",
      "Epoch 179 → Train MSE 35.7080, Val MSE 32.5376, LR 1.25e-04\n",
      "Epoch 180 → Train MSE 35.9391, Val MSE 32.4356, LR 1.25e-04\n",
      "Epoch 181 → Train MSE 35.5454, Val MSE 32.5643, LR 1.25e-04\n",
      "Epoch 182 → Train MSE 35.7031, Val MSE 32.4878, LR 1.25e-04\n",
      "Epoch 183 → Train MSE 35.7483, Val MSE 32.6245, LR 1.25e-04\n",
      "Epoch 184 → Train MSE 35.8428, Val MSE 32.3997, LR 1.25e-04\n",
      "Epoch 185 → Train MSE 35.6366, Val MSE 32.4640, LR 1.25e-04\n",
      "Epoch 186 → Train MSE 35.4882, Val MSE 32.0956, LR 1.25e-04\n",
      " ↳ New best saved.\n",
      "Epoch 187 → Train MSE 35.5619, Val MSE 32.3458, LR 1.25e-04\n",
      "Epoch 188 → Train MSE 35.7474, Val MSE 32.2461, LR 1.25e-04\n",
      "Epoch 189 → Train MSE 35.6328, Val MSE 32.4331, LR 1.25e-04\n",
      "Epoch 190 → Train MSE 35.4665, Val MSE 32.1978, LR 1.25e-04\n",
      "Epoch 191 → Train MSE 35.3295, Val MSE 32.2347, LR 1.25e-04\n",
      "Epoch 192 → Train MSE 35.6762, Val MSE 32.5394, LR 1.25e-04\n",
      "Epoch 193 → Train MSE 35.6954, Val MSE 32.7031, LR 1.25e-04\n",
      "Epoch 194 → Train MSE 36.2182, Val MSE 33.2728, LR 1.25e-04\n",
      "Epoch 195 → Train MSE 36.1449, Val MSE 33.1525, LR 1.25e-04\n",
      "Epoch 196 → Train MSE 36.2476, Val MSE 32.8362, LR 1.25e-04\n",
      "Epoch 197 → Train MSE 36.0202, Val MSE 32.5471, LR 1.25e-04\n",
      "Epoch 198 → Train MSE 36.1264, Val MSE 32.8542, LR 6.25e-05\n",
      "Epoch 199 → Train MSE 35.8376, Val MSE 34.6365, LR 6.25e-05\n",
      "Epoch 200 → Train MSE 35.7622, Val MSE 32.6772, LR 6.25e-05\n",
      "Epoch 201 → Train MSE 36.0713, Val MSE 32.6209, LR 6.25e-05\n",
      "Epoch 202 → Train MSE 35.7390, Val MSE 32.4079, LR 6.25e-05\n",
      "Epoch 203 → Train MSE 35.3511, Val MSE 32.1377, LR 6.25e-05\n",
      "Epoch 204 → Train MSE 35.4250, Val MSE 32.2537, LR 6.25e-05\n",
      "Epoch 205 → Train MSE 35.3281, Val MSE 32.3758, LR 6.25e-05\n",
      "Epoch 206 → Train MSE 35.4466, Val MSE 32.3217, LR 6.25e-05\n",
      " 🛑 Early stopping.\n",
      "✅ Cross-pipe stacking done. Best at output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/stacking_2meta_best.pt\n"
     ]
    }
   ],
   "source": [
    "for p, folder in enumerate(pipe_folders):\n",
    "    for fold_id in range(n_folds):\n",
    "        print(f\"Pipe {p} Fold {fold_id} predicting...\")\n",
    "        # a) load model\n",
    "        ckpt = os.path.join(folder, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "        net  = VisionMLP_MultiTask(tile_dim, center_dim, output_dim=C).to(device)\n",
    "        net.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "        net.eval()\n",
    "\n",
    "        # b) 全样本 forward\n",
    "        preds_full = []\n",
    "        with torch.no_grad():\n",
    "            for batch in full_loader:\n",
    "                tiles, subtiles = batch['tile'].to(device), batch['subtiles'].to(device)\n",
    "                center = subtiles[:, 4]\n",
    "                fuse = torch.cat([\n",
    "                    net.encoder_center(center),\n",
    "                    net.encoder_subtile(subtiles),\n",
    "                    net.encoder_tile(tiles)\n",
    "                ], dim=1)\n",
    "                preds_full.append(net.decoder(fuse).cpu().numpy())\n",
    "\n",
    "        preds_full = np.concatenate(preds_full, axis=0)  # (n_samples, C)\n",
    "        oof_preds[p, fold_id] = preds_full\n",
    "\n",
    "# 4) 构造 stacking 特征矩阵 (n_samples, n_pipes*n_folds*C)\n",
    "#    转轴之后 reshape\n",
    "stack = oof_preds.transpose(2,0,1,3)   # (n_samples, pipe, fold, C)\n",
    "X_stack = stack.reshape(n_samples, n_pipes * n_folds * C)\n",
    "\n",
    "# 5) 划分 train/val\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "    X_stack, y_true, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# 6) DataLoader\n",
    "ds_tr = TensorDataset(torch.from_numpy(X_tr).float(), torch.from_numpy(y_tr).float())\n",
    "ds_va = TensorDataset(torch.from_numpy(X_va).float(), torch.from_numpy(y_va).float())\n",
    "loader_tr = DataLoader(ds_tr, batch_size=BATCH_SIZE, shuffle=True, pin_memory=False)\n",
    "loader_va = DataLoader(ds_va, batch_size=BATCH_SIZE, shuffle=False, pin_memory=False)\n",
    "# 7) 定义 Stacking MLP\n",
    "class StackingMLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dims=[1024,512,256], out_dim=35, dropout=0.2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = in_dim\n",
    "        for h in hidden_dims:\n",
    "            layers += [nn.Linear(prev,h),\n",
    "                       nn.LeakyReLU(0.01),\n",
    "                       nn.BatchNorm1d(h),\n",
    "                       nn.Dropout(dropout)]\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, out_dim))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "in_dim = n_pipes * n_folds * C\n",
    "mlp = StackingMLP(in_dim=in_dim, hidden_dims=[1024,512,256], out_dim=C).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-3)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "best_val, es_cnt, es_patience = float('inf'), 0, 20\n",
    "best_path = os.path.join(pipe_folders[1], \"stacking_2meta_best.pt\")\n",
    "\n",
    "# 8) 训练循环\n",
    "for epoch in range(1, META_EPOCHS+1):\n",
    "    mlp.train()\n",
    "    tr_loss = 0.0\n",
    "    for xb, yb in loader_tr:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        out = mlp(xb)\n",
    "        loss = criterion(out, yb)\n",
    "        optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "        tr_loss += loss.item() * xb.size(0)\n",
    "    tr_loss /= len(ds_tr)\n",
    "\n",
    "    mlp.eval()\n",
    "    va_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader_va:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            va_loss += criterion(mlp(xb), yb).item() * xb.size(0)\n",
    "    va_loss /= len(ds_va)\n",
    "\n",
    "    print(f\"Epoch {epoch} → Train MSE {tr_loss:.4f}, Val MSE {va_loss:.4f}, LR {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "    scheduler.step(va_loss)\n",
    "\n",
    "    if va_loss < best_val:\n",
    "        best_val, es_cnt = va_loss, 0\n",
    "        torch.save(mlp.state_dict(), best_path)\n",
    "        print(\" ↳ New best saved.\")\n",
    "    else:\n",
    "        es_cnt += 1\n",
    "        if es_cnt >= es_patience:\n",
    "            print(\" 🛑 Early stopping.\")\n",
    "            break\n",
    "\n",
    "print(\"✅ Cross-pipe stacking done. Best at\", best_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/21512719.py:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(best_path, map_location=device)\n",
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_7120/21512719.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded StackingMLP from output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/stain_nor_with_4_7/Macenko_masked/stacking_2meta_best.pt onto mps\n",
      "Pipe 0 Fold 0 inference…\n",
      "Pipe 0 Fold 1 inference…\n",
      "Pipe 0 Fold 2 inference…\n",
      "Pipe 0 Fold 3 inference…\n",
      "Pipe 0 Fold 4 inference…\n",
      "Pipe 0 Fold 5 inference…\n",
      "Pipe 1 Fold 0 inference…\n",
      "Pipe 1 Fold 1 inference…\n",
      "Pipe 1 Fold 2 inference…\n",
      "Pipe 1 Fold 3 inference…\n",
      "Pipe 1 Fold 4 inference…\n",
      "Pipe 1 Fold 5 inference…\n",
      "✅ Saved submission → output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/submission_stack_multi_pipe.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1) 初始化 ---\n",
    "n_pipes = len(pipe_folders)    # 2\n",
    "n_folds = 6\n",
    "C       = 35\n",
    "n_test  = len(test_dataset)\n",
    "\n",
    "# 1) 确定 device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else\n",
    "                      \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2) 复现模型结构\n",
    "in_dim     = n_pipes * n_folds * C        # 例如 2*6*35 = 420\n",
    "hidden_dims= [1024, 512, 256]             # 你训练时用的\n",
    "out_dim    = C\n",
    "\n",
    "mlp = StackingMLP(in_dim=in_dim,\n",
    "                  hidden_dims=hidden_dims,\n",
    "                  out_dim=out_dim).to(device)\n",
    "\n",
    "# 3) 加载训练好的权重\n",
    "best_path = os.path.join(pipe_folders[1], \"stacking_2meta_best.pt\")\n",
    "state = torch.load(best_path, map_location=device)\n",
    "mlp.load_state_dict(state)\n",
    "\n",
    "# 4) 切换到 eval 模式\n",
    "mlp.eval()\n",
    "\n",
    "print(f\"✅ Loaded StackingMLP from {best_path} onto {device}\")\n",
    "\n",
    "# oof_test[p, f, i, c] := 第 p 管道，第 f 折 模型 对 test 样本 i 的 第 c 类预测\n",
    "oof_test = np.zeros((n_pipes, n_folds, n_test, C), dtype=np.float32)\n",
    "\n",
    "full_test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "# --- 2) 对每条管道的每折模型做全样本预测 ---\n",
    "for p, folder in enumerate(pipe_folders):\n",
    "    for fold_id in range(n_folds):\n",
    "        print(f\"Pipe {p} Fold {fold_id} inference…\")\n",
    "        # a) 加载对应模型\n",
    "        ckpt = os.path.join(folder, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "        net  = VisionMLP_MultiTask(tile_dim, center_dim, output_dim=C).to(device)\n",
    "        net.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "        net.eval()\n",
    "\n",
    "        # b) 全 test 样本上跑一次 forward\n",
    "        preds_list = []\n",
    "        with torch.no_grad():\n",
    "            for batch in full_test_loader:\n",
    "                tiles, subtiles = batch['tile'].to(device), batch['subtiles'].to(device)\n",
    "                center = subtiles[:, 4]\n",
    "                fuse = torch.cat([\n",
    "                    net.encoder_center(center),\n",
    "                    net.encoder_subtile(subtiles),\n",
    "                    net.encoder_tile(tiles)\n",
    "                ], dim=1)\n",
    "                out = net.decoder(fuse)\n",
    "                preds_list.append(out.cpu().numpy())\n",
    "\n",
    "        preds_full = np.concatenate(preds_list, axis=0)  # (n_test, C)\n",
    "        oof_test[p, fold_id] = preds_full\n",
    "\n",
    "# --- 3) 构造 stacking 特征矩阵 ---\n",
    "# 转轴到 (n_test, pipe, fold, C)，再 reshape → (n_test, n_pipes*n_folds*C)\n",
    "X_test_stack = oof_test.transpose(2, 0, 1, 3).reshape(n_test, n_pipes * n_folds * C)\n",
    "\n",
    "# --- 4) 用训练好的 mlp 做一次性预测 ---\n",
    "mlp.eval()\n",
    "with torch.no_grad():\n",
    "    X_t = torch.from_numpy(X_test_stack).float().to(device)\n",
    "    final_preds = mlp(X_t).cpu().numpy()  # (n_test, C)\n",
    "\n",
    "# --- 5) 存 submission ---\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\", \"r\") as f:\n",
    "    ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"])).index\n",
    "\n",
    "sub = pd.DataFrame(final_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, \"ID\", ids)\n",
    "out_path = os.path.join(pipe_folders[1], \"submission_stack_multi_pipe.csv\")\n",
    "sub.to_csv(out_path, index=False)\n",
    "print(\"✅ Saved submission →\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import rankdata\n",
    "from python_scripts.import_data import importDataset\n",
    "from python_scripts.operate_model import predict\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import h5py\n",
    "import pandas as pd\n",
    "# ---------------- Settings ----------------\n",
    "save_root  = save_folder  # your save_folder path\n",
    "n_folds    = len([d for d in os.listdir(save_root) if d.startswith('fold')])\n",
    "n_samples  = len(full_dataset)\n",
    "C          = 35  # num cell types\n",
    "start_fold = 0\n",
    "BATCH_SIZE = 64\n",
    "# If optimizing Spearman, convert labels to ranks\n",
    "\n",
    "# --- 1) Prepare OOF meta-features ---\n",
    "# Initialize matrix for OOF predictions\n",
    "n_samples = len(full_dataset)\n",
    "oof_preds = np.zeros((n_samples, C), dtype=np.float32)\n",
    "# True labels (raw or rank)\n",
    "# importDataset returns a dict-like sample, so label is under key 'label'\n",
    "y_true = np.vstack([ full_dataset[i]['label'].cpu().numpy() for i in range(n_samples) ])\n",
    "y_meta = y_true\n",
    "\n",
    "# Build CV splitter (must match first stage splits)\n",
    "logo = LeaveOneGroupOut()\n",
    "image_latents = np.zeros((n_samples, 128), dtype=np.float32)\n",
    "\n",
    "# Loop over folds, load best model, predict on validation indices\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "for fold_id, (tr_idx, va_idx) in enumerate(\n",
    "        logo.split(X=np.zeros(n_samples), y=None, groups=slide_idx)):\n",
    "    # Load model\n",
    "    # if fold_id > start_fold:\n",
    "    #     print(f\"⏭️ Skipping fold {fold_id}\")\n",
    "    #     continue\n",
    "    ckpt_path = os.path.join(save_root, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    print(f\"Loading model from {ckpt_path}...\")\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = True\n",
    "    )\n",
    "\n",
    "    # 2) monkey‐patch 一个新的 head\n",
    "    net.decoder  = nn.Sequential(\n",
    "        nn.Linear(64+64, 256),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "        \n",
    "    )\n",
    "    net = net.to(device)    # Alternatively, if your model requires specific args, replace with:\n",
    "    # net = VisionMLP_MultiTask(tile_dim=64, subtile_dim=64, output_dim=35).to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.to(device).eval()\n",
    "    \n",
    "    # Predict on validation set\n",
    "    val_ds = Subset(full_dataset, va_idx)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    preds = []\n",
    "    latents = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            tiles    = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "\n",
    "            center = subtiles[:, 4].contiguous()\n",
    "            f_c = net.enc_center(center)\n",
    "            f_n = net.enc_neigh(subtiles)\n",
    "            fuse = torch.cat([f_c, f_n], dim=1)\n",
    "\n",
    "            output = net.decoder(fuse)\n",
    "\n",
    "            preds.append(output.cpu())\n",
    "            latents.append(fuse.cpu())  # ⬅️ 收集 latent vector\n",
    "\n",
    "    preds = torch.cat(preds, dim=0).numpy()    # (n_val, 35)\n",
    "    latents = torch.cat(latents, dim=0).numpy()  # (n_val, 128)\n",
    "\n",
    "    oof_preds[va_idx] = preds\n",
    "    image_latents[va_idx] = latents\n",
    "\n",
    "    print(f\"Fold {fold_id}: OOF preds shape {preds.shape}, Latent shape: {latents.shape}\")\n",
    "\n",
    "\n",
    "    \n",
    "with h5py.File(\"dataset/realign/filtered_dataset.h5\", \"r\") as f:\n",
    "    train_spots = f[\"spots/Train\"]\n",
    "    \n",
    "    train_spot_tables = {}\n",
    "    \n",
    "    for slide_name in train_spots.keys():\n",
    "        spot_array = np.array(train_spots[slide_name])\n",
    "        df = pd.DataFrame(spot_array)\n",
    "        df[\"slide_name\"] = slide_name\n",
    "        train_spot_tables[slide_name] = df\n",
    "        print(f\"✅ 已讀取 slide: {slide_name}\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 2: 合併所有 slide 的資料\n",
    "# -----------------------------------------------------\n",
    "all_train_spots_df = pd.concat(train_spot_tables.values(), ignore_index=True)\n",
    "# 提取 x, y\n",
    "xy = all_train_spots_df[[\"x\", \"y\"]].to_numpy()  # shape: (8348, 2)\n",
    "\n",
    "# 合併成新的 meta feature\n",
    "meta_features = np.concatenate([oof_preds, xy, image_latents], axis=1)\n",
    "# --- 2) Train LightGBM meta-model ---\n",
    "# Choose objective: regression on rank (for Spearman) or raw (for MSE)\n",
    "# 將 meta features 拆成訓練集與 early stopping 用的驗證集\n",
    "X_train, X_val, y_train, y_val = train_test_split(meta_features, y_meta, test_size=0.2, random_state=42)\n",
    "print(\"Meta feature shape:\", X_train.shape)\n",
    "print(\"Feature std (min/max):\", np.min(np.std(X_train, axis=0)), np.max(np.std(X_train, axis=0)))\n",
    "\n",
    "\n",
    "# # Base model\n",
    "# lgb_base = lgb.LGBMRegressor(\n",
    "#     objective='l2',\n",
    "#     metric='rmse',\n",
    "#     n_estimators=12000,\n",
    "#     max_depth=15,\n",
    "#     learning_rate=0.008,\n",
    "#     num_leaves=32,\n",
    "#     colsample_bytree=0.25\n",
    "# )\n",
    "import optuna\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define Optuna objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'device': 'gpu',                # ✅ GPU 支援\n",
    "        'gpu_platform_id': 0,\n",
    "        'gpu_device_id': 0,\n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.005, 0.1),\n",
    "        'max_depth': trial.suggest_int(\"max_depth\", 4, 15),\n",
    "        'num_leaves': trial.suggest_int(\"num_leaves\", 32, 256),\n",
    "        'min_data_in_leaf': trial.suggest_int(\"min_data_in_leaf\", 20, 100),\n",
    "        'colsample_bytree': trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float(\"reg_alpha\", 0, 1),\n",
    "        'reg_lambda': trial.suggest_float(\"reg_lambda\", 0, 1),\n",
    "        'n_estimators': 12000\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    multi_model = MultiOutputRegressor(model)\n",
    "    multi_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = multi_model.predict(X_val)\n",
    "    rmse = np.mean([\n",
    "        np.sqrt(mean_squared_error(y_val[:, i], y_pred[:, i]))\n",
    "        for i in range(y_val.shape[1])\n",
    "    ])\n",
    "\n",
    "\n",
    "    return rmse\n",
    "\n",
    "# Run optimization\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Use best params to train final models\n",
    "best_params = study.best_trial.params\n",
    "best_params['objective'] = 'l2'\n",
    "best_params['metric'] = 'rmse'\n",
    "best_params['verbosity'] = -1\n",
    "\n",
    "# Train final models with best parameters\n",
    "meta_model = MultiOutputRegressor(lgb.LGBMRegressor(**best_params))\n",
    "meta_model.estimators_ = []\n",
    "\n",
    "print(\"Training LightGBM on OOF meta-features with best Optuna params...\")\n",
    "for i in range(y_train.shape[1]):\n",
    "    print(f\"Training target {i}...\")\n",
    "    model = lgb.LGBMRegressor(**best_params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train[:, i],\n",
    "        eval_set=[(X_val, y_val[:, i])],\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=200),\n",
    "            log_evaluation(period=100)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    meta_model.estimators_.append(model)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(meta_model, os.path.join(save_root, 'meta_model.pkl'))\n",
    "# 保存模型\n",
    "\n",
    "\n",
    "# --- 3) Prepare test meta-features ---\n",
    "n_test = len(test_dataset)\n",
    "test_preds = []\n",
    "test_latents = []\n",
    "\n",
    "for fold_id in range(n_folds):\n",
    "    ckpt_path = os.path.join(save_root, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = True\n",
    "    )\n",
    "\n",
    "    net.decoder = nn.Sequential(\n",
    "        nn.Linear(64+64, 256),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "    )\n",
    "\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.eval()\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds = []\n",
    "    latents = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            tiles = batch['tile'].to(device)\n",
    "            subtiles = batch['subtiles'].to(device)\n",
    "\n",
    "            center = subtiles[:, 4].contiguous()\n",
    "            f_c = net.enc_center(center)\n",
    "            f_n = net.enc_neigh(subtiles)\n",
    "            fuse = torch.cat([f_c, f_n], dim=1)\n",
    "\n",
    "            out = net.decoder(fuse)\n",
    "\n",
    "            preds.append(out.cpu())\n",
    "            latents.append(fuse.cpu())  # image embedding (128D)\n",
    "\n",
    "    test_preds.append(torch.cat(preds, dim=0).numpy())      # shape: (n_test, 35)\n",
    "    test_latents.append(torch.cat(latents, dim=0).numpy())  # shape: (n_test, 128)\n",
    "\n",
    "# === Stack + Average ===\n",
    "test_preds = np.mean(np.stack(test_preds, axis=0), axis=0)      # (n_test, 35)\n",
    "test_latents = np.mean(np.stack(test_latents, axis=0), axis=0)  # (n_test, 128)\n",
    "\n",
    "with h5py.File(\"dataset/elucidata_ai_challenge_data.h5\", \"r\") as f:\n",
    "    test_spots = f[\"spots/Test\"]\n",
    "    spot_array = np.array(test_spots['S_7'])\n",
    "    df = pd.DataFrame(spot_array)\n",
    "\n",
    "xy = df[[\"x\", \"y\"]].to_numpy()  # shape: (n_test, 2)\n",
    "\n",
    "# 合併為最終 test meta features\n",
    "test_meta = np.concatenate([test_preds, xy, test_latents], axis=1)  # shape: (n_test, 35+2+128)\n",
    "\n",
    "\n",
    "\n",
    "final_preds = meta_model.predict(test_meta)\n",
    "\n",
    "# --- Save submission ---\n",
    "import h5py\n",
    "import pandas as pd\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spot_ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"]))\n",
    "sub = pd.DataFrame(final_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, 'ID', test_spot_ids.index)\n",
    "sub.to_csv(os.path.join(save_root, 'submission_stacked.csv'), index=False)\n",
    "print(\"✅ Saved stacked submission.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import lightgbm as lgb\n",
    "from scipy.stats import rankdata\n",
    "from python_scripts.import_data import importDataset\n",
    "from python_scripts.operate_model import predict\n",
    "\n",
    "# --- 配置: 只用哪些 fold 的结果来训练/预测 meta-model ---\n",
    "meta_folds = [0]  # 例如只用 fold0, fold2, fold4\n",
    "\n",
    "# 1) 准备 full_dataset, slide_idx, test_dataset 等\n",
    "full_dataset = importDataset(\n",
    "    grouped_data, model,\n",
    "    image_keys=['tile','subtiles'],\n",
    "    transform=lambda x: x\n",
    ")\n",
    "n_samples = len(full_dataset)\n",
    "C = 35  # 类别数\n",
    "\n",
    "# 2) 预留 oof_preds 和 fold_ids\n",
    "oof_preds    = np.zeros((n_samples, C), dtype=np.float32)\n",
    "oof_fold_ids = np.full(n_samples, -1, dtype=int)\n",
    "\n",
    "# 真标签\n",
    "y_true = np.vstack([ full_dataset[i]['label'].cpu().numpy() for i in range(n_samples) ])\n",
    "y_meta = y_true.copy()  # 不做 rank 时直接用 raw\n",
    "\n",
    "# 3) 生成 OOF 预测并记录 fold id\n",
    "logo = LeaveOneGroupOut()\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "for fold_id, (tr_idx, va_idx) in enumerate(\n",
    "        logo.split(X=np.zeros(n_samples), y=None, groups=slide_idx)):\n",
    "\n",
    "    # 如果当前 fold 不在我们想要的 meta_folds 列表里，就跳过\n",
    "    if fold_id not in meta_folds:\n",
    "        print(f\"⏭️ Skipping OOF for fold {fold_id}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n>>> Generating OOF for fold {fold_id}\")\n",
    "    ckpt_path = os.path.join(save_root, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = True\n",
    "    )\n",
    "\n",
    "    # 2) monkey‐patch 一个新的 head\n",
    "    net.decoder  = nn.Sequential(\n",
    "        nn.Linear(64+64, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "        \n",
    "    )\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.eval()\n",
    "\n",
    "    val_loader = DataLoader(Subset(full_dataset, va_idx), batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds = predict(net, val_loader, device)  # (n_val, C)\n",
    "\n",
    "    oof_preds[va_idx]    = preds\n",
    "    oof_fold_ids[va_idx] = fold_id\n",
    "\n",
    "    print(f\"  → Fold {fold_id} OOF preds shape: {preds.shape}\")\n",
    "# 4) 只选取 meta_folds 的行来训练 meta-model\n",
    "mask = np.isin(oof_fold_ids, meta_folds)\n",
    "X_meta = oof_preds[mask]\n",
    "y_meta_sub = y_meta[mask]\n",
    "\n",
    "print(f\"\\nTraining meta-model on folds {meta_folds}:\")\n",
    "print(f\"  使用样本数：{X_meta.shape[0]} / {n_samples}\")\n",
    "\n",
    "lgb_base = lgb.LGBMRegressor(\n",
    "    objective='regression',\n",
    "    learning_rate=0.001,\n",
    "    n_estimators=1000,\n",
    "    num_leaves=31,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    n_jobs=-1,\n",
    "    force_col_wise=True\n",
    ")\n",
    "meta_model = MultiOutputRegressor(lgb_base)\n",
    "meta_model.fit(X_meta, y_meta_sub)\n",
    "joblib.dump(meta_model, os.path.join(save_root, 'meta_model.pkl'))\n",
    "\n",
    "# 5) 准备 test_meta，只平均 meta_folds 中的预测\n",
    "n_folds = len([d for d in os.listdir(save_root) if d.startswith('fold')])\n",
    "n_test  = len(test_dataset)\n",
    "test_meta = np.zeros((n_test, C), dtype=np.float32)\n",
    "\n",
    "for fold_id in range(n_folds):\n",
    "    if fold_id not in meta_folds:\n",
    "        continue\n",
    "    ckpt_path = os.path.join(save_root, f\"fold{fold_id}\", \"best_model.pt\")\n",
    "    net = PretrainedEncoderRegressor(\n",
    "        ae_checkpoint=checkpoint_path,\n",
    "        ae_type=\"all\",\n",
    "        center_dim=64, neighbor_dim=64, hidden_dim=128,\n",
    "        tile_size=26, output_dim=35,\n",
    "        freeze_encoder = True\n",
    "    )\n",
    "\n",
    "    # 2) monkey‐patch 一个新的 head\n",
    "    net.decoder  = nn.Sequential(\n",
    "        nn.Linear(64+64, 128),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.1),\n",
    "        nn.Linear(64, 35)\n",
    "        \n",
    "    )\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "    net.eval()\n",
    "\n",
    "    loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    preds = predict(net, loader, device)\n",
    "    test_meta += preds\n",
    "\n",
    "# 平均时除以参与的 folds 数目\n",
    "test_meta /= len(meta_folds)\n",
    "\n",
    "# 6) 用 meta-model 做最终预测\n",
    "final_preds = meta_model.predict(test_meta)\n",
    "\n",
    "# --- Save submission ---\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spot_ids = pd.DataFrame(np.array(f[\"spots/Test\"][\"S_7\"]))\n",
    "\n",
    "sub = pd.DataFrame(final_preds, columns=[f\"C{i+1}\" for i in range(C)])\n",
    "sub.insert(0, 'ID', test_spot_ids.index)\n",
    "sub.to_csv(os.path.join(save_root, 'submission_stacked.csv'), index=False)\n",
    "print(\"✅ Saved stacked submission.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/j5s0yzcj34l3v043s7znkplc0000gn/T/ipykernel_23908/317847752.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(torch.load(ckpt, map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved fold 0 predictions to output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/submission_fold0.csv\n",
      "✅ Saved fold 1 predictions to output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/submission_fold1.csv\n",
      "✅ Saved fold 2 predictions to output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/submission_fold2.csv\n",
      "✅ Saved fold 3 predictions to output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/submission_fold3.csv\n",
      "✅ Saved fold 4 predictions to output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/submission_fold4.csv\n",
      "✅ Saved fold 5 predictions to output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/submission_fold5.csv\n",
      "✅ Saved rank‐ensemble submission to output_folder/rank-spot/realign/no_pretrain/3_encoder/filtered_directly_rank/k-fold/realign_all/Macenko_masked/submission_rank_ensemble.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import h5py\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 讀 test spot index\n",
    "with h5py.File(\"./dataset/elucidata_ai_challenge_data.h5\",\"r\") as f:\n",
    "    test_spots     = f[\"spots/Test\"]\n",
    "    test_spot_table= pd.DataFrame(np.array(test_spots['S_7']))\n",
    "\n",
    "fold_ckpts = sorted(glob.glob(os.path.join(trained_oof_model_folder, \"fold*\", \"best_model.pt\")))\n",
    "models = []\n",
    "for ckpt in fold_ckpts:\n",
    "    net = VisionMLP_MultiTask(tile_dim=tile_dim, subtile_dim=center_dim, output_dim=C)\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(ckpt, map_location=\"cpu\"))\n",
    "    net.to(device).eval()\n",
    "    models.append(net)\n",
    "\n",
    "all_fold_preds = []\n",
    "for fold_id, net in enumerate(models):\n",
    "    # 推論\n",
    "    with torch.no_grad():\n",
    "        preds = predict(net, test_loader, device)  # (N_test,35) numpy array\n",
    "\n",
    "    # 1) 存每一折的原始預測\n",
    "    df_fold = pd.DataFrame(preds, columns=[f\"C{i+1}\" for i in range(preds.shape[1])])\n",
    "    df_fold.insert(0, \"ID\", test_spot_table.index)\n",
    "    path_fold = os.path.join(trained_oof_model_folder, f\"submission_fold{fold_id}.csv\")\n",
    "    df_fold.to_csv(path_fold, index=False)\n",
    "    print(f\"✅ Saved fold {fold_id} predictions to {path_fold}\")\n",
    "\n",
    "    all_fold_preds.append(preds)\n",
    "\n",
    "# 2) 做 rank‐average ensemble\n",
    "all_fold_preds = np.stack(all_fold_preds, axis=0)       # (K, N_test, 35)\n",
    "ranks          = all_fold_preds.argsort(axis=2).argsort(axis=2).astype(float)\n",
    "mean_rank      = ranks.mean(axis=0)                    # (N_test,35)\n",
    "\n",
    "# 3) 存 final ensemble\n",
    "df_ens = pd.DataFrame(mean_rank, columns=[f\"C{i+1}\" for i in range(mean_rank.shape[1])])\n",
    "df_ens.insert(0, \"ID\", test_spot_table.index)\n",
    "path_ens = os.path.join(trained_oof_model_folder, \"submission_rank_ensemble.csv\")\n",
    "df_ens.to_csv(path_ens, index=False)\n",
    "print(f\"✅ Saved rank‐ensemble submission to {path_ens}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatialhackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
